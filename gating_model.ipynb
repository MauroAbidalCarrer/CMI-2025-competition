{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "332e7f37",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "21b91065",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import re\n",
    "import os\n",
    "import json \n",
    "import math\n",
    "import shutil\n",
    "import random\n",
    "import warnings\n",
    "from os.path import join\n",
    "from functools import partial\n",
    "from tqdm.notebook import tqdm\n",
    "from collections import defaultdict\n",
    "from operator import methodcaller\n",
    "from typing import Optional, Literal\n",
    "from typing import Optional, Literal, Iterator\n",
    "from itertools import pairwise, starmap, product\n",
    "\n",
    "import torch\n",
    "import optuna\n",
    "import kagglehub \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "from numpy import ndarray\n",
    "from torch import nn, Tensor\n",
    "from numpy.linalg import norm\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Optimizer\n",
    "from pandas import DataFrame as DF\n",
    "from optuna.trial import TrialState\n",
    "from sklearn.metrics import f1_score\n",
    "from optuna.pruners import BasePruner\n",
    "from optuna.exceptions import TrialPruned\n",
    "from torch.utils.data import TensorDataset\n",
    "from scipy.spatial.transform import Rotation\n",
    "import kaggle_evaluation.cmi_inference_server\n",
    "from torch.utils.data import DataLoader as DL\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from rich.progress import Progress, Task, track\n",
    "from sklearn.model_selection import train_test_split\n",
    "from numpy.lib.stride_tricks import sliding_window_view\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from torch.optim.lr_scheduler import ConstantLR, LRScheduler, _LRScheduler\n",
    "\n",
    "from config import *\n",
    "from model import mk_model\n",
    "from utils import seed_everything\n",
    "from preprocessing import get_meta_data\n",
    "from training import split_dataset, move_cmi_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f1783130",
   "metadata": {},
   "outputs": [],
   "source": [
    "GATING_INPUT_FEATURES = [\n",
    "    \"bin_mae\",\n",
    "    \"reg_mae\",\n",
    "    \"y_uncertainty\",\n",
    "    \"bin_uncertainty\",\n",
    "    \"reg_uncertainty\",\n",
    "    \"orient_uncertainty\",\n",
    "]\n",
    "GATING_MODEL_BATCH_SIZE = 256\n",
    "N_GATING_MODEL_EPOCHS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "de9365c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d68aa7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_data = get_meta_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df607b2",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "acbcacaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def record_model_outputs(model:nn.Module, data_loader:DL, device:torch.device) -> tuple[Tensor]:\n",
    "    data:list[tuple[Tensor]] = []\n",
    "    model = model.eval()\n",
    "    tof_and_thm_idx = np.concatenate((meta_data[\"tof_idx\"], meta_data[\"thm_idx\"]))\n",
    "    with torch.no_grad():\n",
    "        for x, *_ in data_loader:\n",
    "            x = x.to(device).clone()\n",
    "            x[:1024 // 2, tof_and_thm_idx] = 0.0\n",
    "            data.append(model(x))\n",
    "    data: tuple[Tensor] = tuple(map(torch.concat, zip(*data)))\n",
    "    return data\n",
    "\n",
    "def mk_gating_model_dataset(dataset: TensorDataset) -> TensorDataset:\n",
    "    device = torch.device(\"cuda\")\n",
    "    data_loader = DL(dataset, batch_size=1024, shuffle=False)\n",
    "    models_outputs: list[tuple[Tensor]] = []\n",
    "    for fold_idx in tqdm(range(N_FOLDS), total=N_FOLDS):\n",
    "        model = mk_model(device=device)\n",
    "        checkpoint = torch.load(\n",
    "            join(\n",
    "                \"models\",\n",
    "                f\"model_fold_{fold_idx}.pth\"\n",
    "            ),\n",
    "            map_location=device,\n",
    "            weights_only=True\n",
    "        )\n",
    "        model.load_state_dict(checkpoint)\n",
    "        models_outputs.append(record_model_outputs(model, data_loader, device))\n",
    "    models_outputs: tuple[Tensor] = tuple(map(partial(torch.stack, dim=1), zip(*models_outputs)))\n",
    "    tensors = (*models_outputs, *dataset.tensors[-2:], dataset.tensors[1])\n",
    "    \n",
    "    return TensorDataset(*tensors)\n",
    "\n",
    "def mk_gating_model_dataset_splits() -> dict[str, TensorDataset]:\n",
    "    cuda_splits = {k: move_cmi_dataset(dataset, torch.device(\"cuda\")) for k, (dataset, _) in split_dataset().items()}\n",
    "    return {k: mk_gating_model_dataset(dataset) for k, dataset in cuda_splits.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bc523faa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70a17f4c54244b2291d4e9fa96ba4edf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5de0f5884d54d5080d241e736ac7ad5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "849b4327b4134cdeaa34f21d5b94cb23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_splits = mk_gating_model_dataset_splits()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b930a7",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "63399999",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_gating_model(dataset: Dataset, gating_model: nn.Module) -> dict:\n",
    "    gating_model = gating_model.eval()\n",
    "    data_loader = DL(dataset, batch_size=1024, shuffle=False)\n",
    "    y_preds = []\n",
    "    y_trues = []\n",
    "    with torch.no_grad():\n",
    "        for *gating_inputs, y in data_loader:\n",
    "            y_preds.append(gating_model(*gating_inputs))\n",
    "            y_trues.append(y)\n",
    "    y_pred = torch.argmax(torch.concat(y_preds), dim=1).cpu().numpy()\n",
    "    y_true = torch.argmax(torch.concat(y_trues), dim=1).cpu().numpy()\n",
    "    model_is_true = y_pred == y_true\n",
    "    binary_true = np.isin(y_true, BFRB_INDICES).astype(int)\n",
    "    binary_pred = np.isin(y_pred, BFRB_INDICES).astype(int)\n",
    "    metrics = {\n",
    "        \"accuracy\": model_is_true.mean().item(),\n",
    "        \"binary_f1\": f1_score(binary_true, binary_pred),\n",
    "    }\n",
    "\n",
    "    # Collapse non-BFRB gestures into a single class\n",
    "    collapsed_true = np.where(\n",
    "        np.isin(y_true, BFRB_INDICES),\n",
    "        y_true,\n",
    "        len(BFRB_GESTURES)  # Single non-BFRB class\n",
    "    )\n",
    "    collapsed_pred = np.where(\n",
    "        np.isin(y_pred, BFRB_INDICES),\n",
    "        y_pred,\n",
    "        len(BFRB_GESTURES)  # Single non-BFRB class\n",
    "    )\n",
    "\n",
    "    # Macro F1 on collapsed classes\n",
    "    metrics[\"macro_f1\"] = f1_score(collapsed_true, collapsed_pred, average='macro')\n",
    "    metrics[\"final_metric\"] = (metrics[\"binary_f1\"] + metrics[\"macro_f1\"]) / 2\n",
    "\n",
    "    return metrics\n",
    "\n",
    "def train_model_on_single_epoch(data_loader: DL, gating_model: nn.Module, criterion: nn.Module, optimizer: Optimizer) -> dict:\n",
    "    metrics = defaultdict(float)\n",
    "    n_samples = 0\n",
    "    gating_model = gating_model.train()\n",
    "    for *gating_inputs, y_true in data_loader:\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = gating_model(*gating_inputs)\n",
    "        loss = criterion(y_pred, y_true)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        n_samples += gating_inputs[0].shape[0]\n",
    "        metrics[\"train_loss\"] += loss.item() * gating_inputs[0].shape[0]\n",
    "\n",
    "    metrics[\"train_loss\"] /= n_samples\n",
    "\n",
    "    return metrics\n",
    "\n",
    "def train_model_on_all_epochs(dataset: Dataset, gating_model: nn.Module) -> DF:\n",
    "    train_loader = DL(dataset, GATING_MODEL_BATCH_SIZE, shuffle=True)\n",
    "    optimizer = torch.optim.AdamW(gating_model.parameters())\n",
    "    metrics: list[dict] = []\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    for epoch in range(N_GATING_MODEL_EPOCHS):\n",
    "        train_metrics = train_model_on_single_epoch(train_loader, gating_model, criterion, optimizer)\n",
    "        eval_metrics = evaluate_gating_model(dataset, gating_model)\n",
    "        metrics.append({\"epoch\": epoch} | train_metrics | eval_metrics)\n",
    "\n",
    "    return DF.from_records(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "26048482",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeanGate(nn.Module):\n",
    "    def ___init__(self, device: torch.device):\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self,\n",
    "            y_preds: Tensor,\n",
    "            orient_preds: Tensor,\n",
    "            bin_demos_y_preds: Tensor,\n",
    "            reg_demos_y_preds: Tensor,\n",
    "            bin_demos_y_true: Tensor,\n",
    "            reg_demos_y_true: Tensor\n",
    "        ) -> Tensor:\n",
    "        return y_preds.mean(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b5872a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preds_uncertainty(y_preds: Tensor) -> Tensor:\n",
    "    \"\"\"\n",
    "    y_preds: Tensor[batch, n_folds, y_targets]\n",
    "    returns: Tensor[batch, n_folds]\n",
    "    \"\"\"\n",
    "    y_preds = torch.nn.functional.softmax(y_preds, dim=2)\n",
    "    clipped_preds = y_preds.clip(EPSILON, 1.0)\n",
    "    return  -((clipped_preds * torch.log(clipped_preds)).sum(dim=2))\n",
    "\n",
    "def mae(y_preds: Tensor, y_true: Tensor) -> Tensor:\n",
    "    \"\"\"\n",
    "    y_preds: Tensor[batch, n_folds, y_targets]\n",
    "    y_true:  Tensor[batch, y_targets]\n",
    "    returns: Tensor[batch, n_folds]\n",
    "    \"\"\"\n",
    "    return torch.abs(y_preds - y_true.unsqueeze(1)).mean(dim=2)\n",
    "\n",
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        hidden_size = 64\n",
    "        self.gate = nn.Sequential(\n",
    "            nn.LazyBatchNorm1d(),\n",
    "            nn.LazyLinear(hidden_size),\n",
    "            nn.ReLU(),\n",
    "            # nn.Dropout(0.2),\n",
    "            nn.LazyBatchNorm1d(),\n",
    "            nn.Linear(hidden_size, N_FOLDS),\n",
    "            # nn.Dropout(0.2),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(\n",
    "            self,\n",
    "            y_preds: Tensor,\n",
    "            orient_preds: Tensor,\n",
    "            bin_demos_y_preds: Tensor,\n",
    "            reg_demos_y_preds: Tensor,\n",
    "            bin_demos_y_true: Tensor,\n",
    "            reg_demos_y_true: Tensor\n",
    "        ) -> Tensor:      \n",
    "        \n",
    "        experts_preds_stats = torch.concatenate((\n",
    "                preds_uncertainty(y_preds),\n",
    "                preds_uncertainty(orient_preds),\n",
    "                preds_uncertainty(bin_demos_y_preds),\n",
    "                preds_uncertainty(reg_demos_y_preds),\n",
    "                mae(nn.functional.sigmoid(bin_demos_y_preds), bin_demos_y_true),\n",
    "                mae(reg_demos_y_preds, reg_demos_y_true),\n",
    "            ),\n",
    "            dim=1,\n",
    "        )\n",
    "        weights = self.gate(experts_preds_stats)\n",
    "        weighted_y_preds = torch.einsum(\"be, bet -> bt\", weights, y_preds)\n",
    "        y_pred = weighted_y_preds / weights.sum(dim=1, keepdim=True)\n",
    "\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "850e3986",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_eval_gating_model(dataset: Dataset, device: torch.device) -> tuple[nn.Module, DF]:\n",
    "    mean_gate_metrics = evaluate_gating_model(dataset, MeanGate())\n",
    "    print(\"mean_gate_metrics:\", mean_gate_metrics)\n",
    "    gating_model = LogisticRegression().to(device)\n",
    "    base_logistic_gate_metrics = evaluate_gating_model(dataset, gating_model)\n",
    "    print(\"base logistic_gate_metrics:\", base_logistic_gate_metrics)\n",
    "    training_metrics = train_model_on_all_epochs(dataset, gating_model)\n",
    "    print(\"trained logistic_gate_metrics:\", training_metrics.iloc[-1].to_dict())\n",
    "\n",
    "    return gating_model, training_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4a00594c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training gating model\n",
      "mean_gate_metrics: {'accuracy': 0.7279411764705882, 'binary_f1': 0.990234375, 'macro_f1': 0.6746485349575297, 'final_metric': 0.8324414549787649}\n",
      "base logistic_gate_metrics: {'accuracy': 0.7279411764705882, 'binary_f1': 0.990234375, 'macro_f1': 0.6744839037942917, 'final_metric': 0.8323591393971459}\n",
      "trained logistic_gate_metrics: {'epoch': 0.0, 'train_loss': 0.8737934477189008, 'accuracy': 0.7291666666666666, 'binary_f1': 0.990234375, 'macro_f1': 0.6762717051323475, 'final_metric': 0.8332530400661737}\n",
      "eval mixture of experts\n",
      "{'accuracy': 0.72870249017038, 'binary_f1': 0.99375, 'macro_f1': 0.6521481700629042, 'final_metric': 0.822949085031452}\n",
      "mean gate on validation split\n",
      "{'accuracy': 0.7260812581913499, 'binary_f1': 0.99375, 'macro_f1': 0.6501750333686362, 'final_metric': 0.8219625166843181}\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "print(\"training gating model\")\n",
    "gating_model, trainin_metrics = train_and_eval_gating_model(dataset_splits[\"gating_train\"], device)\n",
    "print(\"eval mixture of experts\")\n",
    "print(evaluate_gating_model(dataset_splits[\"validation\"], gating_model))\n",
    "print(\"mean gate on validation split\")\n",
    "print(evaluate_gating_model(dataset_splits[\"validation\"], MeanGate()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcff5eb1",
   "metadata": {},
   "source": [
    "## Upload model ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "da455967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.12), please consider upgrading to the latest version (0.3.13).\n",
      "Kaggle credentials successfully validated.\n",
      "Uploading Model https://www.kaggle.com/models/mauroabidalcarrer/cmi-model/pyTorch/single_model_architecture ...\n",
      "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.12), please consider upgrading to the latest version (0.3.13).\n",
      "Starting upload for file models/model_fold_15.pth\n",
      "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.12), please consider upgrading to the latest version (0.3.13).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading: 100%|██████████| 14.4M/14.4M [00:01<00:00, 8.44MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload successful: models/model_fold_15.pth (14MB)\n",
      "Starting upload for file models/model_fold_19.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.12), please consider upgrading to the latest version (0.3.13).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading: 100%|██████████| 14.4M/14.4M [00:01<00:00, 8.19MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload successful: models/model_fold_19.pth (14MB)\n",
      "Starting upload for file models/model_fold_6.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.12), please consider upgrading to the latest version (0.3.13).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading: 100%|██████████| 14.4M/14.4M [00:01<00:00, 8.15MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload successful: models/model_fold_6.pth (14MB)\n",
      "Starting upload for file models/model_fold_5.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.12), please consider upgrading to the latest version (0.3.13).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading: 100%|██████████| 14.4M/14.4M [00:01<00:00, 8.36MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload successful: models/model_fold_5.pth (14MB)\n",
      "Starting upload for file models/model_fold_16.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.12), please consider upgrading to the latest version (0.3.13).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading: 100%|██████████| 14.4M/14.4M [00:01<00:00, 8.40MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload successful: models/model_fold_16.pth (14MB)\n",
      "Starting upload for file models/model_fold_1.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.12), please consider upgrading to the latest version (0.3.13).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading: 100%|██████████| 14.4M/14.4M [00:01<00:00, 8.56MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload successful: models/model_fold_1.pth (14MB)\n",
      "Starting upload for file models/model_fold_8.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.12), please consider upgrading to the latest version (0.3.13).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading: 100%|██████████| 14.4M/14.4M [00:01<00:00, 8.34MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload successful: models/model_fold_8.pth (14MB)\n",
      "Starting upload for file models/model_fold_7.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.12), please consider upgrading to the latest version (0.3.13).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading: 100%|██████████| 14.4M/14.4M [00:01<00:00, 8.29MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload successful: models/model_fold_7.pth (14MB)\n",
      "Starting upload for file models/model_fold_10.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.12), please consider upgrading to the latest version (0.3.13).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading: 100%|██████████| 14.4M/14.4M [00:01<00:00, 8.37MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload successful: models/model_fold_10.pth (14MB)\n",
      "Starting upload for file models/model_fold_4.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.12), please consider upgrading to the latest version (0.3.13).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading: 100%|██████████| 14.4M/14.4M [00:01<00:00, 8.43MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload successful: models/model_fold_4.pth (14MB)\n",
      "Starting upload for file models/model_fold_0.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.12), please consider upgrading to the latest version (0.3.13).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading: 100%|██████████| 14.4M/14.4M [00:01<00:00, 7.79MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload successful: models/model_fold_0.pth (14MB)\n",
      "Starting upload for file models/model_fold_12.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.12), please consider upgrading to the latest version (0.3.13).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading: 100%|██████████| 14.4M/14.4M [00:01<00:00, 8.23MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload successful: models/model_fold_12.pth (14MB)\n",
      "Starting upload for file models/model_fold_3.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.12), please consider upgrading to the latest version (0.3.13).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading: 100%|██████████| 14.4M/14.4M [00:01<00:00, 8.35MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload successful: models/model_fold_3.pth (14MB)\n",
      "Starting upload for file models/model_fold_14.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.12), please consider upgrading to the latest version (0.3.13).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading: 100%|██████████| 14.4M/14.4M [00:01<00:00, 8.50MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload successful: models/model_fold_14.pth (14MB)\n",
      "Starting upload for file models/model_fold_2.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.12), please consider upgrading to the latest version (0.3.13).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading: 100%|██████████| 14.4M/14.4M [00:01<00:00, 8.42MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload successful: models/model_fold_2.pth (14MB)\n",
      "Starting upload for file models/model_fold_13.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.12), please consider upgrading to the latest version (0.3.13).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading: 100%|██████████| 14.4M/14.4M [00:01<00:00, 8.42MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload successful: models/model_fold_13.pth (14MB)\n",
      "Starting upload for file models/model_fold_11.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.12), please consider upgrading to the latest version (0.3.13).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading: 100%|██████████| 14.4M/14.4M [00:01<00:00, 8.53MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload successful: models/model_fold_11.pth (14MB)\n",
      "Starting upload for file models/model_fold_18.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.12), please consider upgrading to the latest version (0.3.13).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading: 100%|██████████| 14.4M/14.4M [00:01<00:00, 8.32MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload successful: models/model_fold_18.pth (14MB)\n",
      "Starting upload for file models/model_fold_17.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.12), please consider upgrading to the latest version (0.3.13).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading: 100%|██████████| 14.4M/14.4M [00:01<00:00, 8.23MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload successful: models/model_fold_17.pth (14MB)\n",
      "Starting upload for file models/model_fold_9.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.12), please consider upgrading to the latest version (0.3.13).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading: 100%|██████████| 14.4M/14.4M [00:01<00:00, 8.20MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload successful: models/model_fold_9.pth (14MB)\n",
      "Starting upload for file models/gating_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.12), please consider upgrading to the latest version (0.3.13).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading: 100%|██████████| 44.0k/44.0k [00:00<00:00, 87.7kB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload successful: models/gating_model.pth (43KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.12), please consider upgrading to the latest version (0.3.13).\n",
      "Your model instance version has been created.\n",
      "Files are being processed...\n",
      "See at: https://www.kaggle.com/models/mauroabidalcarrer/cmi-model/pyTorch/single_model_architecture\n"
     ]
    }
   ],
   "source": [
    "torch.save(gating_model.state_dict(), f\"models/gating_model.pth\")\n",
    "user_input = input(\"Upload model ensemble?: \").lower()\n",
    "if user_input == \"yes\":\n",
    "    kagglehub.model_upload(\n",
    "        handle=join(\n",
    "            kagglehub.whoami()[\"username\"],\n",
    "            MODEL_NAME,\n",
    "            \"pyTorch\",\n",
    "            MODEL_VARIATION,\n",
    "        ),\n",
    "        local_model_dir=\"models\",\n",
    "        version_notes=input(\"Please provide model version notes: \")\n",
    "    )\n",
    "elif user_input == \"no\":\n",
    "    print(\"Model has not been uploaded to kaggle.\")\n",
    "else:\n",
    "    print(\"User input was not understood, model has not been uploaded to kaggle.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CMI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
