{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "332e7f37",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21b91065",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import re\n",
    "import os\n",
    "import json \n",
    "import math\n",
    "import shutil\n",
    "import random\n",
    "import warnings\n",
    "from os.path import join\n",
    "from functools import partial\n",
    "from tqdm.notebook import tqdm\n",
    "from collections import defaultdict\n",
    "from operator import methodcaller\n",
    "from typing import Optional, Literal\n",
    "from typing import Optional, Literal, Iterator\n",
    "from itertools import pairwise, starmap, product\n",
    "\n",
    "import torch\n",
    "import optuna\n",
    "import kagglehub \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "from numpy import ndarray\n",
    "from torch import nn, Tensor\n",
    "from numpy.linalg import norm\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Optimizer\n",
    "from pandas import DataFrame as DF\n",
    "from optuna.trial import TrialState\n",
    "from sklearn.metrics import f1_score\n",
    "from optuna.pruners import BasePruner\n",
    "from optuna.exceptions import TrialPruned\n",
    "from torch.utils.data import TensorDataset\n",
    "from scipy.spatial.transform import Rotation\n",
    "import kaggle_evaluation.cmi_inference_server\n",
    "from torch.utils.data import DataLoader as DL\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from rich.progress import Progress, Task, track\n",
    "from sklearn.model_selection import train_test_split\n",
    "from numpy.lib.stride_tricks import sliding_window_view\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from torch.optim.lr_scheduler import ConstantLR, LRScheduler, _LRScheduler\n",
    "\n",
    "from config import *\n",
    "from model import mk_model\n",
    "from training import CMIDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1783130",
   "metadata": {},
   "outputs": [],
   "source": [
    "GATING_INPUT_FEATURES = [\n",
    "    \"bin_mae\",\n",
    "    \"reg_mae\",\n",
    "    \"y_uncertainty\",\n",
    "    \"bin_uncertainty\",\n",
    "    \"reg_uncertainty\",\n",
    "    \"orient_uncertainty\",\n",
    "]\n",
    "GATING_MODEL_BATCH_SIZE = 256\n",
    "N_GATING_MODEL_EPOCHS = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df607b2",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5942ef71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def record_target_feature(metrics:defaultdict, y_pred:Tensor, y_true:Tensor, preffix:str):\n",
    "    y_pred = y_pred.cpu().numpy()\n",
    "    y_true = y_true.cpu().numpy()\n",
    "    for target_col_idx in range(y_pred.shape[1]):\n",
    "        metrics[preffix + \"_pred_\" + str(target_col_idx)].append(y_pred[:, target_col_idx])\n",
    "        metrics[preffix + \"_true_\" + str(target_col_idx)].append(y_true[:, target_col_idx])\n",
    "\n",
    "def get_perf_and_seq_id(model:nn.Module, data_loader:DL, device:torch.device, seq_meta_data:DF) -> DF:\n",
    "    metrics:dict[list[ndarray]] = defaultdict(list)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch_x, batch_y, batch_orient_y, batch_bin_demos_y, batch_reg_demos_y, idx in data_loader:\n",
    "            batch_x = batch_x.to(device).clone()\n",
    "            batch_y = batch_y.to(device)\n",
    "\n",
    "            outputs, orient_outputs, bin_demos_output, reg_demos_output = model(batch_x)\n",
    "            losses = nn.functional.cross_entropy(\n",
    "                outputs,\n",
    "                batch_y,\n",
    "                label_smoothing=LABEL_SMOOTHING,\n",
    "                reduction=\"none\",\n",
    "            )\n",
    "            orient_losses = nn.functional.cross_entropy(\n",
    "                orient_outputs,\n",
    "                batch_orient_y,\n",
    "                label_smoothing=LABEL_SMOOTHING,\n",
    "                reduction=\"none\",\n",
    "            )\n",
    "            bin_demos_losses = nn.functional.binary_cross_entropy_with_logits(\n",
    "                bin_demos_output,\n",
    "                batch_bin_demos_y,\n",
    "                # label_smoothing=LABEL_SMOOTHING,\n",
    "                reduction=\"none\",\n",
    "            ).cpu().numpy()\n",
    "            reg_demos_losses = nn.functional.mse_loss(reg_demos_output, batch_reg_demos_y, reduction=\"none\").cpu().numpy()\n",
    "            metrics[\"losses\"].append(losses.cpu().numpy())\n",
    "            metrics[\"orient_losses\"].append(orient_losses.cpu().numpy())\n",
    "            record_target_feature(metrics, outputs, batch_y, \"y\")\n",
    "            record_target_feature(metrics, orient_outputs, batch_orient_y, \"orient\")\n",
    "            record_target_feature(metrics, bin_demos_output, batch_bin_demos_y, \"bin\")\n",
    "            record_target_feature(metrics, batch_reg_demos_y, reg_demos_output, \"reg\")\n",
    "            metrics[\"sequence_id\"].append(seq_meta_data[\"sequence_id\"].iloc[idx].values)\n",
    "\n",
    "    metrics = {k: np.concat(v) for k, v in metrics.items()}\n",
    "\n",
    "    return DF(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "acbcacaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPSILON = 1e-12\n",
    "\n",
    "def preds_uncertainty(df:DF, task_preffix:str) -> pd.Series:\n",
    "    preds = df.filter(regex=f\"{task_preffix}_pred_*\", axis=\"columns\")\n",
    "    clipped_preds = preds.clip(EPSILON, 1.0)\n",
    "    df[task_preffix + \"_uncertainty\"] = -((clipped_preds * np.log(clipped_preds)).sum(axis=1))\n",
    "    return df\n",
    "\n",
    "def mae(df:DF, task_preffix:str) -> DF:\n",
    "    df_pred = df.filter(regex=f\"{task_preffix}_pred_*\", axis=\"columns\")\n",
    "    df_true = df.filter(regex=f\"{task_preffix}_true_*\", axis=\"columns\")\n",
    "    df[task_preffix + \"_mae\"] = np.abs(df_pred.values - df_true.values).mean(axis=1)\n",
    "\n",
    "    return df\n",
    "\n",
    "def post_process_df(df:DF) -> DF:\n",
    "    return (\n",
    "        df\n",
    "        .pipe(preds_uncertainty, \"y\")\n",
    "        .pipe(preds_uncertainty, \"orient\")\n",
    "        .pipe(preds_uncertainty, \"bin\")\n",
    "        .pipe(preds_uncertainty, \"reg\")\n",
    "        .pipe(mae, \"y\")\n",
    "        .pipe(mae, \"orient\")\n",
    "        .pipe(mae, \"bin\")\n",
    "        .pipe(mae, \"reg\")\n",
    "    )\n",
    "\n",
    "def record_models_outputs() -> DF:\n",
    "    device = torch.device(\"cuda\")\n",
    "    dataset = CMIDataset(device)\n",
    "    data_loader = DL(dataset, batch_size=1024, shuffle=False)\n",
    "    seq_meta_data = pd.read_parquet(\"preprocessed_dataset/sequences_meta_data.parquet\")\n",
    "    dfs = []\n",
    "    for fold_idx in tqdm(range(N_FOLDS), total=N_FOLDS):\n",
    "        model = mk_model(device=device)\n",
    "        checkpoint = torch.load(\n",
    "            join(\n",
    "                \"models\",\n",
    "                f\"model_fold_{fold_idx}.pth\"\n",
    "            ),\n",
    "            map_location=device,\n",
    "            weights_only=True\n",
    "        )\n",
    "        model.load_state_dict(checkpoint)\n",
    "        model.eval()\n",
    "        df = get_perf_and_seq_id(model, data_loader, device, seq_meta_data)\n",
    "        dfs.append(df.assign(fold=fold_idx))\n",
    "\n",
    "    return pd.concat(dfs).pipe(post_process_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "07101223",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ecf58f689134d5d9741d4b00b80b688",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = record_models_outputs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b930a7",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39500692",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"10\" halign=\"left\">bin_mae</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"10\" halign=\"left\">orient_uncertainty</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fold</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.373200</td>\n",
       "      <td>3.263342</td>\n",
       "      <td>4.640149</td>\n",
       "      <td>4.598254</td>\n",
       "      <td>4.851898</td>\n",
       "      <td>5.196218</td>\n",
       "      <td>4.149457</td>\n",
       "      <td>4.164123</td>\n",
       "      <td>4.707287</td>\n",
       "      <td>3.074975</td>\n",
       "      <td>...</td>\n",
       "      <td>8.289306e-11</td>\n",
       "      <td>8.289306e-11</td>\n",
       "      <td>8.289306e-11</td>\n",
       "      <td>8.289306e-11</td>\n",
       "      <td>8.289306e-11</td>\n",
       "      <td>8.289306e-11</td>\n",
       "      <td>8.289306e-11</td>\n",
       "      <td>8.289306e-11</td>\n",
       "      <td>8.289306e-11</td>\n",
       "      <td>8.289306e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.369648</td>\n",
       "      <td>6.881545</td>\n",
       "      <td>9.064594</td>\n",
       "      <td>7.586702</td>\n",
       "      <td>7.586257</td>\n",
       "      <td>7.663782</td>\n",
       "      <td>7.625151</td>\n",
       "      <td>8.253765</td>\n",
       "      <td>8.368605</td>\n",
       "      <td>8.049928</td>\n",
       "      <td>...</td>\n",
       "      <td>8.289306e-11</td>\n",
       "      <td>8.289306e-11</td>\n",
       "      <td>8.289306e-11</td>\n",
       "      <td>8.289306e-11</td>\n",
       "      <td>8.289306e-11</td>\n",
       "      <td>8.289306e-11</td>\n",
       "      <td>8.289306e-11</td>\n",
       "      <td>8.289306e-11</td>\n",
       "      <td>8.289306e-11</td>\n",
       "      <td>8.289306e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.297356</td>\n",
       "      <td>9.460062</td>\n",
       "      <td>5.012723</td>\n",
       "      <td>5.532870</td>\n",
       "      <td>6.969646</td>\n",
       "      <td>8.566780</td>\n",
       "      <td>7.147378</td>\n",
       "      <td>8.186001</td>\n",
       "      <td>8.710774</td>\n",
       "      <td>5.342514</td>\n",
       "      <td>...</td>\n",
       "      <td>8.289306e-11</td>\n",
       "      <td>8.289306e-11</td>\n",
       "      <td>8.289306e-11</td>\n",
       "      <td>8.289306e-11</td>\n",
       "      <td>8.289306e-11</td>\n",
       "      <td>8.289306e-11</td>\n",
       "      <td>8.289306e-11</td>\n",
       "      <td>8.289306e-11</td>\n",
       "      <td>8.289306e-11</td>\n",
       "      <td>8.289306e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.853631</td>\n",
       "      <td>6.073956</td>\n",
       "      <td>5.834551</td>\n",
       "      <td>7.092682</td>\n",
       "      <td>5.035452</td>\n",
       "      <td>5.440889</td>\n",
       "      <td>6.324386</td>\n",
       "      <td>5.682080</td>\n",
       "      <td>5.922688</td>\n",
       "      <td>4.963815</td>\n",
       "      <td>...</td>\n",
       "      <td>8.289306e-11</td>\n",
       "      <td>8.289306e-11</td>\n",
       "      <td>8.289306e-11</td>\n",
       "      <td>8.289306e-11</td>\n",
       "      <td>8.289306e-11</td>\n",
       "      <td>8.289306e-11</td>\n",
       "      <td>8.289306e-11</td>\n",
       "      <td>8.289306e-11</td>\n",
       "      <td>8.289306e-11</td>\n",
       "      <td>8.289306e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.361362</td>\n",
       "      <td>6.090506</td>\n",
       "      <td>6.644010</td>\n",
       "      <td>4.834425</td>\n",
       "      <td>6.041402</td>\n",
       "      <td>5.543854</td>\n",
       "      <td>4.901386</td>\n",
       "      <td>8.600010</td>\n",
       "      <td>7.591352</td>\n",
       "      <td>7.141142</td>\n",
       "      <td>...</td>\n",
       "      <td>8.289306e-11</td>\n",
       "      <td>8.289306e-11</td>\n",
       "      <td>8.289306e-11</td>\n",
       "      <td>2.628955e-01</td>\n",
       "      <td>8.289306e-11</td>\n",
       "      <td>8.289306e-11</td>\n",
       "      <td>8.289306e-11</td>\n",
       "      <td>8.289306e-11</td>\n",
       "      <td>8.289306e-11</td>\n",
       "      <td>3.664069e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8146</th>\n",
       "      <td>3.854278</td>\n",
       "      <td>4.744507</td>\n",
       "      <td>4.921330</td>\n",
       "      <td>6.221528</td>\n",
       "      <td>5.334171</td>\n",
       "      <td>5.877177</td>\n",
       "      <td>3.079997</td>\n",
       "      <td>5.552984</td>\n",
       "      <td>4.114785</td>\n",
       "      <td>4.454160</td>\n",
       "      <td>...</td>\n",
       "      <td>8.289306e-11</td>\n",
       "      <td>8.289306e-11</td>\n",
       "      <td>8.289306e-11</td>\n",
       "      <td>8.289306e-11</td>\n",
       "      <td>8.289306e-11</td>\n",
       "      <td>8.289306e-11</td>\n",
       "      <td>8.289306e-11</td>\n",
       "      <td>8.289306e-11</td>\n",
       "      <td>8.289306e-11</td>\n",
       "      <td>8.289306e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8147</th>\n",
       "      <td>5.839823</td>\n",
       "      <td>4.647733</td>\n",
       "      <td>5.976115</td>\n",
       "      <td>4.286340</td>\n",
       "      <td>5.743880</td>\n",
       "      <td>4.078864</td>\n",
       "      <td>5.254677</td>\n",
       "      <td>3.685849</td>\n",
       "      <td>5.469068</td>\n",
       "      <td>3.769079</td>\n",
       "      <td>...</td>\n",
       "      <td>8.289306e-11</td>\n",
       "      <td>8.289306e-11</td>\n",
       "      <td>8.289306e-11</td>\n",
       "      <td>8.289306e-11</td>\n",
       "      <td>8.289306e-11</td>\n",
       "      <td>8.289306e-11</td>\n",
       "      <td>8.289306e-11</td>\n",
       "      <td>8.289306e-11</td>\n",
       "      <td>8.289306e-11</td>\n",
       "      <td>8.289306e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8148</th>\n",
       "      <td>4.513684</td>\n",
       "      <td>4.714145</td>\n",
       "      <td>9.269878</td>\n",
       "      <td>4.908830</td>\n",
       "      <td>6.493989</td>\n",
       "      <td>5.337626</td>\n",
       "      <td>7.587003</td>\n",
       "      <td>9.525738</td>\n",
       "      <td>6.214049</td>\n",
       "      <td>5.937212</td>\n",
       "      <td>...</td>\n",
       "      <td>8.289306e-11</td>\n",
       "      <td>8.289306e-11</td>\n",
       "      <td>8.289306e-11</td>\n",
       "      <td>8.289306e-11</td>\n",
       "      <td>8.289306e-11</td>\n",
       "      <td>8.289306e-11</td>\n",
       "      <td>8.289306e-11</td>\n",
       "      <td>8.289306e-11</td>\n",
       "      <td>8.289306e-11</td>\n",
       "      <td>8.289306e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8149</th>\n",
       "      <td>4.107200</td>\n",
       "      <td>5.895021</td>\n",
       "      <td>6.839435</td>\n",
       "      <td>5.656706</td>\n",
       "      <td>4.276178</td>\n",
       "      <td>4.535508</td>\n",
       "      <td>5.213759</td>\n",
       "      <td>5.066491</td>\n",
       "      <td>5.985665</td>\n",
       "      <td>4.973286</td>\n",
       "      <td>...</td>\n",
       "      <td>8.289306e-11</td>\n",
       "      <td>8.289306e-11</td>\n",
       "      <td>8.289306e-11</td>\n",
       "      <td>8.289306e-11</td>\n",
       "      <td>8.289306e-11</td>\n",
       "      <td>8.289306e-11</td>\n",
       "      <td>8.289306e-11</td>\n",
       "      <td>8.289306e-11</td>\n",
       "      <td>8.289306e-11</td>\n",
       "      <td>8.289306e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8150</th>\n",
       "      <td>5.733348</td>\n",
       "      <td>6.049707</td>\n",
       "      <td>8.428114</td>\n",
       "      <td>6.143384</td>\n",
       "      <td>4.578329</td>\n",
       "      <td>5.866724</td>\n",
       "      <td>5.679269</td>\n",
       "      <td>5.547221</td>\n",
       "      <td>5.740637</td>\n",
       "      <td>5.279655</td>\n",
       "      <td>...</td>\n",
       "      <td>8.289306e-11</td>\n",
       "      <td>8.289306e-11</td>\n",
       "      <td>8.289306e-11</td>\n",
       "      <td>3.136526e-01</td>\n",
       "      <td>8.289306e-11</td>\n",
       "      <td>8.289306e-11</td>\n",
       "      <td>8.289306e-11</td>\n",
       "      <td>8.289306e-11</td>\n",
       "      <td>8.289306e-11</td>\n",
       "      <td>8.289306e-11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8151 rows Ã— 120 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       bin_mae                                                              \\\n",
       "fold        0         1         2         3         4         5         6    \n",
       "0     5.373200  3.263342  4.640149  4.598254  4.851898  5.196218  4.149457   \n",
       "1     6.369648  6.881545  9.064594  7.586702  7.586257  7.663782  7.625151   \n",
       "2     8.297356  9.460062  5.012723  5.532870  6.969646  8.566780  7.147378   \n",
       "3     5.853631  6.073956  5.834551  7.092682  5.035452  5.440889  6.324386   \n",
       "4     6.361362  6.090506  6.644010  4.834425  6.041402  5.543854  4.901386   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "8146  3.854278  4.744507  4.921330  6.221528  5.334171  5.877177  3.079997   \n",
       "8147  5.839823  4.647733  5.976115  4.286340  5.743880  4.078864  5.254677   \n",
       "8148  4.513684  4.714145  9.269878  4.908830  6.493989  5.337626  7.587003   \n",
       "8149  4.107200  5.895021  6.839435  5.656706  4.276178  4.535508  5.213759   \n",
       "8150  5.733348  6.049707  8.428114  6.143384  4.578329  5.866724  5.679269   \n",
       "\n",
       "                                    ... orient_uncertainty                \\\n",
       "fold        7         8         9   ...                 10            11   \n",
       "0     4.164123  4.707287  3.074975  ...       8.289306e-11  8.289306e-11   \n",
       "1     8.253765  8.368605  8.049928  ...       8.289306e-11  8.289306e-11   \n",
       "2     8.186001  8.710774  5.342514  ...       8.289306e-11  8.289306e-11   \n",
       "3     5.682080  5.922688  4.963815  ...       8.289306e-11  8.289306e-11   \n",
       "4     8.600010  7.591352  7.141142  ...       8.289306e-11  8.289306e-11   \n",
       "...        ...       ...       ...  ...                ...           ...   \n",
       "8146  5.552984  4.114785  4.454160  ...       8.289306e-11  8.289306e-11   \n",
       "8147  3.685849  5.469068  3.769079  ...       8.289306e-11  8.289306e-11   \n",
       "8148  9.525738  6.214049  5.937212  ...       8.289306e-11  8.289306e-11   \n",
       "8149  5.066491  5.985665  4.973286  ...       8.289306e-11  8.289306e-11   \n",
       "8150  5.547221  5.740637  5.279655  ...       8.289306e-11  8.289306e-11   \n",
       "\n",
       "                                                                            \\\n",
       "fold            12            13            14            15            16   \n",
       "0     8.289306e-11  8.289306e-11  8.289306e-11  8.289306e-11  8.289306e-11   \n",
       "1     8.289306e-11  8.289306e-11  8.289306e-11  8.289306e-11  8.289306e-11   \n",
       "2     8.289306e-11  8.289306e-11  8.289306e-11  8.289306e-11  8.289306e-11   \n",
       "3     8.289306e-11  8.289306e-11  8.289306e-11  8.289306e-11  8.289306e-11   \n",
       "4     8.289306e-11  2.628955e-01  8.289306e-11  8.289306e-11  8.289306e-11   \n",
       "...            ...           ...           ...           ...           ...   \n",
       "8146  8.289306e-11  8.289306e-11  8.289306e-11  8.289306e-11  8.289306e-11   \n",
       "8147  8.289306e-11  8.289306e-11  8.289306e-11  8.289306e-11  8.289306e-11   \n",
       "8148  8.289306e-11  8.289306e-11  8.289306e-11  8.289306e-11  8.289306e-11   \n",
       "8149  8.289306e-11  8.289306e-11  8.289306e-11  8.289306e-11  8.289306e-11   \n",
       "8150  8.289306e-11  3.136526e-01  8.289306e-11  8.289306e-11  8.289306e-11   \n",
       "\n",
       "                                                \n",
       "fold            17            18            19  \n",
       "0     8.289306e-11  8.289306e-11  8.289306e-11  \n",
       "1     8.289306e-11  8.289306e-11  8.289306e-11  \n",
       "2     8.289306e-11  8.289306e-11  8.289306e-11  \n",
       "3     8.289306e-11  8.289306e-11  8.289306e-11  \n",
       "4     8.289306e-11  8.289306e-11  3.664069e-01  \n",
       "...            ...           ...           ...  \n",
       "8146  8.289306e-11  8.289306e-11  8.289306e-11  \n",
       "8147  8.289306e-11  8.289306e-11  8.289306e-11  \n",
       "8148  8.289306e-11  8.289306e-11  8.289306e-11  \n",
       "8149  8.289306e-11  8.289306e-11  8.289306e-11  \n",
       "8150  8.289306e-11  8.289306e-11  8.289306e-11  \n",
       "\n",
       "[8151 rows x 120 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_gating_features(df:DF) -> ndarray:\n",
    "    return (\n",
    "        df\n",
    "        .loc[:, GATING_INPUT_FEATURES + [\"fold\"]]\n",
    "        .pivot(columns=\"fold\")\n",
    "        .values\n",
    "    )\n",
    "\n",
    "def get_experts_outputs(df:DF) -> ndarray:\n",
    "    return (\n",
    "        df\n",
    "        .filter(regex=r\"^y_pred_|^fold$\")\n",
    "        .pivot(columns=\"fold\")\n",
    "        .values\n",
    "        .reshape(-1, N_FOLDS, N_TARGETS)\n",
    "    )\n",
    "\n",
    "def get_gating_targets(df:DF) -> ndarray:\n",
    "    return (\n",
    "        df\n",
    "        .query(\"fold == 0\")\n",
    "        .filter(regex=\"y_true*\")\n",
    "        .values\n",
    "    )\n",
    "\n",
    "class GatingDataset(TensorDataset):\n",
    "    def __init__(self, df: DF, device: torch.device):\n",
    "        super().__init__(\n",
    "            torch.from_numpy(get_gating_features(df)).to(device),\n",
    "            torch.from_numpy(get_experts_outputs(df)).to(device),\n",
    "            torch.from_numpy(get_gating_targets(df)).to(device),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63399999",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_gating_model(dataset: Dataset, gating_model: nn.Module) -> dict:\n",
    "    gating_model = gating_model.eval()\n",
    "    data_loader = DL(dataset, batch_size=1024, shuffle=False)\n",
    "    y_pred = []\n",
    "    with torch.no_grad():\n",
    "        for x, sub_y_preds, _ in data_loader:\n",
    "            weights = gating_model(x)\n",
    "            y_pred.append(None)#sum(weights * input) / sum(weights))\n",
    "    \n",
    "    y_pred = torch.argmax(torch.concat(y_pred), dim=1)\n",
    "    y_true = torch.argmax(dataset.tensors[2], dim=1)\n",
    "    metrics = {\n",
    "        \"accuracy\": (y_pred == y_true).mean(),\n",
    "    }\n",
    "\n",
    "    return metrics\n",
    "\n",
    "def train_model_on_single_epoch(data_loader: DL, gating_model: nn.Module, criterion: nn.Module, optimizer: Optimizer) -> dict:\n",
    "    metrics = defaultdict(float)\n",
    "    n_samples = 0\n",
    "    gating_model = gating_model.train()\n",
    "    for x, sub_y_preds, y_true in data_loader:\n",
    "        optimizer.zero_grad()\n",
    "        weights = gating_model(x)\n",
    "        y_pred = None#sum(weights * input) / sum(weights))\n",
    "        loss = criterion(y_pred, y_true)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        n_samples += x.shape[0]\n",
    "        metrics[\"train_loss\"] += loss.item() * x.shape[0]\n",
    "\n",
    "    metrics[\"train_loss\"] /= n_samples\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "def train_model_on_all_epochs(dataset: Dataset, gating_model: nn.Module) -> DF:\n",
    "    train_loader = DL(dataset, GATING_MODEL_BATCH_SIZE, shuffle=True)\n",
    "    metrics: list[dict] = []\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    for epoch in range(N_GATING_MODEL_EPOCHS):\n",
    "        train_metrics = train_model_on_single_epoch(train_loader, gating_model, criterion)\n",
    "        eval_metrics = evaluate_gating_model(dataset, gating_model)\n",
    "        metrics[-1] = {\"epoch\": epoch} | train_metrics | eval_metrics\n",
    "\n",
    "    return DF.from_records(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5872a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeanGate(nn.Module):\n",
    "    def forward(self, experts_preds: Tensor) -> Tensor:\n",
    "        return experts_preds.mean(dim=1)\n",
    "    \n",
    "class LogisticRegression(nn.Sequential):\n",
    "    def __init__(self):\n",
    "        super().__init__(\n",
    "            nn.LazyLinear(N_TARGETS),\n",
    "            nn.Sigmoid(),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850e3986",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "dataset = GatingDataset(df, device)\n",
    "mean_gate_metrics = evaluate_gating_model(dataset, MeanGate())\n",
    "print(\"mean_gate_metrics:\", mean_gate_metrics)\n",
    "logisticGate = LogisticRegression()\n",
    "base_logistic_gate_metrics = evaluate_gating_model(dataset, logisticGate)\n",
    "print(\"base logistic_gate_metrics:\", base_logistic_gate_metrics)\n",
    "training_metrics = train_model_on_all_epochs(dataset, base_logistic_gate_metrics)\n",
    "print(\"trained logistic_gate_metrics:\", base_logistic_gate_metrics.iloc[-1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CMI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
