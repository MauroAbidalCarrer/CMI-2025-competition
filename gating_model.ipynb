{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "332e7f37",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21b91065",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import re\n",
    "import os\n",
    "import json \n",
    "import math\n",
    "import shutil\n",
    "import random\n",
    "import warnings\n",
    "from os.path import join\n",
    "from functools import partial\n",
    "from tqdm.notebook import tqdm\n",
    "from collections import defaultdict\n",
    "from operator import methodcaller\n",
    "from typing import Optional, Literal\n",
    "from typing import Optional, Literal, Iterator\n",
    "from itertools import pairwise, starmap, product\n",
    "\n",
    "import torch\n",
    "import optuna\n",
    "import kagglehub \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "from numpy import ndarray\n",
    "from torch import nn, Tensor\n",
    "from numpy.linalg import norm\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Optimizer\n",
    "from pandas import DataFrame as DF\n",
    "from optuna.trial import TrialState\n",
    "from sklearn.metrics import f1_score\n",
    "from optuna.pruners import BasePruner\n",
    "from optuna.exceptions import TrialPruned\n",
    "from torch.utils.data import TensorDataset\n",
    "from scipy.spatial.transform import Rotation\n",
    "import kaggle_evaluation.cmi_inference_server\n",
    "from torch.utils.data import DataLoader as DL\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from rich.progress import Progress, Task, track\n",
    "from sklearn.model_selection import train_test_split\n",
    "from numpy.lib.stride_tricks import sliding_window_view\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from torch.optim.lr_scheduler import ConstantLR, LRScheduler, _LRScheduler\n",
    "\n",
    "from config import *\n",
    "from model import mk_model\n",
    "from training import CMIDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1783130",
   "metadata": {},
   "outputs": [],
   "source": [
    "GATING_INPUT_FEATURES = [\n",
    "    \"bin_mae\",\n",
    "    \"reg_mae\",\n",
    "    \"y_uncertainty\",\n",
    "    \"bin_uncertainty\",\n",
    "    \"reg_uncertainty\",\n",
    "    \"orient_uncertainty\",\n",
    "]\n",
    "GATING_MODEL_BATCH_SIZE = 256\n",
    "N_GATING_MODEL_EPOCHS = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df607b2",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5942ef71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def record_target_feature(metrics:defaultdict, y_pred:Tensor, y_true:Tensor, preffix:str):\n",
    "    y_pred = y_pred.cpu().numpy()\n",
    "    y_true = y_true.cpu().numpy()\n",
    "    for target_col_idx in range(y_pred.shape[1]):\n",
    "        metrics[preffix + \"_pred_\" + str(target_col_idx)].append(y_pred[:, target_col_idx])\n",
    "        metrics[preffix + \"_true_\" + str(target_col_idx)].append(y_true[:, target_col_idx])\n",
    "\n",
    "def get_perf_and_seq_id(model:nn.Module, data_loader:DL, device:torch.device, seq_meta_data:DF) -> DF:\n",
    "    metrics:dict[list[ndarray]] = defaultdict(list)\n",
    "    model = model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch_x, batch_y, batch_orient_y, batch_bin_demos_y, batch_reg_demos_y, idx in data_loader:\n",
    "            batch_x = batch_x.to(device).clone()\n",
    "            batch_y = batch_y.to(device)\n",
    "\n",
    "            outputs, orient_outputs, bin_demos_output, reg_demos_output = model(batch_x)\n",
    "            losses = nn.functional.cross_entropy(\n",
    "                outputs,\n",
    "                batch_y,\n",
    "                label_smoothing=LABEL_SMOOTHING,\n",
    "                reduction=\"none\",\n",
    "            )\n",
    "            orient_losses = nn.functional.cross_entropy(\n",
    "                orient_outputs,\n",
    "                batch_orient_y,\n",
    "                label_smoothing=LABEL_SMOOTHING,\n",
    "                reduction=\"none\",\n",
    "            )\n",
    "            bin_demos_losses = nn.functional.binary_cross_entropy_with_logits(\n",
    "                bin_demos_output,\n",
    "                batch_bin_demos_y,\n",
    "                # label_smoothing=LABEL_SMOOTHING,\n",
    "                reduction=\"none\",\n",
    "            ).cpu().numpy()\n",
    "            reg_demos_losses = nn.functional.mse_loss(reg_demos_output, batch_reg_demos_y, reduction=\"none\").cpu().numpy()\n",
    "            metrics[\"losses\"].append(losses.cpu().numpy())\n",
    "            metrics[\"orient_losses\"].append(orient_losses.cpu().numpy())\n",
    "            record_target_feature(metrics, outputs, batch_y, \"y\")\n",
    "            record_target_feature(metrics, orient_outputs, batch_orient_y, \"orient\")\n",
    "            record_target_feature(metrics, bin_demos_output, batch_bin_demos_y, \"bin\")\n",
    "            record_target_feature(metrics, batch_reg_demos_y, reg_demos_output, \"reg\")\n",
    "            metrics[\"sequence_id\"].append(seq_meta_data[\"sequence_id\"].iloc[idx].values)\n",
    "\n",
    "    metrics = {k: np.concat(v) for k, v in metrics.items()}\n",
    "\n",
    "    return DF(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "acbcacaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPSILON = 1e-12\n",
    "\n",
    "def preds_uncertainty(df:DF, task_preffix:str) -> pd.Series:\n",
    "    preds = df.filter(regex=f\"{task_preffix}_pred_*\", axis=\"columns\")\n",
    "    clipped_preds = preds.clip(EPSILON, 1.0)\n",
    "    df[task_preffix + \"_uncertainty\"] = -((clipped_preds * np.log(clipped_preds)).sum(axis=1))\n",
    "    return df\n",
    "\n",
    "def mae(df:DF, task_preffix:str) -> DF:\n",
    "    df_pred = df.filter(regex=f\"{task_preffix}_pred_*\", axis=\"columns\")\n",
    "    df_true = df.filter(regex=f\"{task_preffix}_true_*\", axis=\"columns\")\n",
    "    df[task_preffix + \"_mae\"] = np.abs(df_pred.values - df_true.values).mean(axis=1)\n",
    "\n",
    "    return df\n",
    "\n",
    "def post_process_df(df:DF) -> DF:\n",
    "    return (\n",
    "        df\n",
    "        .pipe(preds_uncertainty, \"y\")\n",
    "        .pipe(preds_uncertainty, \"orient\")\n",
    "        .pipe(preds_uncertainty, \"bin\")\n",
    "        .pipe(preds_uncertainty, \"reg\")\n",
    "        .pipe(mae, \"y\")\n",
    "        .pipe(mae, \"orient\")\n",
    "        .pipe(mae, \"bin\")\n",
    "        .pipe(mae, \"reg\")\n",
    "    )\n",
    "\n",
    "def record_models_outputs() -> DF:\n",
    "    device = torch.device(\"cuda\")\n",
    "    dataset = CMIDataset(device)\n",
    "    data_loader = DL(dataset, batch_size=1024, shuffle=False)\n",
    "    seq_meta_data = pd.read_parquet(\"preprocessed_dataset/sequences_meta_data.parquet\")\n",
    "    dfs = []\n",
    "    for fold_idx in tqdm(range(N_FOLDS), total=N_FOLDS):\n",
    "        model = mk_model(device=device)\n",
    "        checkpoint = torch.load(\n",
    "            join(\n",
    "                \"models\",\n",
    "                f\"model_fold_{fold_idx}.pth\"\n",
    "            ),\n",
    "            map_location=device,\n",
    "            weights_only=True\n",
    "        )\n",
    "        model.load_state_dict(checkpoint)\n",
    "        model.eval()\n",
    "        df = get_perf_and_seq_id(model, data_loader, device, seq_meta_data)\n",
    "        dfs.append(df.assign(fold=fold_idx))\n",
    "\n",
    "    return pd.concat(dfs).pipe(post_process_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07101223",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "beca76d7459f42468c0221f9f253887e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = record_models_outputs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b930a7",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39500692",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gating_features(df:DF) -> ndarray:\n",
    "    return (\n",
    "        df\n",
    "        .loc[:, GATING_INPUT_FEATURES + [\"fold\"]]\n",
    "        .pivot(columns=\"fold\")\n",
    "        .values\n",
    "    )\n",
    "\n",
    "def get_experts_outputs(df:DF) -> ndarray:\n",
    "    return (\n",
    "        df\n",
    "        .filter(regex=r\"^y_pred_|^fold$\")\n",
    "        .pivot(columns=\"fold\")\n",
    "        .values\n",
    "        .reshape(-1, N_FOLDS, N_TARGETS)\n",
    "    )\n",
    "\n",
    "def get_gating_targets(df:DF) -> ndarray:\n",
    "    return (\n",
    "        df\n",
    "        .query(\"fold == 0\")\n",
    "        .filter(regex=\"y_true*\")\n",
    "        .values\n",
    "    )\n",
    "\n",
    "class GatingDataset(TensorDataset):\n",
    "    def __init__(self, df: DF, device: torch.device):\n",
    "        super().__init__(\n",
    "            torch.from_numpy(get_gating_features(df)).to(device),\n",
    "            torch.from_numpy(get_experts_outputs(df)).to(device),\n",
    "            torch.from_numpy(get_gating_targets(df)).to(device),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "63399999",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_gating_model(dataset: Dataset, gating_model: nn.Module) -> dict:\n",
    "    gating_model = gating_model.eval()\n",
    "    data_loader = DL(dataset, batch_size=1024, shuffle=False)\n",
    "    y_preds = []\n",
    "    with torch.no_grad():\n",
    "        for x, experts_y_preds, _ in data_loader:\n",
    "            weights = gating_model(x)\n",
    "            y_pred = torch.einsum(\"be, bet -> bt\", weights, experts_y_preds) / weights.sum(dim=1, keepdim=True)\n",
    "            y_preds.append(y_pred)\n",
    "\n",
    "    y_preds = torch.argmax(torch.concat(y_preds), dim=1)\n",
    "    y_true = torch.argmax(dataset.tensors[2], dim=1)\n",
    "    metrics = {\n",
    "        \"accuracy\": (y_preds == y_true).float().mean(),\n",
    "    }\n",
    "\n",
    "    return metrics\n",
    "\n",
    "def train_model_on_single_epoch(data_loader: DL, gating_model: nn.Module, criterion: nn.Module, optimizer: Optimizer) -> dict:\n",
    "    metrics = defaultdict(float)\n",
    "    n_samples = 0\n",
    "    gating_model = gating_model.train()\n",
    "    for x, experts_y_preds, y_true in data_loader:\n",
    "        optimizer.zero_grad()\n",
    "        weights = gating_model(x)\n",
    "        y_pred = torch.einsum(\"be, bet -> bt\", weights, experts_y_preds) / weights.sum(dim=1, keepdim=True)\n",
    "\n",
    "        loss = criterion(y_pred, y_true)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        n_samples += x.shape[0]\n",
    "        metrics[\"train_loss\"] += loss.item() * x.shape[0]\n",
    "\n",
    "    metrics[\"train_loss\"] /= n_samples\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "def train_model_on_all_epochs(dataset: Dataset, gating_model: nn.Module) -> DF:\n",
    "    train_loader = DL(dataset, GATING_MODEL_BATCH_SIZE, shuffle=True)\n",
    "    optimizer = torch.optim.AdamW(gating_model.parameters())\n",
    "    metrics: list[dict] = []\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    for epoch in range(N_GATING_MODEL_EPOCHS):\n",
    "        train_metrics = train_model_on_single_epoch(train_loader, gating_model, criterion, optimizer)\n",
    "        eval_metrics = evaluate_gating_model(dataset, gating_model)\n",
    "        metrics.append({\"epoch\": epoch} | train_metrics | eval_metrics)\n",
    "\n",
    "    return DF.from_records(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b5872a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeanGate(nn.Module):\n",
    "    def ___init__(self, device: torch.device):\n",
    "        self.device = device\n",
    "    \n",
    "    def forward(self, experts_preds_stats: Tensor) -> Tensor:\n",
    "        return torch.ones((experts_preds_stats.shape[0], N_FOLDS)).cuda()\n",
    "    \n",
    "class LogisticRegression(nn.Sequential):\n",
    "    def __init__(self):\n",
    "        super().__init__(\n",
    "            nn.LazyLinear(N_FOLDS),\n",
    "            nn.Sigmoid(),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850e3986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_gate_metrics: {'accuracy': tensor(0.0518, device='cuda:0')}\n",
      "base logistic_gate_metrics: {'accuracy': tensor(0.0703, device='cuda:0')}\n",
      "trained logistic_gate_metrics: epoch                                       3\n",
      "train_loss                           2.737511\n",
      "accuracy      tensor(0.1554, device='cuda:0')\n",
      "Name: 3, dtype: object\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "dataset = GatingDataset(df, device)\n",
    "mean_gate_metrics = evaluate_gating_model(dataset, MeanGate())\n",
    "print(\"mean_gate_metrics:\", mean_gate_metrics)\n",
    "logisticGate = LogisticRegression().to(device)\n",
    "base_logistic_gate_metrics = evaluate_gating_model(dataset, logisticGate)\n",
    "print(\"base logistic_gate_metrics:\", base_logistic_gate_metrics)\n",
    "training_metrics = train_model_on_all_epochs(dataset, logisticGate)\n",
    "print(\"trained logistic_gate_metrics:\", training_metrics.iloc[-1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CMI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
