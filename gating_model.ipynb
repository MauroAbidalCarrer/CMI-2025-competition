{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "332e7f37",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21b91065",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import re\n",
    "import os\n",
    "import json \n",
    "import math\n",
    "import shutil\n",
    "import random\n",
    "import warnings\n",
    "from os.path import join\n",
    "from functools import partial\n",
    "from tqdm.notebook import tqdm\n",
    "from collections import defaultdict\n",
    "from operator import methodcaller\n",
    "from typing import Optional, Literal\n",
    "from typing import Optional, Literal, Iterator\n",
    "from itertools import pairwise, starmap, product\n",
    "\n",
    "import torch\n",
    "import optuna\n",
    "import kagglehub \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "from numpy import ndarray\n",
    "from torch import nn, Tensor\n",
    "from numpy.linalg import norm\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Optimizer\n",
    "from pandas import DataFrame as DF\n",
    "from optuna.trial import TrialState\n",
    "from sklearn.metrics import f1_score\n",
    "from optuna.pruners import BasePruner\n",
    "from optuna.exceptions import TrialPruned\n",
    "from torch.utils.data import TensorDataset\n",
    "from scipy.spatial.transform import Rotation\n",
    "import kaggle_evaluation.cmi_inference_server\n",
    "from torch.utils.data import DataLoader as DL\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from rich.progress import Progress, Task, track\n",
    "from sklearn.model_selection import train_test_split\n",
    "from numpy.lib.stride_tricks import sliding_window_view\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from torch.optim.lr_scheduler import ConstantLR, LRScheduler, _LRScheduler\n",
    "\n",
    "from config import *\n",
    "from model import mk_model\n",
    "from training import CMIDataset\n",
    "from utils import seed_everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1783130",
   "metadata": {},
   "outputs": [],
   "source": [
    "GATING_INPUT_FEATURES = [\n",
    "    \"bin_mae\",\n",
    "    \"reg_mae\",\n",
    "    \"y_uncertainty\",\n",
    "    \"bin_uncertainty\",\n",
    "    \"reg_uncertainty\",\n",
    "    \"orient_uncertainty\",\n",
    "]\n",
    "GATING_MODEL_BATCH_SIZE = 256\n",
    "N_GATING_MODEL_EPOCHS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de9365c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df607b2",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5942ef71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def record_target_feature(metrics:defaultdict, y_pred:Tensor, y_true:Tensor, preffix:str):\n",
    "    y_pred = y_pred.cpu().numpy()\n",
    "    y_true = y_true.cpu().numpy()\n",
    "    for target_col_idx in range(y_pred.shape[1]):\n",
    "        metrics[preffix + \"_pred_\" + str(target_col_idx)].append(y_pred[:, target_col_idx])\n",
    "        metrics[preffix + \"_true_\" + str(target_col_idx)].append(y_true[:, target_col_idx])\n",
    "\n",
    "def get_perf_and_seq_id(model:nn.Module, data_loader:DL, device:torch.device, seq_meta_data:DF) -> DF:\n",
    "    metrics:dict[list[ndarray]] = defaultdict(list)\n",
    "    model = model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch_x, batch_y, batch_orient_y, batch_bin_demos_y, batch_reg_demos_y, idx in data_loader:\n",
    "            batch_x = batch_x.to(device).clone()\n",
    "            batch_y = batch_y.to(device)\n",
    "\n",
    "            outputs, orient_outputs, bin_demos_output, reg_demos_output = model(batch_x)\n",
    "            losses = nn.functional.cross_entropy(\n",
    "                outputs,\n",
    "                batch_y,\n",
    "                label_smoothing=LABEL_SMOOTHING,\n",
    "                reduction=\"none\",\n",
    "            )\n",
    "            orient_losses = nn.functional.cross_entropy(\n",
    "                orient_outputs,\n",
    "                batch_orient_y,\n",
    "                label_smoothing=LABEL_SMOOTHING,\n",
    "                reduction=\"none\",\n",
    "            )\n",
    "            bin_demos_losses = nn.functional.binary_cross_entropy_with_logits(\n",
    "                bin_demos_output,\n",
    "                batch_bin_demos_y,\n",
    "                # label_smoothing=LABEL_SMOOTHING,\n",
    "                reduction=\"none\",\n",
    "            ).cpu().numpy()\n",
    "            reg_demos_losses = nn.functional.mse_loss(reg_demos_output, batch_reg_demos_y, reduction=\"none\").cpu().numpy()\n",
    "            metrics[\"losses\"].append(losses.cpu().numpy())\n",
    "            metrics[\"orient_losses\"].append(orient_losses.cpu().numpy())\n",
    "            record_target_feature(metrics, outputs, batch_y, \"y\")\n",
    "            record_target_feature(metrics, orient_outputs, batch_orient_y, \"orient\")\n",
    "            record_target_feature(metrics, bin_demos_output, batch_bin_demos_y, \"bin\")\n",
    "            record_target_feature(metrics, batch_reg_demos_y, reg_demos_output, \"reg\")\n",
    "            metrics[\"sequence_id\"].append(seq_meta_data[\"sequence_id\"].iloc[idx].values)\n",
    "\n",
    "    metrics = {k: np.concat(v) for k, v in metrics.items()}\n",
    "\n",
    "    return DF(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "acbcacaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPSILON = 1e-12\n",
    "\n",
    "def preds_uncertainty(df:DF, task_preffix:str) -> pd.Series:\n",
    "    preds = df.filter(regex=f\"{task_preffix}_pred_*\", axis=\"columns\")\n",
    "    clipped_preds = preds.clip(EPSILON, 1.0)\n",
    "    df[task_preffix + \"_uncertainty\"] = -((clipped_preds * np.log(clipped_preds)).sum(axis=1))\n",
    "    return df\n",
    "\n",
    "def mae(df:DF, task_preffix:str) -> DF:\n",
    "    df_pred = df.filter(regex=f\"{task_preffix}_pred_*\", axis=\"columns\")\n",
    "    df_true = df.filter(regex=f\"{task_preffix}_true_*\", axis=\"columns\")\n",
    "    df[task_preffix + \"_mae\"] = np.abs(df_pred.values - df_true.values).mean(axis=1)\n",
    "\n",
    "    return df\n",
    "\n",
    "def post_process_df(df:DF) -> DF:\n",
    "    return (\n",
    "        df\n",
    "        .pipe(preds_uncertainty, \"y\")\n",
    "        .pipe(preds_uncertainty, \"orient\")\n",
    "        .pipe(preds_uncertainty, \"bin\")\n",
    "        .pipe(preds_uncertainty, \"reg\")\n",
    "        .pipe(mae, \"y\")\n",
    "        .pipe(mae, \"orient\")\n",
    "        .pipe(mae, \"bin\")\n",
    "        .pipe(mae, \"reg\")\n",
    "    )\n",
    "\n",
    "def record_models_outputs() -> DF:\n",
    "    device = torch.device(\"cuda\")\n",
    "    dataset = CMIDataset(device)\n",
    "    data_loader = DL(dataset, batch_size=1024, shuffle=False)\n",
    "    seq_meta_data = pd.read_parquet(\"preprocessed_dataset/sequences_meta_data.parquet\")\n",
    "    dfs = []\n",
    "    for fold_idx in tqdm(range(N_FOLDS), total=N_FOLDS):\n",
    "        model = mk_model(device=device)\n",
    "        checkpoint = torch.load(\n",
    "            join(\n",
    "                \"models\",\n",
    "                f\"model_fold_{fold_idx}.pth\"\n",
    "            ),\n",
    "            map_location=device,\n",
    "            weights_only=True\n",
    "        )\n",
    "        model.load_state_dict(checkpoint)\n",
    "        model.eval()\n",
    "        df = get_perf_and_seq_id(model, data_loader, device, seq_meta_data)\n",
    "        dfs.append(df.assign(fold=fold_idx))\n",
    "\n",
    "    return pd.concat(dfs).pipe(post_process_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07101223",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = record_models_outputs()\n",
    "df = pd.read_parquet(\"gating_df.parquet\")#record_models_outputs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a31d097",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet(\"gating_df.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b930a7",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "39500692",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gating_features(df:DF) -> ndarray:\n",
    "    return (\n",
    "        df\n",
    "        .loc[:, GATING_INPUT_FEATURES + [\"fold\"]]\n",
    "        .pivot(columns=\"fold\")\n",
    "        .values\n",
    "    )\n",
    "\n",
    "def get_experts_outputs(df:DF) -> ndarray:\n",
    "    return (\n",
    "        df\n",
    "        .filter(regex=r\"^y_pred_|^fold$\")\n",
    "        .pivot(columns=\"fold\")\n",
    "        .values\n",
    "        .reshape(-1, N_FOLDS, N_TARGETS)\n",
    "    )\n",
    "\n",
    "def get_gating_targets(df:DF, fold=0) -> ndarray:\n",
    "    print(\"fold == \" + str(fold))\n",
    "    return (\n",
    "        df\n",
    "        .query(\"fold == \" + str(fold))\n",
    "        .filter(regex=\"y_true*\")\n",
    "        .values\n",
    "    )\n",
    "\n",
    "class GatingDataset(TensorDataset):\n",
    "    def __init__(self, df: DF, device: torch.device, fold=0):\n",
    "        super().__init__(\n",
    "            torch.from_numpy(get_gating_features(df)).to(device),\n",
    "            torch.from_numpy(get_experts_outputs(df)).to(device),\n",
    "            torch.from_numpy(get_gating_targets(df, fold=fold)).to(device),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "63399999",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_gating_model(dataset: Dataset, gating_model: nn.Module) -> dict:\n",
    "    gating_model = gating_model.eval()\n",
    "    data_loader = DL(dataset, batch_size=1024, shuffle=False)\n",
    "    y_preds = []\n",
    "    y_trues = []\n",
    "    with torch.no_grad():\n",
    "        for x, experts_y_preds, y in data_loader:\n",
    "            y_preds.append(gating_model(x, experts_y_preds))\n",
    "            y_trues.append(y)\n",
    "    y_preds = torch.argmax(torch.concat(y_preds), dim=1)\n",
    "    y_true = torch.argmax(torch.concat(y_trues), dim=1)\n",
    "    model_is_true = y_preds == y_true\n",
    "    print(model_is_true.shape)\n",
    "    print(model_is_true.sum())\n",
    "    metrics = {\n",
    "        \"accuracy\": model_is_true.float().mean().item(),\n",
    "    }\n",
    "\n",
    "    return metrics\n",
    "\n",
    "def train_model_on_single_epoch(data_loader: DL, gating_model: nn.Module, criterion: nn.Module, optimizer: Optimizer) -> dict:\n",
    "    metrics = defaultdict(float)\n",
    "    n_samples = 0\n",
    "    gating_model = gating_model.train()\n",
    "    for x, experts_y_preds, y_true in data_loader:\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = gating_model(x, experts_y_preds)\n",
    "        loss = criterion(y_pred, y_true)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        n_samples += x.shape[0]\n",
    "        metrics[\"train_loss\"] += loss.item() * x.shape[0]\n",
    "\n",
    "    metrics[\"train_loss\"] /= n_samples\n",
    "\n",
    "    return metrics\n",
    "\n",
    "def train_model_on_all_epochs(dataset: Dataset, gating_model: nn.Module) -> DF:\n",
    "    train_loader = DL(dataset, GATING_MODEL_BATCH_SIZE, shuffle=True)\n",
    "    optimizer = torch.optim.AdamW(gating_model.parameters())\n",
    "    metrics: list[dict] = []\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    for epoch in range(N_GATING_MODEL_EPOCHS):\n",
    "        train_metrics = train_model_on_single_epoch(train_loader, gating_model, criterion, optimizer)\n",
    "        eval_metrics = evaluate_gating_model(dataset, gating_model)\n",
    "        metrics.append({\"epoch\": epoch} | train_metrics | eval_metrics)\n",
    "\n",
    "    return DF.from_records(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5872a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeanGate(nn.Module):\n",
    "    def ___init__(self, device: torch.device):\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, experts_preds_stats: Tensor, expert_preds: Tensor) -> Tensor:\n",
    "        return expert_preds.mean(dim=1)\n",
    "\n",
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.log_reg = nn.Sequential(\n",
    "            nn.LazyLinear(N_FOLDS),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, experts_preds_stats: Tensor, expert_preds: Tensor) -> Tensor:\n",
    "        weights = self.log_reg(experts_preds_stats)\n",
    "        weighted_y_preds = torch.einsum(\"be, bet -> bt\", weights, expert_preds)\n",
    "        y_pred = weighted_y_preds / weights.sum(dim=1, keepdim=True)\n",
    "\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "850e3986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold == 0\n",
      "torch.Size([8151])\n",
      "tensor(271, device='cuda:0')\n",
      "mean_gate_metrics: {'accuracy': 0.0332474522292614}\n",
      "torch.Size([8151])\n",
      "tensor(783, device='cuda:0')\n",
      "base logistic_gate_metrics: {'accuracy': 0.0960618332028389}\n",
      "torch.Size([8151])\n",
      "tensor(1127, device='cuda:0')\n",
      "torch.Size([8151])\n",
      "tensor(1244, device='cuda:0')\n",
      "torch.Size([8151])\n",
      "tensor(1245, device='cuda:0')\n",
      "torch.Size([8151])\n",
      "tensor(1245, device='cuda:0')\n",
      "torch.Size([8151])\n",
      "tensor(1232, device='cuda:0')\n",
      "trained logistic_gate_metrics: {'epoch': 4.0, 'train_loss': 2.7252344387818694, 'accuracy': 0.15114709734916687}\n",
      "==================================\n",
      "fold == 1\n",
      "torch.Size([8151])\n",
      "tensor(271, device='cuda:0')\n",
      "mean_gate_metrics: {'accuracy': 0.0332474522292614}\n",
      "torch.Size([8151])\n",
      "tensor(593, device='cuda:0')\n",
      "base logistic_gate_metrics: {'accuracy': 0.07275180518627167}\n",
      "torch.Size([8151])\n",
      "tensor(1161, device='cuda:0')\n",
      "torch.Size([8151])\n",
      "tensor(1257, device='cuda:0')\n",
      "torch.Size([8151])\n",
      "tensor(1270, device='cuda:0')\n",
      "torch.Size([8151])\n",
      "tensor(1296, device='cuda:0')\n",
      "torch.Size([8151])\n",
      "tensor(1299, device='cuda:0')\n",
      "trained logistic_gate_metrics: {'epoch': 4.0, 'train_loss': 2.7279188746163454, 'accuracy': 0.15936695039272308}\n",
      "==================================\n",
      "fold == 2\n",
      "torch.Size([8151])\n",
      "tensor(271, device='cuda:0')\n",
      "mean_gate_metrics: {'accuracy': 0.0332474522292614}\n",
      "torch.Size([8151])\n",
      "tensor(533, device='cuda:0')\n",
      "base logistic_gate_metrics: {'accuracy': 0.06539075076580048}\n",
      "torch.Size([8151])\n",
      "tensor(1129, device='cuda:0')\n",
      "torch.Size([8151])\n",
      "tensor(1257, device='cuda:0')\n",
      "torch.Size([8151])\n",
      "tensor(1229, device='cuda:0')\n",
      "torch.Size([8151])\n",
      "tensor(1177, device='cuda:0')\n",
      "torch.Size([8151])\n",
      "tensor(1306, device='cuda:0')\n",
      "trained logistic_gate_metrics: {'epoch': 4.0, 'train_loss': 2.7320536270183724, 'accuracy': 0.1602257341146469}\n",
      "==================================\n",
      "fold == 3\n",
      "torch.Size([8151])\n",
      "tensor(271, device='cuda:0')\n",
      "mean_gate_metrics: {'accuracy': 0.0332474522292614}\n",
      "torch.Size([8151])\n",
      "tensor(490, device='cuda:0')\n",
      "base logistic_gate_metrics: {'accuracy': 0.06011532247066498}\n",
      "torch.Size([8151])\n",
      "tensor(1122, device='cuda:0')\n",
      "torch.Size([8151])\n",
      "tensor(1206, device='cuda:0')\n",
      "torch.Size([8151])\n",
      "tensor(1260, device='cuda:0')\n",
      "torch.Size([8151])\n",
      "tensor(1263, device='cuda:0')\n",
      "torch.Size([8151])\n",
      "tensor(1236, device='cuda:0')\n",
      "trained logistic_gate_metrics: {'epoch': 4.0, 'train_loss': 2.7327540168848787, 'accuracy': 0.15163783729076385}\n",
      "==================================\n",
      "fold == 4\n",
      "torch.Size([8151])\n",
      "tensor(271, device='cuda:0')\n",
      "mean_gate_metrics: {'accuracy': 0.0332474522292614}\n",
      "torch.Size([8151])\n",
      "tensor(373, device='cuda:0')\n",
      "base logistic_gate_metrics: {'accuracy': 0.04576125368475914}\n",
      "torch.Size([8151])\n",
      "tensor(1082, device='cuda:0')\n",
      "torch.Size([8151])\n",
      "tensor(1198, device='cuda:0')\n",
      "torch.Size([8151])\n",
      "tensor(1252, device='cuda:0')\n",
      "torch.Size([8151])\n",
      "tensor(1214, device='cuda:0')\n",
      "torch.Size([8151])\n",
      "tensor(1248, device='cuda:0')\n",
      "trained logistic_gate_metrics: {'epoch': 4.0, 'train_loss': 2.7337021978043907, 'accuracy': 0.15311004221439362}\n",
      "==================================\n",
      "fold == 5\n",
      "torch.Size([8151])\n",
      "tensor(271, device='cuda:0')\n",
      "mean_gate_metrics: {'accuracy': 0.0332474522292614}\n",
      "torch.Size([8151])\n",
      "tensor(386, device='cuda:0')\n",
      "base logistic_gate_metrics: {'accuracy': 0.047356151044368744}\n",
      "torch.Size([8151])\n",
      "tensor(1064, device='cuda:0')\n",
      "torch.Size([8151])\n",
      "tensor(1206, device='cuda:0')\n",
      "torch.Size([8151])\n",
      "tensor(1254, device='cuda:0')\n",
      "torch.Size([8151])\n",
      "tensor(1292, device='cuda:0')\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     11\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mtrained logistic_gate_metrics:\u001b[39m\u001b[33m\"\u001b[39m, training_metrics.iloc[-\u001b[32m1\u001b[39m].to_dict())\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m fold \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(N_FOLDS):\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m     \u001b[43myes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfold\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m==================================\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 10\u001b[39m, in \u001b[36myes\u001b[39m\u001b[34m(fold)\u001b[39m\n\u001b[32m      8\u001b[39m base_logistic_gate_metrics = evaluate_gating_model(dataset, logisticGate)\n\u001b[32m      9\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mbase logistic_gate_metrics:\u001b[39m\u001b[33m\"\u001b[39m, base_logistic_gate_metrics)\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m training_metrics = \u001b[43mtrain_model_on_all_epochs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogisticGate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mtrained logistic_gate_metrics:\u001b[39m\u001b[33m\"\u001b[39m, training_metrics.iloc[-\u001b[32m1\u001b[39m].to_dict())\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 45\u001b[39m, in \u001b[36mtrain_model_on_all_epochs\u001b[39m\u001b[34m(dataset, gating_model)\u001b[39m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(N_GATING_MODEL_EPOCHS):\n\u001b[32m     44\u001b[39m     train_metrics = train_model_on_single_epoch(train_loader, gating_model, criterion, optimizer)\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m     eval_metrics = \u001b[43mevaluate_gating_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgating_model\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     46\u001b[39m     metrics.append({\u001b[33m\"\u001b[39m\u001b[33mepoch\u001b[39m\u001b[33m\"\u001b[39m: epoch} | train_metrics | eval_metrics)\n\u001b[32m     48\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m DF.from_records(metrics)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 7\u001b[39m, in \u001b[36mevaluate_gating_model\u001b[39m\u001b[34m(dataset, gating_model)\u001b[39m\n\u001b[32m      5\u001b[39m y_trues = []\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexperts_y_preds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata_loader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m        \u001b[49m\u001b[43my_preds\u001b[49m\u001b[43m.\u001b[49m\u001b[43mappend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgating_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexperts_y_preds\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m        \u001b[49m\u001b[43my_trues\u001b[49m\u001b[43m.\u001b[49m\u001b[43mappend\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/venv/CMI/lib/python3.11/site-packages/torch/utils/data/dataloader.py:701\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    698\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    699\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    700\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m701\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    702\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    703\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    704\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    705\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    706\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    707\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/venv/CMI/lib/python3.11/site-packages/torch/utils/data/dataloader.py:757\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    755\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    756\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m757\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    758\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    759\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/venv/CMI/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     50\u001b[39m         data = \u001b[38;5;28mself\u001b[39m.dataset.__getitems__(possibly_batched_index)\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m         data = \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/venv/CMI/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[39m, in \u001b[36m<listcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m     50\u001b[39m         data = \u001b[38;5;28mself\u001b[39m.dataset.__getitems__(possibly_batched_index)\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m         data = [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/venv/CMI/lib/python3.11/site-packages/torch/utils/data/dataset.py:211\u001b[39m, in \u001b[36mTensorDataset.__getitem__\u001b[39m\u001b[34m(self, index)\u001b[39m\n\u001b[32m    210\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, index):\n\u001b[32m--> \u001b[39m\u001b[32m211\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(tensor[index] \u001b[38;5;28;01mfor\u001b[39;00m tensor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.tensors)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/venv/CMI/lib/python3.11/site-packages/torch/utils/data/dataset.py:211\u001b[39m, in \u001b[36m<genexpr>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m    210\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, index):\n\u001b[32m--> \u001b[39m\u001b[32m211\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(tensor[index] \u001b[38;5;28;01mfor\u001b[39;00m tensor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.tensors)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "def yes(fold:int):\n",
    "    # Fold 0 targets\n",
    "    device = torch.device(\"cuda\")\n",
    "    dataset = GatingDataset(df, device, fold=fold)\n",
    "    mean_gate_metrics = evaluate_gating_model(dataset, MeanGate())\n",
    "    print(\"mean_gate_metrics:\", mean_gate_metrics)\n",
    "    logisticGate = LogisticRegression().to(device)\n",
    "    base_logistic_gate_metrics = evaluate_gating_model(dataset, logisticGate)\n",
    "    print(\"base logistic_gate_metrics:\", base_logistic_gate_metrics)\n",
    "    training_metrics = train_model_on_all_epochs(dataset, logisticGate)\n",
    "    print(\"trained logistic_gate_metrics:\", training_metrics.iloc[-1].to_dict())\n",
    "\n",
    "for fold in range(N_FOLDS):\n",
    "    yes(fold)\n",
    "    print(\"==================================\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CMI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
