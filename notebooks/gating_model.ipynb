{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "332e7f37",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b91065",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import re\n",
    "import os\n",
    "import json \n",
    "import math\n",
    "import shutil\n",
    "import random\n",
    "import warnings\n",
    "from os.path import join\n",
    "from functools import partial\n",
    "from tqdm.notebook import tqdm\n",
    "from collections import defaultdict\n",
    "from operator import methodcaller\n",
    "from typing import Optional, Literal\n",
    "from typing import Optional, Literal, Iterator\n",
    "from itertools import pairwise, starmap, product\n",
    "\n",
    "import torch\n",
    "import optuna\n",
    "import kagglehub \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "from numpy import ndarray\n",
    "from torch import nn, Tensor\n",
    "from numpy.linalg import norm\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Optimizer\n",
    "from pandas import DataFrame as DF\n",
    "from optuna.trial import TrialState\n",
    "from sklearn.metrics import f1_score\n",
    "from optuna.pruners import BasePruner\n",
    "from optuna.exceptions import TrialPruned\n",
    "from torch.utils.data import TensorDataset\n",
    "from scipy.spatial.transform import Rotation\n",
    "import kaggle_evaluation.cmi_inference_server\n",
    "from torch.utils.data import DataLoader as DL\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from rich.progress import Progress, Task, track\n",
    "from sklearn.model_selection import train_test_split\n",
    "from numpy.lib.stride_tricks import sliding_window_view\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from torch.optim.lr_scheduler import ConstantLR, LRScheduler, _LRScheduler\n",
    "\n",
    "from config import *\n",
    "from model import mk_model\n",
    "from training import CMIDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df607b2",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5942ef71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def record_target_feature(metrics:defaultdict, y_pred:Tensor, y_true:Tensor, preffix:str):\n",
    "    for target_col_idx in range(y_pred.shape[1]):\n",
    "        metrics[preffix + \"_pred_\" + str(target_col_idx)].append(y_pred[:, target_col_idx])\n",
    "        metrics[preffix + \"_true_\" + str(target_col_idx)].append(y_true[:, target_col_idx])\n",
    "\n",
    "def get_perf_and_seq_id(model:nn.Module, data_loader:DL, device:torch.device, seq_meta_data:DF) -> DF:\n",
    "    metrics:dict[list[ndarray]] = defaultdict(list)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch_x, batch_y, batch_orient_y, batch_bin_demos_y, batch_reg_demos_y, idx in data_loader:\n",
    "            batch_x = batch_x.to(device).clone()\n",
    "            batch_y = batch_y.to(device)\n",
    "\n",
    "            outputs, orient_outputs, bin_demos_output, reg_demos_output = model(batch_x)\n",
    "            losses = nn.functional.cross_entropy(\n",
    "                outputs,\n",
    "                batch_y,\n",
    "                label_smoothing=LABEL_SMOOTHING,\n",
    "                reduction=\"none\",\n",
    "            )\n",
    "            orient_losses = nn.functional.cross_entropy(\n",
    "                orient_outputs,\n",
    "                batch_orient_y,\n",
    "                label_smoothing=LABEL_SMOOTHING,\n",
    "                reduction=\"none\",\n",
    "            )\n",
    "            bin_demos_losses = nn.functional.binary_cross_entropy_with_logits(\n",
    "                bin_demos_output,\n",
    "                batch_bin_demos_y,\n",
    "                # label_smoothing=LABEL_SMOOTHING,\n",
    "                reduction=\"none\",\n",
    "            ).cpu().numpy()\n",
    "            reg_demos_losses = nn.functional.mse_loss(reg_demos_output, batch_reg_demos_y, reduction=\"none\").cpu().numpy()\n",
    "            # Get predicted class indices\n",
    "            y_pred = outputs.cpu().numpy()\n",
    "            # Get true class indices from one-hot\n",
    "            y_true = batch_y.cpu().numpy()\n",
    "\n",
    "            metrics[\"losses\"].append(losses.cpu().numpy())\n",
    "            metrics[\"orient_losses\"].append(orient_losses.cpu().numpy())\n",
    "            record_target_feature(metrics, y_pred, y_true, \"y\")\n",
    "            record_target_feature(metrics, orient_outputs, batch_orient_y, \"orient\")\n",
    "            record_target_feature(metrics, bin_demos_output, batch_bin_demos_y, \"bin\")\n",
    "            record_target_feature(metrics, batch_reg_demos_y, reg_demos_output, \"reg\")\n",
    "            metrics[\"sequence_id\"].append(seq_meta_data[\"sequence_id\"].iloc[idx].values)\n",
    "\n",
    "    metrics = {k: np.concat(v) for k, v in metrics.items()}\n",
    "\n",
    "    return DF(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acbcacaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def record_models_outputs() -> DF:\n",
    "    device = torch.device(\"cuda\")\n",
    "    dataset = CMIDataset(device)\n",
    "    data_loader = DL(dataset, batch_size=1024, shuffle=False)\n",
    "    seq_meta_data = pd.read_parquet(\"preprocessed_dataset/sequences_meta_data.parquet\")\n",
    "    dfs = []\n",
    "    for fold in range(N_FOLDS):\n",
    "        model = mk_model()\n",
    "        checkpoint = torch.load(\n",
    "            join(\n",
    "                \"models\",\n",
    "                f\"model_fold_{fold}.pth\"\n",
    "            ),\n",
    "            map_location=device,\n",
    "            weights_only=True\n",
    "        )\n",
    "        model.load_state_dict(checkpoint)\n",
    "        model.eval()\n",
    "        dfs.append(get_perf_and_seq_id(model, data_loader, device, seq_meta_data))\n",
    "\n",
    "    return pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab1a1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPSILON = 1e-12\n",
    "\n",
    "def preds_uncertainty(df:DF, preds_preffix:str) -> pd.Series:\n",
    "    preds = df.filter(regex=f\"{preds_preffix}*\", axis=\"columns\")\n",
    "    clipped_preds = preds.clip(EPSILON, 1.0)\n",
    "    return -float((clipped_preds * np.log(clipped_preds)).sum())\n",
    "\n",
    "def post_process_df(df:DF) -> DF:\n",
    "    return (\n",
    "        df\n",
    "        .assign(preds_uncertainty, )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07101223",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = record_models_outputs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d82dd10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CMI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
