{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-16T15:02:33.203136Z",
     "iopub.status.busy": "2025-07-16T15:02:33.202842Z",
     "iopub.status.idle": "2025-07-16T15:02:40.444209Z",
     "shell.execute_reply": "2025-07-16T15:02:40.443464Z",
     "shell.execute_reply.started": "2025-07-16T15:02:33.203112Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from os.path import join\n",
    "from itertools import pairwise, product\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "from numpy import ndarray\n",
    "from torch import nn, Tensor\n",
    "import plotly.express as px\n",
    "from scipy.spatial.transform import Rotation\n",
    "from pandas import DataFrame as DF\n",
    "from kagglehub import competition_download, dataset_download, model_download\n",
    "\n",
    "from kaggle_evaluation.cmi_inference_server import CMIInferenceServer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset meta data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-16T15:02:40.446482Z",
     "iopub.status.busy": "2025-07-16T15:02:40.445898Z",
     "iopub.status.idle": "2025-07-16T15:02:40.645830Z",
     "shell.execute_reply": "2025-07-16T15:02:40.645068Z",
     "shell.execute_reply.started": "2025-07-16T15:02:40.446451Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "meta_data_path = dataset_download(\n",
    "    handle=\"mauroabidalcarrer/prepocessed-cmi-2025\",\n",
    "    path=\"preprocessed_dataset/full_dataset_meta_data.json\"\n",
    ")\n",
    "with open(meta_data_path, \"r\") as fp:\n",
    "    meta_data = json.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define preprocessing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-16T15:02:40.647126Z",
     "iopub.status.busy": "2025-07-16T15:02:40.646861Z",
     "iopub.status.idle": "2025-07-16T15:02:40.661301Z",
     "shell.execute_reply": "2025-07-16T15:02:40.660424Z",
     "shell.execute_reply.started": "2025-07-16T15:02:40.647106Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "META_DATA_COLUMNS = [\n",
    "    'row_id',\n",
    "    'sequence_type',\n",
    "    'sequence_id',\n",
    "    'sequence_counter',\n",
    "    'subject',\n",
    "    'orientation',\n",
    "    'behavior',\n",
    "    'phase',\n",
    "    'gesture',\n",
    "]\n",
    "EULER_ANGLES_COLS = [\"euler_x\", \"euler_y\", \"euler_z\"]\n",
    "QUATERNION_COLS = ['rot_w', 'rot_x', 'rot_y', 'rot_z']\n",
    "def rot_euler_angles(seq:DF) -> ndarray:\n",
    "    try:\n",
    "        quat_cols = seq[QUATERNION_COLS]\n",
    "        quat_cols /= np.linalg.norm(quat_cols, axis=1, keepdims=True)\n",
    "        rotation = Rotation.from_quat(quat_cols.values)\n",
    "        return rotation.as_euler(\"xyz\").squeeze()\n",
    "    except ValueError as e:\n",
    "        print(quat_cols)\n",
    "        raise e\n",
    "\n",
    "def add_rot_euler_angles_to_df(df:DF) -> DF:\n",
    "    df.loc[:, EULER_ANGLES_COLS] = (\n",
    "        df\n",
    "        .groupby(\"sequence_id\", as_index=False, observed=True)\n",
    "        .apply(rot_euler_angles, include_groups=False)\n",
    "        .loc[:, EULER_ANGLES_COLS]\n",
    "        .values\n",
    "    )\n",
    "    return df\n",
    "\n",
    "def impute_missing_feature_data(df:DF) -> DF:\n",
    "    feature_cols = list(set(df.columns) - set(META_DATA_COLUMNS))\n",
    "    # Missing ToF values are already imputed by -1 which is inconvinient since we want all missing values to be NaN.    \n",
    "    # So we replace them by NaN and then perform imputing.  \n",
    "    tof_vals_to_nan = {col: -1.0 for col in df.columns if col.startswith(\"tof\")}\n",
    "    # In case the sequence is entirely NaN we need to fill the rotation by unit quaternion which is [1, 0, 0, 0]\n",
    "    fillna_val_per_col = {col: 1.0 if col == 'rot_w' else 0 for col in df.columns}\n",
    "    \n",
    "    df[feature_cols] = (\n",
    "        df\n",
    "        .loc[:, feature_cols]\n",
    "        # df.replace with np.nan sets dtype to floar64 so we set it back to float32\n",
    "        .replace(tof_vals_to_nan, value=np.nan)\n",
    "        .astype(\"float32\")\n",
    "        .groupby(df[\"sequence_id\"], observed=True, as_index=False)\n",
    "        .ffill()\n",
    "        .groupby(df[\"sequence_id\"], observed=True, as_index=False)\n",
    "        .bfill()\n",
    "        # In case there are only nan in the column in the sequence\n",
    "        .fillna(fillna_val_per_col)\n",
    "    )\n",
    "    return df\n",
    "\n",
    "def agg_tof_cols_per_sensor(df:DF) -> DF:\n",
    "    for tof_idx in range(1, 6):\n",
    "        tof_name = f\"tof_{tof_idx}\"\n",
    "        tof_cols = [f\"{tof_name}_v{v_idx}\" for v_idx in range(64)]\n",
    "        if any(map(lambda col: col not in df.columns, tof_cols)):\n",
    "            print(f\"Some (or) all ToF {tof_idx} columns are not in the df. Maybe you already ran this cell?\")\n",
    "            continue\n",
    "        df = (\n",
    "            df\n",
    "            # Need to use a dict otherwise the name of the col will be \"tof_preffix\" instead of the value it contains\n",
    "            .assign(**{tof_name:df[tof_cols].mean(axis=\"columns\")})\n",
    "            .drop(columns=tof_cols)\n",
    "        )\n",
    "    return df\n",
    "\n",
    "def length_normed_sequence_feat_arr(sequence: DF) -> ndarray:\n",
    "    features = (\n",
    "        sequence\n",
    "        .loc[:, meta_data[\"feature_cols\"]]\n",
    "        .values\n",
    "    )\n",
    "    normed_sequence_len = meta_data[\"pad_seq_len\"]\n",
    "    len_diff = abs(normed_sequence_len - len(features))\n",
    "    if len(features) < normed_sequence_len:\n",
    "        padded_features = np.pad(\n",
    "            features,\n",
    "            ((len_diff // 2 + len_diff % 2, len_diff // 2), (0, 0)),\n",
    "        )\n",
    "        return padded_features\n",
    "    elif len(features) > normed_sequence_len:\n",
    "        return features[len_diff // 2:-len_diff // 2]\n",
    "    else:\n",
    "        return features\n",
    "\n",
    "def preprocess_sequence(sequence_df:pl.DataFrame) -> ndarray:\n",
    "    return (\n",
    "        sequence_df                     \n",
    "        .to_pandas()                            # Convert to pandas dataframe\n",
    "        .pipe(impute_missing_feature_data)      # Impute missing data\n",
    "        .pipe(add_rot_euler_angles_to_df)       # Add rotation acc expressed as euler angles.\n",
    "        .pipe(agg_tof_cols_per_sensor)          # Aggregate ToF columns\n",
    "        .loc[:, meta_data[\"feature_cols\"]]\n",
    "        .sub(meta_data[\"mean\"])                 # std norm sequence features\n",
    "        .div(meta_data[\"std\"])\n",
    "        .pipe(length_normed_sequence_feat_arr)  # get feature ndarray of sequence\n",
    "        .T                                      # Transpose to swap channel and X dimensions\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-16T15:02:40.662811Z",
     "iopub.status.busy": "2025-07-16T15:02:40.662413Z",
     "iopub.status.idle": "2025-07-16T15:02:40.734250Z",
     "shell.execute_reply": "2025-07-16T15:02:40.733539Z",
     "shell.execute_reply.started": "2025-07-16T15:02:40.662780Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_chns:int, out_chns:int):\n",
    "        super().__init__()\n",
    "        self.blocks = nn.Sequential(\n",
    "            nn.Conv1d(in_chns, out_chns, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(out_chns),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(out_chns, out_chns, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(out_chns),\n",
    "        )\n",
    "        if in_chns == out_chns:\n",
    "            self.skip_connection = nn.Identity() \n",
    "        else:\n",
    "            # TODO: set bias to False ?\n",
    "            self.skip_connection = nn.Sequential(\n",
    "                nn.Conv1d(in_chns, out_chns, 1),\n",
    "                nn.BatchNorm1d(out_chns)\n",
    "            )\n",
    "\n",
    "    def forward(self, x:Tensor) -> Tensor:\n",
    "        activaition_maps = self.skip_connection(x) + self.blocks(x)\n",
    "        return nn.functional.relu(activaition_maps)\n",
    "\n",
    "class Resnet(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            in_channels:int,\n",
    "            depth:int,\n",
    "            # n_res_block_per_depth:int,\n",
    "            mlp_width:int,\n",
    "            n_class:int,\n",
    "        ):\n",
    "        super().__init__()\n",
    "        chs_per_depth = [in_channels * 2 ** i for i in range(depth)]\n",
    "        blocks_chns_it = pairwise(chs_per_depth)\n",
    "        self.res_blocks = [ResidualBlock(in_chns, out_chns) for in_chns, out_chns in blocks_chns_it]\n",
    "        self.res_blocks = nn.ModuleList(self.res_blocks)\n",
    "        self.mlp_head = nn.Sequential(\n",
    "            nn.LazyLinear(mlp_width),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(mlp_width, n_class),\n",
    "            nn.Softmax(dim=1),\n",
    "        )\n",
    "        \n",
    "        \n",
    "    def forward(self, x:Tensor) -> Tensor:\n",
    "        activation_maps = x\n",
    "        for res_block in self.res_blocks:\n",
    "            activation_maps = nn.functional.max_pool1d(res_block(activation_maps), 2)\n",
    "        out = activation_maps.view(activation_maps.shape[0], -1)\n",
    "        out = self.mlp_head(out)\n",
    "        return out\n",
    "\n",
    "model = Resnet(\n",
    "    in_channels=20,\n",
    "    depth=4,\n",
    "    mlp_width=256,\n",
    "    n_class=18,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-16T15:02:40.735961Z",
     "iopub.status.busy": "2025-07-16T15:02:40.735712Z",
     "iopub.status.idle": "2025-07-16T15:02:41.480571Z",
     "shell.execute_reply": "2025-07-16T15:02:41.479871Z",
     "shell.execute_reply.started": "2025-07-16T15:02:40.735941Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_state_parent_dir = model_download(\"mauroabidalcarrer/cmi-resnet/pyTorch/trained_on_euler_angles\")\n",
    "model_state_filename = os.listdir(model_state_parent_dir)[0]\n",
    "model_state_path = join(model_state_parent_dir, model_state_filename)\n",
    "model_weights_state_dict = torch.load(model_state_path, weights_only=True)[\"model\"]\n",
    "model.load_state_dict(model_weights_state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-16T15:02:41.481303Z",
     "iopub.status.busy": "2025-07-16T15:02:41.481097Z",
     "iopub.status.idle": "2025-07-16T15:02:56.626103Z",
     "shell.execute_reply": "2025-07-16T15:02:56.624850Z",
     "shell.execute_reply.started": "2025-07-16T15:02:41.481284Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mauro/repos/CMI-2025-competition/src/kaggle_evaluation/core/templates.py:136: RuntimeWarning: 1464 seconds elapsed before server startup.\n",
      "                This exceeds the startup time limit of 900 seconds that the gateway will enforce\n",
      "                during the rerun on the hidden test set. Start the server before performing any time consuming steps.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "GatewayRuntimeError",
     "evalue": "(<GatewayRuntimeErrorType.SERVER_RAISED_EXCEPTION: 3>, 'Too many indexers')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mGatewayRuntimeError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 20\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     19\u001b[0m     competition_dataset_path \u001b[38;5;241m=\u001b[39m competition_download(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcmi-detect-behavior-with-sensor-data\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 20\u001b[0m     \u001b[43minference_server\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_local_gateway\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_paths\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m            \u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompetition_dataset_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m            \u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompetition_dataset_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain_demographics.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/repos/CMI-2025-competition/src/kaggle_evaluation/core/templates.py:149\u001b[0m, in \u001b[0;36mInferenceServer.run_local_gateway\u001b[0;34m(self, data_paths, file_share_dir, *args, **kwargs)\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway\u001b[38;5;241m.\u001b[39mrun()\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m--> 149\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m err \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mserver\u001b[38;5;241m.\u001b[39mstop(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/repos/CMI-2025-competition/src/kaggle_evaluation/core/templates.py:147\u001b[0m, in \u001b[0;36mInferenceServer.run_local_gateway\u001b[0;34m(self, data_paths, file_share_dir, *args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_gateway_for_test(data_paths, file_share_dir, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 147\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m err \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/repos/CMI-2025-competition/src/kaggle_evaluation/core/templates.py:105\u001b[0m, in \u001b[0;36mGateway.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrite_result(error)\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m error:\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;66;03m# For local testing\u001b[39;00m\n\u001b[0;32m--> 105\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error\n",
      "File \u001b[0;32m~/repos/CMI-2025-competition/src/kaggle_evaluation/core/templates.py:84\u001b[0m, in \u001b[0;36mGateway.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munpack_data_paths()\n\u001b[0;32m---> 84\u001b[0m     predictions, row_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_all_predictions\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrite_submission(predictions, row_ids)\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m kaggle_evaluation\u001b[38;5;241m.\u001b[39mcore\u001b[38;5;241m.\u001b[39mbase_gateway\u001b[38;5;241m.\u001b[39mGatewayRuntimeError \u001b[38;5;28;01mas\u001b[39;00m gre:\n",
      "File \u001b[0;32m~/repos/CMI-2025-competition/src/kaggle_evaluation/core/templates.py:56\u001b[0m, in \u001b[0;36mGateway.get_all_predictions\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     54\u001b[0m all_row_ids \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m data_batch, row_ids \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate_data_batches():\n\u001b[0;32m---> 56\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdata_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalidate_prediction_batch(predictions, row_ids)\n\u001b[1;32m     58\u001b[0m     all_predictions\u001b[38;5;241m.\u001b[39mappend(predictions)\n",
      "File \u001b[0;32m~/repos/CMI-2025-competition/src/kaggle_evaluation/core/templates.py:72\u001b[0m, in \u001b[0;36mGateway.predict\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39msend(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredict\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m---> 72\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_server_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpredict\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/repos/CMI-2025-competition/src/kaggle_evaluation/core/base_gateway.py:257\u001b[0m, in \u001b[0;36mBaseGateway.handle_server_error\u001b[0;34m(self, exception, endpoint)\u001b[0m\n\u001b[1;32m    255\u001b[0m     message_match \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msearch(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mException calling application: (.*)\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m, exception_str, re\u001b[38;5;241m.\u001b[39mIGNORECASE)\n\u001b[1;32m    256\u001b[0m     message \u001b[38;5;241m=\u001b[39m message_match\u001b[38;5;241m.\u001b[39mgroup(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m message_match \u001b[38;5;28;01melse\u001b[39;00m exception_str\n\u001b[0;32m--> 257\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m GatewayRuntimeError(GatewayRuntimeErrorType\u001b[38;5;241m.\u001b[39mSERVER_RAISED_EXCEPTION, message) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(exception, grpc\u001b[38;5;241m.\u001b[39m_channel\u001b[38;5;241m.\u001b[39m_InactiveRpcError):\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m GatewayRuntimeError(GatewayRuntimeErrorType\u001b[38;5;241m.\u001b[39mSERVER_CONNECTION_FAILED, exception_str) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mGatewayRuntimeError\u001b[0m: (<GatewayRuntimeErrorType.SERVER_RAISED_EXCEPTION: 3>, 'Too many indexers')"
     ]
    }
   ],
   "source": [
    "def predict(sequence_df:pl.DataFrame, _:pl.DataFrame) -> str:\n",
    "    x = preprocess_sequence(sequence_df)\n",
    "    print(x.shape)\n",
    "    x = torch.unsqueeze(Tensor(x), dim=0)\n",
    "    y_pred = (\n",
    "        model(x)\n",
    "        .max(dim=1)[1]\n",
    "        .numpy()\n",
    "        .squeeze()\n",
    "    )\n",
    "    y_pred_str = meta_data[\"target_names\"][y_pred]\n",
    "\n",
    "    return y_pred_str\n",
    "\n",
    "inference_server = CMIInferenceServer(predict)\n",
    "if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
    "    inference_server.serve()\n",
    "else:\n",
    "    competition_dataset_path = competition_download(\"cmi-detect-behavior-with-sensor-data\")\n",
    "    inference_server.run_local_gateway(\n",
    "        data_paths=(\n",
    "            join(competition_dataset_path, \"train.csv\"),\n",
    "            join(competition_dataset_path, \"train_demographics.csv\"),\n",
    "        )\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 12518947,
     "sourceId": 102335,
     "sourceType": "competition"
    },
    {
     "datasetId": 7827890,
     "sourceId": 12481171,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 397996,
     "modelInstanceId": 381604,
     "sourceId": 474001,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
