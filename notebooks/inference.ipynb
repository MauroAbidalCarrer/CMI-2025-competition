{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":102335,"databundleVersionId":12518947,"sourceType":"competition"},{"sourceId":12443074,"sourceType":"datasetVersion","datasetId":7827890},{"sourceId":467959,"sourceType":"modelInstanceVersion","modelInstanceId":377522,"modelId":397996},{"sourceId":468224,"sourceType":"modelInstanceVersion","modelInstanceId":377700,"modelId":397996}],"dockerImageVersionId":31089,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"fedc55e3","cell_type":"markdown","source":"# Inference notebook","metadata":{}},{"id":"6016c573","cell_type":"markdown","source":"## Imports","metadata":{}},{"id":"55b07ac3","cell_type":"code","source":"import os\nimport json\nfrom os.path import join\nfrom itertools import pairwise, product\n\nimport torch\nimport numpy as np\nimport pandas as pd\nimport polars as pl\nfrom numpy import ndarray\nfrom torch import nn, Tensor\nimport plotly.express as px\nfrom pandas import DataFrame as DF\nfrom kagglehub import competition_download, dataset_download, model_download","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-11T19:55:29.356635Z","iopub.execute_input":"2025-07-11T19:55:29.356993Z","iopub.status.idle":"2025-07-11T19:55:37.109824Z","shell.execute_reply.started":"2025-07-11T19:55:29.356968Z","shell.execute_reply":"2025-07-11T19:55:37.108925Z"}},"outputs":[],"execution_count":1},{"id":"de312267","cell_type":"markdown","source":"## Preprocessing","metadata":{}},{"id":"9c91e2d7","cell_type":"markdown","source":"### Load dataset meta data","metadata":{}},{"id":"c0a316a3","cell_type":"code","source":"meta_data_path = dataset_download(\n    handle=\"mauroabidalcarrer/prepocessed-cmi-2025\",\n    path=\"preprocessed_dataset/full_dataset_meta_data.json\"\n)\nwith open(meta_data_path, \"r\") as fp:\n    meta_data = json.load(fp)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-11T19:55:37.111213Z","iopub.execute_input":"2025-07-11T19:55:37.111760Z","iopub.status.idle":"2025-07-11T19:55:37.447965Z","shell.execute_reply.started":"2025-07-11T19:55:37.111733Z","shell.execute_reply":"2025-07-11T19:55:37.446978Z"}},"outputs":[],"execution_count":2},{"id":"12d06dfa","cell_type":"markdown","source":"### Define preprocessing function","metadata":{}},{"id":"35f8a789","cell_type":"code","source":"META_DATA_COLUMNS = [\n    'row_id',\n    'sequence_type',\n    'sequence_id',\n    'sequence_counter',\n    'subject',\n    'orientation',\n    'behavior',\n    'phase',\n    'gesture',\n]\n\ndef impute_missing_feature_data(df:DF) -> DF:\n    feature_cols = list(set(df.columns) - set(META_DATA_COLUMNS))\n    # Missing ToF values are already imputed by -1 which is inconvinient since we want all missing values to be NaN.    \n    # So we replace them by NaN and then perform imputing.  \n    to_replace = {col: -1.0 for col in df.columns if col.startswith(\"tof\")}\n\n    df.loc[:, feature_cols] = (\n        df\n        .loc[:, feature_cols]\n        # df.replace with np.nan sets dtype to floar64 so we set it back to float32\n        .replace(to_replace, value=np.nan)\n        .astype(\"float32\")\n        .groupby(df[\"sequence_id\"], observed=True, as_index=False)\n        .ffill()\n        .groupby(df[\"sequence_id\"], observed=True, as_index=False)\n        .bfill()\n        # In case there are only nan in the column in the sequence\n        .fillna(0)\n    )\n    return df\n\ndef agg_tof_cols_per_sensor(df:DF) -> DF:\n    for tof_idx in range(1, 6):\n        tof_name = f\"tof_{tof_idx}\"\n        tof_cols = [f\"{tof_name}_v{v_idx}\" for v_idx in range(64)]\n        if any(map(lambda col: col not in df.columns, tof_cols)):\n            print(f\"Some (or) all ToF {tof_idx} columns are not in the df. Maybe you already ran this cell?\")\n            continue\n        df = (\n            df\n            # Need to use a dict otherwise the name of the col will be \"tof_preffix\" instead of the value it contains\n            .assign(**{tof_name:df[tof_cols].mean(axis=\"columns\")})\n            .drop(columns=tof_cols)\n        )\n    return df\n\ndef length_normed_sequence_feat_arr(sequence: DF) -> ndarray:\n    features = (\n        sequence\n        .loc[:, meta_data[\"feature_cols\"]]\n        .values\n    )\n    normed_sequence_len = meta_data[\"pad_seq_len\"]\n    len_diff = abs(normed_sequence_len - len(features))\n    if len(features) < normed_sequence_len:\n        padded_features = np.pad(\n            features,\n            ((len_diff // 2 + len_diff % 2, len_diff // 2), (0, 0)),\n        )\n        return padded_features\n    elif len(features) > normed_sequence_len:\n        return features[len_diff // 2:-len_diff // 2]\n    else:\n        return features\n\ndef preprocess_sequence(sequence_df:pl.DataFrame) -> ndarray:\n    return (\n        sequence_df                     \n        .to_pandas()                            # Convert to pandas dataframe\n        .pipe(impute_missing_feature_data)      # Impute missing data\n        .pipe(agg_tof_cols_per_sensor)          # Aggregate ToF columns\n        .loc[:, meta_data[\"feature_cols\"]]\n        .sub(meta_data[\"mean\"])                 # std norm sequence features\n        .div(meta_data[\"std\"])\n        .pipe(length_normed_sequence_feat_arr)  # get feature ndarray of sequence\n        .T                                      # Transpose to swap channel and X dimensions\n    )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-11T19:55:37.448904Z","iopub.execute_input":"2025-07-11T19:55:37.449217Z","iopub.status.idle":"2025-07-11T19:55:37.461311Z","shell.execute_reply.started":"2025-07-11T19:55:37.449186Z","shell.execute_reply":"2025-07-11T19:55:37.460236Z"}},"outputs":[],"execution_count":3},{"id":"d8e3bcb1","cell_type":"markdown","source":"## Load model","metadata":{}},{"id":"43c2d25b","cell_type":"markdown","source":"### Define model","metadata":{}},{"id":"d651d611","cell_type":"code","source":"class ResidualBlock(nn.Module):\n    def __init__(self, in_chns:int, out_chns:int):\n        super().__init__()\n        self.blocks = nn.Sequential(\n            nn.Conv1d(in_chns, out_chns, kernel_size=3, padding=1),\n            nn.BatchNorm1d(out_chns),\n            nn.ReLU(),\n            nn.Conv1d(out_chns, out_chns, kernel_size=3, padding=1),\n            nn.BatchNorm1d(out_chns),\n        )\n        if in_chns == out_chns:\n            self.skip_connection = nn.Identity() \n        else:\n            # TODO: set bias to False ?\n            self.skip_connection = nn.Sequential(\n                nn.Conv1d(in_chns, out_chns, 1),\n                nn.BatchNorm1d(out_chns)\n            )\n\n    def forward(self, x:Tensor) -> Tensor:\n        activaition_maps = self.skip_connection(x) + self.blocks(x)\n        return nn.functional.relu(activaition_maps)\n\nclass Resnet(nn.Module):\n    def __init__(\n            self,\n            in_channels:int,\n            depth:int,\n            # n_res_block_per_depth:int,\n            mlp_width:int,\n            n_class:int,\n        ):\n        super().__init__()\n        chs_per_depth = [in_channels * 2 ** i for i in range(depth)]\n        blocks_chns_it = pairwise(chs_per_depth)\n        self.res_blocks = [ResidualBlock(in_chns, out_chns) for in_chns, out_chns in blocks_chns_it]\n        self.res_blocks = nn.ModuleList(self.res_blocks)\n        self.mlp_head = nn.Sequential(\n            nn.LazyLinear(mlp_width),\n            nn.ReLU(),\n            nn.Linear(mlp_width, n_class),\n            nn.Softmax(dim=1),\n        )\n        \n        \n    def forward(self, x:Tensor) -> Tensor:\n        activation_maps = x\n        for res_block in self.res_blocks:\n            activation_maps = nn.functional.max_pool1d(res_block(activation_maps), 2)\n        out = activation_maps.view(activation_maps.shape[0], -1)\n        out = self.mlp_head(out)\n        return out\n\nmodel = Resnet(\n    in_channels=17,\n    depth=4,\n    mlp_width=256,\n    n_class=18,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-11T19:55:37.462858Z","iopub.execute_input":"2025-07-11T19:55:37.463119Z","iopub.status.idle":"2025-07-11T19:55:37.540675Z","shell.execute_reply.started":"2025-07-11T19:55:37.463096Z","shell.execute_reply":"2025-07-11T19:55:37.539923Z"}},"outputs":[],"execution_count":4},{"id":"8ec76ba3","cell_type":"markdown","source":"### Load model weights","metadata":{}},{"id":"82d900c9","cell_type":"code","source":"model_state_parent_dir = model_download(\"mauroabidalcarrer/cmi-resnet/pyTorch/normalize-full-dataset\")\nmodel_state_filename = os.listdir(model_state_parent_dir)[0]\nmodel_state_path = join(model_state_parent_dir, model_state_filename)\nmodel_weights_state_dict = torch.load(model_state_path, weights_only=True)[\"model\"]\nmodel.load_state_dict(model_weights_state_dict)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-11T19:55:37.541719Z","iopub.execute_input":"2025-07-11T19:55:37.542015Z","iopub.status.idle":"2025-07-11T19:55:38.215196Z","shell.execute_reply.started":"2025-07-11T19:55:37.541985Z","shell.execute_reply":"2025-07-11T19:55:38.214258Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"<All keys matched successfully>"},"metadata":{}}],"execution_count":5},{"id":"26e8dd35","cell_type":"markdown","source":"## Perform inference","metadata":{}},{"id":"e840a6d9","cell_type":"code","source":"\ndef predict(sequence_df:pl.DataFrame, _:pl.DataFrame) -> str:\n    x = preprocess_sequence(sequence_df)\n    x = torch.unsqueeze(Tensor(x), dim=0)\n    y_pred = (\n        model(x)\n        .max(dim=1)[1]\n        .numpy()\n        .squeeze()\n    )\n    y_pred_str = meta_data[\"target_names\"][y_pred]\n\n    return y_pred_str\n\nCATEGORY_COLUMNS = [\n    'row_id',\n    'sequence_type',\n    'sequence_id',\n    'subject',\n    'orientation',\n    'behavior',\n    'phase',\n    'gesture',\n]\n\nDATASET_DF_DTYPES = {\n    \"acc_x\": \"float32\", \"acc_y\": \"float32\", \"acc_z\": \"float32\",\n    \"thm_1\":\"float32\", \"thm_2\":\"float32\", \"thm_3\":\"float32\", \"thm_4\":\"float32\", \"thm_5\":\"float32\",\n    \"sequence_counter\": \"int32\",\n    **{col: \"category\" for col in CATEGORY_COLUMNS},\n    **{f\"tof_{i_1}_v{i_2}\": \"float32\" for i_1, i_2 in product(range(1, 5), range(64))},\n}\n\n# if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\nimport kaggle_evaluation.cmi_inference_server\ninference_server = kaggle_evaluation.cmi_inference_server.CMIInferenceServer(predict)\ninference_server.serve()\n\n# else:\n#     df_path = competition_download(\n#         handle=\"cmi-detect-behavior-with-sensor-data\",\n#         path=\"train.csv\",\n#     )\n#     df = pd.read_csv(df_path, dtype=DATASET_DF_DTYPES)\n#     for _, sequence in df.groupby(\"sequence_id\", observed=True, as_index=False):\n#         sequence = pl.DataFrame(sequence)\n#         display(predict(sequence, None))\n#         break","metadata":{"trusted":true},"outputs":[],"execution_count":7}]}