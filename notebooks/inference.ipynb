{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-20T14:46:34.348502Z",
     "iopub.status.busy": "2025-07-20T14:46:34.348175Z",
     "iopub.status.idle": "2025-07-20T14:46:42.557489Z",
     "shell.execute_reply": "2025-07-20T14:46:42.556749Z",
     "shell.execute_reply.started": "2025-07-20T14:46:34.348471Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import warnings\n",
    "from os.path import join\n",
    "from tqdm.notebook import tqdm\n",
    "from itertools import pairwise, product\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "from numpy import ndarray\n",
    "from torch import nn, Tensor\n",
    "from numpy.linalg import norm\n",
    "from pandas import DataFrame as DF\n",
    "from scipy.spatial.transform import Rotation\n",
    "# from kagglehub import competition_download, dataset_download, model_download\n",
    "import kagglehub\n",
    "metric_package = kagglehub.package_import('wasupandceacar/cmi-metric', bypass_confirmation=True)\n",
    "\n",
    "import kaggle_evaluation.cmi_inference_server"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supress performance warngings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-20T14:46:42.560011Z",
     "iopub.status.busy": "2025-07-20T14:46:42.559488Z",
     "iopub.status.idle": "2025-07-20T14:46:42.564837Z",
     "shell.execute_reply": "2025-07-20T14:46:42.563908Z",
     "shell.execute_reply.started": "2025-07-20T14:46:42.559983Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    message=(\n",
    "        \"DataFrame is highly fragmented.  This is usually the result of \"\n",
    "        \"calling `frame.insert` many times.*\"\n",
    "    ),\n",
    "    category=pd.errors.PerformanceWarning,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-20T14:46:42.566041Z",
     "iopub.status.busy": "2025-07-20T14:46:42.565741Z",
     "iopub.status.idle": "2025-07-20T14:46:42.600942Z",
     "shell.execute_reply": "2025-07-20T14:46:42.599616Z",
     "shell.execute_reply.started": "2025-07-20T14:46:42.566020Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "QUATERNION_COLS = ['rot_w', 'rot_x', 'rot_y', 'rot_z']\n",
    "GRAVITY_WORLD = np.array([0, 0, 9.81], \"float32\")\n",
    "RAW_ACCELRATION_COLS = [\"acc_x\", \"acc_y\", \"acc_z\"]\n",
    "LINEAR_ACC_COLS = [\"gravity_free_\" + col for col in RAW_ACCELRATION_COLS]\n",
    "COMPETITION_HANDLE = \"cmi-detect-behavior-with-sensor-data\"\n",
    "CATEGORY_COLUMNS = [\n",
    "    'row_id',\n",
    "    'sequence_type',\n",
    "    'sequence_id',\n",
    "    'subject',\n",
    "    'orientation',\n",
    "    'behavior',\n",
    "    'phase',\n",
    "    'gesture',\n",
    "]\n",
    "META_DATA_COLUMNS = [\n",
    "    'row_id',\n",
    "    'sequence_type',\n",
    "    'sequence_id',\n",
    "    'sequence_counter',\n",
    "    'subject',\n",
    "    'orientation',\n",
    "    'behavior',\n",
    "    'phase',\n",
    "    'gesture',\n",
    "]\n",
    "DATASET_DF_DTYPES = {\n",
    "    \"acc_x\": \"float32\", \"acc_y\": \"float32\", \"acc_z\": \"float32\",\n",
    "    \"thm_1\":\"float32\", \"thm_2\":\"float32\", \"thm_3\":\"float32\", \"thm_4\":\"float32\", \"thm_5\":\"float32\",\n",
    "    \"sequence_counter\": \"int32\",\n",
    "    **{col: \"category\" for col in CATEGORY_COLUMNS},\n",
    "    **{f\"tof_{i_1}_v{i_2}\": \"float32\" for i_1, i_2 in product(range(1, 5), range(64))},\n",
    "}\n",
    "PREPROCESSED_DATASET_HANDLE = \"mauroabidalcarrer/prepocessed-cmi-2025\"\n",
    "# The quantile of the sequences len used to pad/truncate during preprocessing\n",
    "SEQUENCE_NORMED_LEN_QUANTILE = 0.95\n",
    "# SAMPLING_FREQUENCY = 10 #Hz\n",
    "N_FOLDS = 5\n",
    "VALIDATION_FRACTION = 0.2\n",
    "TARGET_NAMES = [\n",
    "    \"Above ear - pull hair\",\n",
    "    \"Cheek - pinch skin\",\n",
    "    \"Eyebrow - pull hair\",\n",
    "    \"Eyelash - pull hair\",\n",
    "    \"Feel around in tray and pull out an object\",\n",
    "    \"Forehead - pull hairline\",\n",
    "    \"Forehead - scratch\",\n",
    "    \"Neck - pinch skin\",\n",
    "    \"Neck - scratch\",\n",
    "    \"Text on phone\",\n",
    "    \"Wave hello\",\n",
    "    \"Write name in air\",\n",
    "    \"Write name on leg\",\n",
    "    \"Drink from bottle/cup\",\n",
    "    \"Pinch knee/leg skin\",\n",
    "    \"Pull air toward your face\",\n",
    "    \"Scratch knee/leg skin\",\n",
    "    \"Glasses on/off\"\n",
    "]\n",
    "EPSILON=1e-8\n",
    "DELTA_ROTATION_ANGULAR_VELOCITY_COLS = [\"angular_vel_x\", \"angular_vel_y\", \"angular_vel_z\"]\n",
    "DELTA_ROTATION_AXES_COLS = [\"rotation_axis_x\", \"rotation_axis_y\", \"rotation_axis_z\"]\n",
    "EULER_ANGLES_COLS = [\"euler_x\", \"euler_y\", \"euler_z\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define function to get the feature columns\n",
    "Feature columns change over time so it's better to have a function to get them than manually update a variable every time we add/remove features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-20T14:46:42.602245Z",
     "iopub.status.busy": "2025-07-20T14:46:42.601962Z",
     "iopub.status.idle": "2025-07-20T14:46:42.633221Z",
     "shell.execute_reply": "2025-07-20T14:46:42.632225Z",
     "shell.execute_reply.started": "2025-07-20T14:46:42.602220Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_feature_cols(df:DF) -> list[str]:\n",
    "    return list(set(df.columns) - set(META_DATA_COLUMNS) - set(TARGET_NAMES))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset meta data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-20T14:46:42.635004Z",
     "iopub.status.busy": "2025-07-20T14:46:42.634316Z",
     "iopub.status.idle": "2025-07-20T14:46:42.754376Z",
     "shell.execute_reply": "2025-07-20T14:46:42.753216Z",
     "shell.execute_reply.started": "2025-07-20T14:46:42.634964Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "meta_data_path = kagglehub.dataset_download(\n",
    "    handle=\"mauroabidalcarrer/prepocessed-cmi-2025\",\n",
    "    path=\"preprocessed_dataset/full_dataset_meta_data.json\"\n",
    ")\n",
    "with open(meta_data_path, \"r\") as fp:\n",
    "    meta_data = json.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define function to get the feature columns\n",
    "Feature columns change over time so it's better to have a function to get them than manually update a variable every time we add/remove features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-20T14:46:42.755466Z",
     "iopub.status.busy": "2025-07-20T14:46:42.755229Z",
     "iopub.status.idle": "2025-07-20T14:46:42.760461Z",
     "shell.execute_reply": "2025-07-20T14:46:42.759333Z",
     "shell.execute_reply.started": "2025-07-20T14:46:42.755448Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_feature_cols(df:DF) -> list[str]:\n",
    "    return list(set(df.columns) - set(META_DATA_COLUMNS) - set(TARGET_NAMES))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define preprocessing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-20T14:46:42.763202Z",
     "iopub.status.busy": "2025-07-20T14:46:42.762869Z",
     "iopub.status.idle": "2025-07-20T14:46:42.787430Z",
     "shell.execute_reply": "2025-07-20T14:46:42.786255Z",
     "shell.execute_reply.started": "2025-07-20T14:46:42.763179Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_fillna_val_per_feature_col(df:DF) -> dict:\n",
    "    return {col: 1.0 if col == 'rot_w' else 0 for col in get_feature_cols(df)}\n",
    "\n",
    "def imputed_features(df:DF) -> DF:\n",
    "    # Missing ToF values are already imputed by -1 which is inconvinient since we want all missing values to be NaN.    \n",
    "    # So we replace them by NaN and then perform imputing.  \n",
    "    tof_vals_to_nan = {col: -1.0 for col in df.columns if col.startswith(\"tof\")}\n",
    "    # fillna_val_per_col = {col: 1.0 if col == 'rot_w' else 0 for col in df.columns}\n",
    "    #print(get_fillna_val_per_feature_col(df))\n",
    "    df[get_feature_cols(df)] = (\n",
    "        df\n",
    "        .loc[:, get_feature_cols(df)]\n",
    "        # df.replace with np.nan sets dtype to floar64 so we set it back to float32\n",
    "        .replace(tof_vals_to_nan, value=np.nan)\n",
    "        .astype(\"float32\")\n",
    "        .groupby(df[\"sequence_id\"], observed=True, as_index=False)\n",
    "        .ffill()\n",
    "        .groupby(df[\"sequence_id\"], observed=True, as_index=False)\n",
    "        .bfill()\n",
    "        # In case there are only nan in the column in the sequence\n",
    "        .fillna(get_fillna_val_per_feature_col(df))\n",
    "    )\n",
    "    return df\n",
    "\n",
    "def norm_quat_rotations(df:DF) -> DF:\n",
    "    df[QUATERNION_COLS] /= np.linalg.norm(df[QUATERNION_COLS], axis=1, keepdims=True)\n",
    "    return df\n",
    "\n",
    "def add_linear_acc_cols(df:DF) -> DF:\n",
    "    # Vectorized version of https://www.kaggle.com/code/wasupandceacar/lb-0-82-5fold-single-bert-model#Dataset `remove_gravity_from_acc`\n",
    "    rotations:Rotation = Rotation.from_quat(df[QUATERNION_COLS])\n",
    "    gravity_sensor_frame = rotations.apply(GRAVITY_WORLD, inverse=True).astype(\"float32\")\n",
    "    df[LINEAR_ACC_COLS] = df[RAW_ACCELRATION_COLS] - gravity_sensor_frame\n",
    "    return df\n",
    "\n",
    "def add_acc_magnitude(df:DF, acc_cols:list[str], acc_mag_col_name:str) -> DF:\n",
    "    return df.assign(**{acc_mag_col_name: np.linalg.norm(df.loc[:, acc_cols], axis=1)})\n",
    "\n",
    "def add_quat_angle_mag(df:DF) -> DF:\n",
    "    return df.assign(quat_rot_mag=np.arccos(df[\"rot_w\"]) * 2)\n",
    "\n",
    "def add_angular_velocity_features(df:DF) -> DF:\n",
    "    rotations = Rotation.from_quat(df[QUATERNION_COLS])\n",
    "    delta_rotations = rotations[1:] * rotations[:-1].inv()\n",
    "    delta_rot_velocity = delta_rotations.as_rotvec()\n",
    "    # Add extra line to avoid shape mismatch\n",
    "    delta_rot_velocity = np.vstack((np.zeros((1, 3)), delta_rot_velocity))\n",
    "    delta_rot_magnitude = norm(delta_rot_velocity, axis=1, keepdims=True)\n",
    "    delta_rot_axes = delta_rot_velocity / (delta_rot_magnitude + EPSILON)\n",
    "    df[DELTA_ROTATION_ANGULAR_VELOCITY_COLS] = delta_rot_velocity\n",
    "    df[DELTA_ROTATION_AXES_COLS] = delta_rot_axes\n",
    "    df[\"delta_rot_mag\"] = delta_rot_magnitude.squeeze()\n",
    "\n",
    "    return df\n",
    "\n",
    "def rot_euler_angles(df:DF) -> ndarray:\n",
    "    df[EULER_ANGLES_COLS] = (\n",
    "        Rotation\n",
    "        .from_quat(df[QUATERNION_COLS])\n",
    "        .as_euler(\"xyz\")\n",
    "        .squeeze()\n",
    "    )\n",
    "    return df\n",
    "\n",
    "def agg_tof_cols_per_sensor(df:DF) -> DF:\n",
    "    for tof_idx in range(1, 6):\n",
    "        tof_name = f\"tof_{tof_idx}\"\n",
    "        tof_cols = [f\"{tof_name}_v{v_idx}\" for v_idx in range(64)]\n",
    "        if any(map(lambda col: col not in df.columns, tof_cols)):\n",
    "            print(f\"Some (or) all ToF {tof_idx} columns are not in the df. Maybe you already ran this cell?\")\n",
    "            continue\n",
    "        df = (\n",
    "            df\n",
    "            # Need to use a dict otherwise the name of the col will be \"tof_preffix\" instead of the value it contains\n",
    "            .assign(**{tof_name:df[tof_cols].mean(axis=\"columns\")})\n",
    "            .drop(columns=tof_cols)\n",
    "        )\n",
    "    return df\n",
    "\n",
    "def add_diff_features(df:DF) -> DF:\n",
    "    df[[col + \"_diff\" for col in get_feature_cols(df)]] = (\n",
    "        df\n",
    "        .groupby(\"sequence_id\", observed=True)\n",
    "        [get_feature_cols(df)]\n",
    "        .diff()\n",
    "        .fillna(get_fillna_val_per_feature_col(df))\n",
    "        .values\n",
    "    )\n",
    "    return df\n",
    "\n",
    "def length_normed_sequence_feat_arr(sequence: DF) -> ndarray:\n",
    "    features = (\n",
    "        sequence\n",
    "        .loc[:, meta_data[\"feature_cols\"]]\n",
    "        .values\n",
    "    )\n",
    "    normed_sequence_len = meta_data[\"pad_seq_len\"]\n",
    "    len_diff = abs(normed_sequence_len - len(features))\n",
    "    if len(features) < normed_sequence_len:\n",
    "        padded_features = np.pad(\n",
    "            features,\n",
    "            ((len_diff // 2 + len_diff % 2, len_diff // 2), (0, 0)),\n",
    "        )\n",
    "        return padded_features\n",
    "    elif len(features) > normed_sequence_len:\n",
    "        return features[len_diff // 2:-len_diff // 2]\n",
    "    else:\n",
    "        return features\n",
    "\n",
    "def preprocess_sequence(sequence_df:pl.DataFrame) -> ndarray:\n",
    "    return (\n",
    "        sequence_df                     \n",
    "        .to_pandas()                            # Convert to pandas dataframe.\n",
    "        .pipe(imputed_features)                 # Impute missing data.\n",
    "        .pipe(norm_quat_rotations)              # Norm quaternions\n",
    "        .pipe(add_linear_acc_cols)              # Add gravity free acceleration.\n",
    "        .pipe(add_acc_magnitude, RAW_ACCELRATION_COLS, \"raw_acc_mag\")\n",
    "        .pipe(add_acc_magnitude, LINEAR_ACC_COLS, \"linear_acc_mag\")\n",
    "        .pipe(add_quat_angle_mag)\n",
    "        .pipe(add_angular_velocity_features)\n",
    "        .pipe(rot_euler_angles)                 # Add rotation acc expressed as euler angles.\n",
    "        .pipe(agg_tof_cols_per_sensor)          # Aggregate ToF columns.\n",
    "        .pipe(add_diff_features)                # \n",
    "        .loc[:, meta_data[\"feature_cols\"]]      # Retain only the usefull columns a.k.a features.\n",
    "        .sub(meta_data[\"mean\"])                 # Subtract features by their mean, std norm pt.1.\n",
    "        .div(meta_data[\"std\"])                  # Divide by Standard deviation, std norm pt.2.\n",
    "        .pipe(length_normed_sequence_feat_arr)  # get feature ndarray of sequence.\n",
    "        .T                                      # Transpose to swap channel and X dimensions.\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_chns:int, out_chns:int):\n",
    "        super().__init__()\n",
    "        self.blocks = nn.Sequential(\n",
    "            nn.Conv1d(in_chns, out_chns, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(out_chns),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(out_chns, out_chns, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(out_chns),\n",
    "        )\n",
    "        if in_chns == out_chns:\n",
    "            self.skip_connection = nn.Identity() \n",
    "        else:\n",
    "            # TODO: set bias to False ?\n",
    "            self.skip_connection = nn.Sequential(\n",
    "                nn.Conv1d(in_chns, out_chns, 1),\n",
    "                nn.BatchNorm1d(out_chns)\n",
    "            )\n",
    "\n",
    "    def forward(self, x:Tensor) -> Tensor:\n",
    "        activaition_maps = self.skip_connection(x) + self.blocks(x)\n",
    "        return nn.functional.relu(activaition_maps)\n",
    "\n",
    "class Resnet(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            in_channels:int,\n",
    "            depth:int,\n",
    "            # n_res_block_per_depth:int,\n",
    "            mlp_width:int,\n",
    "            n_class:int,\n",
    "        ):\n",
    "        super().__init__()\n",
    "        chs_per_depth = [in_channels * 2 ** i for i in range(depth)]\n",
    "        blocks_chns_it = pairwise(chs_per_depth)\n",
    "        self.res_blocks = [ResidualBlock(in_chns, out_chns) for in_chns, out_chns in blocks_chns_it]\n",
    "        self.res_blocks = nn.ModuleList(self.res_blocks)\n",
    "        self.mlp_head = nn.Sequential(\n",
    "            nn.LazyLinear(mlp_width),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(mlp_width, n_class),\n",
    "            nn.Softmax(dim=1),\n",
    "        )\n",
    "        \n",
    "        \n",
    "    def forward(self, x:Tensor) -> Tensor:\n",
    "        activation_maps = x\n",
    "        for res_block in self.res_blocks:\n",
    "            activation_maps = nn.functional.max_pool1d(res_block(activation_maps), 2)\n",
    "        out = activation_maps.view(activation_maps.shape[0], -1)\n",
    "        out = self.mlp_head(out)\n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-20T14:46:42.851425Z",
     "iopub.status.busy": "2025-07-20T14:46:42.851121Z",
     "iopub.status.idle": "2025-07-20T14:46:42.879560Z",
     "shell.execute_reply": "2025-07-20T14:46:42.878021Z",
     "shell.execute_reply.started": "2025-07-20T14:46:42.851400Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input channels: 66\n"
     ]
    }
   ],
   "source": [
    "def mk_model() -> nn.Module:\n",
    "    nb_in_chans = len(meta_data[\"feature_cols\"])\n",
    "    return (\n",
    "        Resnet(\n",
    "            in_channels=nb_in_chans,\n",
    "            depth=4,\n",
    "            mlp_width=256,\n",
    "            n_class=18\n",
    "        )\n",
    "        .to(device)\n",
    "    )\n",
    "\n",
    "print(\"input channels:\", len(meta_data[\"feature_cols\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-20T14:46:42.880937Z",
     "iopub.status.busy": "2025-07-20T14:46:42.880621Z",
     "iopub.status.idle": "2025-07-20T14:46:52.825933Z",
     "shell.execute_reply": "2025-07-20T14:46:52.824565Z",
     "shell.execute_reply.started": "2025-07-20T14:46:42.880913Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_state_parent_dir = kagglehub.model_download(\"mauroabidalcarrer/cmi-resnet/pyTorch/more_imu_features_epoch_37\")\n",
    "model_state_filename = os.listdir(model_state_parent_dir)[0]\n",
    "model_state_path = join(model_state_parent_dir, model_state_filename)\n",
    "model_weights_state_dict = torch.load(model_state_path, weights_only=True, map_location=device)[\"model\"]\n",
    "model = mk_model()\n",
    "model.load_state_dict(model_weights_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-20T14:46:52.828649Z",
     "iopub.status.busy": "2025-07-20T14:46:52.827746Z",
     "iopub.status.idle": "2025-07-20T14:46:52.836107Z",
     "shell.execute_reply": "2025-07-20T14:46:52.835107Z",
     "shell.execute_reply.started": "2025-07-20T14:46:52.828620Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Resnet(\n",
       "  (res_blocks): ModuleList(\n",
       "    (0): ResidualBlock(\n",
       "      (blocks): Sequential(\n",
       "        (0): Conv1d(66, 132, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv1d(132, 132, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (4): BatchNorm1d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (skip_connection): Sequential(\n",
       "        (0): Conv1d(66, 132, kernel_size=(1,), stride=(1,))\n",
       "        (1): BatchNorm1d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): ResidualBlock(\n",
       "      (blocks): Sequential(\n",
       "        (0): Conv1d(132, 264, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(264, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv1d(264, 264, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (4): BatchNorm1d(264, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (skip_connection): Sequential(\n",
       "        (0): Conv1d(132, 264, kernel_size=(1,), stride=(1,))\n",
       "        (1): BatchNorm1d(264, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (2): ResidualBlock(\n",
       "      (blocks): Sequential(\n",
       "        (0): Conv1d(264, 528, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv1d(528, 528, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (4): BatchNorm1d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (skip_connection): Sequential(\n",
       "        (0): Conv1d(264, 528, kernel_size=(1,), stride=(1,))\n",
       "        (1): BatchNorm1d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (mlp_head): Sequential(\n",
       "    (0): LazyLinear(in_features=0, out_features=256, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=256, out_features=18, bias=True)\n",
       "    (3): Softmax(dim=1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(sequence_df:pl.DataFrame, _:pl.DataFrame) -> str:\n",
    "    x = preprocess_sequence(sequence_df)\n",
    "    x = torch.unsqueeze(Tensor(x), dim=0).to(device)\n",
    "    y_pred = (\n",
    "        model(x)\n",
    "        .max(dim=1)[1]\n",
    "        .cpu()\n",
    "        .numpy()\n",
    "        .squeeze()\n",
    "    )\n",
    "    y_pred_str = meta_data[\"target_names\"][y_pred]\n",
    "\n",
    "    return y_pred_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_with_competition_metrics(predict_func:callable, train_df:DF, nb_train_seq_to_test:None) -> float:\n",
    "    train_seq_grp = train_df.groupby(by=\"sequence_id\")\n",
    "    competition_metric = metric_package.Metric()\n",
    "    nb_train_seq_to_test = nb_train_seq_to_test if nb_train_seq_to_test else len(train_seq_grp)\n",
    "    for seq_idx, (seq_id, seq) in tqdm(enumerate(train_seq_grp), total=nb_train_seq_to_test):\n",
    "        remove_non_imu_features = seq_idx % 2 == 0\n",
    "        if remove_non_imu_features:\n",
    "            non_imu_features = [col for col in seq.columns if col.startswith((\"thm\", \"tof\"))]\n",
    "            seq.loc[:, non_imu_features] = 0\n",
    "        x_seq = seq.drop(columns=[\"gesture\"])\n",
    "        x_seq = pl.DataFrame(seq)\n",
    "        y_pred = predict_func(x_seq, None)\n",
    "        competition_metric.add(y_pred, seq[\"gesture\"].iloc[0])\n",
    "        if seq_idx >= nb_train_seq_to_test:\n",
    "            break\n",
    "\n",
    "    return competition_metric.score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def local_evaluation(server, predict_func:callable):\n",
    "    competition_dataset_path = kagglehub.competition_download(\"cmi-detect-behavior-with-sensor-data\")\n",
    "    test_df = pl.read_csv(join(competition_dataset_path, \"test.csv\"))\n",
    "    print(\"testing the capacity of the predict function on test sequences:\")\n",
    "    for seq_id, seq in test_df.group_by(\"sequence_id\"):\n",
    "        print(predict(seq, None))\n",
    "    print(\"Evaluating the score of the TRAINING dataset:\")\n",
    "    train_df = pd.read_csv(join(competition_dataset_path, \"train.csv\"))\n",
    "    train_score = evaluate_with_competition_metrics(predict_func, train_df, 2000)\n",
    "    print(\"train score:\", train_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-20T14:46:52.837348Z",
     "iopub.status.busy": "2025-07-20T14:46:52.837086Z",
     "iopub.status.idle": "2025-07-20T14:47:12.744975Z",
     "shell.execute_reply": "2025-07-20T14:47:12.743158Z",
     "shell.execute_reply.started": "2025-07-20T14:46:52.837329Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing the capacity of the predict function on test sequences:\n",
      "Forehead - pull hairline\n",
      "Feel around in tray and pull out an object\n",
      "Evaluating the score of the TRAINING dataset:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "999a34bb422b4568abe5a6bb6b67e570",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score: 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/repos/CMI-2025-competition/src/kaggle_evaluation/core/templates.py:136: RuntimeWarning: 921 seconds elapsed before server startup.\n",
      "                This exceeds the startup time limit of 900 seconds that the gateway will enforce\n",
      "                during the rerun on the hidden test set. Start the server before performing any time consuming steps.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m      7\u001b[39m inference_server.run_local_gateway(\n\u001b[32m      8\u001b[39m     data_paths=(\n\u001b[32m      9\u001b[39m         join(competition_dataset_path, \u001b[33m\"\u001b[39m\u001b[33mtest.csv\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     10\u001b[39m         join(competition_dataset_path, \u001b[33m\"\u001b[39m\u001b[33mtest_demographics.csv\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     11\u001b[39m     )\n\u001b[32m     12\u001b[39m )\n\u001b[32m     13\u001b[39m inference_server = kaggle_evaluation.cmi_inference_server.CMIInferenceServer(predict)\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m \u001b[43minference_server\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_local_gateway\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata_paths\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m        \u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompetition_dataset_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtrain.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m        \u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompetition_dataset_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtrain_demographics.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/CMI-2025-competition/src/kaggle_evaluation/core/templates.py:147\u001b[39m, in \u001b[36mInferenceServer.run_local_gateway\u001b[39m\u001b[34m(self, data_paths, file_share_dir, *args, **kwargs)\u001b[39m\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    146\u001b[39m     \u001b[38;5;28mself\u001b[39m.gateway = \u001b[38;5;28mself\u001b[39m._get_gateway_for_test(data_paths, file_share_dir, *args, **kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgateway\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    148\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    149\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m err \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/CMI-2025-competition/src/kaggle_evaluation/core/templates.py:84\u001b[39m, in \u001b[36mGateway.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     82\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     83\u001b[39m     \u001b[38;5;28mself\u001b[39m.unpack_data_paths()\n\u001b[32m---> \u001b[39m\u001b[32m84\u001b[39m     predictions, row_ids = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_all_predictions\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     85\u001b[39m     \u001b[38;5;28mself\u001b[39m.write_submission(predictions, row_ids)\n\u001b[32m     86\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m kaggle_evaluation.core.base_gateway.GatewayRuntimeError \u001b[38;5;28;01mas\u001b[39;00m gre:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/CMI-2025-competition/src/kaggle_evaluation/core/templates.py:56\u001b[39m, in \u001b[36mGateway.get_all_predictions\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     54\u001b[39m all_row_ids = []\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m data_batch, row_ids \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.generate_data_batches():\n\u001b[32m---> \u001b[39m\u001b[32m56\u001b[39m     predictions = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mdata_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     57\u001b[39m     \u001b[38;5;28mself\u001b[39m.validate_prediction_batch(predictions, row_ids)\n\u001b[32m     58\u001b[39m     all_predictions.append(predictions)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/CMI-2025-competition/src/kaggle_evaluation/core/templates.py:70\u001b[39m, in \u001b[36mGateway.predict\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     63\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"self.predict will send all data in args and kwargs to the user container, and\u001b[39;00m\n\u001b[32m     64\u001b[39m \u001b[33;03minstruct the user container to generate a `predict` response.\u001b[39;00m\n\u001b[32m     65\u001b[39m \n\u001b[32m     66\u001b[39m \u001b[33;03mReturns:\u001b[39;00m\n\u001b[32m     67\u001b[39m \u001b[33;03m    Any: The prediction from the user container.\u001b[39;00m\n\u001b[32m     68\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     69\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m70\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mpredict\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     72\u001b[39m     \u001b[38;5;28mself\u001b[39m.handle_server_error(e, \u001b[33m'\u001b[39m\u001b[33mpredict\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/CMI-2025-competition/src/kaggle_evaluation/core/relay.py:311\u001b[39m, in \u001b[36mClient.send\u001b[39m\u001b[34m(self, name, *args, **kwargs)\u001b[39m\n\u001b[32m    300\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Sends a single KaggleEvaluation request.\u001b[39;00m\n\u001b[32m    301\u001b[39m \n\u001b[32m    302\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    308\u001b[39m \u001b[33;03m    The response, which is of one of several allow-listed data types.\u001b[39;00m\n\u001b[32m    309\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    310\u001b[39m request = \u001b[38;5;28mself\u001b[39m.serialize_request(name, *args, **kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m311\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_with_deadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    312\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m _deserialize(response.payload)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/CMI-2025-competition/src/kaggle_evaluation/core/relay.py:258\u001b[39m, in \u001b[36mClient._send_with_deadline\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    256\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._made_first_connection:\n\u001b[32m    257\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m258\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstub\u001b[49m\u001b[43m.\u001b[49m\u001b[43mSend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwait_for_ready\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mendpoint_deadline_seconds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    259\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m _InactiveRpcError \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    260\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mStatusCode.DEADLINE_EXCEEDED\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(err):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/venv/CMI/lib/python3.11/site-packages/grpc/_channel.py:1178\u001b[39m, in \u001b[36m_UnaryUnaryMultiCallable.__call__\u001b[39m\u001b[34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[39m\n\u001b[32m   1166\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\n\u001b[32m   1167\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1168\u001b[39m     request: Any,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1173\u001b[39m     compression: Optional[grpc.Compression] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1174\u001b[39m ) -> Any:\n\u001b[32m   1175\u001b[39m     (\n\u001b[32m   1176\u001b[39m         state,\n\u001b[32m   1177\u001b[39m         call,\n\u001b[32m-> \u001b[39m\u001b[32m1178\u001b[39m     ) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_blocking\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1179\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwait_for_ready\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompression\u001b[49m\n\u001b[32m   1180\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1181\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _end_unary_response_blocking(state, call, \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/venv/CMI/lib/python3.11/site-packages/grpc/_channel.py:1162\u001b[39m, in \u001b[36m_UnaryUnaryMultiCallable._blocking\u001b[39m\u001b[34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[39m\n\u001b[32m   1145\u001b[39m state.target = _common.decode(\u001b[38;5;28mself\u001b[39m._target)\n\u001b[32m   1146\u001b[39m call = \u001b[38;5;28mself\u001b[39m._channel.segregated_call(\n\u001b[32m   1147\u001b[39m     cygrpc.PropagationConstants.GRPC_PROPAGATE_DEFAULTS,\n\u001b[32m   1148\u001b[39m     \u001b[38;5;28mself\u001b[39m._method,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1160\u001b[39m     \u001b[38;5;28mself\u001b[39m._registered_call_handle,\n\u001b[32m   1161\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1162\u001b[39m event = \u001b[43mcall\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnext_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1163\u001b[39m _handle_event(event, state, \u001b[38;5;28mself\u001b[39m._response_deserializer)\n\u001b[32m   1164\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m state, call\n",
      "\u001b[36mFile \u001b[39m\u001b[32msrc/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi:388\u001b[39m, in \u001b[36mgrpc._cython.cygrpc.SegregatedCall.next_event\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32msrc/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi:213\u001b[39m, in \u001b[36mgrpc._cython.cygrpc._next_call_event\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/venv/CMI/lib/python3.11/threading.py:264\u001b[39m, in \u001b[36mCondition.__enter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    261\u001b[39m     \u001b[38;5;28mself\u001b[39m._lock._at_fork_reinit()\n\u001b[32m    262\u001b[39m     \u001b[38;5;28mself\u001b[39m._waiters.clear()\n\u001b[32m--> \u001b[39m\u001b[32m264\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__enter__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    265\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._lock.\u001b[34m__enter__\u001b[39m()\n\u001b[32m    267\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args):\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1753027382.537351   16309 chttp2_transport.cc:1182] ipv6:%5B::1%5D:60053: Got goaway [2] err=UNAVAILABLE:GOAWAY received; Error code: 2; Debug Text: Cancelling all calls {grpc_status:14, http2_error:2, created_time:\"2025-07-20T16:03:02.53725003+00:00\"}\n"
     ]
    }
   ],
   "source": [
    "inference_server = kaggle_evaluation.cmi_inference_server.CMIInferenceServer(predict)\n",
    "if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
    "    inference_server.serve()\n",
    "else:\n",
    "    competition_dataset_path = kagglehub.competition_download(\"cmi-detect-behavior-with-sensor-data\")\n",
    "    local_evaluation(inference_server, predict)\n",
    "    inference_server.run_local_gateway(\n",
    "        data_paths=(\n",
    "            join(competition_dataset_path, \"test.csv\"),\n",
    "            join(competition_dataset_path, \"test_demographics.csv\"),\n",
    "        )\n",
    "    )\n",
    "    inference_server = kaggle_evaluation.cmi_inference_server.CMIInferenceServer(predict)\n",
    "    inference_server.run_local_gateway(\n",
    "        data_paths=(\n",
    "            join(competition_dataset_path, \"train.csv\"),\n",
    "            join(competition_dataset_path, \"train_demographics.csv\"),\n",
    "        )\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 12518947,
     "sourceId": 102335,
     "sourceType": "competition"
    },
    {
     "databundleVersionId": 13100227,
     "datasetId": 7827890,
     "sourceId": 12518488,
     "sourceType": "datasetVersion"
    },
    {
     "databundleVersionId": 13108964,
     "modelInstanceId": 385240,
     "sourceId": 479888,
     "sourceType": "modelInstanceVersion"
    },
    {
     "databundleVersionId": 13107964,
     "modelInstanceId": 385166,
     "sourceId": 479788,
     "sourceType": "modelInstanceVersion"
    },
    {
     "databundleVersionId": 13100407,
     "modelInstanceId": 384629,
     "sourceId": 478689,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
