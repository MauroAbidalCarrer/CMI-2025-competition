{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-16T16:13:38.487900Z",
     "iopub.status.busy": "2025-07-16T16:13:38.487576Z",
     "iopub.status.idle": "2025-07-16T16:13:38.493959Z",
     "shell.execute_reply": "2025-07-16T16:13:38.492831Z",
     "shell.execute_reply.started": "2025-07-16T16:13:38.487873Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from os.path import join\n",
    "from itertools import pairwise, product\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "from numpy import ndarray\n",
    "from torch import nn, Tensor\n",
    "import plotly.express as px\n",
    "from scipy.spatial.transform import Rotation\n",
    "from pandas import DataFrame as DF\n",
    "from kagglehub import competition_download, dataset_download, model_download\n",
    "\n",
    "import kaggle_evaluation.cmi_inference_server"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset meta data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-16T16:13:38.496146Z",
     "iopub.status.busy": "2025-07-16T16:13:38.495794Z",
     "iopub.status.idle": "2025-07-16T16:13:38.725526Z",
     "shell.execute_reply": "2025-07-16T16:13:38.724543Z",
     "shell.execute_reply.started": "2025-07-16T16:13:38.496111Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "meta_data_path = dataset_download(\n",
    "    handle=\"mauroabidalcarrer/prepocessed-cmi-2025\",\n",
    "    path=\"preprocessed_dataset/full_dataset_meta_data.json\"\n",
    ")\n",
    "with open(meta_data_path, \"r\") as fp:\n",
    "    meta_data = json.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define preprocessing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-16T16:13:38.727028Z",
     "iopub.status.busy": "2025-07-16T16:13:38.726657Z",
     "iopub.status.idle": "2025-07-16T16:13:38.743199Z",
     "shell.execute_reply": "2025-07-16T16:13:38.741949Z",
     "shell.execute_reply.started": "2025-07-16T16:13:38.726996Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "META_DATA_COLUMNS = [\n",
    "    'row_id',\n",
    "    'sequence_type',\n",
    "    'sequence_id',\n",
    "    'sequence_counter',\n",
    "    'subject',\n",
    "    'orientation',\n",
    "    'behavior',\n",
    "    'phase',\n",
    "    'gesture',\n",
    "]\n",
    "EULER_ANGLES_COLS = [\"euler_x\", \"euler_y\", \"euler_z\"]\n",
    "QUATERNION_COLS = ['rot_w', 'rot_x', 'rot_y', 'rot_z']\n",
    "def rot_euler_angles(seq:DF) -> ndarray:\n",
    "    try:\n",
    "        quat_cols = seq[QUATERNION_COLS]\n",
    "        quat_cols /= np.linalg.norm(quat_cols, axis=1, keepdims=True)\n",
    "        rotation = Rotation.from_quat(quat_cols.values)\n",
    "        euler_data = rotation.as_euler(\"xyz\").squeeze()\n",
    "        angles_df = DF(\n",
    "            data=euler_data,\n",
    "            columns=EULER_ANGLES_COLS\n",
    "        )\n",
    "        return angles_df\n",
    "    except ValueError as e:\n",
    "        print(quat_cols)\n",
    "        raise e\n",
    "\n",
    "def add_rot_euler_angles_to_df(df:DF) -> DF:\n",
    "    df.loc[:, EULER_ANGLES_COLS] = (\n",
    "        df\n",
    "        .groupby(\"sequence_id\", as_index=False, observed=True)\n",
    "        .apply(rot_euler_angles, include_groups=False)\n",
    "        .loc[:, EULER_ANGLES_COLS]\n",
    "        .values\n",
    "    )\n",
    "    return df\n",
    "\n",
    "def impute_missing_feature_data(df:DF) -> DF:\n",
    "    feature_cols = list(set(df.columns) - set(META_DATA_COLUMNS))\n",
    "    # Missing ToF values are already imputed by -1 which is inconvinient since we want all missing values to be NaN.    \n",
    "    # So we replace them by NaN and then perform imputing.  \n",
    "    tof_vals_to_nan = {col: -1.0 for col in df.columns if col.startswith(\"tof\")}\n",
    "    # In case the sequence is entirely NaN we need to fill the rotation by unit quaternion which is [1, 0, 0, 0]\n",
    "    fillna_val_per_col = {col: 1.0 if col == 'rot_w' else 0 for col in df.columns}\n",
    "    \n",
    "    df[feature_cols] = (\n",
    "        df\n",
    "        .loc[:, feature_cols]\n",
    "        # df.replace with np.nan sets dtype to floar64 so we set it back to float32\n",
    "        .replace(tof_vals_to_nan, value=np.nan)\n",
    "        .astype(\"float32\")\n",
    "        .groupby(df[\"sequence_id\"], observed=True, as_index=False)\n",
    "        .ffill()\n",
    "        .groupby(df[\"sequence_id\"], observed=True, as_index=False)\n",
    "        .bfill()\n",
    "        # In case there are only nan in the column in the sequence\n",
    "        .fillna(fillna_val_per_col)\n",
    "    )\n",
    "    return df\n",
    "\n",
    "def agg_tof_cols_per_sensor(df:DF) -> DF:\n",
    "    for tof_idx in range(1, 6):\n",
    "        tof_name = f\"tof_{tof_idx}\"\n",
    "        tof_cols = [f\"{tof_name}_v{v_idx}\" for v_idx in range(64)]\n",
    "        if any(map(lambda col: col not in df.columns, tof_cols)):\n",
    "            print(f\"Some (or) all ToF {tof_idx} columns are not in the df. Maybe you already ran this cell?\")\n",
    "            continue\n",
    "        df = (\n",
    "            df\n",
    "            # Need to use a dict otherwise the name of the col will be \"tof_preffix\" instead of the value it contains\n",
    "            .assign(**{tof_name:df[tof_cols].mean(axis=\"columns\")})\n",
    "            .drop(columns=tof_cols)\n",
    "        )\n",
    "    return df\n",
    "\n",
    "def length_normed_sequence_feat_arr(sequence: DF) -> ndarray:\n",
    "    features = (\n",
    "        sequence\n",
    "        .loc[:, meta_data[\"feature_cols\"]]\n",
    "        .values\n",
    "    )\n",
    "    normed_sequence_len = meta_data[\"pad_seq_len\"]\n",
    "    len_diff = abs(normed_sequence_len - len(features))\n",
    "    if len(features) < normed_sequence_len:\n",
    "        padded_features = np.pad(\n",
    "            features,\n",
    "            ((len_diff // 2 + len_diff % 2, len_diff // 2), (0, 0)),\n",
    "        )\n",
    "        return padded_features\n",
    "    elif len(features) > normed_sequence_len:\n",
    "        return features[len_diff // 2:-len_diff // 2]\n",
    "    else:\n",
    "        return features\n",
    "\n",
    "def preprocess_sequence(sequence_df:pl.DataFrame) -> ndarray:\n",
    "    return (\n",
    "        sequence_df                     \n",
    "        .to_pandas()                            # Convert to pandas dataframe\n",
    "        .pipe(impute_missing_feature_data)      # Impute missing data\n",
    "        .pipe(add_rot_euler_angles_to_df)       # Add rotation acc expressed as euler angles.\n",
    "        .pipe(agg_tof_cols_per_sensor)          # Aggregate ToF columns\n",
    "        .loc[:, meta_data[\"feature_cols\"]]\n",
    "        .sub(meta_data[\"mean\"])                 # std norm sequence features\n",
    "        .div(meta_data[\"std\"])\n",
    "        .pipe(length_normed_sequence_feat_arr)  # get feature ndarray of sequence\n",
    "        .T                                      # Transpose to swap channel and X dimensions\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-16T16:13:38.744701Z",
     "iopub.status.busy": "2025-07-16T16:13:38.744376Z",
     "iopub.status.idle": "2025-07-16T16:13:38.779990Z",
     "shell.execute_reply": "2025-07-16T16:13:38.778613Z",
     "shell.execute_reply.started": "2025-07-16T16:13:38.744678Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_chns:int, out_chns:int):\n",
    "        super().__init__()\n",
    "        self.blocks = nn.Sequential(\n",
    "            nn.Conv1d(in_chns, out_chns, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(out_chns),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(out_chns, out_chns, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(out_chns),\n",
    "        )\n",
    "        if in_chns == out_chns:\n",
    "            self.skip_connection = nn.Identity() \n",
    "        else:\n",
    "            # TODO: set bias to False ?\n",
    "            self.skip_connection = nn.Sequential(\n",
    "                nn.Conv1d(in_chns, out_chns, 1),\n",
    "                nn.BatchNorm1d(out_chns)\n",
    "            )\n",
    "\n",
    "    def forward(self, x:Tensor) -> Tensor:\n",
    "        activaition_maps = self.skip_connection(x) + self.blocks(x)\n",
    "        return nn.functional.relu(activaition_maps)\n",
    "\n",
    "class Resnet(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            in_channels:int,\n",
    "            depth:int,\n",
    "            # n_res_block_per_depth:int,\n",
    "            mlp_width:int,\n",
    "            n_class:int,\n",
    "        ):\n",
    "        super().__init__()\n",
    "        chs_per_depth = [in_channels * 2 ** i for i in range(depth)]\n",
    "        blocks_chns_it = pairwise(chs_per_depth)\n",
    "        self.res_blocks = [ResidualBlock(in_chns, out_chns) for in_chns, out_chns in blocks_chns_it]\n",
    "        self.res_blocks = nn.ModuleList(self.res_blocks)\n",
    "        self.mlp_head = nn.Sequential(\n",
    "            nn.LazyLinear(mlp_width),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(mlp_width, n_class),\n",
    "            nn.Softmax(dim=1),\n",
    "        )\n",
    "        \n",
    "        \n",
    "    def forward(self, x:Tensor) -> Tensor:\n",
    "        activation_maps = x\n",
    "        for res_block in self.res_blocks:\n",
    "            activation_maps = nn.functional.max_pool1d(res_block(activation_maps), 2)\n",
    "        out = activation_maps.view(activation_maps.shape[0], -1)\n",
    "        out = self.mlp_head(out)\n",
    "        return out\n",
    "\n",
    "model = Resnet(\n",
    "    in_channels=23,\n",
    "    depth=4,\n",
    "    mlp_width=256,\n",
    "    n_class=18,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-16T16:13:38.782132Z",
     "iopub.status.busy": "2025-07-16T16:13:38.781837Z",
     "iopub.status.idle": "2025-07-16T16:13:39.290052Z",
     "shell.execute_reply": "2025-07-16T16:13:39.288582Z",
     "shell.execute_reply.started": "2025-07-16T16:13:38.782107Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_state_parent_dir = model_download(\"mauroabidalcarrer/cmi-resnet/pyTorch/trained_on_euler_angles\")\n",
    "model_state_filename = os.listdir(model_state_parent_dir)[0]\n",
    "model_state_path = join(model_state_parent_dir, model_state_filename)\n",
    "model_weights_state_dict = torch.load(model_state_path, weights_only=True)[\"model\"]\n",
    "model.load_state_dict(model_weights_state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-16T16:14:37.858650Z",
     "iopub.status.busy": "2025-07-16T16:14:37.857592Z",
     "iopub.status.idle": "2025-07-16T16:14:49.811969Z",
     "shell.execute_reply": "2025-07-16T16:14:49.810443Z",
     "shell.execute_reply.started": "2025-07-16T16:14:37.858617Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 127)\n",
      "(20, 127)\n",
      "(20, 127)\n",
      "(20, 127)\n",
      "(20, 127)\n",
      "(20, 127)\n",
      "(20, 127)\n",
      "(20, 127)\n",
      "(20, 127)\n",
      "(20, 127)\n",
      "(20, 127)\n",
      "(20, 127)\n",
      "(20, 127)\n",
      "(20, 127)\n",
      "(20, 127)\n",
      "(20, 127)\n",
      "(20, 127)\n",
      "(20, 127)\n",
      "(20, 127)\n",
      "(20, 127)\n",
      "(20, 127)\n",
      "(20, 127)\n",
      "(20, 127)\n",
      "(20, 127)\n",
      "(20, 127)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_36/1081226640.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0minference_server\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     inference_server.run_local_gateway(\n\u001b[0m\u001b[1;32m     21\u001b[0m         data_paths=(\n\u001b[1;32m     22\u001b[0m             \u001b[0;34m'/kaggle/input/cmi-detect-behavior-with-sensor-data/train.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/kaggle/input/cmi-detect-behavior-with-sensor-data/kaggle_evaluation/core/templates.py\u001b[0m in \u001b[0;36mrun_local_gateway\u001b[0;34m(self, data_paths, file_share_dir, *args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_gateway_for_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_paths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_share_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0merr\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/kaggle/input/cmi-detect-behavior-with-sensor-data/kaggle_evaluation/core/templates.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_data_paths\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m             \u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_all_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_submission\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mkaggle_evaluation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_gateway\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGatewayRuntimeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mgre\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/kaggle/input/cmi-detect-behavior-with-sensor-data/kaggle_evaluation/core/templates.py\u001b[0m in \u001b[0;36mget_all_predictions\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mall_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mall_row_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mdata_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow_ids\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_data_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m             \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdata_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate_prediction_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/kaggle/input/cmi-detect-behavior-with-sensor-data/kaggle_evaluation/cmi_gateway.py\u001b[0m in \u001b[0;36mgenerate_data_batches\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0msequence_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sequence_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mseq_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m             \u001b[0msequence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'sequence_id'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mseq_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m             \u001b[0msequence_demos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdemos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'subject'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0msequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'subject'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msequence_demos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'sequence_id'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mseq_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/polars/dataframe/frame.py\u001b[0m in \u001b[0;36mfilter\u001b[0;34m(self, *predicates, **constraints)\u001b[0m\n\u001b[1;32m   5016\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5017\u001b[0m         \"\"\"\n\u001b[0;32m-> 5018\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlazy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpredicates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mconstraints\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_eager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5019\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5020\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0moverload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/polars/lazyframe/frame.py\u001b[0m in \u001b[0;36mcollect\u001b[0;34m(self, type_coercion, _type_check, predicate_pushdown, projection_pushdown, simplify_expression, slice_pushdown, comm_subplan_elim, comm_subexpr_elim, cluster_with_columns, collapse_joins, no_optimization, streaming, engine, background, _check_order, _eager, **_kwargs)\u001b[0m\n\u001b[1;32m   2054\u001b[0m         \u001b[0;31m# Only for testing purposes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2055\u001b[0m         \u001b[0mcallback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"post_opt_callback\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2056\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrap_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mldf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2057\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2058\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0moverload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def predict(sequence_df:pl.DataFrame, _:pl.DataFrame) -> str:\n",
    "    x = preprocess_sequence(sequence_df)\n",
    "    # print(x.shape)\n",
    "    x = torch.unsqueeze(Tensor(x), dim=0)\n",
    "    y_pred = (\n",
    "        model(x)\n",
    "        .max(dim=1)[1]\n",
    "        .numpy()\n",
    "        .squeeze()\n",
    "    )\n",
    "    y_pred_str = meta_data[\"target_names\"][y_pred]\n",
    "\n",
    "    return y_pred_str\n",
    "\n",
    "inference_server = kaggle_evaluation.cmi_inference_server.CMIInferenceServer(predict)\n",
    "if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
    "    inference_server.serve()\n",
    "else:\n",
    "    competition_dataset_path = competition_download(\"cmi-detect-behavior-with-sensor-data\")\n",
    "    inference_server.run_local_gateway(\n",
    "        data_paths=(\n",
    "            join(competition_dataset_path, \"train.csv\"),\n",
    "            join(competition_dataset_path, \"train_demographics.csv\"),\n",
    "        )\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 12518947,
     "sourceId": 102335,
     "sourceType": "competition"
    },
    {
     "datasetId": 7827890,
     "sourceId": 12481171,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 397996,
     "modelInstanceId": 381604,
     "sourceId": 474001,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "CMI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
