{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a0d2e35",
   "metadata": {
    "papermill": {
     "duration": 0.008511,
     "end_time": "2025-08-02T11:24:41.877382",
     "exception": false,
     "start_time": "2025-08-02T11:24:41.868871",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training & inference notebook\n",
    "Credit to [Tarun Mishra](https://www.kaggle.com/tarundirector) â€“ this code is heavily based on his [notebook](https://www.kaggle.com/code/tarundirector/sensor-pulse-viz-eda-for-bfrb-detection?scriptVersionId=243465321)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8a75d1",
   "metadata": {
    "papermill": {
     "duration": 0.006874,
     "end_time": "2025-08-02T11:24:41.891565",
     "exception": false,
     "start_time": "2025-08-02T11:24:41.884691",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1bea84",
   "metadata": {
    "papermill": {
     "duration": 0.007515,
     "end_time": "2025-08-02T11:24:41.906119",
     "exception": false,
     "start_time": "2025-08-02T11:24:41.898604",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26d92a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import gc\n",
    "import json \n",
    "import math\n",
    "import random\n",
    "import warnings\n",
    "from glob import glob\n",
    "from os.path import join\n",
    "from tqdm.notebook import tqdm\n",
    "from functools import partial\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "from operator import methodcaller\n",
    "from os.path import join, realpath\n",
    "from typing import Optional, Literal\n",
    "from itertools import pairwise, starmap, product\n",
    "\n",
    "import torch\n",
    "import optuna\n",
    "import kagglehub\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "from numpy import ndarray\n",
    "import torch.optim as optim\n",
    "import plotly.express as px\n",
    "from torch import nn, Tensor\n",
    "from numpy.linalg import norm\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Optimizer\n",
    "from pandas import DataFrame as DF\n",
    "from optuna.trial import TrialState\n",
    "from sklearn.metrics import f1_score\n",
    "from torch.utils.data import TensorDataset\n",
    "from scipy.spatial.transform import Rotation\n",
    "import kaggle_evaluation.cmi_inference_server\n",
    "from torch.utils.data import DataLoader as DL\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from rich.progress import Progress, Task, track\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from torch.optim.lr_scheduler import ConstantLR, LRScheduler, _LRScheduler\n",
    "metric_package = kagglehub.package_import('wasupandceacar/cmi-metric', bypass_confirmation=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79bf24d",
   "metadata": {},
   "source": [
    "### Seed everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cfaa2b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed=42):\n",
    "    \"\"\"Set all random seeds for reproducibility\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'\n",
    "    torch.use_deterministic_algorithms(True, warn_only=True)\n",
    "SEED = 42\n",
    "seed_everything(seed=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d32d892",
   "metadata": {
    "papermill": {
     "duration": 0.006769,
     "end_time": "2025-08-02T11:24:51.225973",
     "exception": false,
     "start_time": "2025-08-02T11:24:51.219204",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Configs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85a8694",
   "metadata": {
    "papermill": {
     "duration": 0.006774,
     "end_time": "2025-08-02T11:24:51.239642",
     "exception": false,
     "start_time": "2025-08-02T11:24:51.232868",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Training config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "315f4a8d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-02T11:24:51.254502Z",
     "iopub.status.busy": "2025-08-02T11:24:51.254086Z",
     "iopub.status.idle": "2025-08-02T11:24:51.259267Z",
     "shell.execute_reply": "2025-08-02T11:24:51.258717Z"
    },
    "papermill": {
     "duration": 0.013777,
     "end_time": "2025-08-02T11:24:51.260297",
     "exception": false,
     "start_time": "2025-08-02T11:24:51.246520",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Dataset\n",
    "DATASET_HANDLE = \"mauroabidalcarrer/prepocessed-cmi-2025\"\n",
    "COMPETITION_HANDLE = \"cmi-detect-behavior-with-sensor-data\"\n",
    "TARGET_NAMES = sorted([\n",
    "    \"Above ear - pull hair\",\n",
    "    \"Cheek - pinch skin\",\n",
    "    \"Eyebrow - pull hair\",\n",
    "    \"Eyelash - pull hair\",\n",
    "    \"Feel around in tray and pull out an object\",\n",
    "    \"Forehead - pull hairline\",\n",
    "    \"Forehead - scratch\",\n",
    "    \"Neck - pinch skin\",\n",
    "    \"Neck - scratch\",\n",
    "    \"Text on phone\",\n",
    "    \"Wave hello\",\n",
    "    \"Write name in air\",\n",
    "    \"Write name on leg\",\n",
    "    \"Drink from bottle/cup\",\n",
    "    \"Pinch knee/leg skin\",\n",
    "    \"Pull air toward your face\",\n",
    "    \"Scratch knee/leg skin\",\n",
    "    \"Glasses on/off\"\n",
    "])\n",
    "IMU_FEATS_PREFIXES = (\n",
    "    \"acc\",\n",
    "    \"linear_acc\",\n",
    "    \"rot\",\n",
    "    \"angular\",\n",
    "    \"euler\",\n",
    "    \"quat_rot_mag\",\n",
    "    \"delta_rot_mag\",\n",
    ")\n",
    "# Data augmentation\n",
    "JITTER = 0.25\n",
    "SCALING = 0.2\n",
    "MIXUP = 0.3\n",
    "# Training loop\n",
    "NB_CROSS_VALIDATIONS = 5\n",
    "TRAIN_BATCH_SIZE = 256\n",
    "VALIDATION_BATCH_SIZE = 4 * TRAIN_BATCH_SIZE\n",
    "PATIENCE = 8\n",
    "# Optimizer\n",
    "WEIGHT_DECAY = 3e-3\n",
    "# Scheduler\n",
    "TRAINING_EPOCHS = 25 # Including warmup epochs\n",
    "WARMUP_EPOCHS = 3\n",
    "WARMUP_LR_INIT = 1.822126131809773e-05\n",
    "MAX_TO_MIN_LR_DIV_FACTOR = 100\n",
    "LR_CYCLE_FACTOR = 0.5\n",
    "CYCLE_LENGTH_FACTOR = 0.9\n",
    "INIT_CYCLE_EPOCHS = 6\n",
    "# MIN_LR = 3.810323058740104e-09\n",
    "# MAX_LR = 1e-3\n",
    "# Mock training loop\n",
    "MOCK_TRAINING_EPOCHS = 20\n",
    "MOCK_TRAINING_GAMMA = 1.01\n",
    "CHANNELS_DIMENSION = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5b1887",
   "metadata": {
    "papermill": {
     "duration": 0.006754,
     "end_time": "2025-08-02T11:24:51.273987",
     "exception": false,
     "start_time": "2025-08-02T11:24:51.267233",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Preprocessing (for inference) config "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c199973",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-02T11:24:51.288765Z",
     "iopub.status.busy": "2025-08-02T11:24:51.288386Z",
     "iopub.status.idle": "2025-08-02T11:24:51.295185Z",
     "shell.execute_reply": "2025-08-02T11:24:51.294653Z"
    },
    "papermill": {
     "duration": 0.015378,
     "end_time": "2025-08-02T11:24:51.296287",
     "exception": false,
     "start_time": "2025-08-02T11:24:51.280909",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "QUATERNION_COLS = ['rot_w', 'rot_x', 'rot_y', 'rot_z']\n",
    "GRAVITY_WORLD = np.array([0, 0, 9.81], \"float32\")\n",
    "RAW_ACCELRATION_COLS = [\"acc_x\", \"acc_y\", \"acc_z\"]\n",
    "LINEAR_ACC_COLS = [\"linear_\" + col for col in RAW_ACCELRATION_COLS] # Acceleration without gravity\n",
    "COMPETITION_HANDLE = \"cmi-detect-behavior-with-sensor-data\"\n",
    "CATEGORY_COLUMNS = [\n",
    "    'row_id',\n",
    "    'sequence_type',\n",
    "    'sequence_id',\n",
    "    'subject',\n",
    "    'orientation',\n",
    "    'behavior',\n",
    "    'phase',\n",
    "    'gesture',\n",
    "]\n",
    "META_DATA_COLUMNS = [\n",
    "    'row_id',\n",
    "    'sequence_type',\n",
    "    'sequence_id',\n",
    "    'sequence_counter',\n",
    "    'subject',\n",
    "    'orientation',\n",
    "    'behavior',\n",
    "    'phase',\n",
    "    'gesture',\n",
    "]\n",
    "DATASET_DF_DTYPES = {\n",
    "    \"acc_x\": \"float32\", \"acc_y\": \"float32\", \"acc_z\": \"float32\",\n",
    "    \"thm_1\":\"float32\", \"thm_2\":\"float32\", \"thm_3\":\"float32\", \"thm_4\":\"float32\", \"thm_5\":\"float32\",\n",
    "    \"sequence_counter\": \"int32\",\n",
    "    **{col: \"category\" for col in CATEGORY_COLUMNS},\n",
    "    **{f\"tof_{i_1}_v{i_2}\": \"float32\" for i_1, i_2 in product(range(1, 5), range(64))},\n",
    "}\n",
    "PREPROCESSED_DATASET_HANDLE = \"mauroabidalcarrer/prepocessed-cmi-2025\"\n",
    "# The quantile of the sequences len used to pad/truncate during preprocessing\n",
    "SEQUENCE_NORMED_LEN_QUANTILE = 0.95\n",
    "# SAMPLING_FREQUENCY = 10 #Hz\n",
    "N_FOLDS = 5\n",
    "VALIDATION_FRACTION = 0.2\n",
    "TARGET_NAMES = sorted([\n",
    "    \"Above ear - pull hair\",\n",
    "    \"Cheek - pinch skin\",\n",
    "    \"Eyebrow - pull hair\",\n",
    "    \"Eyelash - pull hair\",\n",
    "    \"Feel around in tray and pull out an object\",\n",
    "    \"Forehead - pull hairline\",\n",
    "    \"Forehead - scratch\",\n",
    "    \"Neck - pinch skin\",\n",
    "    \"Neck - scratch\",\n",
    "    \"Text on phone\",\n",
    "    \"Wave hello\",\n",
    "    \"Write name in air\",\n",
    "    \"Write name on leg\",\n",
    "    \"Drink from bottle/cup\",\n",
    "    \"Pinch knee/leg skin\",\n",
    "    \"Pull air toward your face\",\n",
    "    \"Scratch knee/leg skin\",\n",
    "    \"Glasses on/off\"\n",
    "])\n",
    "EPSILON=1e-8\n",
    "DELTA_ROTATION_ANGULAR_VELOCITY_COLS = [\"angular_vel_x\", \"angular_vel_y\", \"angular_vel_z\"]\n",
    "DELTA_ROTATION_AXES_COLS = [\"rotation_axis_x\", \"rotation_axis_y\", \"rotation_axis_z\"]\n",
    "EULER_ANGLES_COLS = [\"euler_x\", \"euler_y\", \"euler_z\"]\n",
    "TOF_AGG_FUNCS = [\n",
    "    \"mean\",\n",
    "    \"std\",\n",
    "    \"min\",\n",
    "    \"max\",\n",
    "    \"median\",\n",
    "]\n",
    "PAD_SEQ_MODE = \"center\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35036a5",
   "metadata": {
    "papermill": {
     "duration": 0.006863,
     "end_time": "2025-08-02T11:24:51.388547",
     "exception": false,
     "start_time": "2025-08-02T11:24:51.381684",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Supress performance warngings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b96515f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-02T11:24:51.403658Z",
     "iopub.status.busy": "2025-08-02T11:24:51.402937Z",
     "iopub.status.idle": "2025-08-02T11:24:51.406433Z",
     "shell.execute_reply": "2025-08-02T11:24:51.405940Z"
    },
    "papermill": {
     "duration": 0.011979,
     "end_time": "2025-08-02T11:24:51.407463",
     "exception": false,
     "start_time": "2025-08-02T11:24:51.395484",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    message=(\n",
    "        \"DataFrame is highly fragmented.  This is usually the result of \"\n",
    "        \"calling `frame.insert` many times.*\"\n",
    "    ),\n",
    "    category=pd.errors.PerformanceWarning,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37a42bf",
   "metadata": {
    "papermill": {
     "duration": 0.006809,
     "end_time": "2025-08-02T11:24:51.421256",
     "exception": false,
     "start_time": "2025-08-02T11:24:51.414447",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### device setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf88774f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-02T11:24:51.435856Z",
     "iopub.status.busy": "2025-08-02T11:24:51.435651Z",
     "iopub.status.idle": "2025-08-02T11:24:51.489135Z",
     "shell.execute_reply": "2025-08-02T11:24:51.488505Z"
    },
    "papermill": {
     "duration": 0.062045,
     "end_time": "2025-08-02T11:24:51.490238",
     "exception": false,
     "start_time": "2025-08-02T11:24:51.428193",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4888397a",
   "metadata": {
    "papermill": {
     "duration": 0.00725,
     "end_time": "2025-08-02T11:24:51.504769",
     "exception": false,
     "start_time": "2025-08-02T11:24:51.497519",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Dataset Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64f7616",
   "metadata": {
    "papermill": {
     "duration": 0.007032,
     "end_time": "2025-08-02T11:24:51.518918",
     "exception": false,
     "start_time": "2025-08-02T11:24:51.511886",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef222587",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-02T11:24:51.534263Z",
     "iopub.status.busy": "2025-08-02T11:24:51.533771Z",
     "iopub.status.idle": "2025-08-02T11:24:51.538733Z",
     "shell.execute_reply": "2025-08-02T11:24:51.538254Z"
    },
    "papermill": {
     "duration": 0.013617,
     "end_time": "2025-08-02T11:24:51.539757",
     "exception": false,
     "start_time": "2025-08-02T11:24:51.526140",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CMIDataset(TensorDataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        padding_mode:Literal[\"pre\", \"center\", \"post\"],\n",
    "        parent_dir: str,\n",
    "        split: Optional[Literal[\"train\", \"validation\"]]=None,\n",
    "        subset: Optional[int]=None,\n",
    "        force_download=False\n",
    "    ):\n",
    "        dataset_path = kagglehub.dataset_download(DATASET_HANDLE, force_download)\n",
    "        # Quick fix, will need to recompute and upload dataset with properly orederd folders\n",
    "        if parent_dir == \"full_dataset\":\n",
    "            parent_dir = join(\n",
    "                dataset_path,\n",
    "                # \"preprocessed_dataset\",\n",
    "                parent_dir,\n",
    "                padding_mode,\n",
    "            )\n",
    "        else:\n",
    "            parent_dir = join(\n",
    "                dataset_path,\n",
    "                # \"preprocessed_dataset\",\n",
    "                padding_mode,\n",
    "                parent_dir,\n",
    "            )\n",
    "        split = \"\" if split is None else split + \"_\"\n",
    "        x = np.load(join(parent_dir, f\"{split}X.npy\")).swapaxes(1, 2)\n",
    "        y = np.load(join(parent_dir, f\"{split}Y.npy\"))\n",
    "        if subset is not None:\n",
    "            x = x[:subset]\n",
    "            y = y[:subset]\n",
    "        super().__init__(\n",
    "            torch.from_numpy(x).to(device),\n",
    "            torch.from_numpy(y).to(device),\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d2261e",
   "metadata": {
    "papermill": {
     "duration": 0.00713,
     "end_time": "2025-08-02T11:24:51.554030",
     "exception": false,
     "start_time": "2025-08-02T11:24:51.546900",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Meta data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "890b47f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-02T11:24:51.568885Z",
     "iopub.status.busy": "2025-08-02T11:24:51.568712Z",
     "iopub.status.idle": "2025-08-02T11:24:51.754759Z",
     "shell.execute_reply": "2025-08-02T11:24:51.753849Z"
    },
    "papermill": {
     "duration": 0.194808,
     "end_time": "2025-08-02T11:24:51.755943",
     "exception": false,
     "start_time": "2025-08-02T11:24:51.561135",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acc_mag', 'acc_mag_diff', 'acc_x', 'acc_x_diff', 'acc_y', 'acc_y_diff', 'acc_z', 'acc_z_diff', 'angular_vel_x', 'angular_vel_x_diff', 'angular_vel_y', 'angular_vel_y_diff', 'angular_vel_z', 'angular_vel_z_diff', 'delta_rot_mag', 'delta_rot_mag_diff', 'euler_x', 'euler_x_diff', 'euler_y', 'euler_y_diff', 'euler_z', 'euler_z_diff', 'linear_acc_mag', 'linear_acc_mag_diff', 'linear_acc_x', 'linear_acc_x_diff', 'linear_acc_y', 'linear_acc_y_diff', 'linear_acc_z', 'linear_acc_z_diff', 'quat_rot_mag', 'quat_rot_mag_diff', 'rot_w', 'rot_w_diff', 'rot_x', 'rot_x_diff', 'rot_y', 'rot_y_diff', 'rot_z', 'rot_z_diff', 'rotation_axis_x', 'rotation_axis_x_diff', 'rotation_axis_y', 'rotation_axis_y_diff', 'rotation_axis_z', 'rotation_axis_z_diff', 'thm_1', 'thm_1_diff', 'thm_2', 'thm_2_diff', 'thm_3', 'thm_3_diff', 'thm_4', 'thm_4_diff', 'thm_5', 'thm_5_diff', 'tof_1_v00', 'tof_1_v00_diff', 'tof_1_v01', 'tof_1_v01_diff', 'tof_1_v02', 'tof_1_v02_diff', 'tof_1_v03', 'tof_1_v03_diff', 'tof_1_v04', 'tof_1_v04_diff', 'tof_1_v05', 'tof_1_v05_diff', 'tof_1_v06', 'tof_1_v06_diff', 'tof_1_v07', 'tof_1_v07_diff', 'tof_1_v08', 'tof_1_v08_diff', 'tof_1_v09', 'tof_1_v09_diff', 'tof_1_v10', 'tof_1_v10_diff', 'tof_1_v11', 'tof_1_v11_diff', 'tof_1_v12', 'tof_1_v12_diff', 'tof_1_v13', 'tof_1_v13_diff', 'tof_1_v14', 'tof_1_v14_diff', 'tof_1_v15', 'tof_1_v15_diff', 'tof_1_v16', 'tof_1_v16_diff', 'tof_1_v17', 'tof_1_v17_diff', 'tof_1_v18', 'tof_1_v18_diff', 'tof_1_v19', 'tof_1_v19_diff', 'tof_1_v20', 'tof_1_v20_diff', 'tof_1_v21', 'tof_1_v21_diff', 'tof_1_v22', 'tof_1_v22_diff', 'tof_1_v23', 'tof_1_v23_diff', 'tof_1_v24', 'tof_1_v24_diff', 'tof_1_v25', 'tof_1_v25_diff', 'tof_1_v26', 'tof_1_v26_diff', 'tof_1_v27', 'tof_1_v27_diff', 'tof_1_v28', 'tof_1_v28_diff', 'tof_1_v29', 'tof_1_v29_diff', 'tof_1_v30', 'tof_1_v30_diff', 'tof_1_v31', 'tof_1_v31_diff', 'tof_1_v32', 'tof_1_v32_diff', 'tof_1_v33', 'tof_1_v33_diff', 'tof_1_v34', 'tof_1_v34_diff', 'tof_1_v35', 'tof_1_v35_diff', 'tof_1_v36', 'tof_1_v36_diff', 'tof_1_v37', 'tof_1_v37_diff', 'tof_1_v38', 'tof_1_v38_diff', 'tof_1_v39', 'tof_1_v39_diff', 'tof_1_v40', 'tof_1_v40_diff', 'tof_1_v41', 'tof_1_v41_diff', 'tof_1_v42', 'tof_1_v42_diff', 'tof_1_v43', 'tof_1_v43_diff', 'tof_1_v44', 'tof_1_v44_diff', 'tof_1_v45', 'tof_1_v45_diff', 'tof_1_v46', 'tof_1_v46_diff', 'tof_1_v47', 'tof_1_v47_diff', 'tof_1_v48', 'tof_1_v48_diff', 'tof_1_v49', 'tof_1_v49_diff', 'tof_1_v50', 'tof_1_v50_diff', 'tof_1_v51', 'tof_1_v51_diff', 'tof_1_v52', 'tof_1_v52_diff', 'tof_1_v53', 'tof_1_v53_diff', 'tof_1_v54', 'tof_1_v54_diff', 'tof_1_v55', 'tof_1_v55_diff', 'tof_1_v56', 'tof_1_v56_diff', 'tof_1_v57', 'tof_1_v57_diff', 'tof_1_v58', 'tof_1_v58_diff', 'tof_1_v59', 'tof_1_v59_diff', 'tof_1_v60', 'tof_1_v60_diff', 'tof_1_v61', 'tof_1_v61_diff', 'tof_1_v62', 'tof_1_v62_diff', 'tof_1_v63', 'tof_1_v63_diff', 'tof_2_v00', 'tof_2_v00_diff', 'tof_2_v01', 'tof_2_v01_diff', 'tof_2_v02', 'tof_2_v02_diff', 'tof_2_v03', 'tof_2_v03_diff', 'tof_2_v04', 'tof_2_v04_diff', 'tof_2_v05', 'tof_2_v05_diff', 'tof_2_v06', 'tof_2_v06_diff', 'tof_2_v07', 'tof_2_v07_diff', 'tof_2_v08', 'tof_2_v08_diff', 'tof_2_v09', 'tof_2_v09_diff', 'tof_2_v10', 'tof_2_v10_diff', 'tof_2_v11', 'tof_2_v11_diff', 'tof_2_v12', 'tof_2_v12_diff', 'tof_2_v13', 'tof_2_v13_diff', 'tof_2_v14', 'tof_2_v14_diff', 'tof_2_v15', 'tof_2_v15_diff', 'tof_2_v16', 'tof_2_v16_diff', 'tof_2_v17', 'tof_2_v17_diff', 'tof_2_v18', 'tof_2_v18_diff', 'tof_2_v19', 'tof_2_v19_diff', 'tof_2_v20', 'tof_2_v20_diff', 'tof_2_v21', 'tof_2_v21_diff', 'tof_2_v22', 'tof_2_v22_diff', 'tof_2_v23', 'tof_2_v23_diff', 'tof_2_v24', 'tof_2_v24_diff', 'tof_2_v25', 'tof_2_v25_diff', 'tof_2_v26', 'tof_2_v26_diff', 'tof_2_v27', 'tof_2_v27_diff', 'tof_2_v28', 'tof_2_v28_diff', 'tof_2_v29', 'tof_2_v29_diff', 'tof_2_v30', 'tof_2_v30_diff', 'tof_2_v31', 'tof_2_v31_diff', 'tof_2_v32', 'tof_2_v32_diff', 'tof_2_v33', 'tof_2_v33_diff', 'tof_2_v34', 'tof_2_v34_diff', 'tof_2_v35', 'tof_2_v35_diff', 'tof_2_v36', 'tof_2_v36_diff', 'tof_2_v37', 'tof_2_v37_diff', 'tof_2_v38', 'tof_2_v38_diff', 'tof_2_v39', 'tof_2_v39_diff', 'tof_2_v40', 'tof_2_v40_diff', 'tof_2_v41', 'tof_2_v41_diff', 'tof_2_v42', 'tof_2_v42_diff', 'tof_2_v43', 'tof_2_v43_diff', 'tof_2_v44', 'tof_2_v44_diff', 'tof_2_v45', 'tof_2_v45_diff', 'tof_2_v46', 'tof_2_v46_diff', 'tof_2_v47', 'tof_2_v47_diff', 'tof_2_v48', 'tof_2_v48_diff', 'tof_2_v49', 'tof_2_v49_diff', 'tof_2_v50', 'tof_2_v50_diff', 'tof_2_v51', 'tof_2_v51_diff', 'tof_2_v52', 'tof_2_v52_diff', 'tof_2_v53', 'tof_2_v53_diff', 'tof_2_v54', 'tof_2_v54_diff', 'tof_2_v55', 'tof_2_v55_diff', 'tof_2_v56', 'tof_2_v56_diff', 'tof_2_v57', 'tof_2_v57_diff', 'tof_2_v58', 'tof_2_v58_diff', 'tof_2_v59', 'tof_2_v59_diff', 'tof_2_v60', 'tof_2_v60_diff', 'tof_2_v61', 'tof_2_v61_diff', 'tof_2_v62', 'tof_2_v62_diff', 'tof_2_v63', 'tof_2_v63_diff', 'tof_3_v00', 'tof_3_v00_diff', 'tof_3_v01', 'tof_3_v01_diff', 'tof_3_v02', 'tof_3_v02_diff', 'tof_3_v03', 'tof_3_v03_diff', 'tof_3_v04', 'tof_3_v04_diff', 'tof_3_v05', 'tof_3_v05_diff', 'tof_3_v06', 'tof_3_v06_diff', 'tof_3_v07', 'tof_3_v07_diff', 'tof_3_v08', 'tof_3_v08_diff', 'tof_3_v09', 'tof_3_v09_diff', 'tof_3_v10', 'tof_3_v10_diff', 'tof_3_v11', 'tof_3_v11_diff', 'tof_3_v12', 'tof_3_v12_diff', 'tof_3_v13', 'tof_3_v13_diff', 'tof_3_v14', 'tof_3_v14_diff', 'tof_3_v15', 'tof_3_v15_diff', 'tof_3_v16', 'tof_3_v16_diff', 'tof_3_v17', 'tof_3_v17_diff', 'tof_3_v18', 'tof_3_v18_diff', 'tof_3_v19', 'tof_3_v19_diff', 'tof_3_v20', 'tof_3_v20_diff', 'tof_3_v21', 'tof_3_v21_diff', 'tof_3_v22', 'tof_3_v22_diff', 'tof_3_v23', 'tof_3_v23_diff', 'tof_3_v24', 'tof_3_v24_diff', 'tof_3_v25', 'tof_3_v25_diff', 'tof_3_v26', 'tof_3_v26_diff', 'tof_3_v27', 'tof_3_v27_diff', 'tof_3_v28', 'tof_3_v28_diff', 'tof_3_v29', 'tof_3_v29_diff', 'tof_3_v30', 'tof_3_v30_diff', 'tof_3_v31', 'tof_3_v31_diff', 'tof_3_v32', 'tof_3_v32_diff', 'tof_3_v33', 'tof_3_v33_diff', 'tof_3_v34', 'tof_3_v34_diff', 'tof_3_v35', 'tof_3_v35_diff', 'tof_3_v36', 'tof_3_v36_diff', 'tof_3_v37', 'tof_3_v37_diff', 'tof_3_v38', 'tof_3_v38_diff', 'tof_3_v39', 'tof_3_v39_diff', 'tof_3_v40', 'tof_3_v40_diff', 'tof_3_v41', 'tof_3_v41_diff', 'tof_3_v42', 'tof_3_v42_diff', 'tof_3_v43', 'tof_3_v43_diff', 'tof_3_v44', 'tof_3_v44_diff', 'tof_3_v45', 'tof_3_v45_diff', 'tof_3_v46', 'tof_3_v46_diff', 'tof_3_v47', 'tof_3_v47_diff', 'tof_3_v48', 'tof_3_v48_diff', 'tof_3_v49', 'tof_3_v49_diff', 'tof_3_v50', 'tof_3_v50_diff', 'tof_3_v51', 'tof_3_v51_diff', 'tof_3_v52', 'tof_3_v52_diff', 'tof_3_v53', 'tof_3_v53_diff', 'tof_3_v54', 'tof_3_v54_diff', 'tof_3_v55', 'tof_3_v55_diff', 'tof_3_v56', 'tof_3_v56_diff', 'tof_3_v57', 'tof_3_v57_diff', 'tof_3_v58', 'tof_3_v58_diff', 'tof_3_v59', 'tof_3_v59_diff', 'tof_3_v60', 'tof_3_v60_diff', 'tof_3_v61', 'tof_3_v61_diff', 'tof_3_v62', 'tof_3_v62_diff', 'tof_3_v63', 'tof_3_v63_diff', 'tof_4_v00', 'tof_4_v00_diff', 'tof_4_v01', 'tof_4_v01_diff', 'tof_4_v02', 'tof_4_v02_diff', 'tof_4_v03', 'tof_4_v03_diff', 'tof_4_v04', 'tof_4_v04_diff', 'tof_4_v05', 'tof_4_v05_diff', 'tof_4_v06', 'tof_4_v06_diff', 'tof_4_v07', 'tof_4_v07_diff', 'tof_4_v08', 'tof_4_v08_diff', 'tof_4_v09', 'tof_4_v09_diff', 'tof_4_v10', 'tof_4_v10_diff', 'tof_4_v11', 'tof_4_v11_diff', 'tof_4_v12', 'tof_4_v12_diff', 'tof_4_v13', 'tof_4_v13_diff', 'tof_4_v14', 'tof_4_v14_diff', 'tof_4_v15', 'tof_4_v15_diff', 'tof_4_v16', 'tof_4_v16_diff', 'tof_4_v17', 'tof_4_v17_diff', 'tof_4_v18', 'tof_4_v18_diff', 'tof_4_v19', 'tof_4_v19_diff', 'tof_4_v20', 'tof_4_v20_diff', 'tof_4_v21', 'tof_4_v21_diff', 'tof_4_v22', 'tof_4_v22_diff', 'tof_4_v23', 'tof_4_v23_diff', 'tof_4_v24', 'tof_4_v24_diff', 'tof_4_v25', 'tof_4_v25_diff', 'tof_4_v26', 'tof_4_v26_diff', 'tof_4_v27', 'tof_4_v27_diff', 'tof_4_v28', 'tof_4_v28_diff', 'tof_4_v29', 'tof_4_v29_diff', 'tof_4_v30', 'tof_4_v30_diff', 'tof_4_v31', 'tof_4_v31_diff', 'tof_4_v32', 'tof_4_v32_diff', 'tof_4_v33', 'tof_4_v33_diff', 'tof_4_v34', 'tof_4_v34_diff', 'tof_4_v35', 'tof_4_v35_diff', 'tof_4_v36', 'tof_4_v36_diff', 'tof_4_v37', 'tof_4_v37_diff', 'tof_4_v38', 'tof_4_v38_diff', 'tof_4_v39', 'tof_4_v39_diff', 'tof_4_v40', 'tof_4_v40_diff', 'tof_4_v41', 'tof_4_v41_diff', 'tof_4_v42', 'tof_4_v42_diff', 'tof_4_v43', 'tof_4_v43_diff', 'tof_4_v44', 'tof_4_v44_diff', 'tof_4_v45', 'tof_4_v45_diff', 'tof_4_v46', 'tof_4_v46_diff', 'tof_4_v47', 'tof_4_v47_diff', 'tof_4_v48', 'tof_4_v48_diff', 'tof_4_v49', 'tof_4_v49_diff', 'tof_4_v50', 'tof_4_v50_diff', 'tof_4_v51', 'tof_4_v51_diff', 'tof_4_v52', 'tof_4_v52_diff', 'tof_4_v53', 'tof_4_v53_diff', 'tof_4_v54', 'tof_4_v54_diff', 'tof_4_v55', 'tof_4_v55_diff', 'tof_4_v56', 'tof_4_v56_diff', 'tof_4_v57', 'tof_4_v57_diff', 'tof_4_v58', 'tof_4_v58_diff', 'tof_4_v59', 'tof_4_v59_diff', 'tof_4_v60', 'tof_4_v60_diff', 'tof_4_v61', 'tof_4_v61_diff', 'tof_4_v62', 'tof_4_v62_diff', 'tof_4_v63', 'tof_4_v63_diff', 'tof_5_v00', 'tof_5_v00_diff', 'tof_5_v01', 'tof_5_v01_diff', 'tof_5_v02', 'tof_5_v02_diff', 'tof_5_v03', 'tof_5_v03_diff', 'tof_5_v04', 'tof_5_v04_diff', 'tof_5_v05', 'tof_5_v05_diff', 'tof_5_v06', 'tof_5_v06_diff', 'tof_5_v07', 'tof_5_v07_diff', 'tof_5_v08', 'tof_5_v08_diff', 'tof_5_v09', 'tof_5_v09_diff', 'tof_5_v10', 'tof_5_v10_diff', 'tof_5_v11', 'tof_5_v11_diff', 'tof_5_v12', 'tof_5_v12_diff', 'tof_5_v13', 'tof_5_v13_diff', 'tof_5_v14', 'tof_5_v14_diff', 'tof_5_v15', 'tof_5_v15_diff', 'tof_5_v16', 'tof_5_v16_diff', 'tof_5_v17', 'tof_5_v17_diff', 'tof_5_v18', 'tof_5_v18_diff', 'tof_5_v19', 'tof_5_v19_diff', 'tof_5_v20', 'tof_5_v20_diff', 'tof_5_v21', 'tof_5_v21_diff', 'tof_5_v22', 'tof_5_v22_diff', 'tof_5_v23', 'tof_5_v23_diff', 'tof_5_v24', 'tof_5_v24_diff', 'tof_5_v25', 'tof_5_v25_diff', 'tof_5_v26', 'tof_5_v26_diff', 'tof_5_v27', 'tof_5_v27_diff', 'tof_5_v28', 'tof_5_v28_diff', 'tof_5_v29', 'tof_5_v29_diff', 'tof_5_v30', 'tof_5_v30_diff', 'tof_5_v31', 'tof_5_v31_diff', 'tof_5_v32', 'tof_5_v32_diff', 'tof_5_v33', 'tof_5_v33_diff', 'tof_5_v34', 'tof_5_v34_diff', 'tof_5_v35', 'tof_5_v35_diff', 'tof_5_v36', 'tof_5_v36_diff', 'tof_5_v37', 'tof_5_v37_diff', 'tof_5_v38', 'tof_5_v38_diff', 'tof_5_v39', 'tof_5_v39_diff', 'tof_5_v40', 'tof_5_v40_diff', 'tof_5_v41', 'tof_5_v41_diff', 'tof_5_v42', 'tof_5_v42_diff', 'tof_5_v43', 'tof_5_v43_diff', 'tof_5_v44', 'tof_5_v44_diff', 'tof_5_v45', 'tof_5_v45_diff', 'tof_5_v46', 'tof_5_v46_diff', 'tof_5_v47', 'tof_5_v47_diff', 'tof_5_v48', 'tof_5_v48_diff', 'tof_5_v49', 'tof_5_v49_diff', 'tof_5_v50', 'tof_5_v50_diff', 'tof_5_v51', 'tof_5_v51_diff', 'tof_5_v52', 'tof_5_v52_diff', 'tof_5_v53', 'tof_5_v53_diff', 'tof_5_v54', 'tof_5_v54_diff', 'tof_5_v55', 'tof_5_v55_diff', 'tof_5_v56', 'tof_5_v56_diff', 'tof_5_v57', 'tof_5_v57_diff', 'tof_5_v58', 'tof_5_v58_diff', 'tof_5_v59', 'tof_5_v59_diff', 'tof_5_v60', 'tof_5_v60_diff', 'tof_5_v61', 'tof_5_v61_diff', 'tof_5_v62', 'tof_5_v62_diff', 'tof_5_v63', 'tof_5_v63_diff']\n",
      "tof_feats_idx: [56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695]\n",
      "thm_feats_idx: [46, 47, 48, 49, 50, 51, 52, 53, 54, 55]\n",
      "imu_feats_idx: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45]\n"
     ]
    }
   ],
   "source": [
    "dataset_path = kagglehub.dataset_download(DATASET_HANDLE)\n",
    "meta_data_path = join(\n",
    "    dataset_path,\n",
    "    # \"preprocessed_dataset\",\n",
    "    \"full_dataset_meta_data.json\"\n",
    ")\n",
    "with open(meta_data_path, \"r\") as fp:\n",
    "    meta_data = json.load(fp)\n",
    "# Convert target names into a ndarray to index it batchwise.\n",
    "def get_sensor_indices(sensor_prefix: str) -> list[int]:\n",
    "    is_sensor_feat = methodcaller(\"startswith\", sensor_prefix)\n",
    "    return [feat_idx for feat_idx, feat in enumerate(meta_data[\"feature_cols\"]) if is_sensor_feat(feat)]\n",
    "\n",
    "tof_idx = get_sensor_indices(\"tof\")\n",
    "thm_idx = get_sensor_indices(\"thm\")\n",
    "imu_idx = list(filter(lambda idx: idx not in tof_idx + thm_idx, range(len(meta_data[\"feature_cols\"]))))\n",
    "\n",
    "print(meta_data[\"feature_cols\"])\n",
    "print(\"tof_feats_idx:\", tof_idx)\n",
    "print(\"thm_feats_idx:\", thm_idx)\n",
    "print(\"imu_feats_idx:\", imu_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21991d61",
   "metadata": {
    "papermill": {
     "duration": 0.007201,
     "end_time": "2025-08-02T11:24:51.806304",
     "exception": false,
     "start_time": "2025-08-02T11:24:51.799103",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### BFRBs indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2b8864b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-02T11:24:51.821785Z",
     "iopub.status.busy": "2025-08-02T11:24:51.821390Z",
     "iopub.status.idle": "2025-08-02T11:25:20.508716Z",
     "shell.execute_reply": "2025-08-02T11:25:20.507884Z"
    },
    "papermill": {
     "duration": 28.696544,
     "end_time": "2025-08-02T11:25:20.510088",
     "exception": false,
     "start_time": "2025-08-02T11:24:51.813544",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets...\n",
      "Train rows: 574945, Test rows: 107\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading datasets...\")\n",
    "competition_dataset_path = kagglehub.competition_download(COMPETITION_HANDLE)\n",
    "train_df = pd.read_csv(join(competition_dataset_path, \"train.csv\"))\n",
    "train_dem_df = pd.read_csv(join(competition_dataset_path, \"train_demographics.csv\"))\n",
    "test_df = pd.read_csv(join(competition_dataset_path, \"test.csv\"))\n",
    "test_dem_df = pd.read_csv(join(competition_dataset_path, \"test_demographics.csv\"))\n",
    "print(f\"Train rows: {len(train_df)}, Test rows: {len(test_df)}\")\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "train_df['gesture'] = label_encoder.fit_transform(train_df['gesture'].astype(str))\n",
    "gesture_classes = label_encoder.classes_\n",
    "\n",
    "bfrb_gestures = [\n",
    "    'Above ear - pull hair',\n",
    "    'Forehead - pull hairline',\n",
    "    'Forehead - scratch',\n",
    "    'Eyebrow - pull hair',\n",
    "    'Eyelash - pull hair',\n",
    "    'Neck - pinch skin',\n",
    "    'Neck - scratch',\n",
    "    'Cheek - pinch skin'\n",
    "]\n",
    "bfrb_indices = label_encoder.transform(bfrb_gestures)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86df0ba2",
   "metadata": {
    "papermill": {
     "duration": 0.007266,
     "end_time": "2025-08-02T11:25:20.565558",
     "exception": false,
     "start_time": "2025-08-02T11:25:20.558292",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f99a499a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-02T11:25:20.581200Z",
     "iopub.status.busy": "2025-08-02T11:25:20.581013Z",
     "iopub.status.idle": "2025-08-02T11:25:20.601366Z",
     "shell.execute_reply": "2025-08-02T11:25:20.600664Z"
    },
    "papermill": {
     "duration": 0.029642,
     "end_time": "2025-08-02T11:25:20.602493",
     "exception": false,
     "start_time": "2025-08-02T11:25:20.572851",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MultiScaleConvs(nn.Module):\n",
    "    def __init__(self, in_channels:int, kernel_sizes:list[int]):\n",
    "        super().__init__()\n",
    "        def mk_conv_block(k_size) -> nn.Sequential:\n",
    "            return nn.Sequential(\n",
    "                nn.Conv1d(in_channels, in_channels, k_size, padding=k_size // 2, groups=in_channels),\n",
    "                nn.BatchNorm1d(in_channels),\n",
    "                nn.ReLU(),\n",
    "            )\n",
    "        self.convs = nn.ModuleList(map(mk_conv_block, kernel_sizes))\n",
    "\n",
    "    def forward(self, x:Tensor) -> Tensor:\n",
    "        yes = torch.cat([conv(x) for conv in self.convs] + [x], dim=1)\n",
    "        # print(\"stem output shape:\", yes.shape)\n",
    "        return yes\n",
    "\n",
    "class ImuFeatureExtractor(nn.Module):\n",
    "    def __init__(self, in_channels:int, kernel_size:int=15):\n",
    "        super().__init__()\n",
    "\n",
    "        self.lpf = nn.Conv1d(\n",
    "            in_channels,\n",
    "            in_channels,\n",
    "            kernel_size=kernel_size,\n",
    "            padding=kernel_size//2,\n",
    "            groups=in_channels,\n",
    "            bias=False,\n",
    "        )\n",
    "        nn.init.kaiming_uniform_(self.lpf.weight, a=math.sqrt(5))\n",
    "\n",
    "    def forward(self, x:Tensor) -> Tensor:\n",
    "        lpf_output = self.lpf(x)\n",
    "        hpf_output = x - lpf_output\n",
    "        return torch.cat((lpf_output, hpf_output, x), dim=1)  # (B, C_out, T)\n",
    "\n",
    "class SqueezeExcitationBlock(nn.Module):\n",
    "    # Copy/paste of https://www.kaggle.com/code/wasupandceacar/lb-0-82-5fold-single-bert-model#Model implementation\n",
    "    def __init__(self, channels:int, reduction:int=8):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(channels, channels // reduction, bias=True)\n",
    "        self.fc2 = nn.Linear(channels // reduction, channels, bias=True)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, C, L)\n",
    "        se = F.adaptive_avg_pool1d(x, 1).squeeze(-1)      # -> (B, C)\n",
    "        se = F.relu(self.fc1(se), inplace=True)          # -> (B, C//r)\n",
    "        se = self.sigmoid(self.fc2(se)).unsqueeze(-1)    # -> (B, C, 1)\n",
    "        return x * se\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_chns:int, out_chns:int, dropout_ratio:float=0.3, se_reduction:int=8, kernel_size:int=3):\n",
    "        super().__init__()\n",
    "        self.blocks = nn.Sequential(\n",
    "            nn.Conv1d(in_chns, out_chns, kernel_size=kernel_size, padding=kernel_size // 2, bias=False),\n",
    "            nn.BatchNorm1d(out_chns),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(out_chns, out_chns, kernel_size=kernel_size, padding=kernel_size // 2, bias=False),\n",
    "            nn.BatchNorm1d(out_chns),\n",
    "            SqueezeExcitationBlock(out_chns, se_reduction),\n",
    "        )\n",
    "        self.head = nn.Sequential(nn.ReLU(), nn.Dropout(dropout_ratio))\n",
    "        if in_chns == out_chns:\n",
    "            self.skip_connection = nn.Identity() \n",
    "        else:\n",
    "            # TODO: set bias to False ?\n",
    "            self.skip_connection = nn.Sequential(\n",
    "                nn.Conv1d(in_chns, out_chns, 1, bias=False),\n",
    "                nn.BatchNorm1d(out_chns)\n",
    "            )\n",
    "            self.head.insert(1, nn.MaxPool1d(2))\n",
    "\n",
    "    def forward(self, x:Tensor) -> Tensor:\n",
    "        activaition_maps = self.skip_connection(x) + self.blocks(x)\n",
    "        return self.head(activaition_maps)\n",
    "\n",
    "class MBConvBlock(nn.Module):\n",
    "    # From this schema: https://media.licdn.com/dms/image/v2/D5612AQFjbDOm5uyxdw/article-inline_image-shrink_1500_2232/article-inline_image-shrink_1500_2232/0/1683677500817?e=1758153600&v=beta&t=n48_UW5TZTyDPhRFlJXSidUQQPQpuC756M0kNeKmYTY\n",
    "    def __init__(self, in_chns:int, out_chns:int, se_reduction:int=8, expansion_ratio:int=4, dropout_ratio:float=0.3):\n",
    "        super().__init__()\n",
    "        expanded_channels = in_chns * expansion_ratio\n",
    "        self.blocks = nn.Sequential(\n",
    "            nn.Conv1d(in_chns, expanded_channels, kernel_size=1, bias=False),\n",
    "            nn.BatchNorm1d(expanded_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(\n",
    "                expanded_channels,\n",
    "                expanded_channels,\n",
    "                kernel_size=3,\n",
    "                padding=1,\n",
    "                groups=expanded_channels,\n",
    "                bias=False,\n",
    "            ),\n",
    "            nn.BatchNorm1d(expanded_channels),\n",
    "            nn.ReLU(),\n",
    "            SqueezeExcitationBlock(expanded_channels, se_reduction),\n",
    "            nn.Conv1d(expanded_channels, out_chns, kernel_size=1, bias=False)\n",
    "        )\n",
    "        self.head = nn.Sequential(\n",
    "            nn.BatchNorm1d(out_chns)\n",
    "            # nn.ReLU(),\n",
    "            # nn.Dropout(dropout_ratio),\n",
    "        )\n",
    "        if in_chns == out_chns:\n",
    "            self.skip_connection = nn.Identity() \n",
    "        else:\n",
    "            # TODO: set bias to False ?\n",
    "            self.skip_connection = nn.Sequential(\n",
    "                nn.Conv1d(in_chns, out_chns, 1, bias=False),\n",
    "                nn.BatchNorm1d(out_chns)\n",
    "            )\n",
    "            self.head.add_module(\"max_pool\", nn.MaxPool1d(2))\n",
    "            \n",
    "    def forward(self, x:Tensor) -> Tensor:\n",
    "        activaition_maps = self.skip_connection(x) + self.blocks(x)\n",
    "        return self.head(activaition_maps)\n",
    "\n",
    "class AdditiveAttentionLayer(nn.Module):\n",
    "    # Copied (and slightly modified) from https://www.kaggle.com/code/myso1987/cmi3-pyroch-baseline-model-add-aug-folds\n",
    "    def __init__(self, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.attention = nn.Linear(hidden_dim, 1, bias=True)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        # x shape: (batch, channels, seq_len)\n",
    "        x = x.swapaxes(1, 2)\n",
    "        # x shape: (batch, seq_len, hidden_dim)\n",
    "        scores = torch.tanh(self.attention(x))  # (batch, seq_len, 1)\n",
    "        weights = F.softmax(scores.squeeze(-1), dim=1)  # (batch, seq_len)\n",
    "        context = torch.sum(x * weights.unsqueeze(-1), dim=1)  # (batch, hidden_dim)\n",
    "        return context\n",
    "\n",
    "class AlexNet(nn.Sequential):\n",
    "    def __init__(self, channels:list[int], dropout_ratio:float):\n",
    "        def mk_conv_block(in_channels:int, out_channels:int) -> nn.Module:\n",
    "            return nn.Sequential(\n",
    "                nn.Conv1d(in_channels, out_channels, 3, padding=1, bias=False),\n",
    "                nn.BatchNorm1d(out_channels),\n",
    "                nn.MaxPool1d(2),\n",
    "                nn.Dropout(dropout_ratio),\n",
    "            )\n",
    "        return super().__init__(*list(starmap(mk_conv_block, pairwise(channels))))\n",
    "\n",
    "class CMIHARModule(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            imu_idx:list[int],\n",
    "            thm_idx:list[int],\n",
    "            tof_idx:list[int],\n",
    "            mlp_width:int,\n",
    "            n_class:int,            \n",
    "            dataset_x:Tensor,\n",
    "            tof_dropout_ratio:float=0,\n",
    "            thm_dropout_ratio:float=0,\n",
    "        ):\n",
    "        super().__init__()\n",
    "        self.imu_idx = imu_idx\n",
    "        self.tof_idx = tof_idx\n",
    "        self.thm_idx = thm_idx\n",
    "        self.x_mean = dataset_x.mean(dim=(0, 2), keepdim=True)\n",
    "        # print(dataset_x.shape)\n",
    "        # print(self.x_mean.shape)\n",
    "        self.x_std = dataset_x.std(dim=(0, 2), keepdim=True)\n",
    "        # print(self.x_std.shape)\n",
    "        self.imu_branch = nn.Sequential(\n",
    "            # ImuFeatureExtractor(len(imu_idx)),\n",
    "            ResidualBlock(len(imu_idx), 219),\n",
    "            ResidualBlock(219, 500),\n",
    "        )\n",
    "        self.tof_branch = AlexNet([len(tof_idx), 82, 500], tof_dropout_ratio)\n",
    "        self.thm_branch = AlexNet([len(thm_idx), 82, 500], thm_dropout_ratio)\n",
    "        self.rnn = nn.GRU(500 * 3, mlp_width // 2, bidirectional=True)\n",
    "        self.attention = AdditiveAttentionLayer(mlp_width)\n",
    "        self.head = nn.Sequential(\n",
    "            # Head\n",
    "            nn.LazyLinear(mlp_width, bias=False),\n",
    "            nn.BatchNorm1d(mlp_width),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(mlp_width, mlp_width // 2, bias=False),\n",
    "            nn.BatchNorm1d(mlp_width // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(mlp_width // 2, n_class),\n",
    "        )\n",
    "\n",
    "    def forward(self, x:Tensor) -> Tensor:\n",
    "        x = (x - self.x_mean) / self.x_std\n",
    "        concatenated_activation_maps = torch.cat(\n",
    "            (\n",
    "                self.imu_branch(x[:, self.imu_idx]),\n",
    "                self.thm_branch(x[:, self.thm_idx]),\n",
    "                self.tof_branch(x[:, self.tof_idx]),\n",
    "            ),\n",
    "            dim=CHANNELS_DIMENSION,\n",
    "        )\n",
    "        lstm_output, _  = self.rnn(concatenated_activation_maps.swapaxes(1, 2))\n",
    "        lstm_output = lstm_output.swapaxes(1, 2) # redundant\n",
    "        attended = self.attention(lstm_output)\n",
    "        return self.head(attended)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999a5ac6",
   "metadata": {
    "papermill": {
     "duration": 0.007331,
     "end_time": "2025-08-02T11:25:20.617266",
     "exception": false,
     "start_time": "2025-08-02T11:25:20.609935",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Create model function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d55cb1b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-02T11:25:20.632982Z",
     "iopub.status.busy": "2025-08-02T11:25:20.632760Z",
     "iopub.status.idle": "2025-08-02T11:25:20.929218Z",
     "shell.execute_reply": "2025-08-02T11:25:20.928490Z"
    },
    "papermill": {
     "duration": 0.305529,
     "end_time": "2025-08-02T11:25:20.930258",
     "exception": false,
     "start_time": "2025-08-02T11:25:20.624729",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CMIHARModule(\n",
       "  (imu_branch): Sequential(\n",
       "    (0): ResidualBlock(\n",
       "      (blocks): Sequential(\n",
       "        (0): Conv1d(46, 219, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "        (1): BatchNorm1d(219, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv1d(219, 219, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "        (4): BatchNorm1d(219, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): SqueezeExcitationBlock(\n",
       "          (fc1): Linear(in_features=219, out_features=27, bias=True)\n",
       "          (fc2): Linear(in_features=27, out_features=219, bias=True)\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (head): Sequential(\n",
       "        (0): ReLU()\n",
       "        (1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (2): Dropout(p=0.3, inplace=False)\n",
       "      )\n",
       "      (skip_connection): Sequential(\n",
       "        (0): Conv1d(46, 219, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        (1): BatchNorm1d(219, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): ResidualBlock(\n",
       "      (blocks): Sequential(\n",
       "        (0): Conv1d(219, 500, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "        (1): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv1d(500, 500, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "        (4): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): SqueezeExcitationBlock(\n",
       "          (fc1): Linear(in_features=500, out_features=62, bias=True)\n",
       "          (fc2): Linear(in_features=62, out_features=500, bias=True)\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (head): Sequential(\n",
       "        (0): ReLU()\n",
       "        (1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (2): Dropout(p=0.3, inplace=False)\n",
       "      )\n",
       "      (skip_connection): Sequential(\n",
       "        (0): Conv1d(219, 500, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        (1): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (tof_branch): AlexNet(\n",
       "    (0): Sequential(\n",
       "      (0): Conv1d(640, 82, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "      (1): BatchNorm1d(82, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (3): Dropout(p=0, inplace=False)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Conv1d(82, 500, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "      (1): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (3): Dropout(p=0, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (thm_branch): AlexNet(\n",
       "    (0): Sequential(\n",
       "      (0): Conv1d(10, 82, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "      (1): BatchNorm1d(82, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (3): Dropout(p=0, inplace=False)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Conv1d(82, 500, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "      (1): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (3): Dropout(p=0, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (rnn): GRU(1500, 128, bidirectional=True)\n",
       "  (attention): AdditiveAttentionLayer(\n",
       "    (attention): Linear(in_features=256, out_features=1, bias=True)\n",
       "  )\n",
       "  (head): Sequential(\n",
       "    (0): LazyLinear(in_features=0, out_features=256, bias=False)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=128, bias=False)\n",
       "    (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=128, out_features=18, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input channels: 696\n"
     ]
    }
   ],
   "source": [
    "def mk_model(dataset_x:Tensor) -> nn.Module:\n",
    "    return (\n",
    "        CMIHARModule(\n",
    "            imu_idx=imu_idx,\n",
    "            thm_idx=thm_idx,\n",
    "            tof_idx=tof_idx,\n",
    "            mlp_width=256,\n",
    "            n_class=18,\n",
    "            dataset_x=dataset_x,\n",
    "        )\n",
    "        .to(device)\n",
    "    )\n",
    "\n",
    "display(mk_model(torch.arange(12).view(2, 2, -1).float()))\n",
    "print(\"input channels:\", len(meta_data[\"feature_cols\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21c1bcb",
   "metadata": {
    "papermill": {
     "duration": 0.015047,
     "end_time": "2025-08-02T11:26:29.351055",
     "exception": false,
     "start_time": "2025-08-02T11:26:29.336008",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54f9ce8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-02T11:25:20.542848Z",
     "iopub.status.busy": "2025-08-02T11:25:20.542635Z",
     "iopub.status.idle": "2025-08-02T11:25:20.549658Z",
     "shell.execute_reply": "2025-08-02T11:25:20.549107Z"
    },
    "papermill": {
     "duration": 0.016225,
     "end_time": "2025-08-02T11:25:20.550737",
     "exception": false,
     "start_time": "2025-08-02T11:25:20.534512",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CosineAnnealingWarmupRestarts(_LRScheduler):\n",
    "    def __init__(\n",
    "        self,\n",
    "        optimizer: Optimizer,\n",
    "        warmup_steps: int,\n",
    "        max_lr: float,\n",
    "        min_lr: float,\n",
    "        cycle_length: int,\n",
    "        cycle_mult: float = 1.0,\n",
    "        gamma: float = 1.0,\n",
    "        last_epoch: int = -1,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            optimizer: Wrapped optimizer.\n",
    "            warmup_steps: Number of steps for linear warmup.\n",
    "            max_lr: Initial maximum learning rate.\n",
    "            min_lr: Minimum learning rate after decay.\n",
    "            cycle_length: Initial number of steps per cosine cycle.\n",
    "            cycle_mult: Multiplicative factor for increasing cycle lengths.\n",
    "            gamma: Multiplicative decay factor for max_lr after each cycle.\n",
    "            last_epoch: The index of last epoch. Default: -1.\n",
    "        \"\"\"\n",
    "        self.warmup_steps = warmup_steps\n",
    "        self.max_lr = max_lr\n",
    "        self.min_lr = min_lr\n",
    "        self.cycle_length = cycle_length\n",
    "        self.cycle_mult = cycle_mult\n",
    "        self.gamma = gamma\n",
    "\n",
    "        self.current_cycle = 0\n",
    "        self.cycle_step = 0\n",
    "        self.lr = max_lr\n",
    "\n",
    "        super().__init__(optimizer, last_epoch)\n",
    "\n",
    "    def get_lr(self) -> list[float]:\n",
    "        if self.last_epoch < self.warmup_steps:\n",
    "            # Linear warmup\n",
    "            scale = (self.last_epoch + 1) / self.warmup_steps\n",
    "            return [self.min_lr + scale * (self.max_lr - self.min_lr) for _ in self.base_lrs]\n",
    "\n",
    "        # Adjust for post-warmup step index\n",
    "        t = self.cycle_step\n",
    "        T = self.cycle_length\n",
    "\n",
    "        cosine_decay = 0.5 * (1 + math.cos(math.pi * t / T))\n",
    "        lr = self.min_lr + (self.max_lr - self.min_lr) * cosine_decay\n",
    "\n",
    "        return [lr for _ in self.base_lrs]\n",
    "\n",
    "    def step(self, epoch: Optional[int] = None) -> None:\n",
    "        if self.last_epoch >= self.warmup_steps:\n",
    "            self.cycle_step += 1\n",
    "            if self.cycle_step >= self.cycle_length:\n",
    "                self.current_cycle += 1\n",
    "                self.cycle_step = 0\n",
    "                self.cycle_length = max(int(self.cycle_length * self.cycle_mult), 1)\n",
    "                self.max_lr *= self.gamma\n",
    "        super().step(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eccfd5f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-02T11:26:30.302707Z",
     "iopub.status.busy": "2025-08-02T11:26:30.302531Z",
     "iopub.status.idle": "2025-08-02T11:26:30.306635Z",
     "shell.execute_reply": "2025-08-02T11:26:30.306194Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.941075,
     "end_time": "2025-08-02T11:26:30.307624",
     "exception": false,
     "start_time": "2025-08-02T11:26:29.366549",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def mixup_data(x, y, alpha=0.2):\n",
    "    \"\"\"\n",
    "    Return mixed inputs and mixed targets (one-hot) for mixup.\n",
    "    x: Tensor of shape (batch_size, features, seq_len)\n",
    "    y: Tensor of shape (batch_size, num_classes)\n",
    "    \"\"\"\n",
    "    if alpha > 0:\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "    else:\n",
    "        lam = 1.0\n",
    "    batch_size = x.size(0)\n",
    "    index = torch.randperm(batch_size).to(x.device)\n",
    "\n",
    "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "    mixed_y = lam * y + (1 - lam) * y[index, :]\n",
    "    return mixed_x, mixed_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941ea005",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-02T11:26:30.326271Z",
     "iopub.status.busy": "2025-08-02T11:26:30.326049Z",
     "iopub.status.idle": "2025-08-02T11:26:30.343798Z",
     "shell.execute_reply": "2025-08-02T11:26:30.343286Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.027971,
     "end_time": "2025-08-02T11:26:30.344749",
     "exception": false,
     "start_time": "2025-08-02T11:26:30.316778",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(\n",
    "        model:nn.Module,\n",
    "        train_loader:DL,\n",
    "        criterion:callable,\n",
    "        optimizer:torch.optim.Optimizer,\n",
    "        scheduler:_LRScheduler,\n",
    "    ) -> dict:\n",
    "    \"Train model on a single epoch\"\n",
    "    train_metrics = {}\n",
    "    model.train()\n",
    "    train_metrics[\"train_loss\"] = 0.0\n",
    "    total = 0\n",
    "    for batch_x, batch_y in train_loader:\n",
    "        batch_x = batch_x.to(device).clone()\n",
    "        add_noise = torch.randn_like(batch_x, device=device) * 0.04\n",
    "        scale_noise = torch.rand_like(batch_x, device=device) * (1.1 - 0.9) + 0.9\n",
    "        batch_x = (add_noise + batch_x) * scale_noise\n",
    "        batch_x[:TRAIN_BATCH_SIZE // 2, tof_idx + thm_idx] = 0.0\n",
    "        batch_y = batch_y.to(device)\n",
    "        batch_x = batch_x.float()\n",
    "        \n",
    "        batch_x, batch_y = mixup_data(batch_x, batch_y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_x)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        train_metrics[\"train_loss\"] += loss.item() * batch_x.size(0)\n",
    "        total += batch_x.size(0)\n",
    "    train_metrics[\"train_loss\"] /= total\n",
    "\n",
    "    return train_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d8b67aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model:nn.Module, validation_loader:DL, criterion:callable) -> dict:\n",
    "    model.eval()\n",
    "    eval_metrics = {}\n",
    "    eval_metrics[\"val_loss\"] = 0.0\n",
    "    total = 0\n",
    "    all_true = []\n",
    "    all_pred = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_x, batch_y in validation_loader:\n",
    "            batch_x = batch_x.to(device).clone()\n",
    "            batch_y = batch_y.to(device)\n",
    "            batch_x[:VALIDATION_BATCH_SIZE // 2, tof_idx + thm_idx] = 0.0\n",
    "\n",
    "            outputs = model(batch_x)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            eval_metrics[\"val_loss\"] += loss.item() * batch_x.size(0)\n",
    "            total += batch_x.size(0)\n",
    "\n",
    "            # Get predicted class indices\n",
    "            preds = torch.argmax(outputs, dim=1).cpu().numpy()\n",
    "            # Get true class indices from one-hot\n",
    "            trues = torch.argmax(batch_y, dim=1).cpu().numpy()\n",
    "\n",
    "            all_true.append(trues)\n",
    "            all_pred.append(preds)\n",
    "\n",
    "    eval_metrics[\"val_loss\"] /= total\n",
    "    all_true = np.concatenate(all_true)\n",
    "    all_pred = np.concatenate(all_pred)\n",
    "\n",
    "    # Compute competition metrics\n",
    "    # Binary classification: BFRB (1) vs non-BFRB (0)\n",
    "    binary_true = np.isin(all_true, bfrb_indices).astype(int)\n",
    "    binary_pred = np.isin(all_pred, bfrb_indices).astype(int)\n",
    "    eval_metrics[\"binary_f1\"] = f1_score(binary_true, binary_pred)\n",
    "\n",
    "    # Collapse non-BFRB gestures into a single class\n",
    "    collapsed_true = np.where(\n",
    "        np.isin(all_true, bfrb_indices),\n",
    "        all_true,\n",
    "        len(bfrb_gestures)  # Single non-BFRB class\n",
    "    )\n",
    "    collapsed_pred = np.where(\n",
    "        np.isin(all_pred, bfrb_indices),\n",
    "        all_pred,\n",
    "        len(bfrb_gestures)  # Single non-BFRB class\n",
    "    )\n",
    "\n",
    "    # Macro F1 on collapsed classes\n",
    "    eval_metrics[\"macro_f1\"] = f1_score(collapsed_true, collapsed_pred, average='macro')\n",
    "    eval_metrics[\"final_metric\"] = (eval_metrics[\"binary_f1\"] + eval_metrics[\"macro_f1\"]) / 2\n",
    "\n",
    "    return eval_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "02d96f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_on_all_epochs(\n",
    "        model:nn.Module,\n",
    "        train_loader:DL,\n",
    "        validation_loader:DL,\n",
    "        criterion:callable,\n",
    "        optimizer:torch.optim.Optimizer,\n",
    "        scheduler:_LRScheduler,\n",
    "        fold:int,\n",
    "    ) -> DF:\n",
    "\n",
    "    metrics:list[dict] = []\n",
    "    # Early stopping\n",
    "    best_metric = -np.inf\n",
    "    best_binary_f1 = -np.inf\n",
    "    best_macro_f1 = -np.inf\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    for epoch in range(1, TRAINING_EPOCHS + 1):\n",
    "        train_metrics = train_model(model, train_loader, criterion, optimizer, scheduler)\n",
    "        validation_metrics = evaluate_model(model, validation_loader, criterion)\n",
    "        metrics.append({\"fold\": fold, \"epoch\": epoch} | train_metrics | validation_metrics)\n",
    "\n",
    "        print(f\"Epoch {epoch:02d}: Binary F1 = {validation_metrics['binary_f1']:.4f}, Macro F1 = {validation_metrics['macro_f1']:.4f}, Final Metric = {validation_metrics['final_metric']:.4f}\")\n",
    "\n",
    "        if validation_metrics[\"final_metric\"] > best_metric:\n",
    "            best_metric = validation_metrics[\"final_metric\"]\n",
    "            best_binary_f1 = validation_metrics[\"binary_f1\"]\n",
    "            best_macro_f1 = validation_metrics[\"macro_f1\"]\n",
    "            epochs_no_improve = 0\n",
    "            best_model_state = model.state_dict()\n",
    "            print(f\"  New best metric! Saving model...\")\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            if epochs_no_improve >= PATIENCE:\n",
    "                print(f\"Early stopping triggered at epoch {epoch}\")\n",
    "                model.load_state_dict(best_model_state)\n",
    "                break\n",
    "\n",
    "    torch.save(best_model_state, f\"best_model_fold{fold}.pth\")\n",
    "\n",
    "    return DF.from_records(metrics).set_index([\"fold\", \"epoch\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "941ea005",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-02T11:26:30.326271Z",
     "iopub.status.busy": "2025-08-02T11:26:30.326049Z",
     "iopub.status.idle": "2025-08-02T11:26:30.343798Z",
     "shell.execute_reply": "2025-08-02T11:26:30.343286Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.027971,
     "end_time": "2025-08-02T11:26:30.344749",
     "exception": false,
     "start_time": "2025-08-02T11:26:30.316778",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_on_all_folds(lr_scheduler_kw:dict, optimizer_kw:dict) -> tuple[float, DF]:\n",
    "    seed_everything(seed=SEED)\n",
    "\n",
    "    metrics:DF = DF()\n",
    "\n",
    "    for fold in range(NB_CROSS_VALIDATIONS):\n",
    "        seed_everything(seed=SEED + fold)\n",
    "        # Debugging\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(\"training:\", fold + 1)\n",
    "        train_dataset = CMIDataset(PAD_SEQ_MODE, f\"fold_{fold}\", \"train\")\n",
    "        print(f\"Fold {fold + 1}/{NB_CROSS_VALIDATIONS}\")\n",
    "        criterion = torch.nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "        train_loader = DL(train_dataset, TRAIN_BATCH_SIZE, shuffle=True, drop_last=True)\n",
    "        validation_dataset = CMIDataset(PAD_SEQ_MODE, f\"fold_{fold}\", \"validation\")\n",
    "        validation_loader = DL(validation_dataset, VALIDATION_BATCH_SIZE, shuffle=False, drop_last=True)\n",
    "\n",
    "        model = mk_model(train_dataset.tensors[0])\n",
    "\n",
    "        # Optimizer et scheduler\n",
    "        # min_lr = max_lr / 100\n",
    "        optimizer = torch.optim.AdamW(\n",
    "            model.parameters(),\n",
    "            WARMUP_LR_INIT,\n",
    "            weight_decay=optimizer_kw[\"weight_decay\"],\n",
    "            betas=(optimizer_kw[\"beta_0\"], optimizer_kw[\"beta_1\"]),\n",
    "        )\n",
    "        steps_per_epoch = len(train_loader)\n",
    "        scheduler = CosineAnnealingWarmupRestarts(\n",
    "            optimizer,\n",
    "            warmup_steps=lr_scheduler_kw[\"warmup_epochs\"] * steps_per_epoch,\n",
    "            cycle_mult=lr_scheduler_kw[\"cycle_mult\"],\n",
    "            max_lr=lr_scheduler_kw[\"max_lr\"],\n",
    "            min_lr=lr_scheduler_kw[\"max_lr\"] / lr_scheduler_kw[\"max_to_min_div_factor\"],\n",
    "            cycle_length=lr_scheduler_kw[\"init_cycle_epochs\"] * steps_per_epoch,\n",
    "            gamma=lr_scheduler_kw[\"lr_cycle_factor\"],\n",
    "        ) \n",
    "        fold_metrics = train_model_on_all_epochs(\n",
    "            model,\n",
    "            train_loader,\n",
    "            validation_loader,\n",
    "            criterion,\n",
    "            optimizer,\n",
    "            scheduler,\n",
    "            fold,\n",
    "        )\n",
    "        # Free memory used by datasets and data loaders\n",
    "        del train_dataset\n",
    "        del validation_dataset\n",
    "        del train_loader\n",
    "        del validation_loader\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        best_fold_metrics = fold_metrics.loc[fold_metrics[\"final_metric\"].idxmax()]\n",
    "        final_fold_metrics = fold_metrics.iloc[-1]\n",
    "        print(f\"Best  validation metrics - Binary F1: {best_fold_metrics['binary_f1']:.4f}, Macro F1: {best_fold_metrics['macro_f1']:.4f}, Final: {best_fold_metrics['final_metric']:.4f}\")\n",
    "        print(f\"Final validation metrics - Binary F1: {final_fold_metrics['binary_f1']:.4f}, Macro F1: {final_fold_metrics['macro_f1']:.4f}, Final: {final_fold_metrics['final_metric']:.4f}\")\n",
    "\n",
    "        metrics = pd.concat((metrics, fold_metrics))\n",
    "\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"Cross-Validation Results\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "    # Statistiques pour les meilleures mÃ©triques\n",
    "    best_metrics:DF = (\n",
    "        metrics\n",
    "        .loc[:, [\"binary_f1\", \"macro_f1\", \"final_metric\"]]\n",
    "        .groupby(level=0)\n",
    "        .max()\n",
    "    )\n",
    "\n",
    "    print(\"\\nBest Fold-wise Metrics:\")\n",
    "    display(best_metrics)\n",
    "    \n",
    "    print(\"\\nGlobal Statistics (Best Metrics):\")\n",
    "    print(f\"Mean Best Final Metric: {best_metrics['final_metric'].mean():.4f} Â± {best_metrics['final_metric'].std():.4f}\")\n",
    "    print(f\"Mean Best Binary F1: {best_metrics['binary_f1'].mean():.4f} Â± {best_metrics['binary_f1'].std():.4f}\")\n",
    "    print(f\"Mean Best Macro F1: {best_metrics['macro_f1'].mean():.4f} Â± {best_metrics['macro_f1'].std():.4f}\")\n",
    "    \n",
    "    return best_metrics[\"final_metric\"].mean(), metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d0936698",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-02T11:26:30.385055Z",
     "iopub.status.busy": "2025-08-02T11:26:30.384637Z",
     "iopub.status.idle": "2025-08-02T11:33:13.504786Z",
     "shell.execute_reply": "2025-08-02T11:33:13.503986Z"
    },
    "papermill": {
     "duration": 403.130501,
     "end_time": "2025-08-02T11:33:13.506236",
     "exception": false,
     "start_time": "2025-08-02T11:26:30.375735",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "training: 1\n",
      "Fold 1/5\n",
      "Epoch 01: Binary F1 = 0.7002, Macro F1 = 0.2206, Final Metric = 0.4604\n",
      "  New best metric! Saving model...\n",
      "Epoch 02: Binary F1 = 0.9285, Macro F1 = 0.3461, Final Metric = 0.6373\n",
      "  New best metric! Saving model...\n",
      "Epoch 03: Binary F1 = 0.9411, Macro F1 = 0.4148, Final Metric = 0.6779\n",
      "  New best metric! Saving model...\n",
      "Epoch 04: Binary F1 = 0.9237, Macro F1 = 0.4452, Final Metric = 0.6844\n",
      "  New best metric! Saving model...\n",
      "Epoch 05: Binary F1 = 0.9578, Macro F1 = 0.4595, Final Metric = 0.7086\n",
      "  New best metric! Saving model...\n",
      "Epoch 06: Binary F1 = 0.9445, Macro F1 = 0.4518, Final Metric = 0.6981\n",
      "Epoch 07: Binary F1 = 0.9409, Macro F1 = 0.4978, Final Metric = 0.7194\n",
      "  New best metric! Saving model...\n",
      "Epoch 08: Binary F1 = 0.9527, Macro F1 = 0.4729, Final Metric = 0.7128\n",
      "Epoch 09: Binary F1 = 0.9529, Macro F1 = 0.5178, Final Metric = 0.7353\n",
      "  New best metric! Saving model...\n",
      "Epoch 10: Binary F1 = 0.9698, Macro F1 = 0.5211, Final Metric = 0.7454\n",
      "  New best metric! Saving model...\n",
      "Epoch 11: Binary F1 = 0.9669, Macro F1 = 0.5272, Final Metric = 0.7471\n",
      "  New best metric! Saving model...\n",
      "Epoch 12: Binary F1 = 0.9762, Macro F1 = 0.5652, Final Metric = 0.7707\n",
      "  New best metric! Saving model...\n",
      "Epoch 13: Binary F1 = 0.9762, Macro F1 = 0.5785, Final Metric = 0.7774\n",
      "  New best metric! Saving model...\n",
      "Epoch 14: Binary F1 = 0.9708, Macro F1 = 0.5575, Final Metric = 0.7642\n",
      "Epoch 15: Binary F1 = 0.9748, Macro F1 = 0.5624, Final Metric = 0.7686\n",
      "Epoch 16: Binary F1 = 0.9746, Macro F1 = 0.5626, Final Metric = 0.7686\n",
      "Epoch 17: Binary F1 = 0.9778, Macro F1 = 0.5831, Final Metric = 0.7804\n",
      "  New best metric! Saving model...\n",
      "Epoch 18: Binary F1 = 0.9754, Macro F1 = 0.5654, Final Metric = 0.7704\n",
      "Epoch 19: Binary F1 = 0.9754, Macro F1 = 0.5702, Final Metric = 0.7728\n",
      "Epoch 20: Binary F1 = 0.9754, Macro F1 = 0.5740, Final Metric = 0.7747\n",
      "Epoch 21: Binary F1 = 0.9809, Macro F1 = 0.5675, Final Metric = 0.7742\n",
      "Epoch 22: Binary F1 = 0.9778, Macro F1 = 0.5913, Final Metric = 0.7845\n",
      "  New best metric! Saving model...\n",
      "Epoch 23: Binary F1 = 0.9770, Macro F1 = 0.5838, Final Metric = 0.7804\n",
      "Epoch 24: Binary F1 = 0.9785, Macro F1 = 0.5893, Final Metric = 0.7839\n",
      "Epoch 25: Binary F1 = 0.9762, Macro F1 = 0.5743, Final Metric = 0.7752\n",
      "Best  validation metrics - Binary F1: 0.9778, Macro F1: 0.5913, Final: 0.7845\n",
      "Final validation metrics - Binary F1: 0.9762, Macro F1: 0.5743, Final: 0.7752\n",
      "\n",
      "==================================================\n",
      "training: 2\n",
      "Fold 2/5\n",
      "Epoch 01: Binary F1 = 0.6981, Macro F1 = 0.2478, Final Metric = 0.4730\n",
      "  New best metric! Saving model...\n",
      "Epoch 02: Binary F1 = 0.8962, Macro F1 = 0.3544, Final Metric = 0.6253\n",
      "  New best metric! Saving model...\n",
      "Epoch 03: Binary F1 = 0.9208, Macro F1 = 0.4163, Final Metric = 0.6686\n",
      "  New best metric! Saving model...\n",
      "Epoch 04: Binary F1 = 0.9195, Macro F1 = 0.4317, Final Metric = 0.6756\n",
      "  New best metric! Saving model...\n",
      "Epoch 05: Binary F1 = 0.9535, Macro F1 = 0.4767, Final Metric = 0.7151\n",
      "  New best metric! Saving model...\n",
      "Epoch 06: Binary F1 = 0.9439, Macro F1 = 0.4694, Final Metric = 0.7066\n",
      "Epoch 07: Binary F1 = 0.9295, Macro F1 = 0.4865, Final Metric = 0.7080\n",
      "Epoch 08: Binary F1 = 0.9380, Macro F1 = 0.4625, Final Metric = 0.7002\n",
      "Epoch 09: Binary F1 = 0.9525, Macro F1 = 0.4560, Final Metric = 0.7043\n",
      "Epoch 10: Binary F1 = 0.9682, Macro F1 = 0.5224, Final Metric = 0.7453\n",
      "  New best metric! Saving model...\n",
      "Epoch 11: Binary F1 = 0.9703, Macro F1 = 0.5680, Final Metric = 0.7691\n",
      "  New best metric! Saving model...\n",
      "Epoch 12: Binary F1 = 0.9686, Macro F1 = 0.5892, Final Metric = 0.7789\n",
      "  New best metric! Saving model...\n",
      "Epoch 13: Binary F1 = 0.9693, Macro F1 = 0.5956, Final Metric = 0.7824\n",
      "  New best metric! Saving model...\n",
      "Epoch 14: Binary F1 = 0.9630, Macro F1 = 0.5569, Final Metric = 0.7599\n",
      "Epoch 15: Binary F1 = 0.9663, Macro F1 = 0.5968, Final Metric = 0.7815\n",
      "Epoch 16: Binary F1 = 0.9716, Macro F1 = 0.5882, Final Metric = 0.7799\n",
      "Epoch 17: Binary F1 = 0.9694, Macro F1 = 0.6081, Final Metric = 0.7888\n",
      "  New best metric! Saving model...\n",
      "Epoch 18: Binary F1 = 0.9709, Macro F1 = 0.6069, Final Metric = 0.7889\n",
      "  New best metric! Saving model...\n",
      "Epoch 19: Binary F1 = 0.9778, Macro F1 = 0.5846, Final Metric = 0.7812\n",
      "Epoch 20: Binary F1 = 0.9778, Macro F1 = 0.6035, Final Metric = 0.7907\n",
      "  New best metric! Saving model...\n",
      "Epoch 21: Binary F1 = 0.9685, Macro F1 = 0.6012, Final Metric = 0.7849\n",
      "Epoch 22: Binary F1 = 0.9708, Macro F1 = 0.6080, Final Metric = 0.7894\n",
      "Epoch 23: Binary F1 = 0.9716, Macro F1 = 0.6173, Final Metric = 0.7945\n",
      "  New best metric! Saving model...\n",
      "Epoch 24: Binary F1 = 0.9717, Macro F1 = 0.5918, Final Metric = 0.7818\n",
      "Epoch 25: Binary F1 = 0.9709, Macro F1 = 0.6052, Final Metric = 0.7881\n",
      "Best  validation metrics - Binary F1: 0.9716, Macro F1: 0.6173, Final: 0.7945\n",
      "Final validation metrics - Binary F1: 0.9709, Macro F1: 0.6052, Final: 0.7881\n",
      "\n",
      "==================================================\n",
      "training: 3\n",
      "Fold 3/5\n",
      "Epoch 01: Binary F1 = 0.8066, Macro F1 = 0.2715, Final Metric = 0.5391\n",
      "  New best metric! Saving model...\n",
      "Epoch 02: Binary F1 = 0.9363, Macro F1 = 0.3961, Final Metric = 0.6662\n",
      "  New best metric! Saving model...\n",
      "Epoch 03: Binary F1 = 0.9391, Macro F1 = 0.4473, Final Metric = 0.6932\n",
      "  New best metric! Saving model...\n",
      "Epoch 04: Binary F1 = 0.9338, Macro F1 = 0.4703, Final Metric = 0.7020\n",
      "  New best metric! Saving model...\n",
      "Epoch 05: Binary F1 = 0.9433, Macro F1 = 0.5050, Final Metric = 0.7242\n",
      "  New best metric! Saving model...\n",
      "Epoch 06: Binary F1 = 0.9248, Macro F1 = 0.4575, Final Metric = 0.6912\n",
      "Epoch 07: Binary F1 = 0.9400, Macro F1 = 0.4988, Final Metric = 0.7194\n",
      "Epoch 08: Binary F1 = 0.9669, Macro F1 = 0.5540, Final Metric = 0.7605\n",
      "  New best metric! Saving model...\n",
      "Epoch 09: Binary F1 = 0.9646, Macro F1 = 0.5389, Final Metric = 0.7517\n",
      "Epoch 10: Binary F1 = 0.9704, Macro F1 = 0.5510, Final Metric = 0.7607\n",
      "  New best metric! Saving model...\n",
      "Epoch 11: Binary F1 = 0.9671, Macro F1 = 0.5909, Final Metric = 0.7790\n",
      "  New best metric! Saving model...\n",
      "Epoch 12: Binary F1 = 0.9705, Macro F1 = 0.6233, Final Metric = 0.7969\n",
      "  New best metric! Saving model...\n",
      "Epoch 13: Binary F1 = 0.9736, Macro F1 = 0.6328, Final Metric = 0.8032\n",
      "  New best metric! Saving model...\n",
      "Epoch 14: Binary F1 = 0.9703, Macro F1 = 0.5996, Final Metric = 0.7849\n",
      "Epoch 15: Binary F1 = 0.9620, Macro F1 = 0.6136, Final Metric = 0.7878\n",
      "Epoch 16: Binary F1 = 0.9745, Macro F1 = 0.6298, Final Metric = 0.8022\n",
      "Epoch 17: Binary F1 = 0.9760, Macro F1 = 0.6318, Final Metric = 0.8039\n",
      "  New best metric! Saving model...\n",
      "Epoch 18: Binary F1 = 0.9734, Macro F1 = 0.6197, Final Metric = 0.7965\n",
      "Epoch 19: Binary F1 = 0.9759, Macro F1 = 0.6248, Final Metric = 0.8003\n",
      "Epoch 20: Binary F1 = 0.9767, Macro F1 = 0.6196, Final Metric = 0.7981\n",
      "Epoch 21: Binary F1 = 0.9775, Macro F1 = 0.6359, Final Metric = 0.8067\n",
      "  New best metric! Saving model...\n",
      "Epoch 22: Binary F1 = 0.9783, Macro F1 = 0.6415, Final Metric = 0.8099\n",
      "  New best metric! Saving model...\n",
      "Epoch 23: Binary F1 = 0.9751, Macro F1 = 0.6243, Final Metric = 0.7997\n",
      "Epoch 24: Binary F1 = 0.9743, Macro F1 = 0.6298, Final Metric = 0.8020\n",
      "Epoch 25: Binary F1 = 0.9751, Macro F1 = 0.6334, Final Metric = 0.8042\n",
      "Best  validation metrics - Binary F1: 0.9783, Macro F1: 0.6415, Final: 0.8099\n",
      "Final validation metrics - Binary F1: 0.9751, Macro F1: 0.6334, Final: 0.8042\n",
      "\n",
      "==================================================\n",
      "training: 4\n",
      "Fold 4/5\n",
      "Epoch 01: Binary F1 = 0.7835, Macro F1 = 0.2702, Final Metric = 0.5268\n",
      "  New best metric! Saving model...\n",
      "Epoch 02: Binary F1 = 0.9097, Macro F1 = 0.3859, Final Metric = 0.6478\n",
      "  New best metric! Saving model...\n",
      "Epoch 03: Binary F1 = 0.8900, Macro F1 = 0.3986, Final Metric = 0.6443\n",
      "Epoch 04: Binary F1 = 0.9353, Macro F1 = 0.4237, Final Metric = 0.6795\n",
      "  New best metric! Saving model...\n",
      "Epoch 05: Binary F1 = 0.9168, Macro F1 = 0.4465, Final Metric = 0.6816\n",
      "  New best metric! Saving model...\n",
      "Epoch 06: Binary F1 = 0.9301, Macro F1 = 0.4586, Final Metric = 0.6943\n",
      "  New best metric! Saving model...\n",
      "Epoch 07: Binary F1 = 0.9314, Macro F1 = 0.4798, Final Metric = 0.7056\n",
      "  New best metric! Saving model...\n",
      "Epoch 08: Binary F1 = 0.9217, Macro F1 = 0.5099, Final Metric = 0.7158\n",
      "  New best metric! Saving model...\n",
      "Epoch 09: Binary F1 = 0.9429, Macro F1 = 0.4756, Final Metric = 0.7092\n",
      "Epoch 10: Binary F1 = 0.9245, Macro F1 = 0.5569, Final Metric = 0.7407\n",
      "  New best metric! Saving model...\n",
      "Epoch 11: Binary F1 = 0.9515, Macro F1 = 0.5825, Final Metric = 0.7670\n",
      "  New best metric! Saving model...\n",
      "Epoch 12: Binary F1 = 0.9505, Macro F1 = 0.5943, Final Metric = 0.7724\n",
      "  New best metric! Saving model...\n",
      "Epoch 13: Binary F1 = 0.9528, Macro F1 = 0.6118, Final Metric = 0.7823\n",
      "  New best metric! Saving model...\n",
      "Epoch 14: Binary F1 = 0.9482, Macro F1 = 0.5457, Final Metric = 0.7470\n",
      "Epoch 15: Binary F1 = 0.9481, Macro F1 = 0.5547, Final Metric = 0.7514\n",
      "Epoch 16: Binary F1 = 0.9535, Macro F1 = 0.6099, Final Metric = 0.7817\n",
      "Epoch 17: Binary F1 = 0.9504, Macro F1 = 0.6080, Final Metric = 0.7792\n",
      "Epoch 18: Binary F1 = 0.9505, Macro F1 = 0.5865, Final Metric = 0.7685\n",
      "Epoch 19: Binary F1 = 0.9514, Macro F1 = 0.5942, Final Metric = 0.7728\n",
      "Epoch 20: Binary F1 = 0.9504, Macro F1 = 0.6108, Final Metric = 0.7806\n",
      "Epoch 21: Binary F1 = 0.9481, Macro F1 = 0.5946, Final Metric = 0.7714\n",
      "Early stopping triggered at epoch 21\n",
      "Best  validation metrics - Binary F1: 0.9528, Macro F1: 0.6118, Final: 0.7823\n",
      "Final validation metrics - Binary F1: 0.9481, Macro F1: 0.5946, Final: 0.7714\n",
      "\n",
      "==================================================\n",
      "training: 5\n",
      "Fold 5/5\n",
      "Epoch 01: Binary F1 = 0.7072, Macro F1 = 0.2380, Final Metric = 0.4726\n",
      "  New best metric! Saving model...\n",
      "Epoch 02: Binary F1 = 0.8961, Macro F1 = 0.3558, Final Metric = 0.6260\n",
      "  New best metric! Saving model...\n",
      "Epoch 03: Binary F1 = 0.9162, Macro F1 = 0.4211, Final Metric = 0.6687\n",
      "  New best metric! Saving model...\n",
      "Epoch 04: Binary F1 = 0.9352, Macro F1 = 0.4484, Final Metric = 0.6918\n",
      "  New best metric! Saving model...\n",
      "Epoch 05: Binary F1 = 0.9260, Macro F1 = 0.4290, Final Metric = 0.6775\n",
      "Epoch 06: Binary F1 = 0.9461, Macro F1 = 0.4739, Final Metric = 0.7100\n",
      "  New best metric! Saving model...\n",
      "Epoch 07: Binary F1 = 0.9436, Macro F1 = 0.4826, Final Metric = 0.7131\n",
      "  New best metric! Saving model...\n",
      "Epoch 08: Binary F1 = 0.9321, Macro F1 = 0.4924, Final Metric = 0.7123\n",
      "Epoch 09: Binary F1 = 0.9505, Macro F1 = 0.4962, Final Metric = 0.7233\n",
      "  New best metric! Saving model...\n",
      "Epoch 10: Binary F1 = 0.9497, Macro F1 = 0.5403, Final Metric = 0.7450\n",
      "  New best metric! Saving model...\n",
      "Epoch 11: Binary F1 = 0.9555, Macro F1 = 0.5508, Final Metric = 0.7531\n",
      "  New best metric! Saving model...\n",
      "Epoch 12: Binary F1 = 0.9565, Macro F1 = 0.5791, Final Metric = 0.7678\n",
      "  New best metric! Saving model...\n",
      "Epoch 13: Binary F1 = 0.9599, Macro F1 = 0.5799, Final Metric = 0.7699\n",
      "  New best metric! Saving model...\n",
      "Epoch 14: Binary F1 = 0.9501, Macro F1 = 0.4981, Final Metric = 0.7241\n",
      "Epoch 15: Binary F1 = 0.9561, Macro F1 = 0.5318, Final Metric = 0.7439\n",
      "Epoch 16: Binary F1 = 0.9605, Macro F1 = 0.5769, Final Metric = 0.7687\n",
      "Epoch 17: Binary F1 = 0.9658, Macro F1 = 0.5808, Final Metric = 0.7733\n",
      "  New best metric! Saving model...\n",
      "Epoch 18: Binary F1 = 0.9646, Macro F1 = 0.5612, Final Metric = 0.7629\n",
      "Epoch 19: Binary F1 = 0.9585, Macro F1 = 0.5802, Final Metric = 0.7693\n",
      "Epoch 20: Binary F1 = 0.9612, Macro F1 = 0.5824, Final Metric = 0.7718\n",
      "Epoch 21: Binary F1 = 0.9651, Macro F1 = 0.5997, Final Metric = 0.7824\n",
      "  New best metric! Saving model...\n",
      "Epoch 22: Binary F1 = 0.9635, Macro F1 = 0.5934, Final Metric = 0.7784\n",
      "Epoch 23: Binary F1 = 0.9599, Macro F1 = 0.5856, Final Metric = 0.7728\n",
      "Epoch 24: Binary F1 = 0.9589, Macro F1 = 0.5831, Final Metric = 0.7710\n",
      "Epoch 25: Binary F1 = 0.9595, Macro F1 = 0.5829, Final Metric = 0.7712\n",
      "Best  validation metrics - Binary F1: 0.9651, Macro F1: 0.5997, Final: 0.7824\n",
      "Final validation metrics - Binary F1: 0.9595, Macro F1: 0.5829, Final: 0.7712\n",
      "\n",
      "==================================================\n",
      "Cross-Validation Results\n",
      "==================================================\n",
      "\n",
      "Best Fold-wise Metrics:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>binary_f1</th>\n",
       "      <th>macro_f1</th>\n",
       "      <th>final_metric</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fold</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.980901</td>\n",
       "      <td>0.591318</td>\n",
       "      <td>0.784548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.977812</td>\n",
       "      <td>0.617327</td>\n",
       "      <td>0.794487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.978328</td>\n",
       "      <td>0.641525</td>\n",
       "      <td>0.809926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.953545</td>\n",
       "      <td>0.611822</td>\n",
       "      <td>0.782295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.965839</td>\n",
       "      <td>0.599689</td>\n",
       "      <td>0.782389</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      binary_f1  macro_f1  final_metric\n",
       "fold                                   \n",
       "0      0.980901  0.591318      0.784548\n",
       "1      0.977812  0.617327      0.794487\n",
       "2      0.978328  0.641525      0.809926\n",
       "3      0.953545  0.611822      0.782295\n",
       "4      0.965839  0.599689      0.782389"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Global Statistics (Best Metrics):\n",
      "Mean Best Final Metric: 0.7907 Â± 0.0118\n",
      "Mean Best Binary F1: 0.9713 Â± 0.0115\n",
      "Mean Best Macro F1: 0.6123 Â± 0.0192\n",
      "mean best CV: 0.7907290941078444\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>train_loss</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>binary_f1</th>\n",
       "      <th>macro_f1</th>\n",
       "      <th>final_metric</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fold</th>\n",
       "      <th>epoch</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th>1</th>\n",
       "      <td>2.728137</td>\n",
       "      <td>2.564087</td>\n",
       "      <td>0.700190</td>\n",
       "      <td>0.220557</td>\n",
       "      <td>0.460373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.231433</td>\n",
       "      <td>1.976631</td>\n",
       "      <td>0.928467</td>\n",
       "      <td>0.346101</td>\n",
       "      <td>0.637284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.956073</td>\n",
       "      <td>1.918211</td>\n",
       "      <td>0.941088</td>\n",
       "      <td>0.414785</td>\n",
       "      <td>0.677936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.792256</td>\n",
       "      <td>1.792768</td>\n",
       "      <td>0.923695</td>\n",
       "      <td>0.445186</td>\n",
       "      <td>0.684440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.762762</td>\n",
       "      <td>1.718385</td>\n",
       "      <td>0.957790</td>\n",
       "      <td>0.459472</td>\n",
       "      <td>0.708631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">4</th>\n",
       "      <th>21</th>\n",
       "      <td>1.341325</td>\n",
       "      <td>1.420253</td>\n",
       "      <td>0.965089</td>\n",
       "      <td>0.599689</td>\n",
       "      <td>0.782389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.222636</td>\n",
       "      <td>1.415463</td>\n",
       "      <td>0.963481</td>\n",
       "      <td>0.593390</td>\n",
       "      <td>0.778436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.197369</td>\n",
       "      <td>1.426892</td>\n",
       "      <td>0.959877</td>\n",
       "      <td>0.585643</td>\n",
       "      <td>0.772760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.149407</td>\n",
       "      <td>1.424434</td>\n",
       "      <td>0.958947</td>\n",
       "      <td>0.583095</td>\n",
       "      <td>0.771021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.158459</td>\n",
       "      <td>1.418740</td>\n",
       "      <td>0.959502</td>\n",
       "      <td>0.582883</td>\n",
       "      <td>0.771192</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>121 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            train_loss  val_loss  binary_f1  macro_f1  final_metric\n",
       "fold epoch                                                         \n",
       "0    1        2.728137  2.564087   0.700190  0.220557      0.460373\n",
       "     2        2.231433  1.976631   0.928467  0.346101      0.637284\n",
       "     3        1.956073  1.918211   0.941088  0.414785      0.677936\n",
       "     4        1.792256  1.792768   0.923695  0.445186      0.684440\n",
       "     5        1.762762  1.718385   0.957790  0.459472      0.708631\n",
       "...                ...       ...        ...       ...           ...\n",
       "4    21       1.341325  1.420253   0.965089  0.599689      0.782389\n",
       "     22       1.222636  1.415463   0.963481  0.593390      0.778436\n",
       "     23       1.197369  1.426892   0.959877  0.585643      0.772760\n",
       "     24       1.149407  1.424434   0.958947  0.583095      0.771021\n",
       "     25       1.158459  1.418740   0.959502  0.582883      0.771192\n",
       "\n",
       "[121 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mean_best_cv_score, metrics = train_on_all_folds(\n",
    "        lr_scheduler_kw={\n",
    "            \"warmup_epochs\": 8,\n",
    "            \"cycle_mult\": 0.7994284370327427,\n",
    "            \"max_lr\": 0.005581907927062619,\n",
    "            \"max_to_min_div_factor\": 275.0,\n",
    "            \"init_cycle_epochs\": 5,\n",
    "            \"lr_cycle_factor\": 0.5033112105827083,\n",
    "        },\n",
    "        optimizer_kw={\n",
    "            \"weight_decay\": 0.0006702308864102119,\n",
    "            \"beta_0\": 0.9089203414971434,\n",
    "            \"beta_1\": 0.9969898035522793,\n",
    "    }\n",
    ")\n",
    "print(\"mean best CV:\", mean_best_cv_score)\n",
    "display(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c55c18",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8f14d2b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-02T11:26:30.362466Z",
     "iopub.status.busy": "2025-08-02T11:26:30.361893Z",
     "iopub.status.idle": "2025-08-02T11:26:30.366500Z",
     "shell.execute_reply": "2025-08-02T11:26:30.365927Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.014357,
     "end_time": "2025-08-02T11:26:30.367454",
     "exception": false,
     "start_time": "2025-08-02T11:26:30.353097",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(trial: optuna.trial.Trial) -> float:\n",
    "    return train_on_all_folds(\n",
    "        lr_scheduler_kw={\n",
    "            \"warmup_epochs\": trial.suggest_int(\"warmup_epochs\", 1, 10),\n",
    "            \"cycle_mult\": trial.suggest_float(\"cycle_mult\", 0.5, 2),\n",
    "            \"max_lr\": trial.suggest_float(\"max_lr\", 0.005581907927062619 / 3, 0.005581907927062619 * 3),\n",
    "            \"max_to_min_div_factor\": trial.suggest_float(\"max_to_min_div_factor\", 100, 300, step=25),\n",
    "            \"init_cycle_epochs\": trial.suggest_int(\"init_cycle_epochs\", 2, 10),\n",
    "            \"lr_cycle_factor\": trial.suggest_float(\"lr_cycle_factor\", 0.3, 1),\n",
    "        },\n",
    "        optimizer_kw={\n",
    "            \"weight_decay\": trial.suggest_float(\"weight_decay\", 5e-4, 1e-3),\n",
    "            \"beta_0\":trial.suggest_float(\"beta_0\", 0.8, 0.999),\n",
    "            \"beta_1\":trial.suggest_float(\"beta_1\", 0.99, 0.9999),\n",
    "        }\n",
    "    )[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "df9ccf8c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-02T11:33:13.535922Z",
     "iopub.status.busy": "2025-08-02T11:33:13.535715Z",
     "iopub.status.idle": "2025-08-02T11:33:13.539697Z",
     "shell.execute_reply": "2025-08-02T11:33:13.538846Z"
    },
    "papermill": {
     "duration": 0.01955,
     "end_time": "2025-08-02T11:33:13.541052",
     "exception": false,
     "start_time": "2025-08-02T11:33:13.521502",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# study = optuna.create_study(direction=\"maximize\")\n",
    "# study.optimize(objective, n_trials=100, timeout=60 * 60 * 2)\n",
    "\n",
    "# pruned_trials = study.get_trials(deepcopy=False, states=[TrialState.PRUNED])\n",
    "# complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])\n",
    "\n",
    "# print(\"Study statistics: \")\n",
    "# print(\"  Number of finished trials: \", len(study.trials))\n",
    "# print(\"  Number of pruned trials: \", len(pruned_trials))\n",
    "# print(\"  Number of complete trials: \", len(complete_trials))\n",
    "\n",
    "# print(\"Best trial:\")\n",
    "# trial = study.best_trial\n",
    "\n",
    "# print(\"  Value: \", trial.value)\n",
    "\n",
    "# print(\"  Params: \")\n",
    "# for key, value in trial.params.items():\n",
    "#     print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2b2f05",
   "metadata": {
    "papermill": {
     "duration": 0.023297,
     "end_time": "2025-08-02T11:33:13.582486",
     "exception": false,
     "start_time": "2025-08-02T11:33:13.559189",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338e1e1b",
   "metadata": {
    "papermill": {
     "duration": 0.017349,
     "end_time": "2025-08-02T11:33:13.615231",
     "exception": false,
     "start_time": "2025-08-02T11:33:13.597882",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Reloading best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2486858b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-02T11:33:13.644699Z",
     "iopub.status.busy": "2025-08-02T11:33:13.644430Z",
     "iopub.status.idle": "2025-08-02T11:33:13.934618Z",
     "shell.execute_reply": "2025-08-02T11:33:13.933984Z"
    },
    "papermill": {
     "duration": 0.305935,
     "end_time": "2025-08-02T11:33:13.935976",
     "exception": false,
     "start_time": "2025-08-02T11:33:13.630041",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/mauroabidalcarrer/prepocessed-cmi-2025?dataset_version_number=36...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 111M/10.7G [00:03<06:28, 29.4MB/s]   \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m model_ensemble = []\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m fold \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m5\u001b[39m):\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     train_dataset = \u001b[43mCMIDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpre\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfold_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mfold\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtrain\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m     model = mk_model(dataset_x=train_dataset.tensors[\u001b[32m0\u001b[39m])\n\u001b[32m      5\u001b[39m     checkpoint = torch.load(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mbest_model_fold\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.pth\u001b[39m\u001b[33m\"\u001b[39m, map_location=device, weights_only=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 10\u001b[39m, in \u001b[36mCMIDataset.__init__\u001b[39m\u001b[34m(self, padding_mode, parent_dir, split, subset, force_download)\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\n\u001b[32m      3\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m      4\u001b[39m     padding_mode:Literal[\u001b[33m\"\u001b[39m\u001b[33mpre\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcenter\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m      8\u001b[39m     force_download=\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m      9\u001b[39m ):\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m     dataset_path = \u001b[43mkagglehub\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdataset_download\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDATASET_HANDLE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m     \u001b[38;5;66;03m# Quick fix, will need to recompute and upload dataset with properly orederd folders\u001b[39;00m\n\u001b[32m     12\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m parent_dir == \u001b[33m\"\u001b[39m\u001b[33mfull_dataset\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/venv/CMI/lib/python3.11/site-packages/kagglehub/datasets.py:43\u001b[39m, in \u001b[36mdataset_download\u001b[39m\u001b[34m(handle, path, force_download)\u001b[39m\n\u001b[32m     41\u001b[39m h = parse_dataset_handle(handle)\n\u001b[32m     42\u001b[39m logger.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDownloading Dataset: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mh.to_url()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m ...\u001b[39m\u001b[33m\"\u001b[39m, extra={**EXTRA_CONSOLE_BLOCK})\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m path, _ = \u001b[43mregistry\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdataset_resolver\u001b[49m\u001b[43m(\u001b[49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     44\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m path\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/venv/CMI/lib/python3.11/site-packages/kagglehub/registry.py:28\u001b[39m, in \u001b[36mMultiImplRegistry.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m impl \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mreversed\u001b[39m(\u001b[38;5;28mself\u001b[39m._impls):\n\u001b[32m     27\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m impl.is_supported(*args, **kwargs):\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimpl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     29\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     30\u001b[39m         fails.append(\u001b[38;5;28mtype\u001b[39m(impl).\u001b[34m__name__\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/venv/CMI/lib/python3.11/site-packages/kagglehub/resolver.py:29\u001b[39m, in \u001b[36mResolver.__call__\u001b[39m\u001b[34m(self, handle, path, force_download)\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\n\u001b[32m     16\u001b[39m     \u001b[38;5;28mself\u001b[39m, handle: T, path: Optional[\u001b[38;5;28mstr\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m, *, force_download: Optional[\u001b[38;5;28mbool\u001b[39m] = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m     17\u001b[39m ) -> \u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Optional[\u001b[38;5;28mint\u001b[39m]]:\n\u001b[32m     18\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Resolves a handle into a path with the requested file(s) and the resource's version number.\u001b[39;00m\n\u001b[32m     19\u001b[39m \n\u001b[32m     20\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     27\u001b[39m \u001b[33;03m        Some cases where version number might be missing: Competition datasource, API-based models.\u001b[39;00m\n\u001b[32m     28\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m     path, version = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_resolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     31\u001b[39m     \u001b[38;5;66;03m# Note handles are immutable, so _resolve() could not have altered our reference\u001b[39;00m\n\u001b[32m     32\u001b[39m     register_datasource_access(handle, version)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/venv/CMI/lib/python3.11/site-packages/kagglehub/http_resolver.py:130\u001b[39m, in \u001b[36mDatasetHttpResolver._resolve\u001b[39m\u001b[34m(self, h, path, force_download)\u001b[39m\n\u001b[32m    127\u001b[39m os.makedirs(os.path.dirname(archive_path), exist_ok=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    129\u001b[39m \u001b[38;5;66;03m# First, we download the archive.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m130\u001b[39m \u001b[43mapi_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdownload_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marchive_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    132\u001b[39m _extract_archive(archive_path, out_path)\n\u001b[32m    134\u001b[39m \u001b[38;5;66;03m# Delete the archive\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/venv/CMI/lib/python3.11/site-packages/kagglehub/clients.py:217\u001b[39m, in \u001b[36mKaggleApiV1Client.download_file\u001b[39m\u001b[34m(self, path, out_file, resource_handle, cached_path, extract_auto_compressed_file)\u001b[39m\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    216\u001b[39m     logger.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDownloading from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m217\u001b[39m     \u001b[43m_download_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize_read\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhash_object\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m hash_object:\n\u001b[32m    220\u001b[39m     actual_md5_hash = to_b64_digest(hash_object)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/venv/CMI/lib/python3.11/site-packages/kagglehub/clients.py:276\u001b[39m, in \u001b[36m_download_file\u001b[39m\u001b[34m(response, out_file, size_read, total_size, hash_object)\u001b[39m\n\u001b[32m    274\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m tqdm(total=total_size, initial=size_read, unit=\u001b[33m\"\u001b[39m\u001b[33mB\u001b[39m\u001b[33m\"\u001b[39m, unit_scale=\u001b[38;5;28;01mTrue\u001b[39;00m, unit_divisor=\u001b[32m1024\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m progress_bar:\n\u001b[32m    275\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(out_file, open_mode) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m--> \u001b[39m\u001b[32m276\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43miter_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCHUNK_SIZE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    277\u001b[39m \u001b[43m            \u001b[49m\u001b[43mf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    278\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mhash_object\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/venv/CMI/lib/python3.11/site-packages/requests/models.py:820\u001b[39m, in \u001b[36mResponse.iter_content.<locals>.generate\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    818\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.raw, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    819\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m820\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m.raw.stream(chunk_size, decode_content=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    821\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m ProtocolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    822\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m ChunkedEncodingError(e)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/venv/CMI/lib/python3.11/site-packages/urllib3/response.py:1091\u001b[39m, in \u001b[36mHTTPResponse.stream\u001b[39m\u001b[34m(self, amt, decode_content)\u001b[39m\n\u001b[32m   1089\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1090\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_fp_closed(\u001b[38;5;28mself\u001b[39m._fp) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._decoded_buffer) > \u001b[32m0\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m1091\u001b[39m         data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m=\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1093\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m data:\n\u001b[32m   1094\u001b[39m             \u001b[38;5;28;01myield\u001b[39;00m data\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/venv/CMI/lib/python3.11/site-packages/urllib3/response.py:980\u001b[39m, in \u001b[36mHTTPResponse.read\u001b[39m\u001b[34m(self, amt, decode_content, cache_content)\u001b[39m\n\u001b[32m    977\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._decoded_buffer) >= amt:\n\u001b[32m    978\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._decoded_buffer.get(amt)\n\u001b[32m--> \u001b[39m\u001b[32m980\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raw_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    982\u001b[39m flush_decoder = amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m (amt != \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data)\n\u001b[32m    984\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._decoded_buffer) == \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/venv/CMI/lib/python3.11/site-packages/urllib3/response.py:904\u001b[39m, in \u001b[36mHTTPResponse._raw_read\u001b[39m\u001b[34m(self, amt, read1)\u001b[39m\n\u001b[32m    901\u001b[39m fp_closed = \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m._fp, \u001b[33m\"\u001b[39m\u001b[33mclosed\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    903\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._error_catcher():\n\u001b[32m--> \u001b[39m\u001b[32m904\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fp_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mread1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mread1\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fp_closed \u001b[38;5;28;01melse\u001b[39;00m \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    905\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt != \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data:\n\u001b[32m    906\u001b[39m         \u001b[38;5;66;03m# Platform-specific: Buggy versions of Python.\u001b[39;00m\n\u001b[32m    907\u001b[39m         \u001b[38;5;66;03m# Close the connection when no data is returned\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    912\u001b[39m         \u001b[38;5;66;03m# not properly close the connection in all cases. There is\u001b[39;00m\n\u001b[32m    913\u001b[39m         \u001b[38;5;66;03m# no harm in redundantly calling close.\u001b[39;00m\n\u001b[32m    914\u001b[39m         \u001b[38;5;28mself\u001b[39m._fp.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/venv/CMI/lib/python3.11/site-packages/urllib3/response.py:887\u001b[39m, in \u001b[36mHTTPResponse._fp_read\u001b[39m\u001b[34m(self, amt, read1)\u001b[39m\n\u001b[32m    884\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._fp.read1(amt) \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m._fp.read1()\n\u001b[32m    885\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    886\u001b[39m     \u001b[38;5;66;03m# StringIO doesn't like amt=None\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m887\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m._fp.read()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/venv/CMI/lib/python3.11/http/client.py:466\u001b[39m, in \u001b[36mHTTPResponse.read\u001b[39m\u001b[34m(self, amt)\u001b[39m\n\u001b[32m    463\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.length \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt > \u001b[38;5;28mself\u001b[39m.length:\n\u001b[32m    464\u001b[39m     \u001b[38;5;66;03m# clip the read to the \"end of response\"\u001b[39;00m\n\u001b[32m    465\u001b[39m     amt = \u001b[38;5;28mself\u001b[39m.length\n\u001b[32m--> \u001b[39m\u001b[32m466\u001b[39m s = \u001b[38;5;28mself\u001b[39m.fp.read(amt)\n\u001b[32m    467\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m s \u001b[38;5;129;01mand\u001b[39;00m amt:\n\u001b[32m    468\u001b[39m     \u001b[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[32m    469\u001b[39m     \u001b[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[32m    470\u001b[39m     \u001b[38;5;28mself\u001b[39m._close_conn()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/venv/CMI/lib/python3.11/socket.py:706\u001b[39m, in \u001b[36mSocketIO.readinto\u001b[39m\u001b[34m(self, b)\u001b[39m\n\u001b[32m    704\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    705\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m706\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    707\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[32m    708\u001b[39m         \u001b[38;5;28mself\u001b[39m._timeout_occurred = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/venv/CMI/lib/python3.11/ssl.py:1311\u001b[39m, in \u001b[36mSSLSocket.recv_into\u001b[39m\u001b[34m(self, buffer, nbytes, flags)\u001b[39m\n\u001b[32m   1307\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m flags != \u001b[32m0\u001b[39m:\n\u001b[32m   1308\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1309\u001b[39m           \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1310\u001b[39m           \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1311\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1312\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1313\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().recv_into(buffer, nbytes, flags)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/venv/CMI/lib/python3.11/ssl.py:1167\u001b[39m, in \u001b[36mSSLSocket.read\u001b[39m\u001b[34m(self, len, buffer)\u001b[39m\n\u001b[32m   1165\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1166\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1167\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1168\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1169\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sslobj.read(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "model_ensemble = []\n",
    "for fold in range(5):\n",
    "    train_dataset = CMIDataset(\"pre\", f\"fold_{fold}\", \"train\")\n",
    "    model = mk_model(dataset_x=train_dataset.tensors[0])\n",
    "    checkpoint = torch.load(f\"best_model_fold{fold}.pth\", map_location=device, weights_only=True)\n",
    "    model.load_state_dict(checkpoint)\n",
    "    model.eval()\n",
    "    model_ensemble.append(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf8ae42",
   "metadata": {
    "papermill": {
     "duration": 0.013809,
     "end_time": "2025-08-02T11:33:13.964329",
     "exception": false,
     "start_time": "2025-08-02T11:33:13.950520",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Define preprocessing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab2d57b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-02T11:33:13.993213Z",
     "iopub.status.busy": "2025-08-02T11:33:13.992841Z",
     "iopub.status.idle": "2025-08-02T11:33:14.011288Z",
     "shell.execute_reply": "2025-08-02T11:33:14.010718Z"
    },
    "papermill": {
     "duration": 0.03452,
     "end_time": "2025-08-02T11:33:14.012421",
     "exception": false,
     "start_time": "2025-08-02T11:33:13.977901",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_feature_cols(df:DF) -> list[str]:\n",
    "    return sorted(list(set(df.columns) - set(META_DATA_COLUMNS) - set(TARGET_NAMES)))\n",
    "\n",
    "def get_fillna_val_per_feature_col(df:DF) -> dict:\n",
    "    return {col: 1.0 if col == 'rot_w' else 0 for col in get_feature_cols(df)}\n",
    "\n",
    "def imputed_features(df:DF) -> DF:\n",
    "    # Missing ToF values are already imputed by -1 which is inconvinient since we want all missing values to be NaN.    \n",
    "    # So we replace them by NaN and then perform imputing.  \n",
    "    tof_vals_to_nan = {col: -1.0 for col in df.columns if col.startswith(\"tof\")}\n",
    "\n",
    "    df[get_feature_cols(df)] = (\n",
    "        df\n",
    "        .loc[:, get_feature_cols(df)]\n",
    "        # df.replace with np.nan sets dtype to floar64 so we set it back to float32\n",
    "        .replace(tof_vals_to_nan, value=np.nan)\n",
    "        .astype(\"float32\")\n",
    "        .groupby(df[\"sequence_id\"], observed=True, as_index=False)\n",
    "        .ffill()\n",
    "        .groupby(df[\"sequence_id\"], observed=True, as_index=False)\n",
    "        .bfill()\n",
    "        # In case there are only nan in the column in the sequence\n",
    "        .fillna(get_fillna_val_per_feature_col(df))\n",
    "    )\n",
    "    return df\n",
    "\n",
    "def standardize_tof_cols_names(df: DF) -> DF:\n",
    "    renamed_cols = {}\n",
    "    pattern = re.compile(r\"^(tof_\\d_v)(\\d)$\")  # match 'tof_X_vY' where Y is a single digit\n",
    "\n",
    "    for col in df.columns:\n",
    "        match = pattern.match(col)\n",
    "        if match:\n",
    "            prefix, version = match.groups()\n",
    "            new_col = f\"{prefix}0{version}\"\n",
    "            renamed_cols[col] = new_col\n",
    "\n",
    "    return df.rename(columns=renamed_cols)\n",
    "\n",
    "def norm_quat_rotations(df:DF) -> DF:\n",
    "    df[QUATERNION_COLS] /= np.linalg.norm(df[QUATERNION_COLS], axis=1, keepdims=True)\n",
    "    return df\n",
    "\n",
    "def add_linear_acc_cols(df:DF) -> DF:\n",
    "    # Vectorized version of https://www.kaggle.com/code/wasupandceacar/lb-0-82-5fold-single-bert-model#Dataset `remove_gravity_from_acc`\n",
    "    rotations:Rotation = Rotation.from_quat(df[QUATERNION_COLS])\n",
    "    gravity_sensor_frame = rotations.apply(GRAVITY_WORLD, inverse=True).astype(\"float32\")\n",
    "    df[LINEAR_ACC_COLS] = df[RAW_ACCELRATION_COLS] - gravity_sensor_frame\n",
    "    return df\n",
    "\n",
    "def add_acc_magnitude(df:DF, acc_cols:list[str], acc_mag_col_name:str) -> DF:\n",
    "    return df.assign(**{acc_mag_col_name: np.linalg.norm(df.loc[:, acc_cols], axis=1)})\n",
    "\n",
    "def add_quat_angle_mag(df:DF) -> DF:\n",
    "    return df.assign(quat_rot_mag=np.arccos(df[\"rot_w\"]) * 2)\n",
    "\n",
    "def add_angular_velocity_features(df:DF) -> DF:\n",
    "    rotations = Rotation.from_quat(df[QUATERNION_COLS])\n",
    "    delta_rotations = rotations[1:] * rotations[:-1].inv()\n",
    "    delta_rot_velocity = delta_rotations.as_rotvec()\n",
    "    # Add extra line to avoid shape mismatch\n",
    "    delta_rot_velocity = np.vstack((np.zeros((1, 3)), delta_rot_velocity))\n",
    "    delta_rot_magnitude = norm(delta_rot_velocity, axis=1, keepdims=True)\n",
    "    delta_rot_axes = delta_rot_velocity / (delta_rot_magnitude + EPSILON)\n",
    "    df[DELTA_ROTATION_ANGULAR_VELOCITY_COLS] = delta_rot_velocity\n",
    "    df[DELTA_ROTATION_AXES_COLS] = delta_rot_axes\n",
    "    df[\"delta_rot_mag\"] = delta_rot_magnitude.squeeze()\n",
    "\n",
    "    return df\n",
    "\n",
    "def rot_euler_angles(df:DF) -> ndarray:\n",
    "    df[EULER_ANGLES_COLS] = (\n",
    "        Rotation\n",
    "        .from_quat(df[QUATERNION_COLS])\n",
    "        .as_euler(\"xyz\")\n",
    "        .squeeze()\n",
    "    )\n",
    "    return df\n",
    "\n",
    "def agg_tof_cols_per_sensor(df:DF) -> DF:\n",
    "    for tof_idx in tqdm(range(1, 6)):\n",
    "        tof_name = f\"tof_{tof_idx}\"\n",
    "        tof_cols = [f\"{tof_name}_v{v_idx}\" for v_idx in range(64)]\n",
    "        if any(map(lambda col: col not in df.columns, tof_cols)):\n",
    "            print(f\"Some (or) all ToF {tof_idx} columns are not in the df. Maybe you already ran this cell?\")\n",
    "            continue\n",
    "        df = pd.concat(\n",
    "            (\n",
    "                df.drop(columns=tof_cols),\n",
    "                # For some reasons, it's faster to call all the aggregation functions seperatly than agg(list of functions)\n",
    "                df[tof_cols].mean(axis=\"columns\").to_frame(tof_name + \"_mean\"),\n",
    "                df[tof_cols].std(axis=\"columns\").to_frame(tof_name + \"_std\"),\n",
    "                df[tof_cols].median(axis=\"columns\").to_frame(tof_name + \"_median\"),\n",
    "                df[tof_cols].min(axis=\"columns\").to_frame(tof_name + \"_min\"),\n",
    "                df[tof_cols].max(axis=\"columns\").to_frame(tof_name + \"_max\"),\n",
    "            ),\n",
    "            axis=\"columns\",\n",
    "        )\n",
    "    return df\n",
    "\n",
    "def add_diff_features(df:DF) -> DF:\n",
    "    return pd.concat(\n",
    "        (\n",
    "            df,\n",
    "            df\n",
    "            .groupby(\"sequence_id\", as_index=False, observed=True)\n",
    "            [get_feature_cols(df)]\n",
    "            .diff()\n",
    "            .fillna(get_fillna_val_per_feature_col(df))\n",
    "            .add_suffix(\"_diff\")\n",
    "        ),\n",
    "        axis=\"columns\",\n",
    "    )\n",
    "\n",
    "def length_normed_sequence_feat_arr(\n",
    "        sequence: DF,\n",
    "        pad_trunc_mode:Literal[\"pre\", \"center\", \"post\"]\n",
    "    ) -> ndarray:\n",
    "    features = (\n",
    "        sequence\n",
    "        .loc[:, meta_data[\"feature_cols\"]]\n",
    "        .values\n",
    "    )\n",
    "    normed_sequence_len = meta_data[\"pad_seq_len\"]\n",
    "    len_diff = abs(normed_sequence_len - len(features))\n",
    "    len_diff_h = len_diff // 2 # half len diff\n",
    "    len_diff_r = len_diff % 2 # len diff remainder\n",
    "    if len(features) < normed_sequence_len:\n",
    "        padding_dict = {\n",
    "            \"pre\": (len_diff, 0),\n",
    "            \"center\": (len_diff_h + len_diff_r, len_diff_h),\n",
    "            \"post\": (0, len_diff),\n",
    "        }\n",
    "        padded_features = np.pad(\n",
    "            features,\n",
    "            (padding_dict[pad_trunc_mode], (0, 0)),\n",
    "        )\n",
    "        return padded_features\n",
    "    elif len(features) > normed_sequence_len:\n",
    "        truncating_dict = {\n",
    "            \"pre\": slice(len_diff),\n",
    "            \"center\": slice(len_diff_h, -len_diff_h),\n",
    "            \"post\": slice(0, -len_diff),\n",
    "        }\n",
    "        return features[len_diff // 2:-len_diff // 2]\n",
    "    else:\n",
    "        return features\n",
    "\n",
    "\n",
    "def preprocess_sequence(sequence_df:pl.DataFrame) -> ndarray:\n",
    "    return (\n",
    "        sequence_df                     \n",
    "        .to_pandas()                            # Convert to pandas dataframe.\n",
    "        .pipe(imputed_features)                 # Impute missing data.\n",
    "        .pipe(standardize_tof_cols_names)\n",
    "        .pipe(norm_quat_rotations)              # Norm quaternions\n",
    "        .pipe(add_linear_acc_cols)              # Add gravity free acceleration.\n",
    "        .pipe(add_acc_magnitude, RAW_ACCELRATION_COLS, \"acc_mag\")\n",
    "        .pipe(add_acc_magnitude, LINEAR_ACC_COLS, \"linear_acc_mag\")\n",
    "        .pipe(add_quat_angle_mag)\n",
    "        .pipe(add_angular_velocity_features)\n",
    "        .pipe(rot_euler_angles)                 # Add rotation acc expressed as euler angles.\n",
    "        # .pipe(agg_tof_cols_per_sensor)          # Aggregate ToF columns.\n",
    "        .pipe(add_diff_features)                # \n",
    "        .loc[:, sorted(meta_data[\"feature_cols\"])]      # Retain only the usefull columns a.k.a features.\n",
    "        .sub(meta_data[\"mean\"])                 # Subtract features by their mean, std norm pt.1.\n",
    "        .div(meta_data[\"std\"])                  # Divide by Standard deviation, std norm pt.2.\n",
    "        .pipe(length_normed_sequence_feat_arr, PAD_SEQ_MODE)  # get feature ndarray of sequence.\n",
    "        .T                                      # Transpose to swap channel and X dimensions.\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6df209",
   "metadata": {
    "papermill": {
     "duration": 0.013789,
     "end_time": "2025-08-02T11:33:14.040022",
     "exception": false,
     "start_time": "2025-08-02T11:33:14.026233",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Define prediction function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f9148b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-02T11:33:14.068055Z",
     "iopub.status.busy": "2025-08-02T11:33:14.067800Z",
     "iopub.status.idle": "2025-08-02T11:33:14.073586Z",
     "shell.execute_reply": "2025-08-02T11:33:14.072760Z"
    },
    "papermill": {
     "duration": 0.02134,
     "end_time": "2025-08-02T11:33:14.074819",
     "exception": false,
     "start_time": "2025-08-02T11:33:14.053479",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict(sequence: pl.DataFrame, _: pl.DataFrame) -> str:\n",
    "    \"\"\"\n",
    "    Kaggle evaluation API will call this for each sequence.\n",
    "    sequence: polars DataFrame for a single sequence\n",
    "    demographics: unused in this model\n",
    "    Returns: predicted gesture string\n",
    "    \"\"\"\n",
    "    x_tensor = (\n",
    "        torch.unsqueeze(Tensor(preprocess_sequence(sequence)), dim=0)\n",
    "        .float()\n",
    "        .to(device)\n",
    "    )\n",
    "    print(x_tensor.shape)\n",
    "\n",
    "    all_outputs = []\n",
    "    with torch.no_grad():\n",
    "        for model_idx, model in enumerate(model_ensemble): # Only take the first one bc it's the only one that takes in the correct input shape\n",
    "            outputs = model(x_tensor)\n",
    "            all_outputs.append(outputs)\n",
    "\n",
    "    avg_outputs = torch.mean(torch.stack(all_outputs), dim=0)\n",
    "    pred_idx = torch.argmax(avg_outputs, dim=1).item()\n",
    "\n",
    "    return str(gesture_classes[pred_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac4beee",
   "metadata": {
    "papermill": {
     "duration": 0.015954,
     "end_time": "2025-08-02T11:33:14.106655",
     "exception": false,
     "start_time": "2025-08-02T11:33:14.090701",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Run inference server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5eebc2a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-02T11:33:14.139851Z",
     "iopub.status.busy": "2025-08-02T11:33:14.139570Z",
     "iopub.status.idle": "2025-08-02T11:33:16.046743Z",
     "shell.execute_reply": "2025-08-02T11:33:16.045996Z"
    },
    "papermill": {
     "duration": 1.924797,
     "end_time": "2025-08-02T11:33:16.047890",
     "exception": false,
     "start_time": "2025-08-02T11:33:14.123093",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 696, 127])\n",
      "torch.Size([1, 696, 127])\n"
     ]
    }
   ],
   "source": [
    "inference_server = kaggle_evaluation.cmi_inference_server.CMIInferenceServer(predict)\n",
    "\n",
    "if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
    "    inference_server.serve()\n",
    "else:\n",
    "    inference_server.run_local_gateway(\n",
    "        data_paths=(\n",
    "            join(competition_dataset_path, 'test.csv'),\n",
    "            join(competition_dataset_path, 'test_demographics.csv'),\n",
    "        )\n",
    "    )\n",
    "    inference_server = kaggle_evaluation.cmi_inference_server.CMIInferenceServer(predict)\n",
    "    # inference_server.run_local_gateway(\n",
    "    #     data_paths=(\n",
    "    #         join(competition_dataset_path, 'train.csv'),\n",
    "    #         join(competition_dataset_path, 'train_demographics.csv'),\n",
    "    #     )\n",
    "    # )"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 12518947,
     "isSourceIdPinned": false,
     "sourceId": 102335,
     "sourceType": "competition"
    },
    {
     "datasetId": 7827890,
     "sourceId": 12633323,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 251413288,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 520.311851,
   "end_time": "2025-08-02T11:33:18.085561",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-08-02T11:24:37.773710",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "425cbf555f1849f7a521e356d70d429b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7f82f6965842469988401e5a9260b41f": {
      "model_module": "@jupyter-widgets/output",
      "model_module_version": "1.0.0",
      "model_name": "OutputModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/output",
       "_model_module_version": "1.0.0",
       "_model_name": "OutputModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/output",
       "_view_module_version": "1.0.0",
       "_view_name": "OutputView",
       "layout": "IPY_MODEL_425cbf555f1849f7a521e356d70d429b",
       "msg_id": "",
       "outputs": [
        {
         "data": {
          "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">epoch: 14, batch_loss: 1.06,  <span style=\"color: #f92672; text-decoration-color: #f92672\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•¸</span><span style=\"color: #3a3a3a; text-decoration-color: #3a3a3a\">â”</span> <span style=\"color: #800080; text-decoration-color: #800080\"> 97%</span> <span style=\"color: #008080; text-decoration-color: #008080\">0:00:00</span>\n</pre>\n",
          "text/plain": "epoch: 14, batch_loss: 1.06,  \u001b[38;2;249;38;114mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[38;2;249;38;114mâ•¸\u001b[0m\u001b[38;5;237mâ”\u001b[0m \u001b[35m 97%\u001b[0m \u001b[36m0:00:00\u001b[0m\n"
         },
         "metadata": {},
         "output_type": "display_data"
        }
       ],
       "tabbable": null,
       "tooltip": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
