{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9747e1b1",
   "metadata": {
    "papermill": {
     "duration": 0.007982,
     "end_time": "2025-08-15T23:50:30.291513",
     "exception": false,
     "start_time": "2025-08-15T23:50:30.283531",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training & inference notebook\n",
    "Credit to [Tarun Mishra](https://www.kaggle.com/tarundirector) â€“ this code is heavily based on his [notebook](https://www.kaggle.com/code/tarundirector/sensor-pulse-viz-eda-for-bfrb-detection?scriptVersionId=243465321)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be8fc48",
   "metadata": {
    "papermill": {
     "duration": 0.005781,
     "end_time": "2025-08-15T23:50:30.303573",
     "exception": false,
     "start_time": "2025-08-15T23:50:30.297792",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1402e6e4",
   "metadata": {
    "papermill": {
     "duration": 0.005959,
     "end_time": "2025-08-15T23:50:30.315456",
     "exception": false,
     "start_time": "2025-08-15T23:50:30.309497",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f609af7e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-15T23:50:30.329205Z",
     "iopub.status.busy": "2025-08-15T23:50:30.328922Z",
     "iopub.status.idle": "2025-08-15T23:50:38.285390Z",
     "shell.execute_reply": "2025-08-15T23:50:38.284544Z"
    },
    "papermill": {
     "duration": 7.964852,
     "end_time": "2025-08-15T23:50:38.286949",
     "exception": false,
     "start_time": "2025-08-15T23:50:30.322097",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import json \n",
    "import math\n",
    "import shutil\n",
    "import random\n",
    "import warnings\n",
    "from os.path import join\n",
    "from functools import partial\n",
    "from tqdm.notebook import tqdm\n",
    "from collections import defaultdict\n",
    "from operator import methodcaller\n",
    "from typing import Optional, Literal\n",
    "from typing import Optional, Literal, Iterator\n",
    "from itertools import pairwise, starmap, product\n",
    "\n",
    "import torch\n",
    "import optuna\n",
    "import kagglehub \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "from numpy import ndarray\n",
    "from torch import nn, Tensor\n",
    "from numpy.linalg import norm\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Optimizer\n",
    "from pandas import DataFrame as DF\n",
    "from optuna.trial import TrialState\n",
    "from sklearn.metrics import f1_score\n",
    "from torch.utils.data import TensorDataset\n",
    "from scipy.spatial.transform import Rotation\n",
    "import kaggle_evaluation.cmi_inference_server\n",
    "from torch.utils.data import DataLoader as DL\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from rich.progress import Progress, Task, track\n",
    "from sklearn.model_selection import train_test_split\n",
    "from numpy.lib.stride_tricks import sliding_window_view\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from torch.optim.lr_scheduler import ConstantLR, LRScheduler, _LRScheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2055c2",
   "metadata": {
    "papermill": {
     "duration": 0.005961,
     "end_time": "2025-08-15T23:50:38.299394",
     "exception": false,
     "start_time": "2025-08-15T23:50:38.293433",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b49d21fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-15T23:50:38.312951Z",
     "iopub.status.busy": "2025-08-15T23:50:38.312114Z",
     "iopub.status.idle": "2025-08-15T23:50:38.322717Z",
     "shell.execute_reply": "2025-08-15T23:50:38.322167Z"
    },
    "papermill": {
     "duration": 0.018408,
     "end_time": "2025-08-15T23:50:38.323712",
     "exception": false,
     "start_time": "2025-08-15T23:50:38.305304",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Dataset\n",
    "COMPETITION_HANDLE = \"cmi-detect-behavior-with-sensor-data\"\n",
    "TARGET_NAMES = sorted([\n",
    "    \"Above ear - pull hair\",\n",
    "    \"Cheek - pinch skin\",\n",
    "    \"Eyebrow - pull hair\",\n",
    "    \"Eyelash - pull hair\",\n",
    "    \"Feel around in tray and pull out an object\",\n",
    "    \"Forehead - pull hairline\",\n",
    "    \"Forehead - scratch\",\n",
    "    \"Neck - pinch skin\",\n",
    "    \"Neck - scratch\",\n",
    "    \"Text on phone\",\n",
    "    \"Wave hello\",\n",
    "    \"Write name in air\",\n",
    "    \"Write name on leg\",\n",
    "    \"Drink from bottle/cup\",\n",
    "    \"Pinch knee/leg skin\",\n",
    "    \"Pull air toward your face\",\n",
    "    \"Scratch knee/leg skin\",\n",
    "    \"Glasses on/off\"\n",
    "])\n",
    "BFRB_GESTURES = [\n",
    "    'Above ear - pull hair',\n",
    "    'Forehead - pull hairline',\n",
    "    'Forehead - scratch',\n",
    "    'Eyebrow - pull hair',\n",
    "    'Eyelash - pull hair',\n",
    "    'Neck - pinch skin',\n",
    "    'Neck - scratch',\n",
    "    'Cheek - pinch skin'\n",
    "]\n",
    "BFRB_INDICES = [idx for idx, gesture in enumerate(TARGET_NAMES) if gesture in BFRB_GESTURES]\n",
    "IMU_FEATS_PREFIXES = (\n",
    "    \"acc\",\n",
    "    \"linear_acc\",\n",
    "    \"rot\",\n",
    "    \"angular\",\n",
    "    \"euler\",\n",
    "    \"quat_rot_mag\",\n",
    "    \"delta_rot_mag\",\n",
    ")\n",
    "QUATERNION_COLS = ['rot_w', 'rot_x', 'rot_y', 'rot_z']\n",
    "GRAVITY_WORLD = np.array([0, 0, 9.81], \"float32\")\n",
    "RAW_ACCELRATION_COLS = [\"acc_x\", \"acc_y\", \"acc_z\"]\n",
    "LINEAR_ACC_COLS = [\"linear_\" + col for col in RAW_ACCELRATION_COLS] # Acceleration without gravity\n",
    "COMPETITION_HANDLE = \"cmi-detect-behavior-with-sensor-data\"\n",
    "CATEGORY_COLUMNS = [\n",
    "    'row_id',\n",
    "    'sequence_type',\n",
    "    'sequence_id',\n",
    "    'subject',\n",
    "    'orientation',\n",
    "    'behavior',\n",
    "    'phase',\n",
    "    'gesture',\n",
    "]\n",
    "META_DATA_COLUMNS = [\n",
    "    'row_id',\n",
    "    'sequence_type',\n",
    "    'sequence_id',\n",
    "    'sequence_counter',\n",
    "    'subject',\n",
    "    'orientation',\n",
    "    'behavior',\n",
    "    'phase',\n",
    "    'gesture',\n",
    "]\n",
    "DATASET_DF_DTYPES = {\n",
    "    \"acc_x\": \"float32\", \"acc_y\": \"float32\", \"acc_z\": \"float32\",\n",
    "    \"thm_1\":\"float32\", \"thm_2\":\"float32\", \"thm_3\":\"float32\", \"thm_4\":\"float32\", \"thm_5\":\"float32\",\n",
    "    \"sequence_counter\": \"int32\",\n",
    "    **{col: \"category\" for col in CATEGORY_COLUMNS},\n",
    "    **{f\"tof_{i_1}_v{i_2}\": \"float32\" for i_1, i_2 in product(range(1, 5), range(64))},\n",
    "}\n",
    "PREPROCESSED_DATASET_HANDLE = \"mauroabidalcarrer/prepocessed-cmi-2025\"\n",
    "# The quantile of the sequences len used to pad/truncate during preprocessing\n",
    "SEQUENCE_NORMED_LEN_QUANTILE = 0.95\n",
    "# SAMPLING_FREQUENCY = 10 #Hz\n",
    "VALIDATION_FRACTION = 0.2\n",
    "EPSILON=1e-8\n",
    "DELTA_ROTATION_ANGULAR_VELOCITY_COLS = [\"angular_vel_x\", \"angular_vel_y\", \"angular_vel_z\"]\n",
    "DELTA_ROTATION_AXES_COLS = [\"rotation_axis_x\", \"rotation_axis_y\", \"rotation_axis_z\"]\n",
    "EULER_ANGLES_COLS = [\"euler_x\", \"euler_y\", \"euler_z\"]\n",
    "pad_trunc_mode_type = Literal[\"pre\", \"center\", \"post\"]\n",
    "SEQ_PAD_TRUNC_MODE: pad_trunc_mode_type = \"center\"\n",
    "DEFAULT_VERSION_NOTES = \"Preprocessed Child Mind Institue 2025 competition preprocessed dataset.\"\n",
    "NB_COLS_PER_TOF_SENSOR = 64\n",
    "TOF_PATCH_SIZE = 2\n",
    "assert ((NB_COLS_PER_TOF_SENSOR // 2) % TOF_PATCH_SIZE) == 0, \"tof side len should be dividable by TOF_PATCH_SIZE!\"\n",
    "TOF_AGG_FUNCTIONS = [\n",
    "    \"mean\",\n",
    "    \"std\",\n",
    "    \"median\",\n",
    "    \"min\",\n",
    "    \"max\",\n",
    "]\n",
    "# Data augmentation\n",
    "JITTER = 0.25\n",
    "SCALING = 0.2\n",
    "MIXUP = 0.3\n",
    "LABEL_SMOOTHING = 0.1\n",
    "# Training loop\n",
    "NB_CROSS_VALIDATIONS = 10\n",
    "TRAIN_BATCH_SIZE = 256\n",
    "VALIDATION_BATCH_SIZE = 4 * TRAIN_BATCH_SIZE\n",
    "PATIENCE = 8\n",
    "# Optimizer\n",
    "WEIGHT_DECAY = 3e-3\n",
    "# Scheduler\n",
    "TRAINING_EPOCHS = 35 # Including warmup epochs\n",
    "WARMUP_EPOCHS = 3\n",
    "WARMUP_LR_INIT = 1.822126131809773e-05\n",
    "MAX_TO_MIN_LR_DIV_FACTOR = 100\n",
    "LR_CYCLE_FACTOR = 0.5\n",
    "CYCLE_LENGTH_FACTOR = 0.9\n",
    "INIT_CYCLE_EPOCHS = 6\n",
    "# Mock training loop\n",
    "MOCK_TRAINING_EPOCHS = 20\n",
    "MOCK_TRAINING_GAMMA = 1.01\n",
    "CHANNELS_DIMENSION = 1\n",
    "SEED = 42\n",
    "FOLDS_VAL_SCORE_ORDER = [\n",
    "    4,\n",
    "    7,\n",
    "    1,\n",
    "    9,\n",
    "    6,\n",
    "    2,\n",
    "    3,\n",
    "    8,\n",
    "    0,\n",
    "    5,\n",
    "]\n",
    "# model\n",
    "KAGGLE_USERNAME = \"mauroabidalcarrer\"\n",
    "MODEL_NAME = \"cmi-model\"\n",
    "MODEL_VARIATION = \"single_model_architecture\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ce75b5",
   "metadata": {
    "papermill": {
     "duration": 0.00608,
     "end_time": "2025-08-15T23:50:38.335653",
     "exception": false,
     "start_time": "2025-08-15T23:50:38.329573",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Seed everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d476632",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-15T23:50:38.348646Z",
     "iopub.status.busy": "2025-08-15T23:50:38.348412Z",
     "iopub.status.idle": "2025-08-15T23:50:38.357448Z",
     "shell.execute_reply": "2025-08-15T23:50:38.356918Z"
    },
    "papermill": {
     "duration": 0.016763,
     "end_time": "2025-08-15T23:50:38.358464",
     "exception": false,
     "start_time": "2025-08-15T23:50:38.341701",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed=42):\n",
    "    \"\"\"Set all random seeds for reproducibility\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'\n",
    "    torch.use_deterministic_algorithms(True, warn_only=True)\n",
    "seed_everything(seed=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35477146",
   "metadata": {
    "papermill": {
     "duration": 0.005908,
     "end_time": "2025-08-15T23:50:38.370402",
     "exception": false,
     "start_time": "2025-08-15T23:50:38.364494",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Supress performance warngings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a4981ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-15T23:50:38.383382Z",
     "iopub.status.busy": "2025-08-15T23:50:38.383139Z",
     "iopub.status.idle": "2025-08-15T23:50:38.386656Z",
     "shell.execute_reply": "2025-08-15T23:50:38.386161Z"
    },
    "papermill": {
     "duration": 0.01141,
     "end_time": "2025-08-15T23:50:38.387725",
     "exception": false,
     "start_time": "2025-08-15T23:50:38.376315",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    message=(\n",
    "        \"DataFrame is highly fragmented.  This is usually the result of \"\n",
    "        \"calling `frame.insert` many times.*\"\n",
    "    ),\n",
    "    category=pd.errors.PerformanceWarning,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d70e0ed",
   "metadata": {
    "papermill": {
     "duration": 0.006011,
     "end_time": "2025-08-15T23:50:38.399839",
     "exception": false,
     "start_time": "2025-08-15T23:50:38.393828",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### device setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a28755b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-15T23:50:38.413015Z",
     "iopub.status.busy": "2025-08-15T23:50:38.412530Z",
     "iopub.status.idle": "2025-08-15T23:50:38.482752Z",
     "shell.execute_reply": "2025-08-15T23:50:38.482121Z"
    },
    "papermill": {
     "duration": 0.078136,
     "end_time": "2025-08-15T23:50:38.483881",
     "exception": false,
     "start_time": "2025-08-15T23:50:38.405745",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1844323e",
   "metadata": {
    "papermill": {
     "duration": 0.006094,
     "end_time": "2025-08-15T23:50:38.496685",
     "exception": false,
     "start_time": "2025-08-15T23:50:38.490591",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1bada2b",
   "metadata": {
    "papermill": {
     "duration": 0.005889,
     "end_time": "2025-08-15T23:50:38.508587",
     "exception": false,
     "start_time": "2025-08-15T23:50:38.502698",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3872d715",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-15T23:50:38.521914Z",
     "iopub.status.busy": "2025-08-15T23:50:38.521642Z",
     "iopub.status.idle": "2025-08-15T23:50:38.543634Z",
     "shell.execute_reply": "2025-08-15T23:50:38.542920Z"
    },
    "papermill": {
     "duration": 0.030209,
     "end_time": "2025-08-15T23:50:38.544734",
     "exception": false,
     "start_time": "2025-08-15T23:50:38.514525",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_feature_cols(df:DF) -> list[str]:\n",
    "    return sorted(list(set(df.columns) - set(META_DATA_COLUMNS) - set(TARGET_NAMES)))\n",
    "\n",
    "# Missing ToF values are already imputed by -1 which is inconvinient since we want all missing values to be NaN.    \n",
    "# So we replace them by NaN and then perform imputing.\n",
    "def get_fillna_val_per_feature_col(df:DF) -> dict:\n",
    "    return {col: 1.0 if col == 'rot_w' else 0 for col in get_feature_cols(df)}\n",
    "\n",
    "def imputed_features(df:DF) -> DF:\n",
    "    # Missing ToF values are already imputed by -1 which is inconvinient since we want all missing values to be NaN.    \n",
    "    # So we replace them by NaN and then perform imputing.  \n",
    "    tof_vals_to_nan = {col: -1.0 for col in df.columns if col.startswith(\"tof\")}\n",
    "    # fillna_val_per_col = {col: 1.0 if col == 'rot_w' else 0 for col in df.columns}\n",
    "\n",
    "    df[get_feature_cols(df)] = (\n",
    "        df\n",
    "        .loc[:, get_feature_cols(df)]\n",
    "        # df.replace with np.nan sets dtype to floar64 so we set it back to float32\n",
    "        .replace(tof_vals_to_nan, value=np.nan)\n",
    "        .astype(\"float32\")\n",
    "        .groupby(df[\"sequence_id\"], observed=True, as_index=False)\n",
    "        .ffill()\n",
    "        .groupby(df[\"sequence_id\"], observed=True, as_index=False)\n",
    "        .bfill()\n",
    "        # In case there are only nan in the column in the sequence\n",
    "        .fillna(get_fillna_val_per_feature_col(df))\n",
    "    )\n",
    "    return df\n",
    "\n",
    "def standardize_tof_cols_names(df: DF) -> DF:\n",
    "    renamed_cols = {}\n",
    "    pattern = re.compile(r\"^(tof_\\d_v)(\\d)$\")  # match 'tof_X_vY' where Y is a single digit\n",
    "\n",
    "    for col in df.columns:\n",
    "        match = pattern.match(col)\n",
    "        if match:\n",
    "            prefix, version = match.groups()\n",
    "            new_col = f\"{prefix}0{version}\"\n",
    "            renamed_cols[col] = new_col\n",
    "\n",
    "    return df.rename(columns=renamed_cols)\n",
    "\n",
    "def norm_quat_rotations(df:DF) -> DF:\n",
    "    df[QUATERNION_COLS] /= np.linalg.norm(df[QUATERNION_COLS], axis=1, keepdims=True)\n",
    "    return df\n",
    "\n",
    "def add_linear_acc_cols(df:DF) -> DF:\n",
    "    # Vectorized version of https://www.kaggle.com/code/wasupandceacar/lb-0-82-5fold-single-bert-model#Dataset `remove_gravity_from_acc`\n",
    "    rotations:Rotation = Rotation.from_quat(df[QUATERNION_COLS])\n",
    "    gravity_sensor_frame = rotations.apply(GRAVITY_WORLD, inverse=True).astype(\"float32\")\n",
    "    df[LINEAR_ACC_COLS] = df[RAW_ACCELRATION_COLS] - gravity_sensor_frame\n",
    "    return df\n",
    "\n",
    "def add_acc_magnitude(df:DF, acc_cols:list[str], acc_mag_col_name:str) -> DF:\n",
    "    return df.assign(**{acc_mag_col_name: np.linalg.norm(df.loc[:, acc_cols], axis=1)})\n",
    "\n",
    "def add_quat_angle_mag(df:DF) -> DF:\n",
    "    return df.assign(quat_rot_mag=np.arccos(df[\"rot_w\"]) * 2)\n",
    "\n",
    "def add_angular_velocity_features(df:DF) -> DF:\n",
    "    rotations = Rotation.from_quat(df[QUATERNION_COLS])\n",
    "    delta_rotations = rotations[1:] * rotations[:-1].inv()\n",
    "    delta_rot_velocity = delta_rotations.as_rotvec()\n",
    "    # Add extra line to avoid shape mismatch\n",
    "    delta_rot_velocity = np.vstack((np.zeros((1, 3)), delta_rot_velocity))\n",
    "    delta_rot_magnitude = norm(delta_rot_velocity, axis=1, keepdims=True)\n",
    "    delta_rot_axes = delta_rot_velocity / (delta_rot_magnitude + EPSILON)\n",
    "    df[DELTA_ROTATION_ANGULAR_VELOCITY_COLS] = delta_rot_velocity\n",
    "    df[DELTA_ROTATION_AXES_COLS] = delta_rot_axes\n",
    "    df[\"delta_rot_mag\"] = delta_rot_magnitude.squeeze()\n",
    "\n",
    "    return df\n",
    "\n",
    "def rot_euler_angles(df:DF) -> ndarray:\n",
    "    df[EULER_ANGLES_COLS] = (\n",
    "        Rotation\n",
    "        .from_quat(df[QUATERNION_COLS])\n",
    "        .as_euler(\"xyz\")\n",
    "        .squeeze()\n",
    "    )\n",
    "    return df\n",
    "\n",
    "def agg_tof_patch(tof_views:np.ndarray, f_name:str) -> ndarray:\n",
    "    views_agg_func = methodcaller(f_name, tof_views, axis=(1, 2))\n",
    "    return (\n",
    "        views_agg_func(np)\n",
    "        .reshape(tof_views.shape[0], -1)\n",
    "    )\n",
    "\n",
    "def agg_tof_cols_per_sensor(df:DF) -> DF:\n",
    "    \"\"\"\n",
    "    ## Description:\n",
    "    Computes the sensor and patch sensor wise stats.\n",
    "    ## Resturns:\n",
    "    The dataframe with the added stats.\n",
    "    \"\"\"\n",
    "    for tof_idx in tqdm(range(1, 6)):\n",
    "        tof_name = f\"tof_{tof_idx}\"\n",
    "        all_tof_cols = [f\"{tof_name}_v{v_idx:02d}\" for v_idx in range(64)]\n",
    "        tof_feats = (\n",
    "            df\n",
    "            .loc[:, all_tof_cols]\n",
    "            .values\n",
    "            .reshape(-1, 8, 8)\n",
    "        )\n",
    "        agg_func = partial(df[all_tof_cols].agg, axis=\"columns\")\n",
    "        mk_fe_col_name = lambda f_name: tof_name + \"_\" + f_name\n",
    "        engineered_feats = DF({mk_fe_col_name(f_name): agg_func(f_name) for f_name in TOF_AGG_FUNCTIONS})\n",
    "        stats_cols_names = list(map(mk_fe_col_name, TOF_AGG_FUNCTIONS))\n",
    "        # Patch Feature engineering\n",
    "        tof_views:np.ndarray = sliding_window_view(tof_feats, (TOF_PATCH_SIZE, TOF_PATCH_SIZE), (1, 2))\n",
    "        patch_fe = {}\n",
    "        for f_name in TOF_AGG_FUNCTIONS:\n",
    "            tof_patch_stats = agg_tof_patch(tof_views, f_name)\n",
    "            for patch_idx in range(tof_patch_stats.shape[1]):\n",
    "                key = mk_fe_col_name(f_name) + f\"_{patch_idx:02d}\"\n",
    "                patch_fe[key] = tof_patch_stats[:, patch_idx]\n",
    "        patch_df = DF(patch_fe)\n",
    "        # concat results\n",
    "        df = pd.concat(\n",
    "            (\n",
    "                df.drop(columns=filter(df.columns.__contains__, stats_cols_names)),\n",
    "                engineered_feats,\n",
    "                patch_df,\n",
    "            ),\n",
    "            axis=\"columns\",\n",
    "        )\n",
    "    return df\n",
    "\n",
    "def add_diff_features(df:DF) -> DF:\n",
    "    return pd.concat(\n",
    "        (\n",
    "            df,\n",
    "            (\n",
    "                df\n",
    "                .groupby(\"sequence_id\", as_index=False, observed=True)\n",
    "                [get_feature_cols(df)]\n",
    "                .diff()\n",
    "                .fillna(get_fillna_val_per_feature_col(df))\n",
    "                .add_suffix(\"_diff\")\n",
    "            )\n",
    "        ),\n",
    "        axis=\"columns\",\n",
    "    )\n",
    "\n",
    "def one_hot_encode_targets(df:DF) -> DF:\n",
    "    one_hot_target = pd.get_dummies(df[\"gesture\"], dtype=\"float32\")\n",
    "    df[TARGET_NAMES] = one_hot_target[TARGET_NAMES]\n",
    "    return df\n",
    "\n",
    "def length_normed_sequence_feat_arr(\n",
    "        sequence: DF,\n",
    "        normed_sequence_len: int,\n",
    "        SEQ_PAD_TRUNC_MODE:Literal[\"pre\", \"center\", \"post\"]\n",
    "    ) -> ndarray:\n",
    "    features = (\n",
    "        sequence\n",
    "        .loc[:, get_feature_cols(sequence)]\n",
    "        .values\n",
    "    )\n",
    "    len_diff = abs(normed_sequence_len - len(features))\n",
    "    len_diff_h = len_diff // 2 # half len diff\n",
    "    len_diff_r = len_diff % 2 # len diff remainder\n",
    "    if len(features) < normed_sequence_len:\n",
    "        padding_dict = {\n",
    "            \"pre\": (len_diff, 0),\n",
    "            \"center\": (len_diff_h + len_diff_r, len_diff_h),\n",
    "            \"post\": (0, len_diff),\n",
    "        }\n",
    "        padded_features = np.pad(\n",
    "            features,\n",
    "            (padding_dict[SEQ_PAD_TRUNC_MODE], (0, 0)),\n",
    "        )\n",
    "        return padded_features\n",
    "    elif len(features) > normed_sequence_len:\n",
    "        truncating_dict = {\n",
    "            \"pre\": slice(len_diff),\n",
    "            \"center\": slice(len_diff_h, -len_diff_h),\n",
    "            \"post\": slice(0, -len_diff),\n",
    "        }\n",
    "        return features[len_diff // 2:-len_diff // 2]\n",
    "    else:\n",
    "        return features\n",
    "\n",
    "def df_to_ndarrays(df:DF, normed_sequence_len:int, seq_pad_trunc_mode:str) -> tuple[np.ndarray, np.ndarray]:\n",
    "    sequence_it = df.groupby(\"sequence_id\", observed=True, as_index=False)\n",
    "    x = np.empty(\n",
    "        shape=(len(sequence_it), normed_sequence_len, len(get_feature_cols(df))),\n",
    "        dtype=\"float32\"\n",
    "    )\n",
    "    y = np.empty(\n",
    "        shape=(len(sequence_it), len(TARGET_NAMES)),\n",
    "        dtype=\"float32\"\n",
    "    )\n",
    "    for sequence_idx, (_, sequence) in tqdm(enumerate(sequence_it), total=len(sequence_it)):\n",
    "        normed_seq_feat_arr = length_normed_sequence_feat_arr(sequence, normed_sequence_len, seq_pad_trunc_mode)\n",
    "        x[sequence_idx] = normed_seq_feat_arr\n",
    "        # Take the first value as they are(or at least should be) all the same in a single sequence\n",
    "        y[sequence_idx] = sequence[TARGET_NAMES].iloc[0].values\n",
    "\n",
    "    return x, y\n",
    "\n",
    "def get_normed_seq_len(dataset:DF) -> int:\n",
    "    return int(\n",
    "        dataset\n",
    "        .groupby(\"sequence_id\", observed=True)\n",
    "        .size()\n",
    "        .quantile(SEQUENCE_NORMED_LEN_QUANTILE)\n",
    "    )\n",
    "\n",
    "def fold_dfs_to_ndarrays(train:DF, validation:DF, dataset_normed_seq_len:int, seq_pad_trunc_mode:str) -> tuple[ndarray, ndarray, ndarray, ndarray]:\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "        (train X, train Y, validation X, validation Y)\n",
    "    \"\"\"\n",
    "    # full_dataset_normed_seq_len = get_normed_seq_len(df)\n",
    "    return (\n",
    "        *df_to_ndarrays(train, dataset_normed_seq_len, seq_pad_trunc_mode),\n",
    "        *df_to_ndarrays(validation, dataset_normed_seq_len, seq_pad_trunc_mode),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d9d58b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-15T23:50:38.558073Z",
     "iopub.status.busy": "2025-08-15T23:50:38.557854Z",
     "iopub.status.idle": "2025-08-15T23:50:38.564884Z",
     "shell.execute_reply": "2025-08-15T23:50:38.564219Z"
    },
    "papermill": {
     "duration": 0.014959,
     "end_time": "2025-08-15T23:50:38.566036",
     "exception": false,
     "start_time": "2025-08-15T23:50:38.551077",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_competitino_dataset() -> DF:\n",
    "    csv_path = kagglehub.competition_download(COMPETITION_HANDLE, path=\"train.csv\")\n",
    "    return (\n",
    "        pd.read_csv(csv_path, dtype=DATASET_DF_DTYPES)\n",
    "        .pipe(imputed_features)\n",
    "        .pipe(standardize_tof_cols_names)\n",
    "        .pipe(norm_quat_rotations)\n",
    "        .pipe(add_linear_acc_cols)\n",
    "        .pipe(add_acc_magnitude, RAW_ACCELRATION_COLS, \"acc_mag\")\n",
    "        .pipe(add_acc_magnitude, LINEAR_ACC_COLS, \"linear_acc_mag\")\n",
    "        .pipe(add_quat_angle_mag)\n",
    "        .pipe(add_angular_velocity_features)\n",
    "        .pipe(rot_euler_angles)\n",
    "        .pipe(add_quat_angle_mag)\n",
    "        .pipe(one_hot_encode_targets)\n",
    "        .pipe(agg_tof_cols_per_sensor)\n",
    "        .pipe(add_diff_features)\n",
    "    )\n",
    "\n",
    "def save_sequence_meta_data(df:DF) -> DF:\n",
    "    demographics_csv_path = kagglehub.competition_download(COMPETITION_HANDLE, path=\"train_demographics.csv\")\n",
    "    demographics = pd.read_csv(demographics_csv_path)\n",
    "    seq_meta_data = (\n",
    "        df\n",
    "        .groupby(\"sequence_id\", as_index=False, observed=True)\n",
    "        [META_DATA_COLUMNS]\n",
    "        .last()\n",
    "        .merge(demographics, how=\"left\", on=\"subject\")\n",
    "    )\n",
    "    seq_meta_data.to_parquet(\"preprocessed_dataset/sequences_meta_data.parquet\")\n",
    "    np.save(\n",
    "        \"preprocessed_dataset/auxialiary_Y.npy\",\n",
    "        pd.get_dummies(seq_meta_data[\"orientation\"], dtype=\"float32\").values,\n",
    "    )\n",
    "\n",
    "def save_df_meta_data(df:DF):\n",
    "    full_dataset_meta_data = {\n",
    "        \"mean\": df[get_feature_cols(df)].mean().astype(\"float32\").to_dict(),\n",
    "        \"std\": df[get_feature_cols(df)].std().astype(\"float32\").to_dict(),\n",
    "        \"pad_seq_len\": get_normed_seq_len(df),\n",
    "        \"feature_cols\": get_feature_cols(df),\n",
    "        \"n_aux_classes\": df[\"orientation\"].nunique(),\n",
    "    }\n",
    "    with open(\"preprocessed_dataset/full_dataset_meta_data.json\", \"w\") as fp:\n",
    "        json.dump(full_dataset_meta_data, fp, indent=4)\n",
    "\n",
    "def create_preprocessed_dataset():\n",
    "    shutil.rmtree(\"preprocessed_dataset\", ignore_errors=True)\n",
    "    os.makedirs(\"preprocessed_dataset\")\n",
    "    df = preprocess_competitino_dataset()\n",
    "    full_dataset_sequence_length_norm = get_normed_seq_len(df)\n",
    "    full_x, full_y = df_to_ndarrays(df, full_dataset_sequence_length_norm, SEQ_PAD_TRUNC_MODE)\n",
    "    np.save(join(\"preprocessed_dataset\", \"X.npy\"), full_x, allow_pickle=False)\n",
    "    np.save(join(\"preprocessed_dataset\", \"Y.npy\"), full_y, allow_pickle=False)\n",
    "    # Save meta data\n",
    "    save_sequence_meta_data(df)\n",
    "    save_df_meta_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13770476",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-15T23:50:38.578805Z",
     "iopub.status.busy": "2025-08-15T23:50:38.578578Z",
     "iopub.status.idle": "2025-08-15T23:52:32.676408Z",
     "shell.execute_reply": "2025-08-15T23:52:32.675578Z"
    },
    "papermill": {
     "duration": 114.105986,
     "end_time": "2025-08-15T23:52:32.677960",
     "exception": false,
     "start_time": "2025-08-15T23:50:38.571974",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create_preprocessed_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9d88e8",
   "metadata": {
    "papermill": {
     "duration": 0.006272,
     "end_time": "2025-08-15T23:52:32.691304",
     "exception": false,
     "start_time": "2025-08-15T23:52:32.685032",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f24ba64c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-15T23:52:32.705337Z",
     "iopub.status.busy": "2025-08-15T23:52:32.704695Z",
     "iopub.status.idle": "2025-08-15T23:52:32.709341Z",
     "shell.execute_reply": "2025-08-15T23:52:32.708635Z"
    },
    "papermill": {
     "duration": 0.012748,
     "end_time": "2025-08-15T23:52:32.710427",
     "exception": false,
     "start_time": "2025-08-15T23:52:32.697679",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CMIDataset(TensorDataset):\n",
    "    def __init__(self):\n",
    "        x = np.load(join(\"preprocessed_dataset\", \"X.npy\")).swapaxes(1, 2)\n",
    "        y = np.load(join(\"preprocessed_dataset\", \"Y.npy\"))\n",
    "        auxiliary_y = np.load(join(\"preprocessed_dataset\", \"auxialiary_Y.npy\"))\n",
    "        super().__init__(\n",
    "            torch.from_numpy(x).to(device),\n",
    "            torch.from_numpy(y).to(device),\n",
    "            torch.from_numpy(auxiliary_y).to(device),\n",
    "        )\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return *super().__getitem__(index), index\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1565ac4",
   "metadata": {
    "papermill": {
     "duration": 0.006004,
     "end_time": "2025-08-15T23:52:32.742403",
     "exception": false,
     "start_time": "2025-08-15T23:52:32.736399",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Meta data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dbfedd7a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-15T23:52:32.755425Z",
     "iopub.status.busy": "2025-08-15T23:52:32.755227Z",
     "iopub.status.idle": "2025-08-15T23:52:32.768112Z",
     "shell.execute_reply": "2025-08-15T23:52:32.767447Z"
    },
    "papermill": {
     "duration": 0.020503,
     "end_time": "2025-08-15T23:52:32.769168",
     "exception": false,
     "start_time": "2025-08-15T23:52:32.748665",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "meta_data_path = join(\n",
    "    \"preprocessed_dataset\",\n",
    "    \"full_dataset_meta_data.json\"\n",
    ")\n",
    "with open(meta_data_path, \"r\") as fp:\n",
    "    meta_data = json.load(fp)\n",
    "seq_meta_data = pd.read_parquet(\"preprocessed_dataset/sequences_meta_data.parquet\")\n",
    "# Convert target names into a ndarray to index it batchwise.\n",
    "def get_sensor_indices(sensor_prefix: str) -> list[int]:\n",
    "    is_sensor_feat = methodcaller(\"startswith\", sensor_prefix)\n",
    "    return [feat_idx for feat_idx, feat in enumerate(meta_data[\"feature_cols\"]) if is_sensor_feat(feat)]\n",
    "\n",
    "tof_idx = get_sensor_indices(\"tof\")\n",
    "thm_idx = get_sensor_indices(\"thm\")\n",
    "imu_idx = list(filter(lambda idx: idx not in tof_idx + thm_idx, range(len(meta_data[\"feature_cols\"]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26912379",
   "metadata": {
    "papermill": {
     "duration": 0.006273,
     "end_time": "2025-08-15T23:52:32.781903",
     "exception": false,
     "start_time": "2025-08-15T23:52:32.775630",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2744791d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-15T23:52:32.847167Z",
     "iopub.status.busy": "2025-08-15T23:52:32.846653Z",
     "iopub.status.idle": "2025-08-15T23:52:32.873082Z",
     "shell.execute_reply": "2025-08-15T23:52:32.872269Z"
    },
    "papermill": {
     "duration": 0.03564,
     "end_time": "2025-08-15T23:52:32.874453",
     "exception": false,
     "start_time": "2025-08-15T23:52:32.838813",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MultiScaleConvs(nn.Module):\n",
    "    def __init__(self, in_channels:int, kernel_sizes:list[int]):\n",
    "        super().__init__()\n",
    "        def mk_conv_block(k_size) -> nn.Sequential:\n",
    "            return nn.Sequential(\n",
    "                nn.Conv1d(in_channels, in_channels, k_size, padding=k_size // 2, groups=in_channels),\n",
    "                nn.BatchNorm1d(in_channels),\n",
    "                nn.ReLU(),\n",
    "            )\n",
    "        self.convs = nn.ModuleList(map(mk_conv_block, kernel_sizes))\n",
    "\n",
    "    def forward(self, x:Tensor) -> Tensor:\n",
    "        yes = torch.cat([conv(x) for conv in self.convs] + [x], dim=1)\n",
    "        # print(\"stem output shape:\", yes.shape)\n",
    "        return yes\n",
    "\n",
    "class ImuFeatureExtractor(nn.Module):\n",
    "    def __init__(self, in_channels:int, kernel_size:int=15):\n",
    "        super().__init__()\n",
    "\n",
    "        self.lpf = nn.Conv1d(\n",
    "            in_channels,\n",
    "            in_channels,\n",
    "            kernel_size=kernel_size,\n",
    "            padding=kernel_size//2,\n",
    "            groups=in_channels,\n",
    "            bias=False,\n",
    "        )\n",
    "        nn.init.kaiming_uniform_(self.lpf.weight, a=math.sqrt(5))\n",
    "\n",
    "    def forward(self, x:Tensor) -> Tensor:\n",
    "        lpf_output = self.lpf(x)\n",
    "        hpf_output = x - lpf_output\n",
    "        return torch.cat((lpf_output, hpf_output, x), dim=1)  # (B, C_out, T)\n",
    "\n",
    "class SqueezeExcitationBlock(nn.Module):\n",
    "    # Copy/paste of https://www.kaggle.com/code/wasupandceacar/lb-0-82-5fold-single-bert-model#Model implementation\n",
    "    def __init__(self, channels:int, reduction:int=8):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(channels, channels // reduction, bias=True)\n",
    "        self.fc2 = nn.Linear(channels // reduction, channels, bias=True)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, C, L)\n",
    "        se = F.adaptive_avg_pool1d(x, 1).squeeze(-1)      # -> (B, C)\n",
    "        se = F.relu(self.fc1(se), inplace=True)          # -> (B, C//r)\n",
    "        se = self.sigmoid(self.fc2(se)).unsqueeze(-1)    # -> (B, C, 1)\n",
    "        return x * se\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_chns:int, out_chns:int, dropout_ratio:float=0.3, se_reduction:int=8, kernel_size:int=3):\n",
    "        super().__init__()\n",
    "        self.blocks = nn.Sequential(\n",
    "            nn.Conv1d(in_chns, out_chns, kernel_size=kernel_size, padding=kernel_size // 2, bias=False),\n",
    "            nn.BatchNorm1d(out_chns),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(out_chns, out_chns, kernel_size=kernel_size, padding=kernel_size // 2, bias=False),\n",
    "            nn.BatchNorm1d(out_chns),\n",
    "            SqueezeExcitationBlock(out_chns, se_reduction),\n",
    "        )\n",
    "        self.head = nn.Sequential(nn.ReLU(), nn.Dropout(dropout_ratio))\n",
    "        if in_chns == out_chns:\n",
    "            self.skip_connection = nn.Identity() \n",
    "        else:\n",
    "            # TODO: set bias to False ?\n",
    "            self.skip_connection = nn.Sequential(\n",
    "                nn.Conv1d(in_chns, out_chns, 1, bias=False),\n",
    "                nn.BatchNorm1d(out_chns)\n",
    "            )\n",
    "            self.head.insert(1, nn.MaxPool1d(2))\n",
    "\n",
    "    def forward(self, x:Tensor) -> Tensor:\n",
    "        activaition_maps = self.skip_connection(x) + self.blocks(x)\n",
    "        return self.head(activaition_maps)\n",
    "\n",
    "class MBConvBlock(nn.Module):\n",
    "    # From this schema: https://media.licdn.com/dms/image/v2/D5612AQFjbDOm5uyxdw/article-inline_image-shrink_1500_2232/article-inline_image-shrink_1500_2232/0/1683677500817?e=1758153600&v=beta&t=n48_UW5TZTyDPhRFlJXSidUQQPQpuC756M0kNeKmYTY\n",
    "    def __init__(self, in_chns:int, out_chns:int, se_reduction:int=8, expansion_ratio:int=4, dropout_ratio:float=0.3):\n",
    "        super().__init__()\n",
    "        expanded_channels = in_chns * expansion_ratio\n",
    "        self.blocks = nn.Sequential(\n",
    "            nn.Conv1d(in_chns, expanded_channels, kernel_size=1, bias=False),\n",
    "            nn.BatchNorm1d(expanded_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(\n",
    "                expanded_channels,\n",
    "                expanded_channels,\n",
    "                kernel_size=3,\n",
    "                padding=1,\n",
    "                groups=expanded_channels,\n",
    "                bias=False,\n",
    "            ),\n",
    "            nn.BatchNorm1d(expanded_channels),\n",
    "            nn.ReLU(),\n",
    "            SqueezeExcitationBlock(expanded_channels, se_reduction),\n",
    "            nn.Conv1d(expanded_channels, out_chns, kernel_size=1, bias=False)\n",
    "        )\n",
    "        self.head = nn.Sequential(\n",
    "            nn.BatchNorm1d(out_chns)\n",
    "            # nn.ReLU(),\n",
    "            # nn.Dropout(dropout_ratio),\n",
    "        )\n",
    "        if in_chns == out_chns:\n",
    "            self.skip_connection = nn.Identity() \n",
    "        else:\n",
    "            # TODO: set bias to False ?\n",
    "            self.skip_connection = nn.Sequential(\n",
    "                nn.Conv1d(in_chns, out_chns, 1, bias=False),\n",
    "                nn.BatchNorm1d(out_chns)\n",
    "            )\n",
    "            self.head.add_module(\"max_pool\", nn.MaxPool1d(2))\n",
    "            \n",
    "    def forward(self, x:Tensor) -> Tensor:\n",
    "        activaition_maps = self.skip_connection(x) + self.blocks(x)\n",
    "        return self.head(activaition_maps)\n",
    "\n",
    "class AdditiveAttentionLayer(nn.Module):\n",
    "    # Copied (and slightly modified) from https://www.kaggle.com/code/myso1987/cmi3-pyroch-baseline-model-add-aug-folds\n",
    "    def __init__(self, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.attention = nn.Linear(hidden_dim, 1, bias=True)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        # x shape: (batch, channels, seq_len)\n",
    "        x = x.swapaxes(1, 2)\n",
    "        # x shape: (batch, seq_len, hidden_dim)\n",
    "        scores = torch.tanh(self.attention(x))  # (batch, seq_len, 1)\n",
    "        weights = F.softmax(scores.squeeze(-1), dim=1)  # (batch, seq_len)\n",
    "        context = torch.sum(x * weights.unsqueeze(-1), dim=1)  # (batch, hidden_dim)\n",
    "        return context\n",
    "\n",
    "class AlexNet(nn.Sequential):\n",
    "    def __init__(self, channels:list[int], dropout_ratio:float):\n",
    "        def mk_conv_block(in_channels:int, out_channels:int) -> nn.Module:\n",
    "            return nn.Sequential(\n",
    "                nn.Conv1d(in_channels, out_channels, 3, padding=1, bias=False),\n",
    "                nn.BatchNorm1d(out_channels),\n",
    "                nn.MaxPool1d(2),\n",
    "                nn.Dropout(dropout_ratio),\n",
    "            )\n",
    "        return super().__init__(*list(starmap(mk_conv_block, pairwise(channels))))\n",
    "\n",
    "class CMIHARModule(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            imu_idx:list[int],\n",
    "            thm_idx:list[int],\n",
    "            tof_idx:list[int],\n",
    "            mlp_width:int,\n",
    "            dataset_x:Optional[Tensor]=None,\n",
    "            tof_dropout_ratio:float=0,\n",
    "            thm_dropout_ratio:float=0,\n",
    "            imu_dropout_ratio:float=0,\n",
    "        ):\n",
    "        super().__init__()\n",
    "        self.imu_idx = imu_idx\n",
    "        self.tof_idx = tof_idx\n",
    "        self.thm_idx = thm_idx\n",
    "        if dataset_x is not None:\n",
    "            x_mean = dataset_x.mean(dim=(0, 2), keepdim=True)\n",
    "            x_std = dataset_x.std(dim=(0, 2), keepdim=True)\n",
    "            self.register_buffer(\"x_mean\", x_mean)\n",
    "            self.register_buffer(\"x_std\", x_std)\n",
    "        else:\n",
    "            x_stats_size = (1, len(meta_data[\"feature_cols\"]), 1)\n",
    "            self.register_buffer(\"x_mean\", torch.empty(x_stats_size))\n",
    "            self.register_buffer(\"x_std\", torch.empty(x_stats_size))\n",
    "        self.imu_branch = nn.Sequential(\n",
    "            ResidualBlock(len(imu_idx), 219, imu_dropout_ratio),\n",
    "            ResidualBlock(219, 500, imu_dropout_ratio),\n",
    "        )\n",
    "        self.tof_branch = AlexNet([len(tof_idx), 82, 500], tof_dropout_ratio)\n",
    "        self.thm_branch = AlexNet([len(thm_idx), 82, 500], thm_dropout_ratio)\n",
    "        self.rnn = nn.GRU(500 * 3, mlp_width // 2, bidirectional=True)\n",
    "        self.attention = AdditiveAttentionLayer(mlp_width)\n",
    "        self.meain_head = nn.Sequential(\n",
    "            # Head\n",
    "            nn.LazyLinear(mlp_width, bias=False),\n",
    "            nn.BatchNorm1d(mlp_width),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(mlp_width, mlp_width // 2, bias=False),\n",
    "            nn.BatchNorm1d(mlp_width // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(mlp_width // 2, 18),\n",
    "        )\n",
    "        self.aux_head = nn.Sequential(\n",
    "            # Head\n",
    "            nn.LazyLinear(mlp_width, bias=False),\n",
    "            nn.BatchNorm1d(mlp_width),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(mlp_width, mlp_width // 2, bias=False),\n",
    "            nn.BatchNorm1d(mlp_width // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(mlp_width // 2, meta_data[\"n_aux_classes\"]),\n",
    "        )\n",
    "\n",
    "    def forward(self, x:Tensor) -> Tensor:\n",
    "        assert self.x_mean is not None and self.x_std is not None, f\"Nor x_mean nor x_std should be None.\\nx_std: {self.x_std}\\nx_mean: {self.x_mean}\"\n",
    "        x = (x - self.x_mean) / self.x_std\n",
    "        concatenated_activation_maps = torch.cat(\n",
    "            (\n",
    "                self.imu_branch(x[:, self.imu_idx]),\n",
    "                self.thm_branch(x[:, self.thm_idx]),\n",
    "                self.tof_branch(x[:, self.tof_idx]),\n",
    "            ),\n",
    "            dim=CHANNELS_DIMENSION,\n",
    "        )\n",
    "        lstm_output, _  = self.rnn(concatenated_activation_maps.swapaxes(1, 2))\n",
    "        lstm_output = lstm_output.swapaxes(1, 2) # redundant\n",
    "        attended = self.attention(lstm_output)\n",
    "        return self.meain_head(attended), self.aux_head(attended)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb7d70e",
   "metadata": {
    "papermill": {
     "duration": 0.007436,
     "end_time": "2025-08-15T23:52:32.889823",
     "exception": false,
     "start_time": "2025-08-15T23:52:32.882387",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Create model function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c9054880",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-15T23:52:32.907505Z",
     "iopub.status.busy": "2025-08-15T23:52:32.906807Z",
     "iopub.status.idle": "2025-08-15T23:52:33.315496Z",
     "shell.execute_reply": "2025-08-15T23:52:33.314838Z"
    },
    "papermill": {
     "duration": 0.417012,
     "end_time": "2025-08-15T23:52:33.316640",
     "exception": false,
     "start_time": "2025-08-15T23:52:32.899628",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CMIHARModule(\n",
       "  (imu_branch): Sequential(\n",
       "    (0): ResidualBlock(\n",
       "      (blocks): Sequential(\n",
       "        (0): Conv1d(46, 219, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "        (1): BatchNorm1d(219, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv1d(219, 219, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "        (4): BatchNorm1d(219, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): SqueezeExcitationBlock(\n",
       "          (fc1): Linear(in_features=219, out_features=27, bias=True)\n",
       "          (fc2): Linear(in_features=27, out_features=219, bias=True)\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (head): Sequential(\n",
       "        (0): ReLU()\n",
       "        (1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (2): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (skip_connection): Sequential(\n",
       "        (0): Conv1d(46, 219, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        (1): BatchNorm1d(219, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): ResidualBlock(\n",
       "      (blocks): Sequential(\n",
       "        (0): Conv1d(219, 500, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "        (1): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv1d(500, 500, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "        (4): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): SqueezeExcitationBlock(\n",
       "          (fc1): Linear(in_features=500, out_features=62, bias=True)\n",
       "          (fc2): Linear(in_features=62, out_features=500, bias=True)\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (head): Sequential(\n",
       "        (0): ReLU()\n",
       "        (1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (2): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (skip_connection): Sequential(\n",
       "        (0): Conv1d(219, 500, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        (1): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (tof_branch): AlexNet(\n",
       "    (0): Sequential(\n",
       "      (0): Conv1d(890, 82, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "      (1): BatchNorm1d(82, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (3): Dropout(p=0.2, inplace=False)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Conv1d(82, 500, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "      (1): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (3): Dropout(p=0.2, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (thm_branch): AlexNet(\n",
       "    (0): Sequential(\n",
       "      (0): Conv1d(10, 82, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "      (1): BatchNorm1d(82, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (3): Dropout(p=0.2, inplace=False)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Conv1d(82, 500, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "      (1): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (3): Dropout(p=0.2, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (rnn): GRU(1500, 128, bidirectional=True)\n",
       "  (attention): AdditiveAttentionLayer(\n",
       "    (attention): Linear(in_features=256, out_features=1, bias=True)\n",
       "  )\n",
       "  (meain_head): Sequential(\n",
       "    (0): LazyLinear(in_features=0, out_features=256, bias=False)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=128, bias=False)\n",
       "    (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=128, out_features=18, bias=True)\n",
       "  )\n",
       "  (aux_head): Sequential(\n",
       "    (0): LazyLinear(in_features=0, out_features=256, bias=False)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=128, bias=False)\n",
       "    (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=128, out_features=4, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input channels: 946\n"
     ]
    }
   ],
   "source": [
    "def mk_model(\n",
    "    dataset_x:Optional[Tensor]=None,\n",
    ") -> nn.Module:\n",
    "    return (\n",
    "        CMIHARModule(\n",
    "            imu_idx=imu_idx,\n",
    "            thm_idx=thm_idx,\n",
    "            tof_idx=tof_idx,\n",
    "            mlp_width=256,\n",
    "            dataset_x=dataset_x,\n",
    "            imu_dropout_ratio=0.2,\n",
    "            tof_dropout_ratio=0.2,\n",
    "            thm_dropout_ratio=0.2,\n",
    "\n",
    "        )\n",
    "        .to(device)\n",
    "    )\n",
    "\n",
    "display(mk_model(torch.arange(12).view(2, 2, -1).float()))\n",
    "print(\"input channels:\", len(meta_data[\"feature_cols\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4013f150",
   "metadata": {
    "papermill": {
     "duration": 0.006614,
     "end_time": "2025-08-15T23:52:33.330292",
     "exception": false,
     "start_time": "2025-08-15T23:52:33.323678",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "64348e01",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-15T23:52:33.358759Z",
     "iopub.status.busy": "2025-08-15T23:52:33.358489Z",
     "iopub.status.idle": "2025-08-15T23:52:33.366488Z",
     "shell.execute_reply": "2025-08-15T23:52:33.365515Z"
    },
    "papermill": {
     "duration": 0.03131,
     "end_time": "2025-08-15T23:52:33.368107",
     "exception": false,
     "start_time": "2025-08-15T23:52:33.336797",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CosineAnnealingWarmupRestarts(_LRScheduler):\n",
    "    def __init__(\n",
    "        self,\n",
    "        optimizer: Optimizer,\n",
    "        warmup_steps: int,\n",
    "        max_lr: float,\n",
    "        min_lr: float,\n",
    "        cycle_length: int,\n",
    "        cycle_mult: float = 1.0,\n",
    "        gamma: float = 1.0,\n",
    "        last_epoch: int = -1,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            optimizer: Wrapped optimizer.\n",
    "            warmup_steps: Number of steps for linear warmup.\n",
    "            max_lr: Initial maximum learning rate.\n",
    "            min_lr: Minimum learning rate after decay.\n",
    "            cycle_length: Initial number of steps per cosine cycle.\n",
    "            cycle_mult: Multiplicative factor for increasing cycle lengths.\n",
    "            gamma: Multiplicative decay factor for max_lr after each cycle.\n",
    "            last_epoch: The index of last epoch. Default: -1.\n",
    "        \"\"\"\n",
    "        self.warmup_steps = warmup_steps\n",
    "        self.max_lr = max_lr\n",
    "        self.min_lr = min_lr\n",
    "        self.cycle_length = cycle_length\n",
    "        self.cycle_mult = cycle_mult\n",
    "        self.gamma = gamma\n",
    "\n",
    "        self.current_cycle = 0\n",
    "        self.cycle_step = 0\n",
    "        self.lr = max_lr\n",
    "\n",
    "        super().__init__(optimizer, last_epoch)\n",
    "\n",
    "    def get_lr(self) -> list[float]:\n",
    "        if self.last_epoch < self.warmup_steps:\n",
    "            # Linear warmup\n",
    "            scale = (self.last_epoch + 1) / self.warmup_steps\n",
    "            return [self.min_lr + scale * (self.max_lr - self.min_lr) for _ in self.base_lrs]\n",
    "\n",
    "        # Adjust for post-warmup step index\n",
    "        t = self.cycle_step\n",
    "        T = self.cycle_length\n",
    "\n",
    "        cosine_decay = 0.5 * (1 + math.cos(math.pi * t / T))\n",
    "        lr = self.min_lr + (self.max_lr - self.min_lr) * cosine_decay\n",
    "\n",
    "        return [lr for _ in self.base_lrs]\n",
    "\n",
    "    def step(self, epoch: Optional[int] = None) -> None:\n",
    "        if self.last_epoch >= self.warmup_steps:\n",
    "            self.cycle_step += 1\n",
    "            if self.cycle_step >= self.cycle_length:\n",
    "                self.current_cycle += 1\n",
    "                self.cycle_step = 0\n",
    "                self.cycle_length = max(int(self.cycle_length * self.cycle_mult), 1)\n",
    "                self.max_lr *= self.gamma\n",
    "        super().step(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2046b564",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-15T23:52:33.383095Z",
     "iopub.status.busy": "2025-08-15T23:52:33.382827Z",
     "iopub.status.idle": "2025-08-15T23:52:33.387725Z",
     "shell.execute_reply": "2025-08-15T23:52:33.387210Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.014439,
     "end_time": "2025-08-15T23:52:33.389927",
     "exception": false,
     "start_time": "2025-08-15T23:52:33.375488",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def mixup_data(\n",
    "    x:Tensor,\n",
    "    y:Tensor,\n",
    "    aux_y:Tensor,\n",
    "    alpha=0.2\n",
    ") -> tuple[Tensor, Tensor] | tuple[Tensor, Tensor, Tensor]:\n",
    "    \"\"\"\n",
    "    Return mixed inputs and mixed targets (one-hot) for mixup.\n",
    "    x: Tensor of shape (batch_size, features, seq_len)\n",
    "    y: Tensor of shape (batch_size, num_classes)\n",
    "    \"\"\"\n",
    "    if alpha > 0:\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "    else:\n",
    "        lam = 1.0\n",
    "    batch_size = x.size(0)\n",
    "    index = torch.randperm(batch_size).to(x.device)\n",
    "\n",
    "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "    mixed_y = lam * y + (1 - lam) * y[index, :]\n",
    "    mixed_aux_y = lam * aux_y + (1 - lam) * aux_y[index, :]\n",
    "    \n",
    "    return mixed_x, mixed_y, mixed_aux_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ca86b9fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-15T23:52:33.404309Z",
     "iopub.status.busy": "2025-08-15T23:52:33.404085Z",
     "iopub.status.idle": "2025-08-15T23:52:33.410320Z",
     "shell.execute_reply": "2025-08-15T23:52:33.409616Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.014782,
     "end_time": "2025-08-15T23:52:33.411374",
     "exception": false,
     "start_time": "2025-08-15T23:52:33.396592",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model_on_single_epoch(\n",
    "        model:nn.Module,\n",
    "        train_loader:DL,\n",
    "        criterion:callable,\n",
    "        optimizer:torch.optim.Optimizer,\n",
    "        scheduler:_LRScheduler,\n",
    "        training_kw:dict,\n",
    "    ) -> dict:\n",
    "    \"Train model on a single epoch\"\n",
    "    train_metrics = {}\n",
    "    model.train()\n",
    "    train_metrics[\"train_loss\"] = 0.0\n",
    "    total = 0\n",
    "    for batch_x, batch_y, batch_aux_y, idx in train_loader:\n",
    "        batch_aux_y = batch_aux_y.clone()\n",
    "        batch_x = batch_x.to(device).clone()\n",
    "        add_noise = torch.randn_like(batch_x, device=device) * 0.04\n",
    "        scale_noise = torch.rand_like(batch_x, device=device) * (1.1 - 0.9) + 0.9\n",
    "        batch_x = (add_noise + batch_x) * scale_noise\n",
    "        batch_x[:TRAIN_BATCH_SIZE // 2, tof_idx + thm_idx] = 0.0\n",
    "        batch_y = batch_y.to(device)\n",
    "        batch_x = batch_x.float()\n",
    "        \n",
    "        batch_x, batch_y, batch_aux_y = mixup_data(batch_x, batch_y, batch_aux_y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs, aux_output = model(batch_x)\n",
    "        loss = criterion(outputs, batch_y) + criterion(aux_output, batch_aux_y) * training_kw[\"aux_loss_weigth\"]\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        train_metrics[\"train_loss\"] += loss.item() * batch_x.size(0)\n",
    "        total += batch_x.size(0)\n",
    "\n",
    "    train_metrics[\"train_loss\"] /= total\n",
    "\n",
    "    return train_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8f6a9911",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-15T23:52:33.427675Z",
     "iopub.status.busy": "2025-08-15T23:52:33.427415Z",
     "iopub.status.idle": "2025-08-15T23:52:33.434594Z",
     "shell.execute_reply": "2025-08-15T23:52:33.434082Z"
    },
    "papermill": {
     "duration": 0.017342,
     "end_time": "2025-08-15T23:52:33.435646",
     "exception": false,
     "start_time": "2025-08-15T23:52:33.418304",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model:nn.Module, validation_loader:DL, criterion:callable) -> dict:\n",
    "    model.eval()\n",
    "    eval_metrics = {}\n",
    "    eval_metrics[\"val_loss\"] = 0.0\n",
    "    total = 0\n",
    "    all_true = []\n",
    "    all_pred = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_x, batch_y, batch_aux_y, idx in validation_loader:\n",
    "            batch_x = batch_x.to(device).clone()\n",
    "            batch_y = batch_y.to(device)\n",
    "            batch_x[:VALIDATION_BATCH_SIZE // 2, tof_idx + thm_idx] = 0.0\n",
    "\n",
    "            outputs, _ = model(batch_x)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            eval_metrics[\"val_loss\"] += loss.item() * batch_x.size(0)\n",
    "            total += batch_x.size(0)\n",
    "\n",
    "            # Get predicted class indices\n",
    "            preds = torch.argmax(outputs, dim=1).cpu().numpy()\n",
    "            # Get true class indices from one-hot\n",
    "            trues = torch.argmax(batch_y, dim=1).cpu().numpy()\n",
    "\n",
    "            all_true.append(trues)\n",
    "            all_pred.append(preds)\n",
    "\n",
    "    eval_metrics[\"val_loss\"] /= total\n",
    "    all_true = np.concatenate(all_true)\n",
    "    all_pred = np.concatenate(all_pred)\n",
    "\n",
    "    # Compute competition metrics\n",
    "    # Binary classification: BFRB (1) vs non-BFRB (0)\n",
    "    binary_true = np.isin(all_true, BFRB_INDICES).astype(int)\n",
    "    binary_pred = np.isin(all_pred, BFRB_INDICES).astype(int)\n",
    "    eval_metrics[\"binary_f1\"] = f1_score(binary_true, binary_pred)\n",
    "\n",
    "    # Collapse non-BFRB gestures into a single class\n",
    "    collapsed_true = np.where(\n",
    "        np.isin(all_true, BFRB_INDICES),\n",
    "        all_true,\n",
    "        len(BFRB_GESTURES)  # Single non-BFRB class\n",
    "    )\n",
    "    collapsed_pred = np.where(\n",
    "        np.isin(all_pred, BFRB_INDICES),\n",
    "        all_pred,\n",
    "        len(BFRB_GESTURES)  # Single non-BFRB class\n",
    "    )\n",
    "\n",
    "    # Macro F1 on collapsed classes\n",
    "    eval_metrics[\"macro_f1\"] = f1_score(collapsed_true, collapsed_pred, average='macro')\n",
    "    eval_metrics[\"final_metric\"] = (eval_metrics[\"binary_f1\"] + eval_metrics[\"macro_f1\"]) / 2\n",
    "\n",
    "    return eval_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1234325d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_perf_and_seq_id(model:nn.Module, data_loader:DL) -> DF:\n",
    "    metrics:dict[list[ndarray]] = defaultdict(list)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch_x, batch_y, batch_aux_y, idx in data_loader:\n",
    "            batch_x = batch_x.to(device).clone()\n",
    "            batch_y = batch_y.to(device)\n",
    "            # batch_x[:VALIDATION_BATCH_SIZE // 2, tof_idx + thm_idx] = 0.0\n",
    "\n",
    "            outputs, aux_outputs = model(batch_x)\n",
    "            losses = nn.functional.cross_entropy(\n",
    "                outputs,\n",
    "                batch_y,\n",
    "                label_smoothing=LABEL_SMOOTHING,\n",
    "                reduction=\"none\",\n",
    "            )\n",
    "            aux_losses = nn.functional.cross_entropy(\n",
    "                aux_outputs,\n",
    "                batch_aux_y,\n",
    "                label_smoothing=LABEL_SMOOTHING,\n",
    "                reduction=\"none\",\n",
    "            )\n",
    "            # Get predicted class indices\n",
    "            preds = torch.argmax(outputs, dim=1).cpu().numpy()\n",
    "            # Get true class indices from one-hot\n",
    "            trues = torch.argmax(batch_y, dim=1).cpu().numpy()\n",
    "            accuracies = (preds == trues) #.cpu().numpy()\n",
    "\n",
    "            metrics[\"losses\"].append(losses.cpu().numpy())\n",
    "            metrics[\"aux_losses\"].append(aux_losses.cpu().numpy())\n",
    "            metrics[\"preds\"].append(preds)\n",
    "            metrics[\"trues\"].append(trues)\n",
    "            metrics[\"accuracies\"].append(accuracies)\n",
    "            metrics[\"sequence_id\"].append(seq_meta_data[\"sequence_id\"].iloc[idx].values)\n",
    "\n",
    "    metrics = {k: np.concat(v) for k, v in metrics.items()}\n",
    "    \n",
    "    return DF.from_records(metrics)\n",
    "\n",
    "def get_per_sequence_meta_data(model:nn.Module, train_dataset:Dataset, val_dataset:Dataset) -> DF:\n",
    "    train_DL = DL(train_dataset, VALIDATION_BATCH_SIZE, shuffle=False)\n",
    "    val_DL = DL(val_dataset, VALIDATION_BATCH_SIZE, shuffle=False)\n",
    "    return (\n",
    "        pd.concat((\n",
    "            get_perf_and_seq_id(model, train_DL).assign(is_train=True),\n",
    "            get_perf_and_seq_id(model, val_DL).assign(is_train=False),\n",
    "        ))\n",
    "        .merge(seq_meta_data, how=\"left\", on=\"sequence_id\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "90e307d9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-15T23:52:33.450349Z",
     "iopub.status.busy": "2025-08-15T23:52:33.450093Z",
     "iopub.status.idle": "2025-08-15T23:52:33.457637Z",
     "shell.execute_reply": "2025-08-15T23:52:33.457096Z"
    },
    "papermill": {
     "duration": 0.016236,
     "end_time": "2025-08-15T23:52:33.458766",
     "exception": false,
     "start_time": "2025-08-15T23:52:33.442530",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model_on_all_epochs(\n",
    "        model:nn.Module,\n",
    "        train_dataset:Dataset,\n",
    "        validation_dataset:Dataset,\n",
    "        criterion:callable,\n",
    "        optimizer:torch.optim.Optimizer,\n",
    "        scheduler:_LRScheduler,\n",
    "        fold:int,\n",
    "        training_kw:dict,\n",
    "    ) -> tuple[DF, DF]:\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "        tuple[DF, DF]: epoch wise metrics, sample(sequence) wise meta data metrics\n",
    "    \"\"\"\n",
    "    train_loader = DL(train_dataset, TRAIN_BATCH_SIZE, shuffle=True, drop_last=False)\n",
    "    validation_loader = DL(validation_dataset, VALIDATION_BATCH_SIZE, shuffle=False, drop_last=False)\n",
    "\n",
    "    metrics:list[dict] = []\n",
    "    # Early stopping\n",
    "    best_metric = -np.inf\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    for epoch in range(1, TRAINING_EPOCHS + 1):\n",
    "        train_metrics = train_model_on_single_epoch(model, train_loader, criterion, optimizer, scheduler, training_kw)\n",
    "        validation_metrics = evaluate_model(model, validation_loader, criterion)\n",
    "        metrics.append({\"fold\": fold, \"epoch\": epoch} | train_metrics | validation_metrics)\n",
    "\n",
    "        print(f\"Epoch {epoch:02d}: Binary F1 = {validation_metrics['binary_f1']:.4f}, Macro F1 = {validation_metrics['macro_f1']:.4f}, Final Metric = {validation_metrics['final_metric']:.4f}\")\n",
    "\n",
    "        if validation_metrics[\"final_metric\"] > best_metric:\n",
    "            best_metric = validation_metrics[\"final_metric\"]\n",
    "            epochs_no_improve = 0\n",
    "            best_model_state = model.state_dict()\n",
    "            print(f\"  New best metric! Saving model...\")\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            if epochs_no_improve >= PATIENCE:\n",
    "                print(f\"Early stopping triggered at epoch {epoch}\")\n",
    "                model.load_state_dict(best_model_state)\n",
    "                break\n",
    "    os.makedirs(\"models\", exist_ok=True)\n",
    "    torch.save(best_model_state, f\"models/model_fold_{fold}.pth\")\n",
    "    epoch_wise_metrics = DF.from_records(metrics).set_index([\"fold\", \"epoch\"])\n",
    "    sample_wise_meta_data = get_per_sequence_meta_data(model, train_dataset, validation_dataset)\n",
    "\n",
    "    return epoch_wise_metrics, sample_wise_meta_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "44fc09db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-15T23:52:33.473353Z",
     "iopub.status.busy": "2025-08-15T23:52:33.472825Z",
     "iopub.status.idle": "2025-08-15T23:52:33.477863Z",
     "shell.execute_reply": "2025-08-15T23:52:33.477272Z"
    },
    "papermill": {
     "duration": 0.013385,
     "end_time": "2025-08-15T23:52:33.478871",
     "exception": false,
     "start_time": "2025-08-15T23:52:33.465486",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sgkf_from_tensor_dataset(\n",
    "    dataset: TensorDataset,\n",
    "    n_splits: int = 5,\n",
    "    shuffle: bool = True,\n",
    ") -> Iterator[tuple[Subset, Subset]]:\n",
    "    # Load sequence meta data to get classes and groups parameters\n",
    "    seq_meta = pd.read_parquet(\"preprocessed_dataset/sequences_meta_data.parquet\")\n",
    "    X, *_ = dataset.tensors\n",
    "    sgkf = StratifiedGroupKFold(\n",
    "        n_splits=n_splits,\n",
    "        shuffle=shuffle,\n",
    "    )\n",
    "\n",
    "    fold_indices = list(sgkf.split(X.cpu().numpy(), seq_meta[\"gesture\"], seq_meta[\"subject\"]))\n",
    "    fold_indices\n",
    "\n",
    "    for fold_idx in FOLDS_VAL_SCORE_ORDER:\n",
    "        seed_everything(seed=SEED + fold_idx)\n",
    "        train_idx, val_idx = fold_indices[fold_idx]\n",
    "        yield Subset(dataset, train_idx), Subset(dataset, val_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9eeaf689",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-15T23:52:33.493664Z",
     "iopub.status.busy": "2025-08-15T23:52:33.493354Z",
     "iopub.status.idle": "2025-08-15T23:52:33.505512Z",
     "shell.execute_reply": "2025-08-15T23:52:33.504826Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.021169,
     "end_time": "2025-08-15T23:52:33.506592",
     "exception": false,
     "start_time": "2025-08-15T23:52:33.485423",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_on_all_folds(\n",
    "    lr_scheduler_kw:dict,\n",
    "    optimizer_kw:dict,\n",
    "    training_kw:dict,\n",
    "    best_folds_scores:Optional[dict]=None,\n",
    ") -> tuple[float, DF, DF]:\n",
    "    seed_everything(seed=SEED)\n",
    "    epoch_metrics:DF = DF()\n",
    "    seq_meta_data_metrics:DF = DF()\n",
    "    full_dataset = CMIDataset()\n",
    "    folds_it = sgkf_from_tensor_dataset(full_dataset, NB_CROSS_VALIDATIONS)\n",
    "    fold_training_early_stopped = False\n",
    "    for fold_idx, (train_dataset, validation_dataset) in enumerate(folds_it):\n",
    "        # Debugging\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(\"training:\", fold_idx + 1)\n",
    "        print(f\"Fold {fold_idx + 1}/{NB_CROSS_VALIDATIONS}\")\n",
    "        criterion = torch.nn.CrossEntropyLoss(label_smoothing=LABEL_SMOOTHING)\n",
    "        all_train_x = train_dataset.dataset.tensors[0][train_dataset.indices]\n",
    "        model = mk_model(all_train_x)\n",
    "        # Optimizer et scheduler\n",
    "        optimizer = torch.optim.AdamW(\n",
    "            model.parameters(),\n",
    "            WARMUP_LR_INIT,\n",
    "            weight_decay=optimizer_kw[\"weight_decay\"],\n",
    "            betas=(optimizer_kw[\"beta_0\"], optimizer_kw[\"beta_1\"]),\n",
    "        )\n",
    "        steps_per_epoch = len(DL(train_dataset, TRAIN_BATCH_SIZE)) # ugly, i know\n",
    "        scheduler = CosineAnnealingWarmupRestarts(\n",
    "            optimizer,\n",
    "            warmup_steps=lr_scheduler_kw[\"warmup_epochs\"] * steps_per_epoch,\n",
    "            cycle_mult=lr_scheduler_kw[\"cycle_mult\"],\n",
    "            max_lr=lr_scheduler_kw[\"max_lr\"],\n",
    "            min_lr=lr_scheduler_kw[\"max_lr\"] / lr_scheduler_kw[\"max_to_min_div_factor\"],\n",
    "            cycle_length=lr_scheduler_kw[\"init_cycle_epochs\"] * steps_per_epoch,\n",
    "            gamma=lr_scheduler_kw[\"lr_cycle_factor\"],\n",
    "        ) \n",
    "        fold_metrics_epoch_metrics, fold_seq_meta_data_metrics = train_model_on_all_epochs(\n",
    "            model,\n",
    "            train_dataset,\n",
    "            validation_dataset,\n",
    "            criterion,\n",
    "            optimizer,\n",
    "            scheduler,\n",
    "            fold_idx,\n",
    "            training_kw,\n",
    "        )\n",
    "\n",
    "        best_fold_metrics = fold_metrics_epoch_metrics.loc[fold_metrics_epoch_metrics[\"final_metric\"].idxmax()]\n",
    "        final_fold_metrics = fold_metrics_epoch_metrics.iloc[-1]\n",
    "        print(f\"Best validation metrics - Binary F1: {best_fold_metrics['binary_f1']:.4f}, Macro F1: {best_fold_metrics['macro_f1']:.4f}, Final: {best_fold_metrics['final_metric']:.4f}\")\n",
    "        print(f\"Final validation metrics - Binary F1: {final_fold_metrics['binary_f1']:.4f}, Macro F1: {final_fold_metrics['macro_f1']:.4f}, Final: {final_fold_metrics['final_metric']:.4f}\")\n",
    "\n",
    "        epoch_metrics = pd.concat((epoch_metrics, fold_metrics_epoch_metrics))\n",
    "        seq_meta_data_metrics = pd.concat((seq_meta_data_metrics, fold_seq_meta_data_metrics))\n",
    "\n",
    "        if (\n",
    "            best_folds_scores is not None\n",
    "            and\n",
    "            best_fold_metrics[\"final_metric\"] < best_folds_scores[fold_idx]\n",
    "        ):\n",
    "            print(f\"Fold wise early stopping triggered at fold {fold_idx} score: {best_fold_metrics['final_metric']}, best score: {best_folds_scores[fold_idx]}\")\n",
    "            fold_training_early_stopped = True\n",
    "            break\n",
    "\n",
    "    if not fold_training_early_stopped and best_folds_scores is not None:\n",
    "        new_best_folds_scores = (\n",
    "            epoch_metrics\n",
    "            .groupby(level=0)\n",
    "            .max()\n",
    "            [\"final_metric\"]\n",
    "            .to_dict()\n",
    "        )\n",
    "        print(\n",
    "            \"Found new best fold scores:\",\n",
    "            new_best_folds_scores,\n",
    "            \"Old best scores:\",\n",
    "            best_folds_scores,\n",
    "            sep=\"\\n\"\n",
    "        )\n",
    "        best_folds_scores.update(new_best_folds_scores)\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"Cross-Validation Results\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "    # Statistiques pour les meilleures mÃ©triques\n",
    "    best_metrics:DF = (\n",
    "        epoch_metrics\n",
    "        .loc[:, [\"binary_f1\", \"macro_f1\", \"final_metric\"]]\n",
    "        .groupby(level=0)\n",
    "        .max()\n",
    "    )\n",
    "\n",
    "    print(\"\\nBest Fold-wise Metrics:\")\n",
    "    display(best_metrics)\n",
    "    print(\"\\nGlobal Statistics (Best Metrics):\")\n",
    "    print(f\"Mean Best Final Metric: {best_metrics['final_metric'].mean():.4f} Â± {best_metrics['final_metric'].std():.4f}\")\n",
    "    print(f\"Mean Best Binary F1: {best_metrics['binary_f1'].mean():.4f} Â± {best_metrics['binary_f1'].std():.4f}\")\n",
    "    print(f\"Mean Best Macro F1: {best_metrics['macro_f1'].mean():.4f} Â± {best_metrics['macro_f1'].std():.4f}\")\n",
    "\n",
    "    return best_metrics[\"final_metric\"].mean(), epoch_metrics, seq_meta_data_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6ee96db6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-15T23:52:33.521201Z",
     "iopub.status.busy": "2025-08-15T23:52:33.520957Z",
     "iopub.status.idle": "2025-08-15T23:58:38.571487Z",
     "shell.execute_reply": "2025-08-15T23:58:38.570699Z"
    },
    "papermill": {
     "duration": 365.059074,
     "end_time": "2025-08-15T23:58:38.572688",
     "exception": false,
     "start_time": "2025-08-15T23:52:33.513614",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "training: 1\n",
      "Fold 1/10\n",
      "Epoch 01: Binary F1 = 0.7639, Macro F1 = 0.1905, Final Metric = 0.4772\n",
      "  New best metric! Saving model...\n",
      "Epoch 02: Binary F1 = 0.8563, Macro F1 = 0.2463, Final Metric = 0.5513\n",
      "  New best metric! Saving model...\n",
      "Epoch 03: Binary F1 = 0.8910, Macro F1 = 0.3188, Final Metric = 0.6049\n",
      "  New best metric! Saving model...\n",
      "Epoch 04: Binary F1 = 0.9006, Macro F1 = 0.3570, Final Metric = 0.6288\n",
      "  New best metric! Saving model...\n",
      "Epoch 05: Binary F1 = 0.8661, Macro F1 = 0.3064, Final Metric = 0.5862\n",
      "Epoch 06: Binary F1 = 0.8846, Macro F1 = 0.3690, Final Metric = 0.6268\n",
      "Epoch 07: Binary F1 = 0.8958, Macro F1 = 0.4091, Final Metric = 0.6524\n",
      "  New best metric! Saving model...\n",
      "Epoch 08: Binary F1 = 0.8717, Macro F1 = 0.3919, Final Metric = 0.6318\n",
      "Epoch 09: Binary F1 = 0.8778, Macro F1 = 0.4142, Final Metric = 0.6460\n",
      "Epoch 10: Binary F1 = 0.8758, Macro F1 = 0.3747, Final Metric = 0.6253\n",
      "Epoch 11: Binary F1 = 0.9084, Macro F1 = 0.3905, Final Metric = 0.6494\n",
      "Epoch 12: Binary F1 = 0.9006, Macro F1 = 0.4014, Final Metric = 0.6510\n",
      "Epoch 13: Binary F1 = 0.8690, Macro F1 = 0.4059, Final Metric = 0.6375\n",
      "Epoch 14: Binary F1 = 0.8629, Macro F1 = 0.4122, Final Metric = 0.6375\n",
      "Epoch 15: Binary F1 = 0.8222, Macro F1 = 0.4270, Final Metric = 0.6246\n",
      "Early stopping triggered at epoch 15\n",
      "Best validation metrics - Binary F1: 0.8958, Macro F1: 0.4091, Final: 0.6524\n",
      "Final validation metrics - Binary F1: 0.8222, Macro F1: 0.4270, Final: 0.6246\n",
      "\n",
      "==================================================\n",
      "training: 2\n",
      "Fold 2/10\n",
      "Epoch 01: Binary F1 = 0.6966, Macro F1 = 0.1603, Final Metric = 0.4284\n",
      "  New best metric! Saving model...\n",
      "Epoch 02: Binary F1 = 0.8738, Macro F1 = 0.2906, Final Metric = 0.5822\n",
      "  New best metric! Saving model...\n",
      "Epoch 03: Binary F1 = 0.8975, Macro F1 = 0.3173, Final Metric = 0.6074\n",
      "  New best metric! Saving model...\n",
      "Epoch 04: Binary F1 = 0.9161, Macro F1 = 0.3912, Final Metric = 0.6536\n",
      "  New best metric! Saving model...\n",
      "Epoch 05: Binary F1 = 0.9145, Macro F1 = 0.3973, Final Metric = 0.6559\n",
      "  New best metric! Saving model...\n",
      "Epoch 06: Binary F1 = 0.9408, Macro F1 = 0.4160, Final Metric = 0.6784\n",
      "  New best metric! Saving model...\n",
      "Epoch 07: Binary F1 = 0.9352, Macro F1 = 0.4521, Final Metric = 0.6937\n",
      "  New best metric! Saving model...\n",
      "Epoch 08: Binary F1 = 0.8801, Macro F1 = 0.4432, Final Metric = 0.6616\n",
      "Epoch 09: Binary F1 = 0.9362, Macro F1 = 0.3983, Final Metric = 0.6672\n",
      "Epoch 10: Binary F1 = 0.9217, Macro F1 = 0.4478, Final Metric = 0.6848\n",
      "Epoch 11: Binary F1 = 0.9506, Macro F1 = 0.4820, Final Metric = 0.7163\n",
      "  New best metric! Saving model...\n",
      "Epoch 12: Binary F1 = 0.9454, Macro F1 = 0.4935, Final Metric = 0.7194\n",
      "  New best metric! Saving model...\n",
      "Epoch 13: Binary F1 = 0.9393, Macro F1 = 0.4557, Final Metric = 0.6975\n",
      "Epoch 14: Binary F1 = 0.9149, Macro F1 = 0.4992, Final Metric = 0.7071\n",
      "Epoch 15: Binary F1 = 0.9472, Macro F1 = 0.4679, Final Metric = 0.7075\n",
      "Epoch 16: Binary F1 = 0.9454, Macro F1 = 0.4730, Final Metric = 0.7092\n",
      "Epoch 17: Binary F1 = 0.9459, Macro F1 = 0.4591, Final Metric = 0.7025\n",
      "Epoch 18: Binary F1 = 0.9544, Macro F1 = 0.5551, Final Metric = 0.7547\n",
      "  New best metric! Saving model...\n",
      "Epoch 19: Binary F1 = 0.9552, Macro F1 = 0.5714, Final Metric = 0.7633\n",
      "  New best metric! Saving model...\n",
      "Epoch 20: Binary F1 = 0.9562, Macro F1 = 0.5722, Final Metric = 0.7642\n",
      "  New best metric! Saving model...\n",
      "Epoch 21: Binary F1 = 0.9580, Macro F1 = 0.5422, Final Metric = 0.7501\n",
      "Epoch 22: Binary F1 = 0.9540, Macro F1 = 0.5236, Final Metric = 0.7388\n",
      "Epoch 23: Binary F1 = 0.9486, Macro F1 = 0.5866, Final Metric = 0.7676\n",
      "  New best metric! Saving model...\n",
      "Epoch 24: Binary F1 = 0.9502, Macro F1 = 0.5772, Final Metric = 0.7637\n",
      "Epoch 25: Binary F1 = 0.9587, Macro F1 = 0.5654, Final Metric = 0.7620\n",
      "Epoch 26: Binary F1 = 0.9603, Macro F1 = 0.5783, Final Metric = 0.7693\n",
      "  New best metric! Saving model...\n",
      "Epoch 27: Binary F1 = 0.9593, Macro F1 = 0.5737, Final Metric = 0.7665\n",
      "Epoch 28: Binary F1 = 0.9532, Macro F1 = 0.5583, Final Metric = 0.7557\n",
      "Epoch 29: Binary F1 = 0.9594, Macro F1 = 0.5760, Final Metric = 0.7677\n",
      "Epoch 30: Binary F1 = 0.9602, Macro F1 = 0.5622, Final Metric = 0.7612\n",
      "Epoch 31: Binary F1 = 0.9530, Macro F1 = 0.5682, Final Metric = 0.7606\n",
      "Epoch 32: Binary F1 = 0.9646, Macro F1 = 0.5616, Final Metric = 0.7631\n",
      "Epoch 33: Binary F1 = 0.9596, Macro F1 = 0.5624, Final Metric = 0.7610\n",
      "Epoch 34: Binary F1 = 0.9594, Macro F1 = 0.5697, Final Metric = 0.7646\n",
      "Early stopping triggered at epoch 34\n",
      "Best validation metrics - Binary F1: 0.9603, Macro F1: 0.5783, Final: 0.7693\n",
      "Final validation metrics - Binary F1: 0.9594, Macro F1: 0.5697, Final: 0.7646\n",
      "\n",
      "==================================================\n",
      "training: 3\n",
      "Fold 3/10\n",
      "Epoch 01: Binary F1 = 0.6088, Macro F1 = 0.1679, Final Metric = 0.3884\n",
      "  New best metric! Saving model...\n",
      "Epoch 02: Binary F1 = 0.8923, Macro F1 = 0.2946, Final Metric = 0.5935\n",
      "  New best metric! Saving model...\n",
      "Epoch 03: Binary F1 = 0.9506, Macro F1 = 0.4359, Final Metric = 0.6932\n",
      "  New best metric! Saving model...\n",
      "Epoch 04: Binary F1 = 0.9429, Macro F1 = 0.4479, Final Metric = 0.6954\n",
      "  New best metric! Saving model...\n",
      "Epoch 05: Binary F1 = 0.9372, Macro F1 = 0.4243, Final Metric = 0.6807\n",
      "Epoch 06: Binary F1 = 0.9431, Macro F1 = 0.4095, Final Metric = 0.6763\n",
      "Epoch 07: Binary F1 = 0.9505, Macro F1 = 0.4840, Final Metric = 0.7172\n",
      "  New best metric! Saving model...\n",
      "Epoch 08: Binary F1 = 0.9131, Macro F1 = 0.4331, Final Metric = 0.6731\n",
      "Epoch 09: Binary F1 = 0.9152, Macro F1 = 0.4895, Final Metric = 0.7023\n",
      "Epoch 10: Binary F1 = 0.9448, Macro F1 = 0.5141, Final Metric = 0.7295\n",
      "  New best metric! Saving model...\n",
      "Epoch 11: Binary F1 = 0.9218, Macro F1 = 0.4846, Final Metric = 0.7032\n",
      "Epoch 12: Binary F1 = 0.9309, Macro F1 = 0.5307, Final Metric = 0.7308\n",
      "  New best metric! Saving model...\n",
      "Epoch 13: Binary F1 = 0.9486, Macro F1 = 0.5162, Final Metric = 0.7324\n",
      "  New best metric! Saving model...\n",
      "Epoch 14: Binary F1 = 0.9184, Macro F1 = 0.4901, Final Metric = 0.7043\n",
      "Epoch 15: Binary F1 = 0.9531, Macro F1 = 0.4955, Final Metric = 0.7243\n",
      "Epoch 16: Binary F1 = 0.9595, Macro F1 = 0.5223, Final Metric = 0.7409\n",
      "  New best metric! Saving model...\n",
      "Epoch 17: Binary F1 = 0.9686, Macro F1 = 0.5788, Final Metric = 0.7737\n",
      "  New best metric! Saving model...\n",
      "Epoch 18: Binary F1 = 0.9619, Macro F1 = 0.5502, Final Metric = 0.7561\n",
      "Epoch 19: Binary F1 = 0.9600, Macro F1 = 0.5938, Final Metric = 0.7769\n",
      "  New best metric! Saving model...\n",
      "Epoch 20: Binary F1 = 0.9683, Macro F1 = 0.5959, Final Metric = 0.7821\n",
      "  New best metric! Saving model...\n",
      "Epoch 21: Binary F1 = 0.9701, Macro F1 = 0.5714, Final Metric = 0.7707\n",
      "Epoch 22: Binary F1 = 0.9622, Macro F1 = 0.6035, Final Metric = 0.7828\n",
      "  New best metric! Saving model...\n",
      "Epoch 23: Binary F1 = 0.9622, Macro F1 = 0.5830, Final Metric = 0.7726\n",
      "Epoch 24: Binary F1 = 0.9724, Macro F1 = 0.5868, Final Metric = 0.7796\n",
      "Epoch 25: Binary F1 = 0.9579, Macro F1 = 0.5951, Final Metric = 0.7765\n",
      "Epoch 26: Binary F1 = 0.9723, Macro F1 = 0.6055, Final Metric = 0.7889\n",
      "  New best metric! Saving model...\n",
      "Epoch 27: Binary F1 = 0.9713, Macro F1 = 0.5989, Final Metric = 0.7851\n",
      "Epoch 28: Binary F1 = 0.9713, Macro F1 = 0.6106, Final Metric = 0.7909\n",
      "  New best metric! Saving model...\n",
      "Epoch 29: Binary F1 = 0.9684, Macro F1 = 0.5876, Final Metric = 0.7780\n",
      "Epoch 30: Binary F1 = 0.9713, Macro F1 = 0.5825, Final Metric = 0.7769\n",
      "Epoch 31: Binary F1 = 0.9663, Macro F1 = 0.5932, Final Metric = 0.7798\n",
      "Epoch 32: Binary F1 = 0.9736, Macro F1 = 0.5912, Final Metric = 0.7824\n",
      "Epoch 33: Binary F1 = 0.9702, Macro F1 = 0.6097, Final Metric = 0.7900\n",
      "Epoch 34: Binary F1 = 0.9712, Macro F1 = 0.5977, Final Metric = 0.7844\n",
      "Epoch 35: Binary F1 = 0.9744, Macro F1 = 0.5937, Final Metric = 0.7840\n",
      "Best validation metrics - Binary F1: 0.9713, Macro F1: 0.6106, Final: 0.7909\n",
      "Final validation metrics - Binary F1: 0.9744, Macro F1: 0.5937, Final: 0.7840\n",
      "\n",
      "==================================================\n",
      "training: 4\n",
      "Fold 4/10\n",
      "Epoch 01: Binary F1 = 0.7500, Macro F1 = 0.1846, Final Metric = 0.4673\n",
      "  New best metric! Saving model...\n",
      "Epoch 02: Binary F1 = 0.8519, Macro F1 = 0.2681, Final Metric = 0.5600\n",
      "  New best metric! Saving model...\n",
      "Epoch 03: Binary F1 = 0.8933, Macro F1 = 0.3294, Final Metric = 0.6114\n",
      "  New best metric! Saving model...\n",
      "Epoch 04: Binary F1 = 0.9431, Macro F1 = 0.3707, Final Metric = 0.6569\n",
      "  New best metric! Saving model...\n",
      "Epoch 05: Binary F1 = 0.9437, Macro F1 = 0.3956, Final Metric = 0.6696\n",
      "  New best metric! Saving model...\n",
      "Epoch 06: Binary F1 = 0.9507, Macro F1 = 0.4678, Final Metric = 0.7093\n",
      "  New best metric! Saving model...\n",
      "Epoch 07: Binary F1 = 0.9468, Macro F1 = 0.4148, Final Metric = 0.6808\n",
      "Epoch 08: Binary F1 = 0.9646, Macro F1 = 0.4277, Final Metric = 0.6961\n",
      "Epoch 09: Binary F1 = 0.9435, Macro F1 = 0.4800, Final Metric = 0.7118\n",
      "  New best metric! Saving model...\n",
      "Epoch 10: Binary F1 = 0.9489, Macro F1 = 0.3826, Final Metric = 0.6657\n",
      "Epoch 11: Binary F1 = 0.9588, Macro F1 = 0.4603, Final Metric = 0.7096\n",
      "Epoch 12: Binary F1 = 0.8761, Macro F1 = 0.4827, Final Metric = 0.6794\n",
      "Epoch 13: Binary F1 = 0.9554, Macro F1 = 0.4797, Final Metric = 0.7175\n",
      "  New best metric! Saving model...\n",
      "Epoch 14: Binary F1 = 0.9511, Macro F1 = 0.4968, Final Metric = 0.7239\n",
      "  New best metric! Saving model...\n",
      "Epoch 15: Binary F1 = 0.9615, Macro F1 = 0.5040, Final Metric = 0.7328\n",
      "  New best metric! Saving model...\n",
      "Epoch 16: Binary F1 = 0.9526, Macro F1 = 0.4805, Final Metric = 0.7165\n",
      "Epoch 17: Binary F1 = 0.9685, Macro F1 = 0.5309, Final Metric = 0.7497\n",
      "  New best metric! Saving model...\n",
      "Epoch 18: Binary F1 = 0.9765, Macro F1 = 0.5774, Final Metric = 0.7770\n",
      "  New best metric! Saving model...\n",
      "Epoch 19: Binary F1 = 0.9794, Macro F1 = 0.5863, Final Metric = 0.7829\n",
      "  New best metric! Saving model...\n",
      "Epoch 20: Binary F1 = 0.9796, Macro F1 = 0.6018, Final Metric = 0.7907\n",
      "  New best metric! Saving model...\n",
      "Epoch 21: Binary F1 = 0.9815, Macro F1 = 0.5708, Final Metric = 0.7762\n",
      "Epoch 22: Binary F1 = 0.9786, Macro F1 = 0.5776, Final Metric = 0.7781\n",
      "Epoch 23: Binary F1 = 0.9748, Macro F1 = 0.5941, Final Metric = 0.7844\n",
      "Epoch 24: Binary F1 = 0.9785, Macro F1 = 0.5902, Final Metric = 0.7844\n",
      "Epoch 25: Binary F1 = 0.9747, Macro F1 = 0.6131, Final Metric = 0.7939\n",
      "  New best metric! Saving model...\n",
      "Epoch 26: Binary F1 = 0.9746, Macro F1 = 0.6053, Final Metric = 0.7900\n",
      "Epoch 27: Binary F1 = 0.9756, Macro F1 = 0.6172, Final Metric = 0.7964\n",
      "  New best metric! Saving model...\n",
      "Epoch 28: Binary F1 = 0.9754, Macro F1 = 0.6039, Final Metric = 0.7896\n",
      "Epoch 29: Binary F1 = 0.9785, Macro F1 = 0.6274, Final Metric = 0.8030\n",
      "  New best metric! Saving model...\n",
      "Epoch 30: Binary F1 = 0.9767, Macro F1 = 0.6063, Final Metric = 0.7915\n",
      "Epoch 31: Binary F1 = 0.9738, Macro F1 = 0.6245, Final Metric = 0.7991\n",
      "Epoch 32: Binary F1 = 0.9784, Macro F1 = 0.6206, Final Metric = 0.7995\n",
      "Epoch 33: Binary F1 = 0.9755, Macro F1 = 0.6216, Final Metric = 0.7985\n",
      "Epoch 34: Binary F1 = 0.9784, Macro F1 = 0.6167, Final Metric = 0.7976\n",
      "Epoch 35: Binary F1 = 0.9766, Macro F1 = 0.6245, Final Metric = 0.8005\n",
      "Best validation metrics - Binary F1: 0.9785, Macro F1: 0.6274, Final: 0.8030\n",
      "Final validation metrics - Binary F1: 0.9766, Macro F1: 0.6245, Final: 0.8005\n",
      "\n",
      "==================================================\n",
      "training: 5\n",
      "Fold 5/10\n",
      "Epoch 01: Binary F1 = 0.8395, Macro F1 = 0.2018, Final Metric = 0.5206\n",
      "  New best metric! Saving model...\n",
      "Epoch 02: Binary F1 = 0.9048, Macro F1 = 0.3066, Final Metric = 0.6057\n",
      "  New best metric! Saving model...\n",
      "Epoch 03: Binary F1 = 0.9241, Macro F1 = 0.3708, Final Metric = 0.6474\n",
      "  New best metric! Saving model...\n",
      "Epoch 04: Binary F1 = 0.9239, Macro F1 = 0.4164, Final Metric = 0.6701\n",
      "  New best metric! Saving model...\n",
      "Epoch 05: Binary F1 = 0.9496, Macro F1 = 0.4710, Final Metric = 0.7103\n",
      "  New best metric! Saving model...\n",
      "Epoch 06: Binary F1 = 0.9592, Macro F1 = 0.4668, Final Metric = 0.7130\n",
      "  New best metric! Saving model...\n",
      "Epoch 07: Binary F1 = 0.9604, Macro F1 = 0.4701, Final Metric = 0.7152\n",
      "  New best metric! Saving model...\n",
      "Epoch 08: Binary F1 = 0.9655, Macro F1 = 0.5215, Final Metric = 0.7435\n",
      "  New best metric! Saving model...\n",
      "Epoch 09: Binary F1 = 0.9624, Macro F1 = 0.5118, Final Metric = 0.7371\n",
      "Epoch 10: Binary F1 = 0.9468, Macro F1 = 0.4947, Final Metric = 0.7208\n",
      "Epoch 11: Binary F1 = 0.9506, Macro F1 = 0.4269, Final Metric = 0.6887\n",
      "Epoch 12: Binary F1 = 0.9248, Macro F1 = 0.5402, Final Metric = 0.7325\n",
      "Epoch 13: Binary F1 = 0.9616, Macro F1 = 0.5705, Final Metric = 0.7661\n",
      "  New best metric! Saving model...\n",
      "Epoch 14: Binary F1 = 0.9594, Macro F1 = 0.5217, Final Metric = 0.7405\n",
      "Epoch 15: Binary F1 = 0.9486, Macro F1 = 0.4962, Final Metric = 0.7224\n",
      "Epoch 16: Binary F1 = 0.9602, Macro F1 = 0.5295, Final Metric = 0.7448\n",
      "Epoch 17: Binary F1 = 0.9699, Macro F1 = 0.5801, Final Metric = 0.7750\n",
      "  New best metric! Saving model...\n",
      "Epoch 18: Binary F1 = 0.9653, Macro F1 = 0.5914, Final Metric = 0.7784\n",
      "  New best metric! Saving model...\n",
      "Epoch 19: Binary F1 = 0.9688, Macro F1 = 0.6199, Final Metric = 0.7944\n",
      "  New best metric! Saving model...\n",
      "Epoch 20: Binary F1 = 0.9767, Macro F1 = 0.6276, Final Metric = 0.8022\n",
      "  New best metric! Saving model...\n",
      "Epoch 21: Binary F1 = 0.9700, Macro F1 = 0.6085, Final Metric = 0.7893\n",
      "Epoch 22: Binary F1 = 0.9728, Macro F1 = 0.6202, Final Metric = 0.7965\n",
      "Epoch 23: Binary F1 = 0.9719, Macro F1 = 0.5984, Final Metric = 0.7852\n",
      "Epoch 24: Binary F1 = 0.9691, Macro F1 = 0.6006, Final Metric = 0.7848\n",
      "Epoch 25: Binary F1 = 0.9709, Macro F1 = 0.6206, Final Metric = 0.7957\n",
      "Epoch 26: Binary F1 = 0.9660, Macro F1 = 0.6259, Final Metric = 0.7959\n",
      "Epoch 27: Binary F1 = 0.9717, Macro F1 = 0.6183, Final Metric = 0.7950\n",
      "Epoch 28: Binary F1 = 0.9727, Macro F1 = 0.6111, Final Metric = 0.7919\n",
      "Early stopping triggered at epoch 28\n",
      "Best validation metrics - Binary F1: 0.9767, Macro F1: 0.6276, Final: 0.8022\n",
      "Final validation metrics - Binary F1: 0.9727, Macro F1: 0.6111, Final: 0.7919\n",
      "\n",
      "==================================================\n",
      "training: 6\n",
      "Fold 6/10\n",
      "Epoch 01: Binary F1 = 0.5536, Macro F1 = 0.1186, Final Metric = 0.3361\n",
      "  New best metric! Saving model...\n",
      "Epoch 02: Binary F1 = 0.9181, Macro F1 = 0.2813, Final Metric = 0.5997\n",
      "  New best metric! Saving model...\n",
      "Epoch 03: Binary F1 = 0.9411, Macro F1 = 0.3584, Final Metric = 0.6497\n",
      "  New best metric! Saving model...\n",
      "Epoch 04: Binary F1 = 0.9433, Macro F1 = 0.4339, Final Metric = 0.6886\n",
      "  New best metric! Saving model...\n",
      "Epoch 05: Binary F1 = 0.9466, Macro F1 = 0.4034, Final Metric = 0.6750\n",
      "Epoch 06: Binary F1 = 0.9624, Macro F1 = 0.4884, Final Metric = 0.7254\n",
      "  New best metric! Saving model...\n",
      "Epoch 07: Binary F1 = 0.9591, Macro F1 = 0.4540, Final Metric = 0.7066\n",
      "Epoch 08: Binary F1 = 0.8971, Macro F1 = 0.4188, Final Metric = 0.6579\n",
      "Epoch 09: Binary F1 = 0.9653, Macro F1 = 0.4914, Final Metric = 0.7283\n",
      "  New best metric! Saving model...\n",
      "Epoch 10: Binary F1 = 0.9613, Macro F1 = 0.5090, Final Metric = 0.7351\n",
      "  New best metric! Saving model...\n",
      "Epoch 11: Binary F1 = 0.9642, Macro F1 = 0.4846, Final Metric = 0.7244\n",
      "Epoch 12: Binary F1 = 0.9626, Macro F1 = 0.4893, Final Metric = 0.7260\n",
      "Epoch 13: Binary F1 = 0.9704, Macro F1 = 0.4855, Final Metric = 0.7280\n",
      "Epoch 14: Binary F1 = 0.9627, Macro F1 = 0.4767, Final Metric = 0.7197\n",
      "Epoch 15: Binary F1 = 0.9744, Macro F1 = 0.4901, Final Metric = 0.7322\n",
      "Epoch 16: Binary F1 = 0.9661, Macro F1 = 0.5236, Final Metric = 0.7448\n",
      "  New best metric! Saving model...\n",
      "Epoch 17: Binary F1 = 0.9531, Macro F1 = 0.5073, Final Metric = 0.7302\n",
      "Epoch 18: Binary F1 = 0.9863, Macro F1 = 0.5881, Final Metric = 0.7872\n",
      "  New best metric! Saving model...\n",
      "Epoch 19: Binary F1 = 0.9844, Macro F1 = 0.6203, Final Metric = 0.8023\n",
      "  New best metric! Saving model...\n",
      "Epoch 20: Binary F1 = 0.9844, Macro F1 = 0.6187, Final Metric = 0.8016\n",
      "Epoch 21: Binary F1 = 0.9844, Macro F1 = 0.6167, Final Metric = 0.8006\n",
      "Epoch 22: Binary F1 = 0.9844, Macro F1 = 0.6029, Final Metric = 0.7937\n",
      "Epoch 23: Binary F1 = 0.9853, Macro F1 = 0.6272, Final Metric = 0.8062\n",
      "  New best metric! Saving model...\n",
      "Epoch 24: Binary F1 = 0.9873, Macro F1 = 0.6075, Final Metric = 0.7974\n",
      "Epoch 25: Binary F1 = 0.9854, Macro F1 = 0.6103, Final Metric = 0.7978\n",
      "Epoch 26: Binary F1 = 0.9863, Macro F1 = 0.6216, Final Metric = 0.8039\n",
      "Epoch 27: Binary F1 = 0.9892, Macro F1 = 0.6243, Final Metric = 0.8068\n",
      "  New best metric! Saving model...\n",
      "Epoch 28: Binary F1 = 0.9873, Macro F1 = 0.6211, Final Metric = 0.8042\n",
      "Epoch 29: Binary F1 = 0.9893, Macro F1 = 0.6304, Final Metric = 0.8099\n",
      "  New best metric! Saving model...\n",
      "Epoch 30: Binary F1 = 0.9854, Macro F1 = 0.6162, Final Metric = 0.8008\n",
      "Epoch 31: Binary F1 = 0.9873, Macro F1 = 0.6336, Final Metric = 0.8105\n",
      "  New best metric! Saving model...\n",
      "Epoch 32: Binary F1 = 0.9873, Macro F1 = 0.6291, Final Metric = 0.8082\n",
      "Epoch 33: Binary F1 = 0.9893, Macro F1 = 0.6193, Final Metric = 0.8043\n",
      "Epoch 34: Binary F1 = 0.9893, Macro F1 = 0.6258, Final Metric = 0.8075\n",
      "Epoch 35: Binary F1 = 0.9883, Macro F1 = 0.6142, Final Metric = 0.8013\n",
      "Best validation metrics - Binary F1: 0.9873, Macro F1: 0.6336, Final: 0.8105\n",
      "Final validation metrics - Binary F1: 0.9883, Macro F1: 0.6142, Final: 0.8013\n",
      "\n",
      "==================================================\n",
      "training: 7\n",
      "Fold 7/10\n",
      "Epoch 01: Binary F1 = 0.8310, Macro F1 = 0.1985, Final Metric = 0.5147\n",
      "  New best metric! Saving model...\n",
      "Epoch 02: Binary F1 = 0.9144, Macro F1 = 0.3080, Final Metric = 0.6112\n",
      "  New best metric! Saving model...\n",
      "Epoch 03: Binary F1 = 0.9628, Macro F1 = 0.4147, Final Metric = 0.6888\n",
      "  New best metric! Saving model...\n",
      "Epoch 04: Binary F1 = 0.9508, Macro F1 = 0.4509, Final Metric = 0.7008\n",
      "  New best metric! Saving model...\n",
      "Epoch 05: Binary F1 = 0.9789, Macro F1 = 0.4718, Final Metric = 0.7253\n",
      "  New best metric! Saving model...\n",
      "Epoch 06: Binary F1 = 0.9528, Macro F1 = 0.4587, Final Metric = 0.7057\n",
      "Epoch 07: Binary F1 = 0.9605, Macro F1 = 0.4440, Final Metric = 0.7022\n",
      "Epoch 08: Binary F1 = 0.9806, Macro F1 = 0.5151, Final Metric = 0.7479\n",
      "  New best metric! Saving model...\n",
      "Epoch 09: Binary F1 = 0.9702, Macro F1 = 0.4996, Final Metric = 0.7349\n",
      "Epoch 10: Binary F1 = 0.9614, Macro F1 = 0.5201, Final Metric = 0.7407\n",
      "Epoch 11: Binary F1 = 0.9687, Macro F1 = 0.5406, Final Metric = 0.7546\n",
      "  New best metric! Saving model...\n",
      "Epoch 12: Binary F1 = 0.9893, Macro F1 = 0.5391, Final Metric = 0.7642\n",
      "  New best metric! Saving model...\n",
      "Epoch 13: Binary F1 = 0.9717, Macro F1 = 0.5499, Final Metric = 0.7608\n",
      "Epoch 14: Binary F1 = 0.9746, Macro F1 = 0.5020, Final Metric = 0.7383\n",
      "Epoch 15: Binary F1 = 0.9615, Macro F1 = 0.5582, Final Metric = 0.7599\n",
      "Epoch 16: Binary F1 = 0.9912, Macro F1 = 0.5532, Final Metric = 0.7722\n",
      "  New best metric! Saving model...\n",
      "Epoch 17: Binary F1 = 0.9822, Macro F1 = 0.5992, Final Metric = 0.7907\n",
      "  New best metric! Saving model...\n",
      "Epoch 18: Binary F1 = 0.9893, Macro F1 = 0.6070, Final Metric = 0.7981\n",
      "  New best metric! Saving model...\n",
      "Epoch 19: Binary F1 = 0.9903, Macro F1 = 0.6358, Final Metric = 0.8130\n",
      "  New best metric! Saving model...\n",
      "Epoch 20: Binary F1 = 0.9903, Macro F1 = 0.6308, Final Metric = 0.8105\n",
      "Epoch 21: Binary F1 = 0.9903, Macro F1 = 0.6438, Final Metric = 0.8171\n",
      "  New best metric! Saving model...\n",
      "Epoch 22: Binary F1 = 0.9874, Macro F1 = 0.6071, Final Metric = 0.7972\n",
      "Epoch 23: Binary F1 = 0.9884, Macro F1 = 0.6193, Final Metric = 0.8039\n",
      "Epoch 24: Binary F1 = 0.9932, Macro F1 = 0.6359, Final Metric = 0.8146\n",
      "Epoch 25: Binary F1 = 0.9894, Macro F1 = 0.5989, Final Metric = 0.7941\n",
      "Epoch 26: Binary F1 = 0.9912, Macro F1 = 0.6275, Final Metric = 0.8093\n",
      "Epoch 27: Binary F1 = 0.9884, Macro F1 = 0.6201, Final Metric = 0.8042\n",
      "Epoch 28: Binary F1 = 0.9922, Macro F1 = 0.6329, Final Metric = 0.8126\n",
      "Epoch 29: Binary F1 = 0.9893, Macro F1 = 0.6226, Final Metric = 0.8059\n",
      "Early stopping triggered at epoch 29\n",
      "Best validation metrics - Binary F1: 0.9903, Macro F1: 0.6438, Final: 0.8171\n",
      "Final validation metrics - Binary F1: 0.9893, Macro F1: 0.6226, Final: 0.8059\n",
      "\n",
      "==================================================\n",
      "training: 8\n",
      "Fold 8/10\n",
      "Epoch 01: Binary F1 = 0.5959, Macro F1 = 0.1559, Final Metric = 0.3759\n",
      "  New best metric! Saving model...\n",
      "Epoch 02: Binary F1 = 0.9020, Macro F1 = 0.2982, Final Metric = 0.6001\n",
      "  New best metric! Saving model...\n",
      "Epoch 03: Binary F1 = 0.9391, Macro F1 = 0.3464, Final Metric = 0.6428\n",
      "  New best metric! Saving model...\n",
      "Epoch 04: Binary F1 = 0.9008, Macro F1 = 0.3160, Final Metric = 0.6084\n",
      "Epoch 05: Binary F1 = 0.9576, Macro F1 = 0.4388, Final Metric = 0.6982\n",
      "  New best metric! Saving model...\n",
      "Epoch 06: Binary F1 = 0.9348, Macro F1 = 0.4453, Final Metric = 0.6900\n",
      "Epoch 07: Binary F1 = 0.9554, Macro F1 = 0.4773, Final Metric = 0.7164\n",
      "  New best metric! Saving model...\n",
      "Epoch 08: Binary F1 = 0.9510, Macro F1 = 0.3551, Final Metric = 0.6531\n",
      "Epoch 09: Binary F1 = 0.9499, Macro F1 = 0.4833, Final Metric = 0.7166\n",
      "  New best metric! Saving model...\n",
      "Epoch 10: Binary F1 = 0.9606, Macro F1 = 0.4391, Final Metric = 0.6999\n",
      "Epoch 11: Binary F1 = 0.9538, Macro F1 = 0.5007, Final Metric = 0.7273\n",
      "  New best metric! Saving model...\n",
      "Epoch 12: Binary F1 = 0.9670, Macro F1 = 0.5019, Final Metric = 0.7344\n",
      "  New best metric! Saving model...\n",
      "Epoch 13: Binary F1 = 0.9627, Macro F1 = 0.4861, Final Metric = 0.7244\n",
      "Epoch 14: Binary F1 = 0.9567, Macro F1 = 0.5133, Final Metric = 0.7350\n",
      "  New best metric! Saving model...\n",
      "Epoch 15: Binary F1 = 0.9669, Macro F1 = 0.5259, Final Metric = 0.7464\n",
      "  New best metric! Saving model...\n",
      "Epoch 16: Binary F1 = 0.9457, Macro F1 = 0.5514, Final Metric = 0.7485\n",
      "  New best metric! Saving model...\n",
      "Epoch 17: Binary F1 = 0.9692, Macro F1 = 0.5566, Final Metric = 0.7629\n",
      "  New best metric! Saving model...\n",
      "Epoch 18: Binary F1 = 0.9617, Macro F1 = 0.5880, Final Metric = 0.7749\n",
      "  New best metric! Saving model...\n",
      "Epoch 19: Binary F1 = 0.9754, Macro F1 = 0.6382, Final Metric = 0.8068\n",
      "  New best metric! Saving model...\n",
      "Epoch 20: Binary F1 = 0.9754, Macro F1 = 0.6330, Final Metric = 0.8042\n",
      "Epoch 21: Binary F1 = 0.9684, Macro F1 = 0.5935, Final Metric = 0.7810\n",
      "Epoch 22: Binary F1 = 0.9771, Macro F1 = 0.6299, Final Metric = 0.8035\n",
      "Epoch 23: Binary F1 = 0.9744, Macro F1 = 0.6119, Final Metric = 0.7932\n",
      "Epoch 24: Binary F1 = 0.9607, Macro F1 = 0.6271, Final Metric = 0.7939\n",
      "Epoch 25: Binary F1 = 0.9746, Macro F1 = 0.6246, Final Metric = 0.7996\n",
      "Epoch 26: Binary F1 = 0.9725, Macro F1 = 0.6392, Final Metric = 0.8059\n",
      "Epoch 27: Binary F1 = 0.9709, Macro F1 = 0.6471, Final Metric = 0.8090\n",
      "  New best metric! Saving model...\n",
      "Epoch 28: Binary F1 = 0.9753, Macro F1 = 0.6430, Final Metric = 0.8091\n",
      "  New best metric! Saving model...\n",
      "Epoch 29: Binary F1 = 0.9700, Macro F1 = 0.6466, Final Metric = 0.8083\n",
      "Epoch 30: Binary F1 = 0.9727, Macro F1 = 0.6521, Final Metric = 0.8124\n",
      "  New best metric! Saving model...\n",
      "Epoch 31: Binary F1 = 0.9708, Macro F1 = 0.6289, Final Metric = 0.7999\n",
      "Epoch 32: Binary F1 = 0.9718, Macro F1 = 0.6465, Final Metric = 0.8092\n",
      "Epoch 33: Binary F1 = 0.9718, Macro F1 = 0.6397, Final Metric = 0.8058\n",
      "Epoch 34: Binary F1 = 0.9708, Macro F1 = 0.6393, Final Metric = 0.8051\n",
      "Epoch 35: Binary F1 = 0.9718, Macro F1 = 0.6539, Final Metric = 0.8129\n",
      "  New best metric! Saving model...\n",
      "Best validation metrics - Binary F1: 0.9718, Macro F1: 0.6539, Final: 0.8129\n",
      "Final validation metrics - Binary F1: 0.9718, Macro F1: 0.6539, Final: 0.8129\n",
      "\n",
      "==================================================\n",
      "training: 9\n",
      "Fold 9/10\n",
      "Epoch 01: Binary F1 = 0.7885, Macro F1 = 0.1951, Final Metric = 0.4918\n",
      "  New best metric! Saving model...\n",
      "Epoch 02: Binary F1 = 0.9526, Macro F1 = 0.3806, Final Metric = 0.6666\n",
      "  New best metric! Saving model...\n",
      "Epoch 03: Binary F1 = 0.9617, Macro F1 = 0.4460, Final Metric = 0.7039\n",
      "  New best metric! Saving model...\n",
      "Epoch 04: Binary F1 = 0.9511, Macro F1 = 0.4574, Final Metric = 0.7043\n",
      "  New best metric! Saving model...\n",
      "Epoch 05: Binary F1 = 0.9556, Macro F1 = 0.4672, Final Metric = 0.7114\n",
      "  New best metric! Saving model...\n",
      "Epoch 06: Binary F1 = 0.9679, Macro F1 = 0.5287, Final Metric = 0.7483\n",
      "  New best metric! Saving model...\n",
      "Epoch 07: Binary F1 = 0.8985, Macro F1 = 0.4899, Final Metric = 0.6942\n",
      "Epoch 08: Binary F1 = 0.9665, Macro F1 = 0.4898, Final Metric = 0.7281\n",
      "Epoch 09: Binary F1 = 0.9670, Macro F1 = 0.5424, Final Metric = 0.7547\n",
      "  New best metric! Saving model...\n",
      "Epoch 10: Binary F1 = 0.9737, Macro F1 = 0.5499, Final Metric = 0.7618\n",
      "  New best metric! Saving model...\n",
      "Epoch 11: Binary F1 = 0.9791, Macro F1 = 0.5692, Final Metric = 0.7742\n",
      "  New best metric! Saving model...\n",
      "Epoch 12: Binary F1 = 0.9660, Macro F1 = 0.5334, Final Metric = 0.7497\n",
      "Epoch 13: Binary F1 = 0.9833, Macro F1 = 0.5262, Final Metric = 0.7548\n",
      "Epoch 14: Binary F1 = 0.9845, Macro F1 = 0.5632, Final Metric = 0.7738\n",
      "Epoch 15: Binary F1 = 0.9693, Macro F1 = 0.5386, Final Metric = 0.7539\n",
      "Epoch 16: Binary F1 = 0.9746, Macro F1 = 0.5155, Final Metric = 0.7450\n",
      "Epoch 17: Binary F1 = 0.9885, Macro F1 = 0.6470, Final Metric = 0.8178\n",
      "  New best metric! Saving model...\n",
      "Epoch 18: Binary F1 = 0.9832, Macro F1 = 0.6099, Final Metric = 0.7965\n",
      "Epoch 19: Binary F1 = 0.9896, Macro F1 = 0.6532, Final Metric = 0.8214\n",
      "  New best metric! Saving model...\n",
      "Epoch 20: Binary F1 = 0.9885, Macro F1 = 0.6620, Final Metric = 0.8252\n",
      "  New best metric! Saving model...\n",
      "Epoch 21: Binary F1 = 0.9906, Macro F1 = 0.6557, Final Metric = 0.8232\n",
      "Epoch 22: Binary F1 = 0.9866, Macro F1 = 0.6441, Final Metric = 0.8153\n",
      "Epoch 23: Binary F1 = 0.9916, Macro F1 = 0.6380, Final Metric = 0.8148\n",
      "Epoch 24: Binary F1 = 0.9917, Macro F1 = 0.6550, Final Metric = 0.8234\n",
      "Epoch 25: Binary F1 = 0.9917, Macro F1 = 0.6543, Final Metric = 0.8230\n",
      "Epoch 26: Binary F1 = 0.9906, Macro F1 = 0.6666, Final Metric = 0.8286\n",
      "  New best metric! Saving model...\n",
      "Epoch 27: Binary F1 = 0.9916, Macro F1 = 0.6570, Final Metric = 0.8243\n",
      "Epoch 28: Binary F1 = 0.9937, Macro F1 = 0.6503, Final Metric = 0.8220\n",
      "Epoch 29: Binary F1 = 0.9896, Macro F1 = 0.6614, Final Metric = 0.8255\n",
      "Epoch 30: Binary F1 = 0.9885, Macro F1 = 0.6672, Final Metric = 0.8278\n",
      "Epoch 31: Binary F1 = 0.9875, Macro F1 = 0.6605, Final Metric = 0.8240\n",
      "Epoch 32: Binary F1 = 0.9885, Macro F1 = 0.6579, Final Metric = 0.8232\n",
      "Epoch 33: Binary F1 = 0.9896, Macro F1 = 0.6594, Final Metric = 0.8245\n",
      "Epoch 34: Binary F1 = 0.9896, Macro F1 = 0.6718, Final Metric = 0.8307\n",
      "  New best metric! Saving model...\n",
      "Epoch 35: Binary F1 = 0.9874, Macro F1 = 0.6764, Final Metric = 0.8319\n",
      "  New best metric! Saving model...\n",
      "Best validation metrics - Binary F1: 0.9874, Macro F1: 0.6764, Final: 0.8319\n",
      "Final validation metrics - Binary F1: 0.9874, Macro F1: 0.6764, Final: 0.8319\n",
      "\n",
      "==================================================\n",
      "training: 10\n",
      "Fold 10/10\n",
      "Epoch 01: Binary F1 = 0.7962, Macro F1 = 0.2236, Final Metric = 0.5099\n",
      "  New best metric! Saving model...\n",
      "Epoch 02: Binary F1 = 0.9237, Macro F1 = 0.2770, Final Metric = 0.6003\n",
      "  New best metric! Saving model...\n",
      "Epoch 03: Binary F1 = 0.9479, Macro F1 = 0.3903, Final Metric = 0.6691\n",
      "  New best metric! Saving model...\n",
      "Epoch 04: Binary F1 = 0.9606, Macro F1 = 0.4594, Final Metric = 0.7100\n",
      "  New best metric! Saving model...\n",
      "Epoch 05: Binary F1 = 0.9644, Macro F1 = 0.4816, Final Metric = 0.7230\n",
      "  New best metric! Saving model...\n",
      "Epoch 06: Binary F1 = 0.9742, Macro F1 = 0.4803, Final Metric = 0.7272\n",
      "  New best metric! Saving model...\n",
      "Epoch 07: Binary F1 = 0.9787, Macro F1 = 0.5107, Final Metric = 0.7447\n",
      "  New best metric! Saving model...\n",
      "Epoch 08: Binary F1 = 0.9609, Macro F1 = 0.5527, Final Metric = 0.7568\n",
      "  New best metric! Saving model...\n",
      "Epoch 09: Binary F1 = 0.9671, Macro F1 = 0.4890, Final Metric = 0.7281\n",
      "Epoch 10: Binary F1 = 0.9824, Macro F1 = 0.5380, Final Metric = 0.7602\n",
      "  New best metric! Saving model...\n",
      "Epoch 11: Binary F1 = 0.9756, Macro F1 = 0.5740, Final Metric = 0.7748\n",
      "  New best metric! Saving model...\n",
      "Epoch 12: Binary F1 = 0.9656, Macro F1 = 0.5237, Final Metric = 0.7447\n",
      "Epoch 13: Binary F1 = 0.9469, Macro F1 = 0.5863, Final Metric = 0.7666\n",
      "Epoch 14: Binary F1 = 0.9678, Macro F1 = 0.5897, Final Metric = 0.7787\n",
      "  New best metric! Saving model...\n",
      "Epoch 15: Binary F1 = 0.9745, Macro F1 = 0.5748, Final Metric = 0.7746\n",
      "Epoch 16: Binary F1 = 0.9791, Macro F1 = 0.5809, Final Metric = 0.7800\n",
      "  New best metric! Saving model...\n",
      "Epoch 17: Binary F1 = 0.9741, Macro F1 = 0.5951, Final Metric = 0.7846\n",
      "  New best metric! Saving model...\n",
      "Epoch 18: Binary F1 = 0.9902, Macro F1 = 0.6719, Final Metric = 0.8310\n",
      "  New best metric! Saving model...\n",
      "Epoch 19: Binary F1 = 0.9872, Macro F1 = 0.6721, Final Metric = 0.8296\n",
      "Epoch 20: Binary F1 = 0.9892, Macro F1 = 0.6852, Final Metric = 0.8372\n",
      "  New best metric! Saving model...\n",
      "Epoch 21: Binary F1 = 0.9842, Macro F1 = 0.6344, Final Metric = 0.8093\n",
      "Epoch 22: Binary F1 = 0.9862, Macro F1 = 0.6464, Final Metric = 0.8163\n",
      "Epoch 23: Binary F1 = 0.9853, Macro F1 = 0.6240, Final Metric = 0.8046\n",
      "Epoch 24: Binary F1 = 0.9892, Macro F1 = 0.6266, Final Metric = 0.8079\n",
      "Epoch 25: Binary F1 = 0.9842, Macro F1 = 0.6810, Final Metric = 0.8326\n",
      "Epoch 26: Binary F1 = 0.9852, Macro F1 = 0.6686, Final Metric = 0.8269\n",
      "Epoch 27: Binary F1 = 0.9872, Macro F1 = 0.6685, Final Metric = 0.8278\n",
      "Epoch 28: Binary F1 = 0.9882, Macro F1 = 0.6489, Final Metric = 0.8185\n",
      "Early stopping triggered at epoch 28\n",
      "Best validation metrics - Binary F1: 0.9892, Macro F1: 0.6852, Final: 0.8372\n",
      "Final validation metrics - Binary F1: 0.9882, Macro F1: 0.6489, Final: 0.8185\n",
      "\n",
      "==================================================\n",
      "Cross-Validation Results\n",
      "==================================================\n",
      "\n",
      "Best Fold-wise Metrics:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>binary_f1</th>\n",
       "      <th>macro_f1</th>\n",
       "      <th>final_metric</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fold</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.908382</td>\n",
       "      <td>0.426994</td>\n",
       "      <td>0.652413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.964637</td>\n",
       "      <td>0.586566</td>\n",
       "      <td>0.769302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.610592</td>\n",
       "      <td>0.790925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.981535</td>\n",
       "      <td>0.627425</td>\n",
       "      <td>0.802970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.976699</td>\n",
       "      <td>0.627614</td>\n",
       "      <td>0.802157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.989289</td>\n",
       "      <td>0.633634</td>\n",
       "      <td>0.810488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.993197</td>\n",
       "      <td>0.643848</td>\n",
       "      <td>0.817050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.977072</td>\n",
       "      <td>0.653900</td>\n",
       "      <td>0.812866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.993737</td>\n",
       "      <td>0.676444</td>\n",
       "      <td>0.831946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.990157</td>\n",
       "      <td>0.685202</td>\n",
       "      <td>0.837182</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      binary_f1  macro_f1  final_metric\n",
       "fold                                   \n",
       "0      0.908382  0.426994      0.652413\n",
       "1      0.964637  0.586566      0.769302\n",
       "2      0.974359  0.610592      0.790925\n",
       "3      0.981535  0.627425      0.802970\n",
       "4      0.976699  0.627614      0.802157\n",
       "5      0.989289  0.633634      0.810488\n",
       "6      0.993197  0.643848      0.817050\n",
       "7      0.977072  0.653900      0.812866\n",
       "8      0.993737  0.676444      0.831946\n",
       "9      0.990157  0.685202      0.837182"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Global Statistics (Best Metrics):\n",
      "Mean Best Final Metric: 0.7927 Â± 0.0530\n",
      "Mean Best Binary F1: 0.9749 Â± 0.0252\n",
      "Mean Best Macro F1: 0.6172 Â± 0.0729\n",
      "Model has not been uploaded to kaggle.\n"
     ]
    }
   ],
   "source": [
    "if not os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
    "    mean_best_cv_score, epoch_metrics, seq_meta_data_metrics = train_on_all_folds(\n",
    "        lr_scheduler_kw={\n",
    "            'warmup_epochs': 15,\n",
    "            'cycle_mult': 1.5,\n",
    "            'max_lr': 0.004921271951375079,\n",
    "            'init_cycle_epochs': 5,\n",
    "            'lr_cycle_factor': 0.3,\n",
    "            'max_to_min_div_factor': 250,\n",
    "        },\n",
    "        optimizer_kw={\n",
    "            'weight_decay': 0.0005345701899759787, \n",
    "            'beta_0': 0.8767300066532935,\n",
    "            'beta_1': 0.9935604207618539,\n",
    "        },\n",
    "        training_kw={'aux_loss_weigth': 0.30000000000000004},\n",
    "    )\n",
    "    user_input = input(\"Upload model ensemble?\").lower()\n",
    "    if user_input == \"yes\":\n",
    "        kagglehub.model_upload(\n",
    "            handle=join(\n",
    "                kagglehub.whoami()[\"username\"],\n",
    "                MODEL_NAME,\n",
    "                \"pyTorch\",\n",
    "                MODEL_VARIATION,\n",
    "            ),\n",
    "            local_model_dir=\"models\",\n",
    "            version_notes=input(\"Please provide model version notes:\")\n",
    "        )\n",
    "    elif user_input == \"no\":\n",
    "        print(\"Model has not been uploaded to kaggle.\")\n",
    "    else:\n",
    "        print(\"User input was not understood, model has not been uploaded to kaggle.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "31172e76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "accuracies              1.000000\n",
       "losses                  0.833982\n",
       "is_train                0.300473\n",
       "aux_losses              0.208857\n",
       "trues                   0.097784\n",
       "preds                   0.068453\n",
       "sex                     0.029490\n",
       "handedness              0.026766\n",
       "adult_child             0.024002\n",
       "age                     0.023508\n",
       "height_cm               0.022496\n",
       "sequence_counter        0.012870\n",
       "shoulder_to_wrist_cm    0.006829\n",
       "elbow_to_wrist_cm       0.002287\n",
       "Name: accuracies, dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    seq_meta_data_metrics\n",
    "    .corr(numeric_only=True)\n",
    "    [\"accuracies\"]\n",
    "    .abs()\n",
    "    .sort_values(ascending=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a56c7362",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_meta_data_metrics.to_parquet(\"first_seq_meta_data_metrics.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294f369b",
   "metadata": {
    "papermill": {
     "duration": 0.01147,
     "end_time": "2025-08-15T23:58:38.596242",
     "exception": false,
     "start_time": "2025-08-15T23:58:38.584772",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "417c831a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-15T23:58:38.621341Z",
     "iopub.status.busy": "2025-08-15T23:58:38.620647Z",
     "iopub.status.idle": "2025-08-15T23:58:38.626531Z",
     "shell.execute_reply": "2025-08-15T23:58:38.625826Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.019703,
     "end_time": "2025-08-15T23:58:38.627642",
     "exception": false,
     "start_time": "2025-08-15T23:58:38.607939",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(trial: optuna.trial.Trial, best_folds_scores:dict) -> float:\n",
    "    return train_on_all_folds(\n",
    "        lr_scheduler_kw={\n",
    "            \"warmup_epochs\": trial.suggest_int(\"warmup_epochs\", 12, 15),\n",
    "            \"cycle_mult\": trial.suggest_float(\"cycle_mult\", 0.9, 1.6, step=0.1),\n",
    "            \"max_lr\": trial.suggest_float(\"max_lr\", 0.005581907927062619 / 1.5, 0.005581907927062619 * 1.5, step=0.0001),\n",
    "            \"max_to_min_div_factor\": 250, #trial.suggest_float(\"max_to_min_div_factor\", 100, 300, step=25),\n",
    "            \"init_cycle_epochs\": trial.suggest_int(\"init_cycle_epochs\", 2, 10, ),\n",
    "            \"lr_cycle_factor\": trial.suggest_float(\"lr_cycle_factor\", 0.25, 0.6, step=0.05),\n",
    "        },\n",
    "        optimizer_kw={\n",
    "            \"weight_decay\": trial.suggest_float(\"weight_decay\", 5e-4, 1e-3),\n",
    "            \"beta_0\":trial.suggest_float(\"beta_0\", 0.8, 0.999),\n",
    "            \"beta_1\":trial.suggest_float(\"beta_1\", 0.99, 0.9999),\n",
    "        },\n",
    "        training_kw={\"aux_loss_weigth\": trial.suggest_float(\"aux_loss_weigth\", 0, 1, step=0.1)},\n",
    "        best_folds_scores=best_folds_scores,\n",
    "    )[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "04d79b91",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-15T23:58:38.651966Z",
     "iopub.status.busy": "2025-08-15T23:58:38.651711Z",
     "iopub.status.idle": "2025-08-16T07:59:09.834469Z",
     "shell.execute_reply": "2025-08-16T07:59:09.833544Z"
    },
    "papermill": {
     "duration": 28831.196235,
     "end_time": "2025-08-16T07:59:09.835676",
     "exception": false,
     "start_time": "2025-08-15T23:58:38.639441",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-17 16:55:10,794] A new study created in memory with name: no-name-2d53974f-ec23-4212-8646-0f473533fc8a\n",
      "/venv/CMI/lib/python3.11/site-packages/optuna/distributions.py:687: UserWarning: The distribution is specified by [0.0037212719513750794, 0.008372861890593929] and step=0.0001, but the range is not divisible by `step`. It will be replaced by [0.0037212719513750794, 0.00832127195137508].\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "training: 1\n",
      "Fold 1/10\n",
      "Epoch 01: Binary F1 = 0.7275, Macro F1 = 0.1697, Final Metric = 0.4486\n",
      "  New best metric! Saving model...\n",
      "Epoch 02: Binary F1 = 0.8480, Macro F1 = 0.2508, Final Metric = 0.5494\n",
      "  New best metric! Saving model...\n",
      "Epoch 03: Binary F1 = 0.8550, Macro F1 = 0.3253, Final Metric = 0.5902\n",
      "  New best metric! Saving model...\n",
      "Epoch 04: Binary F1 = 0.8171, Macro F1 = 0.3544, Final Metric = 0.5857\n",
      "Epoch 05: Binary F1 = 0.8958, Macro F1 = 0.3780, Final Metric = 0.6369\n",
      "  New best metric! Saving model...\n",
      "Epoch 06: Binary F1 = 0.8507, Macro F1 = 0.3595, Final Metric = 0.6051\n",
      "Epoch 07: Binary F1 = 0.9065, Macro F1 = 0.4069, Final Metric = 0.6567\n",
      "  New best metric! Saving model...\n",
      "Epoch 08: Binary F1 = 0.9028, Macro F1 = 0.3873, Final Metric = 0.6451\n",
      "Epoch 09: Binary F1 = 0.8738, Macro F1 = 0.3716, Final Metric = 0.6227\n",
      "Epoch 10: Binary F1 = 0.8746, Macro F1 = 0.3840, Final Metric = 0.6293\n",
      "Epoch 11: Binary F1 = 0.8831, Macro F1 = 0.3825, Final Metric = 0.6328\n",
      "Epoch 12: Binary F1 = 0.8728, Macro F1 = 0.4374, Final Metric = 0.6551\n",
      "Epoch 13: Binary F1 = 0.8954, Macro F1 = 0.4085, Final Metric = 0.6519\n",
      "Epoch 14: Binary F1 = 0.8884, Macro F1 = 0.4311, Final Metric = 0.6598\n",
      "  New best metric! Saving model...\n",
      "Epoch 15: Binary F1 = 0.8938, Macro F1 = 0.4515, Final Metric = 0.6726\n",
      "  New best metric! Saving model...\n",
      "Epoch 16: Binary F1 = 0.8903, Macro F1 = 0.4312, Final Metric = 0.6608\n",
      "Epoch 17: Binary F1 = 0.9083, Macro F1 = 0.4565, Final Metric = 0.6824\n",
      "  New best metric! Saving model...\n",
      "Epoch 18: Binary F1 = 0.9110, Macro F1 = 0.4582, Final Metric = 0.6846\n",
      "  New best metric! Saving model...\n",
      "Epoch 19: Binary F1 = 0.8975, Macro F1 = 0.4939, Final Metric = 0.6957\n",
      "  New best metric! Saving model...\n",
      "Epoch 20: Binary F1 = 0.9095, Macro F1 = 0.4751, Final Metric = 0.6923\n",
      "Epoch 21: Binary F1 = 0.9070, Macro F1 = 0.4724, Final Metric = 0.6897\n",
      "Epoch 22: Binary F1 = 0.9113, Macro F1 = 0.4771, Final Metric = 0.6942\n",
      "Epoch 23: Binary F1 = 0.9045, Macro F1 = 0.4660, Final Metric = 0.6853\n",
      "Epoch 24: Binary F1 = 0.9124, Macro F1 = 0.4669, Final Metric = 0.6896\n",
      "Epoch 25: Binary F1 = 0.9080, Macro F1 = 0.4869, Final Metric = 0.6974\n",
      "  New best metric! Saving model...\n",
      "Epoch 26: Binary F1 = 0.9070, Macro F1 = 0.4606, Final Metric = 0.6838\n",
      "Epoch 27: Binary F1 = 0.8870, Macro F1 = 0.4660, Final Metric = 0.6765\n",
      "Epoch 28: Binary F1 = 0.9052, Macro F1 = 0.4698, Final Metric = 0.6875\n",
      "Epoch 29: Binary F1 = 0.9102, Macro F1 = 0.4667, Final Metric = 0.6884\n",
      "Epoch 30: Binary F1 = 0.9084, Macro F1 = 0.4725, Final Metric = 0.6904\n",
      "Epoch 31: Binary F1 = 0.9235, Macro F1 = 0.4769, Final Metric = 0.7002\n",
      "  New best metric! Saving model...\n",
      "Epoch 32: Binary F1 = 0.9198, Macro F1 = 0.4672, Final Metric = 0.6935\n",
      "Epoch 33: Binary F1 = 0.9220, Macro F1 = 0.4677, Final Metric = 0.6948\n",
      "Epoch 34: Binary F1 = 0.9245, Macro F1 = 0.4887, Final Metric = 0.7066\n",
      "  New best metric! Saving model...\n",
      "Epoch 35: Binary F1 = 0.9168, Macro F1 = 0.4898, Final Metric = 0.7033\n",
      "Best validation metrics - Binary F1: 0.9245, Macro F1: 0.4887, Final: 0.7066\n",
      "Final validation metrics - Binary F1: 0.9168, Macro F1: 0.4898, Final: 0.7033\n",
      "\n",
      "==================================================\n",
      "training: 2\n",
      "Fold 2/10\n",
      "Epoch 01: Binary F1 = 0.6553, Macro F1 = 0.1660, Final Metric = 0.4106\n",
      "  New best metric! Saving model...\n",
      "Epoch 02: Binary F1 = 0.9130, Macro F1 = 0.2334, Final Metric = 0.5732\n",
      "  New best metric! Saving model...\n",
      "Epoch 03: Binary F1 = 0.9149, Macro F1 = 0.3315, Final Metric = 0.6232\n",
      "  New best metric! Saving model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2025-08-17 16:56:34,245] Trial 0 failed with parameters: {'warmup_epochs': 12, 'cycle_mult': 1.5, 'max_lr': 0.006921271951375079, 'init_cycle_epochs': 10, 'lr_cycle_factor': 0.55, 'weight_decay': 0.000696167534923795, 'beta_0': 0.9602343643830354, 'beta_1': 0.9962049637645664, 'aux_loss_weigth': 0.2} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/venv/CMI/lib/python3.11/site-packages/optuna/study/_optimize.py\", line 201, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_24728/898881149.py\", line 2, in objective\n",
      "    return train_on_all_folds(\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_24728/2086849695.py\", line 38, in train_on_all_folds\n",
      "    fold_metrics_epoch_metrics, fold_seq_meta_data_metrics = train_model_on_all_epochs(\n",
      "                                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_24728/1975043025.py\", line 24, in train_model_on_all_epochs\n",
      "    train_metrics = train_model_on_single_epoch(model, train_loader, criterion, optimizer, scheduler, training_kw)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_24728/2116267756.py\", line 29, in train_model_on_single_epoch\n",
      "    loss.backward()\n",
      "  File \"/venv/CMI/lib/python3.11/site-packages/torch/_tensor.py\", line 581, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/venv/CMI/lib/python3.11/site-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/venv/CMI/lib/python3.11/site-packages/torch/autograd/graph.py\", line 825, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "[W 2025-08-17 16:56:34,249] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m best_folds_scores = {fold_idx:\u001b[32m0\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m fold_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(NB_CROSS_VALIDATIONS)}\n\u001b[32m      3\u001b[39m study = optuna.create_study(direction=\u001b[33m\"\u001b[39m\u001b[33mmaximize\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[43mstudy\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbest_folds_scores\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbest_folds_scores\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m60\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m60\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m8\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m pruned_trials = study.get_trials(deepcopy=\u001b[38;5;28;01mFalse\u001b[39;00m, states=[TrialState.PRUNED])\n\u001b[32m      7\u001b[39m complete_trials = study.get_trials(deepcopy=\u001b[38;5;28;01mFalse\u001b[39;00m, states=[TrialState.COMPLETE])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/venv/CMI/lib/python3.11/site-packages/optuna/study/study.py:489\u001b[39m, in \u001b[36mStudy.optimize\u001b[39m\u001b[34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m    387\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34moptimize\u001b[39m(\n\u001b[32m    388\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    389\u001b[39m     func: ObjectiveFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m    396\u001b[39m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    397\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    398\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[32m    399\u001b[39m \n\u001b[32m    400\u001b[39m \u001b[33;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    487\u001b[39m \u001b[33;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[32m    488\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m489\u001b[39m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    490\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/venv/CMI/lib/python3.11/site-packages/optuna/study/_optimize.py:64\u001b[39m, in \u001b[36m_optimize\u001b[39m\u001b[34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     63\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs == \u001b[32m1\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     66\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     67\u001b[39m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     75\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     76\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     77\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs == -\u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/venv/CMI/lib/python3.11/site-packages/optuna/study/_optimize.py:161\u001b[39m, in \u001b[36m_optimize_sequential\u001b[39m\u001b[34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[39m\n\u001b[32m    158\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    160\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m161\u001b[39m     frozen_trial = \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    163\u001b[39m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[32m    164\u001b[39m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[32m    165\u001b[39m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[32m    166\u001b[39m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[32m    167\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/venv/CMI/lib/python3.11/site-packages/optuna/study/_optimize.py:253\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    246\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mShould not reach.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    248\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    249\u001b[39m     frozen_trial.state == TrialState.FAIL\n\u001b[32m    250\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    251\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[32m    252\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m253\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[32m    254\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/venv/CMI/lib/python3.11/site-packages/optuna/study/_optimize.py:201\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    199\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial._trial_id, study._storage):\n\u001b[32m    200\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m201\u001b[39m         value_or_values = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    202\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions.TrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    203\u001b[39m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[32m    204\u001b[39m         state = TrialState.PRUNED\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 2\u001b[39m, in \u001b[36mobjective\u001b[39m\u001b[34m(trial, best_folds_scores)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mobjective\u001b[39m(trial: optuna.trial.Trial, best_folds_scores:\u001b[38;5;28mdict\u001b[39m) -> \u001b[38;5;28mfloat\u001b[39m:\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrain_on_all_folds\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlr_scheduler_kw\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mwarmup_epochs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m.\u001b[49m\u001b[43msuggest_int\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mwarmup_epochs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m12\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m15\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcycle_mult\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m.\u001b[49m\u001b[43msuggest_float\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcycle_mult\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0.9\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1.6\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_lr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m.\u001b[49m\u001b[43msuggest_float\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_lr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0.005581907927062619\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0.005581907927062619\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.0001\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_to_min_div_factor\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m250\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m#trial.suggest_float(\"max_to_min_div_factor\", 100, 300, step=25),\u001b[39;49;00m\n\u001b[32m      8\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minit_cycle_epochs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m.\u001b[49m\u001b[43msuggest_int\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minit_cycle_epochs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlr_cycle_factor\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m.\u001b[49m\u001b[43msuggest_float\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlr_cycle_factor\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0.25\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0.6\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.05\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptimizer_kw\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweight_decay\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m.\u001b[49m\u001b[43msuggest_float\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweight_decay\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m5e-4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1e-3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbeta_0\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m.\u001b[49m\u001b[43msuggest_float\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbeta_0\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0.8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0.999\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbeta_1\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m.\u001b[49m\u001b[43msuggest_float\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbeta_1\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0.99\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0.9999\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtraining_kw\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43maux_loss_weigth\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m.\u001b[49m\u001b[43msuggest_float\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43maux_loss_weigth\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbest_folds_scores\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbest_folds_scores\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 38\u001b[39m, in \u001b[36mtrain_on_all_folds\u001b[39m\u001b[34m(lr_scheduler_kw, optimizer_kw, training_kw, best_folds_scores)\u001b[39m\n\u001b[32m     28\u001b[39m steps_per_epoch = \u001b[38;5;28mlen\u001b[39m(DL(train_dataset, TRAIN_BATCH_SIZE)) \u001b[38;5;66;03m# ugly, i know\u001b[39;00m\n\u001b[32m     29\u001b[39m scheduler = CosineAnnealingWarmupRestarts(\n\u001b[32m     30\u001b[39m     optimizer,\n\u001b[32m     31\u001b[39m     warmup_steps=lr_scheduler_kw[\u001b[33m\"\u001b[39m\u001b[33mwarmup_epochs\u001b[39m\u001b[33m\"\u001b[39m] * steps_per_epoch,\n\u001b[32m   (...)\u001b[39m\u001b[32m     36\u001b[39m     gamma=lr_scheduler_kw[\u001b[33m\"\u001b[39m\u001b[33mlr_cycle_factor\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m     37\u001b[39m ) \n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m fold_metrics_epoch_metrics, fold_seq_meta_data_metrics = \u001b[43mtrain_model_on_all_epochs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     39\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     40\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidation_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     44\u001b[39m \u001b[43m    \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     45\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfold_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     46\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtraining_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     47\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     49\u001b[39m best_fold_metrics = fold_metrics_epoch_metrics.loc[fold_metrics_epoch_metrics[\u001b[33m\"\u001b[39m\u001b[33mfinal_metric\u001b[39m\u001b[33m\"\u001b[39m].idxmax()]\n\u001b[32m     50\u001b[39m final_fold_metrics = fold_metrics_epoch_metrics.iloc[-\u001b[32m1\u001b[39m]\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 24\u001b[39m, in \u001b[36mtrain_model_on_all_epochs\u001b[39m\u001b[34m(model, train_dataset, validation_dataset, criterion, optimizer, scheduler, fold, training_kw)\u001b[39m\n\u001b[32m     21\u001b[39m epochs_no_improve = \u001b[32m0\u001b[39m\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m, TRAINING_EPOCHS + \u001b[32m1\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m     train_metrics = \u001b[43mtrain_model_on_single_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining_kw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     25\u001b[39m     validation_metrics = evaluate_model(model, validation_loader, criterion)\n\u001b[32m     26\u001b[39m     metrics.append({\u001b[33m\"\u001b[39m\u001b[33mfold\u001b[39m\u001b[33m\"\u001b[39m: fold, \u001b[33m\"\u001b[39m\u001b[33mepoch\u001b[39m\u001b[33m\"\u001b[39m: epoch} | train_metrics | validation_metrics)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 29\u001b[39m, in \u001b[36mtrain_model_on_single_epoch\u001b[39m\u001b[34m(model, train_loader, criterion, optimizer, scheduler, training_kw)\u001b[39m\n\u001b[32m     27\u001b[39m outputs, aux_output = model(batch_x)\n\u001b[32m     28\u001b[39m loss = criterion(outputs, batch_y) + criterion(aux_output, batch_aux_y) * training_kw[\u001b[33m\"\u001b[39m\u001b[33maux_loss_weigth\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     30\u001b[39m optimizer.step()\n\u001b[32m     31\u001b[39m scheduler.step()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/venv/CMI/lib/python3.11/site-packages/torch/_tensor.py:581\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    571\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    572\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    573\u001b[39m         Tensor.backward,\n\u001b[32m    574\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    579\u001b[39m         inputs=inputs,\n\u001b[32m    580\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m581\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    582\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    583\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/venv/CMI/lib/python3.11/site-packages/torch/autograd/__init__.py:347\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    342\u001b[39m     retain_graph = create_graph\n\u001b[32m    344\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    345\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    346\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m347\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    348\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    349\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    350\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    351\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    352\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    353\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/venv/CMI/lib/python3.11/site-packages/torch/autograd/graph.py:825\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    823\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    824\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m825\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    826\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    827\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    828\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    829\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "best_folds_scores = {fold_idx:0 for fold_idx in range(NB_CROSS_VALIDATIONS)}\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(partial(objective, best_folds_scores=best_folds_scores), n_trials=1000, timeout=60 * 60 * 8)\n",
    "\n",
    "pruned_trials = study.get_trials(deepcopy=False, states=[TrialState.PRUNED])\n",
    "complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])\n",
    "\n",
    "print(\"Study statistics: \")\n",
    "print(\"  Number of finished trials: \", len(study.trials))\n",
    "print(\"  Number of pruned trials: \", len(pruned_trials))\n",
    "print(\"  Number of complete trials: \", len(complete_trials))\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"  Value: \", trial.value)\n",
    "\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d7dda5",
   "metadata": {
    "papermill": {
     "duration": 0.596983,
     "end_time": "2025-08-16T07:59:10.908412",
     "exception": false,
     "start_time": "2025-08-16T07:59:10.311429",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec94c28",
   "metadata": {
    "papermill": {
     "duration": 0.471961,
     "end_time": "2025-08-16T07:59:11.853288",
     "exception": false,
     "start_time": "2025-08-16T07:59:11.381327",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Reloading best models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce15c16",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T07:59:12.801809Z",
     "iopub.status.busy": "2025-08-16T07:59:12.801022Z",
     "iopub.status.idle": "2025-08-16T07:59:13.154246Z",
     "shell.execute_reply": "2025-08-16T07:59:13.153615Z"
    },
    "papermill": {
     "duration": 0.832143,
     "end_time": "2025-08-16T07:59:13.155565",
     "exception": false,
     "start_time": "2025-08-16T07:59:12.323422",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_model_ensemble(parent_dir:str) -> list[nn.Module]:\n",
    "    model_ensemble = []\n",
    "    for fold in range(NB_CROSS_VALIDATIONS):\n",
    "        model = mk_model(n_aux_classes=meta_data[\"n_aux_classes\"])\n",
    "        checkpoint = torch.load(\n",
    "            join(\n",
    "                parent_dir,\n",
    "                f\"model_fold_{fold}.pth\"\n",
    "            ),\n",
    "            map_location=device,\n",
    "            weights_only=True\n",
    "        )\n",
    "        model.load_state_dict(checkpoint)\n",
    "        model.eval()\n",
    "        model_ensemble.append(model)\n",
    "    \n",
    "    return model_ensemble\n",
    "    \n",
    "if not os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
    "    model_ensemble = load_model_ensemble(\"models\")\n",
    "else:\n",
    "    models_dir = kagglehub.model_download(\n",
    "        join(\n",
    "            KAGGLE_USERNAME,\n",
    "            MODEL_NAME,\n",
    "            \"pyTorch\",\n",
    "            MODEL_VARIATION,\n",
    "        )\n",
    "    )\n",
    "    model_ensemble = load_model_ensemble(models_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36ab60f",
   "metadata": {
    "papermill": {
     "duration": 0.47096,
     "end_time": "2025-08-16T07:59:14.222888",
     "exception": false,
     "start_time": "2025-08-16T07:59:13.751928",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Define prediction function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af158f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T07:59:15.174608Z",
     "iopub.status.busy": "2025-08-16T07:59:15.174277Z",
     "iopub.status.idle": "2025-08-16T07:59:15.181638Z",
     "shell.execute_reply": "2025-08-16T07:59:15.180958Z"
    },
    "papermill": {
     "duration": 0.484658,
     "end_time": "2025-08-16T07:59:15.182803",
     "exception": false,
     "start_time": "2025-08-16T07:59:14.698145",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_sequence_at_inference(sequence_df:pl.DataFrame) -> ndarray:\n",
    "    return (\n",
    "        sequence_df                     \n",
    "        .to_pandas()                            # Convert to pandas dataframe.\n",
    "        .pipe(imputed_features)                 # Impute missing data.\n",
    "        .pipe(standardize_tof_cols_names)\n",
    "        .pipe(norm_quat_rotations)              # Norm quaternions\n",
    "        .pipe(add_linear_acc_cols)              # Add gravity free acceleration.\n",
    "        .pipe(add_acc_magnitude, RAW_ACCELRATION_COLS, \"acc_mag\")\n",
    "        .pipe(add_acc_magnitude, LINEAR_ACC_COLS, \"linear_acc_mag\")\n",
    "        .pipe(add_quat_angle_mag)\n",
    "        .pipe(add_angular_velocity_features)\n",
    "        .pipe(rot_euler_angles)                 # Add rotation acc expressed as euler angles.\n",
    "        .pipe(agg_tof_cols_per_sensor)          # Aggregate ToF columns.\n",
    "        .pipe(add_diff_features)                # \n",
    "        .loc[:, sorted(meta_data[\"feature_cols\"])]      # Retain only the usefull columns a.k.a features.\n",
    "        # .sub(meta_data[\"mean\"])                 # Subtract features by their mean, std norm pt.1.\n",
    "        # .div(meta_data[\"std\"])                  # Divide by Standard deviation, std norm pt.2.\n",
    "        .pipe(length_normed_sequence_feat_arr, meta_data[\"pad_seq_len\"], SEQ_PAD_TRUNC_MODE)  # get feature ndarray of sequence.\n",
    "        .T                                      # Transpose to swap channel and X dimensions.\n",
    "    )\n",
    "\n",
    "def predict(sequence: pl.DataFrame, _: pl.DataFrame) -> str:\n",
    "    \"\"\"\n",
    "    Kaggle evaluation API will call this for each sequence.\n",
    "    sequence: polars DataFrame for a single sequence\n",
    "    demographics: unused in this model\n",
    "    Returns: predicted gesture string\n",
    "    \"\"\"\n",
    "    x_tensor = (\n",
    "        torch.unsqueeze(Tensor(preprocess_sequence_at_inference(sequence)), dim=0)\n",
    "        .float()\n",
    "        .to(device)\n",
    "    )\n",
    "    print(x_tensor.shape)\n",
    "\n",
    "    all_outputs = []\n",
    "    with torch.no_grad():\n",
    "        for model_idx, model in enumerate(model_ensemble): # Only take the first one bc it's the only one that takes in the correct input shape\n",
    "            outputs, _ = model(x_tensor)\n",
    "            all_outputs.append(outputs)\n",
    "\n",
    "    avg_outputs = torch.mean(torch.stack(all_outputs), dim=0)\n",
    "    pred_idx = torch.argmax(avg_outputs, dim=1).item()\n",
    "\n",
    "    return str(TARGET_NAMES[pred_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c4da03",
   "metadata": {
    "papermill": {
     "duration": 0.594447,
     "end_time": "2025-08-16T07:59:16.246526",
     "exception": false,
     "start_time": "2025-08-16T07:59:15.652079",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Run inference server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2276f156",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T07:59:17.185868Z",
     "iopub.status.busy": "2025-08-16T07:59:17.185567Z",
     "iopub.status.idle": "2025-08-16T07:59:19.474799Z",
     "shell.execute_reply": "2025-08-16T07:59:19.473949Z"
    },
    "papermill": {
     "duration": 2.761877,
     "end_time": "2025-08-16T07:59:19.476066",
     "exception": false,
     "start_time": "2025-08-16T07:59:16.714189",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "inference_server = kaggle_evaluation.cmi_inference_server.CMIInferenceServer(predict)\n",
    "\n",
    "if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
    "    inference_server.serve()\n",
    "else:\n",
    "    competition_dataset_path = kagglehub.competition_download(COMPETITION_HANDLE)\n",
    "    inference_server.run_local_gateway(\n",
    "        data_paths=(\n",
    "            join(competition_dataset_path, 'test.csv'),\n",
    "            join(competition_dataset_path, 'test_demographics.csv'),\n",
    "        )\n",
    "    )\n",
    "    inference_server = kaggle_evaluation.cmi_inference_server.CMIInferenceServer(predict)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 12518947,
     "isSourceIdPinned": false,
     "sourceId": 102335,
     "sourceType": "competition"
    },
    {
     "sourceId": 251413288,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "CMI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 29336.774009,
   "end_time": "2025-08-16T07:59:22.911175",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-08-15T23:50:26.137166",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "017e004fa48d47d3922ff8430c622d6b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_7d8dea81cf9b408b887ab76cebf54d86",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_e3b7c7212f284283b66093c53abaa043",
       "tabbable": null,
       "tooltip": null,
       "value": "â€‡5/5â€‡[00:00&lt;00:00,â€‡164.67it/s]"
      }
     },
     "03d9334a5018410abc4771c246117629": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "05ee8aec88c2443d889e216f16c6ad11": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "0734f6873fb3437a84921cf587d45d0e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_e7066fd0494743b0ad2752ae62efeb7b",
       "max": 5,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_460d5448949a4a11aed77ae2927b4540",
       "tabbable": null,
       "tooltip": null,
       "value": 5
      }
     },
     "097884cfcba041d98899d35a95cae6ae": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "17f53136c6bf40398c8428e211041703": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_097884cfcba041d98899d35a95cae6ae",
       "max": 8151,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_273195c05aac4f5bb5ff70687df4abf3",
       "tabbable": null,
       "tooltip": null,
       "value": 8151
      }
     },
     "1bb6c7a3bff843e78a7245ae8ad512d2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "22f4f3f9962741c1850328a4fe1cfa79": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "273195c05aac4f5bb5ff70687df4abf3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "286819ff1762413bb224feb474df6e3f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "28e8dc3d8f3243c7aaaeefedf963caf0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "29d45f5a60b44e3e9f62adcc85ea16ca": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "31ab7bf146634062a4f1865bf925dc1e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_edc2dba1ca9a45f1929bd3278cac29cf",
        "IPY_MODEL_0734f6873fb3437a84921cf587d45d0e",
        "IPY_MODEL_f6f2dd8782294cad9bce3a62bbceef07"
       ],
       "layout": "IPY_MODEL_9dfaf92605494ed3a2f1b5c637e0419b",
       "tabbable": null,
       "tooltip": null
      }
     },
     "321714e081c9487f9e20dd023d1e2265": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "458972638648434ca5c27b69c2acc6bb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_8dd4be7cfed24952bc04cdc0cfb73bbd",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_fecb29d6f1dd4a298feac803959cd6a9",
       "tabbable": null,
       "tooltip": null,
       "value": "100%"
      }
     },
     "460d5448949a4a11aed77ae2927b4540": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "52adbc19c8e44dd79dd41ff92bdd1816": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "54c80211a4ef4250bf25ae58d0a3055a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "6b4ab61d8d5743b49ab6e95677dd857c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_bcd7b3c2307a4a0e8c9c450914adfda6",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_8ec2da7fcc604d41aa24e0c45b77230c",
       "tabbable": null,
       "tooltip": null,
       "value": "â€‡5/5â€‡[00:00&lt;00:00,â€‡143.06it/s]"
      }
     },
     "6d640398a33d481ca5018b8fe4fffb79": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "7079432256be4bb8a0cb0ec0cd10db0e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7c75795d3f424748b7c9fc6d0fc8361e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "7d8dea81cf9b408b887ab76cebf54d86": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7f43bbc4630f49ff9948da7e800ec840": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_29d45f5a60b44e3e9f62adcc85ea16ca",
       "max": 5,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_7c75795d3f424748b7c9fc6d0fc8361e",
       "tabbable": null,
       "tooltip": null,
       "value": 5
      }
     },
     "82e111789e964a0ebefb9dd1e2c2299a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8668098f9eb14baf8c7e5e4ca2d57e6e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_458972638648434ca5c27b69c2acc6bb",
        "IPY_MODEL_7f43bbc4630f49ff9948da7e800ec840",
        "IPY_MODEL_6b4ab61d8d5743b49ab6e95677dd857c"
       ],
       "layout": "IPY_MODEL_28e8dc3d8f3243c7aaaeefedf963caf0",
       "tabbable": null,
       "tooltip": null
      }
     },
     "8d519c6a0eb045fea7a6df81a3693636": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_e6f463cff43044edb0fbaac48ca2cc31",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_52adbc19c8e44dd79dd41ff92bdd1816",
       "tabbable": null,
       "tooltip": null,
       "value": "â€‡8151/8151â€‡[00:20&lt;00:00,â€‡420.70it/s]"
      }
     },
     "8dd4be7cfed24952bc04cdc0cfb73bbd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8ec2da7fcc604d41aa24e0c45b77230c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "9dfaf92605494ed3a2f1b5c637e0419b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a11a198be91047c09c48aa55a8186751": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b354eac7a32d4408ab6baa3ad6743b66": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_e6e557ad11984b28b2b9df7f17643dde",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_6d640398a33d481ca5018b8fe4fffb79",
       "tabbable": null,
       "tooltip": null,
       "value": "100%"
      }
     },
     "bcd7b3c2307a4a0e8c9c450914adfda6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c0f9991c19f349eda5ca0a020be538ac": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_b354eac7a32d4408ab6baa3ad6743b66",
        "IPY_MODEL_17f53136c6bf40398c8428e211041703",
        "IPY_MODEL_8d519c6a0eb045fea7a6df81a3693636"
       ],
       "layout": "IPY_MODEL_a11a198be91047c09c48aa55a8186751",
       "tabbable": null,
       "tooltip": null
      }
     },
     "e3b7c7212f284283b66093c53abaa043": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "e6e557ad11984b28b2b9df7f17643dde": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e6f463cff43044edb0fbaac48ca2cc31": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e7066fd0494743b0ad2752ae62efeb7b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e950be5edb444871868457fc2360ff57": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_286819ff1762413bb224feb474df6e3f",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_05ee8aec88c2443d889e216f16c6ad11",
       "tabbable": null,
       "tooltip": null,
       "value": "100%"
      }
     },
     "edc2dba1ca9a45f1929bd3278cac29cf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_7079432256be4bb8a0cb0ec0cd10db0e",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_321714e081c9487f9e20dd023d1e2265",
       "tabbable": null,
       "tooltip": null,
       "value": "100%"
      }
     },
     "ee1ce3f7047d4a3faf596bfdbf9d7782": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_1bb6c7a3bff843e78a7245ae8ad512d2",
       "max": 5,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_54c80211a4ef4250bf25ae58d0a3055a",
       "tabbable": null,
       "tooltip": null,
       "value": 5
      }
     },
     "f697397c1f224f2ca5d62ed7aaf729ee": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_e950be5edb444871868457fc2360ff57",
        "IPY_MODEL_ee1ce3f7047d4a3faf596bfdbf9d7782",
        "IPY_MODEL_017e004fa48d47d3922ff8430c622d6b"
       ],
       "layout": "IPY_MODEL_82e111789e964a0ebefb9dd1e2c2299a",
       "tabbable": null,
       "tooltip": null
      }
     },
     "f6f2dd8782294cad9bce3a62bbceef07": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_03d9334a5018410abc4771c246117629",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_22f4f3f9962741c1850328a4fe1cfa79",
       "tabbable": null,
       "tooltip": null,
       "value": "â€‡5/5â€‡[00:24&lt;00:00,â€‡â€‡5.04s/it]"
      }
     },
     "fecb29d6f1dd4a298feac803959cd6a9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
