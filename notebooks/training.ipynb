{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53d41434",
   "metadata": {},
   "source": [
    "# Training model\n",
    "The goal of this notebook is to train a model and upload it to kaggle."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696a0573",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4c23f0",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66f429fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from glob import glob\n",
    "from datetime import datetime\n",
    "from itertools import pairwise\n",
    "from os.path import join, realpath\n",
    "from typing import Optional, Literal\n",
    "\n",
    "import torch\n",
    "import kagglehub\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from torch import nn, Tensor\n",
    "from pandas import DataFrame as DF\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader as DL\n",
    "from rich.progress import Progress, Task, track\n",
    "from torch.optim.lr_scheduler import ConstantLR, LRScheduler\n",
    "metric_package = kagglehub.package_import('wasupandceacar/cmi-metric', bypass_confirmation=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe9b25b",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82515f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_EPOCHS = 60\n",
    "STARTING_LR = 0.0005\n",
    "BATCH_SIZE = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca49598",
   "metadata": {},
   "source": [
    "### Make plotly renders a bit more github frendly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b48ecc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "561af8f7",
   "metadata": {},
   "source": [
    "### Dataset Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63a131e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/mauroabidalcarrer/prepocessed-cmi-2025?dataset_version_number=25...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 753M/753M [06:34<00:00, 2.00MB/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset_path = kagglehub.dataset_download(\n",
    "    handle=\"mauroabidalcarrer/prepocessed-cmi-2025\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e46c3b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CMIDataset(TensorDataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        parent_dir: str,\n",
    "        split: Optional[Literal[\"train\", \"validation\"]]=None,\n",
    "        subset: Optional[int]=None,\n",
    "        force_download=False\n",
    "    ):\n",
    "        dataset_path = kagglehub.dataset_download(\n",
    "            handle=\"mauroabidalcarrer/prepocessed-cmi-2025\",\n",
    "            force_download=force_download\n",
    "        )\n",
    "        parent_dir = join(dataset_path, \"preprocessed_dataset\", parent_dir)\n",
    "        split = \"\" if split is None else split + \"_\"\n",
    "        x = np.load(join(parent_dir, f\"{split}X.npy\")).swapaxes(1, 2)\n",
    "        y = np.load(join(parent_dir, f\"{split}Y.npy\"))\n",
    "        if subset is not None:\n",
    "            x = x[:subset]\n",
    "            y = y[:subset]\n",
    "        super().__init__(\n",
    "            torch.from_numpy(x), \n",
    "            torch.from_numpy(y),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2de4288",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_data_path = join(\n",
    "    dataset_path,\n",
    "    \"preprocessed_dataset\",\n",
    "    \"full_dataset_meta_data.json\"\n",
    ")\n",
    "with open(meta_data_path, \"r\") as fp:\n",
    "    meta_data = json.load(fp)\n",
    "# Convert target names into a ndarray to index it batchwise.\n",
    "meta_data[\"target_names\"] = np.asarray(meta_data[\"target_names\"])\n",
    "non_imu_feats_idx = [feat_idx for feat_idx, feat in enumerate(meta_data[\"feature_cols\"]) if feat.startswith((\"thm\", \"tof\"))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7cce363",
   "metadata": {},
   "source": [
    "### device setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2710f791",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7405a353",
   "metadata": {},
   "source": [
    "## Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ecc32a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_chns:int, out_chns:int):\n",
    "        super().__init__()\n",
    "        self.blocks = nn.Sequential(\n",
    "            nn.Conv1d(in_chns, out_chns, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(out_chns),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(out_chns, out_chns, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(out_chns),\n",
    "        )\n",
    "        if in_chns == out_chns:\n",
    "            self.skip_connection = nn.Identity() \n",
    "        else:\n",
    "            # TODO: set bias to False ?\n",
    "            self.skip_connection = nn.Sequential(\n",
    "                nn.Conv1d(in_chns, out_chns, 1),\n",
    "                nn.BatchNorm1d(out_chns)\n",
    "            )\n",
    "\n",
    "    def forward(self, x:Tensor) -> Tensor:\n",
    "        activaition_maps = self.skip_connection(x) + self.blocks(x)\n",
    "        return nn.functional.relu(activaition_maps)\n",
    "\n",
    "class Resnet(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            in_channels:int,\n",
    "            depth:int,\n",
    "            # n_res_block_per_depth:int,\n",
    "            mlp_width:int,\n",
    "            n_class:int,\n",
    "        ):\n",
    "        super().__init__()\n",
    "        chs_per_depth = [in_channels * 2 ** i for i in range(depth)]\n",
    "        blocks_chns_it = pairwise(chs_per_depth)\n",
    "        self.res_blocks = [ResidualBlock(in_chns, out_chns) for in_chns, out_chns in blocks_chns_it]\n",
    "        self.res_blocks = nn.ModuleList(self.res_blocks)\n",
    "        self.mlp_head = nn.Sequential(\n",
    "            nn.LazyLinear(mlp_width),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(mlp_width, n_class),\n",
    "            nn.Softmax(dim=1),\n",
    "        )\n",
    "        \n",
    "        \n",
    "    def forward(self, x:Tensor) -> Tensor:\n",
    "        activation_maps = x\n",
    "        for res_block in self.res_blocks:\n",
    "            activation_maps = nn.functional.max_pool1d(res_block(activation_maps), 2)\n",
    "        out = activation_maps.view(activation_maps.shape[0], -1)\n",
    "        out = self.mlp_head(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a83f1e7",
   "metadata": {},
   "source": [
    "## Training functions "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8014fc2",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7cc879eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(epochs:int,\n",
    "        model: nn.Module,\n",
    "        scheduler: LRScheduler,\n",
    "        optimizer: torch.optim.Optimizer,\n",
    "        train_loader: DL,\n",
    "        criterion: callable=nn.L1Loss(),\n",
    "        evaluation_func: callable=None,\n",
    "        validation_loader: DL=None,\n",
    "        save_checkpoints=True,\n",
    "    ) -> tuple[DF, str]:\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "        (training_metrics, path_to_checkpoints)\n",
    "    \"\"\"\n",
    "    # Setup\n",
    "    metrics: list[dict] = []\n",
    "    checkpoints_dir = os.path.join(\"checkpoints\", mk_date_now_str())\n",
    "    step = 0\n",
    "    model_device = next(model.parameters()).device\n",
    "    last_epoch_metric = {}\n",
    "    # Training loop\n",
    "    with Progress() as progress:\n",
    "        task: Task = progress.add_task(\n",
    "            \"training...\",\n",
    "            total=len(train_loader),\n",
    "        )\n",
    "        for epoch in range(epochs):\n",
    "            progress.update(\n",
    "                task,\n",
    "                description=f\"epoch: {epoch}\",\n",
    "                completed=0,\n",
    "            )\n",
    "            total_epoch_loss = 0\n",
    "            total_accuracy = 0\n",
    "            for batch_idx, (x, y) in enumerate(train_loader):\n",
    "                # forward\n",
    "                x = x.to(model_device)\n",
    "                y = y.to(model_device)\n",
    "                model.train()\n",
    "                optimizer.zero_grad()\n",
    "                y_pred: Tensor = model(x)\n",
    "                loss_value = criterion(y_pred, y)\n",
    "                # Verify loss value\n",
    "                if torch.isnan(loss_value).any().item():\n",
    "                    progress.print(\"Warning: Got NaN loss, stopped training.\")\n",
    "                    return DF.from_records(metrics) \n",
    "                if torch.isinf(loss_value).any().item():\n",
    "                    progress.print(\"Warning: Got infinite loss, stopped training.\")\n",
    "                    return DF.from_records(metrics) \n",
    "                # TODO: Use gradient clipping?\n",
    "                loss_value.backward()\n",
    "                optimizer.step()\n",
    "                if step > 0: # If it's not the first training step, idk why it throws an error otherwise\n",
    "                    scheduler.step()\n",
    "                # metrics\n",
    "                total_epoch_loss += loss_value.item()\n",
    "                batch_accuracy = compute_accuracy(y_pred, y)\n",
    "                total_accuracy += batch_accuracy\n",
    "                metrics.append({\n",
    "                    \"step\": step,\n",
    "                    \"epoch\": epoch,\n",
    "                    \"batch_train_loss\": loss_value.item(),\n",
    "                    \"lr\": optimizer.state_dict()[\"param_groups\"][-1][\"lr\"],\n",
    "                    \"batch_accuracy\": batch_accuracy,\n",
    "                })\n",
    "                step += 1\n",
    "                if \"validation_accuracy\" in last_epoch_metric:\n",
    "                    last_validation_acc = \"%.2f\" % last_epoch_metric[\"validation_accuracy\"]\n",
    "                    val_acc_str = \"val. acc: \" + last_validation_acc\n",
    "                else:\n",
    "                    val_acc_str = \"\"\n",
    "                progress.update(\n",
    "                    task,\n",
    "                    advance=1,\n",
    "                    description=f\"epoch: {epoch}, batch_loss: {(total_epoch_loss / (batch_idx+1)):.2f}, {val_acc_str}\"\n",
    "                )\n",
    "            # Post epoch evalution\n",
    "            metrics[-1][\"train_epoch_loss\"] = total_epoch_loss / len(train_loader)\n",
    "            metrics[-1][\"train_epoch_accuracy\"] = total_accuracy / len(train_loader)\n",
    "            if evaluation_func:\n",
    "                progress.update(\n",
    "                    task,\n",
    "                    completed=0,\n",
    "                    description=f\"epoch: {epoch}, evaluating...\"\n",
    "                )\n",
    "                eval_metrics = evaluation_func(model, criterion, validation_loader)\n",
    "                metrics[-1].update(eval_metrics)\n",
    "            last_epoch_metric = metrics[-1]\n",
    "            # Save checkpoint\n",
    "            if save_checkpoints:\n",
    "                checkpoint = mk_checkpoint(epoch, model, scheduler, optimizer)\n",
    "                metrics_df = DF.from_records(metrics)\n",
    "                best_model_metric = \"validation_loss\" if \"validation_loss\" in metrics_df.columns else \"train_epoch_loss\"\n",
    "                is_best_checkpoint = (\n",
    "                    DF.from_records(metrics)\n",
    "                    .eval(f\"min_{best_model_metric} = {best_model_metric}.min()\")\n",
    "                    .eval(f\"is_best_{best_model_metric} = {best_model_metric} == min_{best_model_metric}\")\n",
    "                    .dropna(subset=f\"is_best_{best_model_metric}\")\n",
    "                    .iloc[-1]\n",
    "                    .loc[f\"is_best_{best_model_metric}\"]\n",
    "                )\n",
    "                save_checkpoint(checkpoint, checkpoints_dir, is_best_checkpoint)\n",
    "\n",
    "    return DF.from_records(metrics), checkpoints_dir\n",
    "\n",
    "def evaluate_model(\n",
    "        model: torch.nn.Module,\n",
    "        critirion:callable,\n",
    "        validation_loader:DL,\n",
    "    ) -> dict:\n",
    "    model = model.eval()\n",
    "    model_device = next(model.parameters()).device\n",
    "    competition_metric = metric_package.Metric()\n",
    "\n",
    "    total_accuracy = 0\n",
    "    total_test_loss = 0\n",
    "    for x, y in validation_loader:\n",
    "        x = x.to(model_device)\n",
    "        y = y.to(model_device)\n",
    "\n",
    "        half = BATCH_SIZE // 2         \n",
    "        x_front = x[:half]               \n",
    "        x_back  = x[half:].clone()      \n",
    "        \n",
    "        x_back[:, :, non_imu_feats_idx] = 0.0    \n",
    "        x = torch.cat([x_front, x_back], dim=0)  # (B, C, T)\n",
    "\n",
    "        y_pred = model(x)\n",
    "        total_test_loss += critirion(y_pred, y).item()\n",
    "        batch_accuracy = compute_accuracy(y_pred, y)\n",
    "        total_accuracy += batch_accuracy\n",
    "        competition_metric.add(get_str_target(y), get_str_target(y_pred))\n",
    "\n",
    "    return {\n",
    "        \"validation_loss\": total_test_loss / len(validation_loader),\n",
    "        \"validation_accuracy\": total_accuracy / len(validation_loader),\n",
    "        \"competition_score\": competition_metric.score(),\n",
    "    }\n",
    "\n",
    "def get_str_target(y:Tensor) -> str:\n",
    "    y_idx = y.max(dim=1)[1].tolist()\n",
    "    return meta_data[\"target_names\"][y_idx]\n",
    "\n",
    "def compute_accuracy(y_pred:Tensor, y:Tensor) -> float:\n",
    "    return (\n",
    "            (y.max(dim=1)[1] == y_pred.max(dim=1)[1])\n",
    "            .sum()\n",
    "            .item()\n",
    "    ) / y.shape[0]\n",
    "\n",
    "def mk_checkpoint(\n",
    "        epoch:int,\n",
    "        model: torch.nn.Module,\n",
    "        scheduler: LRScheduler,\n",
    "        optimizer: torch.optim.Optimizer\n",
    "    ) -> dict:\n",
    "    if torch.cuda.is_available():\n",
    "        model_state_dict = {k: v.detach().cpu() for k, v in model.state_dict().items()}\n",
    "    else:\n",
    "        model_state_dict = model.state_dict()\n",
    "\n",
    "    return {\n",
    "        \"epoch\": epoch,\n",
    "        \"model\": model.state_dict(),\n",
    "        \"optimizer\": optimizer.state_dict(),\n",
    "        \"scheduler\": scheduler.state_dict(),\n",
    "    }\n",
    "\n",
    "def save_checkpoint(checkpoint:dict, parent_dir:str, is_best_checkpoint=False):\n",
    "    # Create model name\n",
    "    checkpoint_filename = f\"epoch_{checkpoint['epoch']}_{mk_date_now_str()}.pth\"\n",
    "    # Save model\n",
    "    os.makedirs(parent_dir, exist_ok=True)\n",
    "    checkpoint_path = os.path.join(parent_dir, checkpoint_filename)\n",
    "    torch.save(checkpoint, checkpoint_path)\n",
    "    mk_symlink(checkpoint_path, os.path.join(parent_dir, \"latest_checkpoint.pth\"))\n",
    "    if is_best_checkpoint:\n",
    "        mk_symlink(checkpoint_path, os.path.join(parent_dir, \"best_checkpoint.pth\"))\n",
    "\n",
    "def mk_date_now_str() -> str:\n",
    "    return datetime.now().strftime(\"%d-%m-%Y_%H-%M\")\n",
    "\n",
    "def mk_symlink(dest:str, symlink_path:str):\n",
    "    if os.path.islink(symlink_path) or os.path.exists(symlink_path):\n",
    "        os.remove(symlink_path)\n",
    "    os.symlink(dest, symlink_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "534c536e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input channels: 66\n"
     ]
    }
   ],
   "source": [
    "def mk_model() -> nn.Module:\n",
    "    nb_in_chans = len(meta_data[\"feature_cols\"])\n",
    "    return (\n",
    "        Resnet(\n",
    "            in_channels=nb_in_chans,\n",
    "            depth=4,\n",
    "            mlp_width=256,\n",
    "            n_class=18\n",
    "        )\n",
    "        .to(device)\n",
    "    )\n",
    "\n",
    "print(\"input channels:\", len(meta_data[\"feature_cols\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe1e327c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mk_model_and_fit(train_loader:DL, validation_loader:Optional[DL]=None) -> tuple[nn.Module, DF, list[str]]:\n",
    "    model = mk_model()\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), STARTING_LR)\n",
    "    constant_lr_scheduler = ConstantLR(optimizer, factor=1, total_iters=len(train_loader) * TRAINING_EPOCHS)\n",
    "    training_metrics, model_checkpoints = fit(\n",
    "        epochs=TRAINING_EPOCHS,\n",
    "        model=model,\n",
    "        scheduler=constant_lr_scheduler,\n",
    "        optimizer=optimizer,\n",
    "        train_loader=train_loader,\n",
    "        criterion=nn.CrossEntropyLoss(),\n",
    "        evaluation_func=evaluate_model if validation_loader else None,\n",
    "        validation_loader=validation_loader,\n",
    "        save_checkpoints=True,\n",
    "    )\n",
    "\n",
    "    return model, training_metrics, model_checkpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ddd2294",
   "metadata": {},
   "source": [
    "### Training metrics plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4619c4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plt_train_split_training_metrics(training_metrics:DF):\n",
    "    (\n",
    "        px.scatter(\n",
    "            (\n",
    "                training_metrics\n",
    "                .melt(\n",
    "                    id_vars=\"step\",\n",
    "                    value_vars=[\n",
    "                        \"batch_train_loss\",\n",
    "                        \"batch_accuracy\",\n",
    "                    ]\n",
    "                )\n",
    "            ),\n",
    "            x=\"step\",\n",
    "            y=\"value\",\n",
    "            facet_row=\"variable\",\n",
    "            trendline=\"ewm\",\n",
    "            trendline_options={\"com\": 30},\n",
    "            trendline_color_override=\"red\",\n",
    "            title=\"batch metrics\",\n",
    "        )\n",
    "        .update_yaxes(matches=None)\n",
    "        .show()\n",
    "    )\n",
    "\n",
    "def plt_validation_split_training_metrics(training_metrics:DF):\n",
    "    (\n",
    "        px.line(\n",
    "            (\n",
    "                training_metrics\n",
    "                .query(\"validation_loss.notna()\")\n",
    "                .melt(\n",
    "                    id_vars=\"epoch\",\n",
    "                    value_vars=['train_epoch_loss', 'train_epoch_accuracy', 'validation_loss', 'validation_accuracy', \"competition_score\"]\n",
    "                )\n",
    "            ),\n",
    "            x=\"epoch\",\n",
    "            y=\"value\",\n",
    "            color=\"variable\",\n",
    "            facet_row=\"variable\",\n",
    "            title=\"epoch metrics\",\n",
    "            render_mode=\"line+marker\",\n",
    "        ).update_yaxes(matches=None)\n",
    "        .show()\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92bee315",
   "metadata": {},
   "source": [
    "## Cross validation training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a711c430",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training: 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8d9c3653ae44c40b01e9755f4bbfe73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "NB_CROSS_VALIDATIONS = 5\n",
    "fold_patterns = join(dataset_path, \"preprocessed_dataset\", \"fold*\")\n",
    "fold_pths = glob(fold_patterns)[:NB_CROSS_VALIDATIONS]\n",
    "all_training_metrics = {}\n",
    "\n",
    "for fold_idx, fold_pth in enumerate(fold_pths):\n",
    "    print(\"training:\", fold_idx + 1)\n",
    "    train_dataset = CMIDataset(fold_pth, \"train\")\n",
    "    train_data_loader = DL(train_dataset, BATCH_SIZE, shuffle=True)\n",
    "    validation_dataset = CMIDataset(fold_pth, \"validation\")\n",
    "    validation_data_loader = DL(validation_dataset, BATCH_SIZE, shuffle=False)\n",
    "    _, training_metrics, _ = mk_model_and_fit(train_data_loader, validation_data_loader)\n",
    "    all_training_metrics[\"fold_\" + str(fold_idx)] = training_metrics\n",
    "    plt_validation_split_training_metrics(training_metrics)\n",
    "    print(\"=========================\")\n",
    "\n",
    "all_training_metrics = pd.concat(all_training_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e54c23c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_epoch_loss</th>\n",
       "      <th>train_epoch_accuracy</th>\n",
       "      <th>validation_loss</th>\n",
       "      <th>validation_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.669838</td>\n",
       "      <td>0.308898</td>\n",
       "      <td>2.675632</td>\n",
       "      <td>0.304093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.081791</td>\n",
       "      <td>0.082968</td>\n",
       "      <td>0.054775</td>\n",
       "      <td>0.054583</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      train_epoch_loss  train_epoch_accuracy  validation_loss  \\\n",
       "mean          2.669838              0.308898         2.675632   \n",
       "std           0.081791              0.082968         0.054775   \n",
       "\n",
       "      validation_accuracy  \n",
       "mean             0.304093  \n",
       "std              0.054583  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    all_training_metrics\n",
    "    .loc[:, [\"train_epoch_loss\", \"train_epoch_accuracy\", \"validation_loss\", \"validation_accuracy\"]]\n",
    "    .agg([\"mean\", \"std\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab08b93",
   "metadata": {},
   "source": [
    "## Full dataset training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a350f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21d93ce1afc74e54a1e9b1f835da8fea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[38]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m full_dataset = CMIDataset(\u001b[33m\"\u001b[39m\u001b[33mfull_dataset\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      2\u001b[39m full_dataset_loader = DL(full_dataset, BATCH_SIZE, shuffle=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m model, full_train_metrics, checkpoints = \u001b[43mmk_model_and_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfull_dataset_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m plt_train_split_training_metrics(full_train_metrics)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[34]\u001b[39m\u001b[32m, line 5\u001b[39m, in \u001b[36mmk_model_and_fit\u001b[39m\u001b[34m(train_loader, validation_loader)\u001b[39m\n\u001b[32m      3\u001b[39m optimizer = torch.optim.AdamW(model.parameters(), STARTING_LR)\n\u001b[32m      4\u001b[39m constant_lr_scheduler = ConstantLR(optimizer, factor=\u001b[32m1\u001b[39m, total_iters=\u001b[38;5;28mlen\u001b[39m(train_loader) * TRAINING_EPOCHS)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m training_metrics, model_checkpoints = \u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mTRAINING_EPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconstant_lr_scheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCrossEntropyLoss\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevaluation_func\u001b[49m\u001b[43m=\u001b[49m\u001b[43mevaluate_model\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mvalidation_loader\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidation_loader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalidation_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[43msave_checkpoints\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m model, training_metrics, model_checkpoints\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[32]\u001b[39m\u001b[32m, line 51\u001b[39m, in \u001b[36mfit\u001b[39m\u001b[34m(epochs, model, scheduler, optimizer, train_loader, criterion, evaluation_func, validation_loader, save_checkpoints)\u001b[39m\n\u001b[32m     49\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m DF.from_records(metrics) \n\u001b[32m     50\u001b[39m \u001b[38;5;66;03m# TODO: Use gradient clipping?\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m \u001b[43mloss_value\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     52\u001b[39m optimizer.step()\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m step > \u001b[32m0\u001b[39m: \u001b[38;5;66;03m# If it's not the first training step, idk why it throws an error otherwise\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/CMI/lib/python3.11/site-packages/torch/_tensor.py:581\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    571\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    572\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    573\u001b[39m         Tensor.backward,\n\u001b[32m    574\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    579\u001b[39m         inputs=inputs,\n\u001b[32m    580\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m581\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    582\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    583\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/CMI/lib/python3.11/site-packages/torch/autograd/__init__.py:347\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    342\u001b[39m     retain_graph = create_graph\n\u001b[32m    344\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    345\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    346\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m347\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    348\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    349\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    350\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    351\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    352\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    353\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/CMI/lib/python3.11/site-packages/torch/autograd/graph.py:825\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    823\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    824\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m825\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    826\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    827\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    828\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    829\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "full_dataset = CMIDataset(\"full_dataset\")\n",
    "full_dataset_loader = DL(full_dataset, BATCH_SIZE, shuffle=True)\n",
    "model, full_train_metrics, checkpoints = mk_model_and_fit(full_dataset_loader)\n",
    "plt_train_split_training_metrics(full_train_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0081b6e",
   "metadata": {},
   "source": [
    "## Model upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87578050",
   "metadata": {},
   "outputs": [],
   "source": [
    "handle = f\"{whoami()['username']}/cmi-resnet/pyTorch/{mk_date_now_str().replace('_', '-')}\"\n",
    "model_path = realpath(join(checkpoints, \"best_checkpoint.pth\"))\n",
    "model_upload(handle, model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CMI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
