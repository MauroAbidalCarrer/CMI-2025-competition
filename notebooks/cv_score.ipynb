{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf6438da",
   "metadata": {},
   "source": [
    "# Training & inference notebook\n",
    "Credit to [Tarun Mishra](https://www.kaggle.com/tarundirector) â€“ this code is heavily based on his [notebook](https://www.kaggle.com/code/tarundirector/sensor-pulse-viz-eda-for-bfrb-detection?scriptVersionId=243465321)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e752c660",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473b69f6",
   "metadata": {},
   "source": [
    "### imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d4b210",
   "metadata": {},
   "source": [
    "#### Training imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b842c804",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import json\n",
    "import math\n",
    "from glob import glob\n",
    "from functools import partial\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "from os.path import join, realpath\n",
    "from typing import Optional, Literal\n",
    "from itertools import pairwise, starmap\n",
    "\n",
    "import torch\n",
    "import kagglehub\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from torch import nn, Tensor\n",
    "from pandas import DataFrame as DF\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.optim import Optimizer\n",
    "# from timm.scheduler import CosineLRScheduler\n",
    "from torch.utils.data import DataLoader as DL\n",
    "from rich.progress import Progress, Task, track\n",
    "from torch.optim.lr_scheduler import ConstantLR, LRScheduler, _LRScheduler\n",
    "metric_package = kagglehub.package_import('wasupandceacar/cmi-metric', bypass_confirmation=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3ae962",
   "metadata": {},
   "source": [
    "#### inference imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "915c9ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import warnings\n",
    "from os.path import join\n",
    "from tqdm.notebook import tqdm\n",
    "from itertools import pairwise, product\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "from numpy import ndarray\n",
    "from torch import nn, Tensor\n",
    "from numpy.linalg import norm\n",
    "from pandas import DataFrame as DF\n",
    "from scipy.spatial.transform import Rotation\n",
    "# from kagglehub import competition_download, dataset_download, model_download\n",
    "import kagglehub\n",
    "metric_package = kagglehub.package_import('wasupandceacar/cmi-metric', bypass_confirmation=True)\n",
    "\n",
    "import training\n",
    "import kaggle_evaluation.cmi_inference_server"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd3c8bd",
   "metadata": {},
   "source": [
    "#### kaggle notbook Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce2e25ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "\n",
    "def seed_everything(seed=42):\n",
    "    \"\"\"Set all random seeds for reproducibility\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'\n",
    "    torch.use_deterministic_algorithms(True, warn_only=True)\n",
    "\n",
    "SEED = 42\n",
    "seed_everything(seed=SEED)\n",
    "\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import kaggle_evaluation.cmi_inference_server\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e34cce",
   "metadata": {},
   "source": [
    "### Configs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b0b925",
   "metadata": {},
   "source": [
    "#### Training config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1296f174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "DATASET_HANDLE = \"mauroabidalcarrer/prepocessed-cmi-2025/versions/34\"\n",
    "COMPETITION_HANDLE = \"cmi-detect-behavior-with-sensor-data\"\n",
    "TARGET_NAMES = sorted([\n",
    "    \"Above ear - pull hair\",\n",
    "    \"Cheek - pinch skin\",\n",
    "    \"Eyebrow - pull hair\",\n",
    "    \"Eyelash - pull hair\",\n",
    "    \"Feel around in tray and pull out an object\",\n",
    "    \"Forehead - pull hairline\",\n",
    "    \"Forehead - scratch\",\n",
    "    \"Neck - pinch skin\",\n",
    "    \"Neck - scratch\",\n",
    "    \"Text on phone\",\n",
    "    \"Wave hello\",\n",
    "    \"Write name in air\",\n",
    "    \"Write name on leg\",\n",
    "    \"Drink from bottle/cup\",\n",
    "    \"Pinch knee/leg skin\",\n",
    "    \"Pull air toward your face\",\n",
    "    \"Scratch knee/leg skin\",\n",
    "    \"Glasses on/off\"\n",
    "])\n",
    "IMU_FEATS_PREFIXES = (\n",
    "    \"acc\",\n",
    "    \"linear_acc\",\n",
    "    \"rot\",\n",
    "    \"angular\",\n",
    "    \"euler\",\n",
    "    \"quat_rot_mag\",\n",
    "    \"delta_rot_mag\",\n",
    ")\n",
    "# Data augmentation\n",
    "JITTER = 0.25\n",
    "SCALING = 0.2\n",
    "MIXUP = 0.3\n",
    "# Training loop\n",
    "NB_CROSS_VALIDATIONS = 5\n",
    "TRAIN_BATCH_SIZE = 256\n",
    "VALIDATION_BATCH_SIZE = 4 * TRAIN_BATCH_SIZE\n",
    "PATIENCE = 8\n",
    "# Optimizer\n",
    "WEIGHT_DECAY = 3e-3\n",
    "# Scheduler\n",
    "TRAINING_EPOCHS = 25 # Including warmup epochs\n",
    "WARMUP_EPOCHS = 3\n",
    "WARMUP_LR_INIT = 1.822126131809773e-05\n",
    "MAX_TO_MIN_LR_DIV_FACTOR = 100\n",
    "LR_CYCLE_FACTOR = 0.5\n",
    "CYCLE_LENGTH_FACTOR = 0.9\n",
    "INIT_CYCLE_EPOCHS = 6\n",
    "# MIN_LR = 3.810323058740104e-09\n",
    "# MAX_LR = 1e-3\n",
    "# Mock training loop\n",
    "MOCK_TRAINING_EPOCHS = 15\n",
    "MOCK_TRAINING_GAMMA = 1.01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1393b8af",
   "metadata": {},
   "source": [
    "#### Preprocessing (for inference) config "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ad8c78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUATERNION_COLS = ['rot_w', 'rot_x', 'rot_y', 'rot_z']\n",
    "GRAVITY_WORLD = np.array([0, 0, 9.81], \"float32\")\n",
    "RAW_ACCELRATION_COLS = [\"acc_x\", \"acc_y\", \"acc_z\"]\n",
    "LINEAR_ACC_COLS = [\"linear_\" + col for col in RAW_ACCELRATION_COLS] # Acceleration without gravity\n",
    "COMPETITION_HANDLE = \"cmi-detect-behavior-with-sensor-data\"\n",
    "CATEGORY_COLUMNS = [\n",
    "    'row_id',\n",
    "    'sequence_type',\n",
    "    'sequence_id',\n",
    "    'subject',\n",
    "    'orientation',\n",
    "    'behavior',\n",
    "    'phase',\n",
    "    'gesture',\n",
    "]\n",
    "META_DATA_COLUMNS = [\n",
    "    'row_id',\n",
    "    'sequence_type',\n",
    "    'sequence_id',\n",
    "    'sequence_counter',\n",
    "    'subject',\n",
    "    'orientation',\n",
    "    'behavior',\n",
    "    'phase',\n",
    "    'gesture',\n",
    "]\n",
    "DATASET_DF_DTYPES = {\n",
    "    \"acc_x\": \"float32\", \"acc_y\": \"float32\", \"acc_z\": \"float32\",\n",
    "    \"thm_1\":\"float32\", \"thm_2\":\"float32\", \"thm_3\":\"float32\", \"thm_4\":\"float32\", \"thm_5\":\"float32\",\n",
    "    \"sequence_counter\": \"int32\",\n",
    "    **{col: \"category\" for col in CATEGORY_COLUMNS},\n",
    "    **{f\"tof_{i_1}_v{i_2}\": \"float32\" for i_1, i_2 in product(range(1, 5), range(64))},\n",
    "}\n",
    "PREPROCESSED_DATASET_HANDLE = \"mauroabidalcarrer/prepocessed-cmi-2025\"\n",
    "# The quantile of the sequences len used to pad/truncate during preprocessing\n",
    "SEQUENCE_NORMED_LEN_QUANTILE = 0.95\n",
    "# SAMPLING_FREQUENCY = 10 #Hz\n",
    "N_FOLDS = 5\n",
    "VALIDATION_FRACTION = 0.2\n",
    "TARGET_NAMES = sorted([\n",
    "    \"Above ear - pull hair\",\n",
    "    \"Cheek - pinch skin\",\n",
    "    \"Eyebrow - pull hair\",\n",
    "    \"Eyelash - pull hair\",\n",
    "    \"Feel around in tray and pull out an object\",\n",
    "    \"Forehead - pull hairline\",\n",
    "    \"Forehead - scratch\",\n",
    "    \"Neck - pinch skin\",\n",
    "    \"Neck - scratch\",\n",
    "    \"Text on phone\",\n",
    "    \"Wave hello\",\n",
    "    \"Write name in air\",\n",
    "    \"Write name on leg\",\n",
    "    \"Drink from bottle/cup\",\n",
    "    \"Pinch knee/leg skin\",\n",
    "    \"Pull air toward your face\",\n",
    "    \"Scratch knee/leg skin\",\n",
    "    \"Glasses on/off\"\n",
    "])\n",
    "EPSILON=1e-8\n",
    "DELTA_ROTATION_ANGULAR_VELOCITY_COLS = [\"angular_vel_x\", \"angular_vel_y\", \"angular_vel_z\"]\n",
    "DELTA_ROTATION_AXES_COLS = [\"rotation_axis_x\", \"rotation_axis_y\", \"rotation_axis_z\"]\n",
    "EULER_ANGLES_COLS = [\"euler_x\", \"euler_y\", \"euler_z\"]\n",
    "TOF_AGG_FUNCS = [\n",
    "    \"mean\",\n",
    "    \"std\",\n",
    "    \"min\",\n",
    "    \"max\",\n",
    "    \"median\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4bfefa",
   "metadata": {},
   "source": [
    "### Define function to get the feature columns\n",
    "Feature columns change over time so it's better to have a function to get them than manually update a variable every time we add/remove features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3d40b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_cols(df:DF) -> list[str]:\n",
    "    return sorted(list(set(df.columns) - set(META_DATA_COLUMNS) - set(TARGET_NAMES)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eac0e5a",
   "metadata": {},
   "source": [
    "### Supress performance warngings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "086420e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    message=(\n",
    "        \"DataFrame is highly fragmented.  This is usually the result of \"\n",
    "        \"calling `frame.insert` many times.*\"\n",
    "    ),\n",
    "    category=pd.errors.PerformanceWarning,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7749c3bd",
   "metadata": {},
   "source": [
    "### device setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa7f99a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a563074",
   "metadata": {},
   "source": [
    "### Dataset Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a7f347",
   "metadata": {},
   "source": [
    "#### Dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2bc2e83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CMIDataset(TensorDataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        parent_dir: str,\n",
    "        split: Optional[Literal[\"train\", \"validation\"]]=None,\n",
    "        subset: Optional[int]=None,\n",
    "        force_download=False\n",
    "    ):\n",
    "        dataset_path = kagglehub.dataset_download(DATASET_HANDLE, force_download)\n",
    "        parent_dir = join(dataset_path, \"preprocessed_dataset\", parent_dir)\n",
    "        split = \"\" if split is None else split + \"_\"\n",
    "        x = np.load(join(parent_dir, f\"{split}X.npy\")).swapaxes(1, 2)\n",
    "        y = np.load(join(parent_dir, f\"{split}Y.npy\"))\n",
    "        if subset is not None:\n",
    "            x = x[:subset]\n",
    "            y = y[:subset]\n",
    "        super().__init__(\n",
    "            torch.from_numpy(x).to(device),\n",
    "            torch.from_numpy(y).to(device),\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da7064d",
   "metadata": {},
   "source": [
    "#### Meta data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5aae295d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acc_mag', 'acc_mag_diff', 'acc_x', 'acc_x_diff', 'acc_y', 'acc_y_diff', 'acc_z', 'acc_z_diff', 'angular_vel_x', 'angular_vel_x_diff', 'angular_vel_y', 'angular_vel_y_diff', 'angular_vel_z', 'angular_vel_z_diff', 'delta_rot_mag', 'delta_rot_mag_diff', 'euler_x', 'euler_x_diff', 'euler_y', 'euler_y_diff', 'euler_z', 'euler_z_diff', 'linear_acc_mag', 'linear_acc_mag_diff', 'linear_acc_x', 'linear_acc_x_diff', 'linear_acc_y', 'linear_acc_y_diff', 'linear_acc_z', 'linear_acc_z_diff', 'quat_rot_mag', 'quat_rot_mag_diff', 'rot_w', 'rot_w_diff', 'rot_x', 'rot_x_diff', 'rot_y', 'rot_y_diff', 'rot_z', 'rot_z_diff', 'rotation_axis_x', 'rotation_axis_x_diff', 'rotation_axis_y', 'rotation_axis_y_diff', 'rotation_axis_z', 'rotation_axis_z_diff', 'thm_1', 'thm_1_diff', 'thm_2', 'thm_2_diff', 'thm_3', 'thm_3_diff', 'thm_4', 'thm_4_diff', 'thm_5', 'thm_5_diff', 'tof_1_v0', 'tof_1_v0_diff', 'tof_1_v1', 'tof_1_v10', 'tof_1_v10_diff', 'tof_1_v11', 'tof_1_v11_diff', 'tof_1_v12', 'tof_1_v12_diff', 'tof_1_v13', 'tof_1_v13_diff', 'tof_1_v14', 'tof_1_v14_diff', 'tof_1_v15', 'tof_1_v15_diff', 'tof_1_v16', 'tof_1_v16_diff', 'tof_1_v17', 'tof_1_v17_diff', 'tof_1_v18', 'tof_1_v18_diff', 'tof_1_v19', 'tof_1_v19_diff', 'tof_1_v1_diff', 'tof_1_v2', 'tof_1_v20', 'tof_1_v20_diff', 'tof_1_v21', 'tof_1_v21_diff', 'tof_1_v22', 'tof_1_v22_diff', 'tof_1_v23', 'tof_1_v23_diff', 'tof_1_v24', 'tof_1_v24_diff', 'tof_1_v25', 'tof_1_v25_diff', 'tof_1_v26', 'tof_1_v26_diff', 'tof_1_v27', 'tof_1_v27_diff', 'tof_1_v28', 'tof_1_v28_diff', 'tof_1_v29', 'tof_1_v29_diff', 'tof_1_v2_diff', 'tof_1_v3', 'tof_1_v30', 'tof_1_v30_diff', 'tof_1_v31', 'tof_1_v31_diff', 'tof_1_v32', 'tof_1_v32_diff', 'tof_1_v33', 'tof_1_v33_diff', 'tof_1_v34', 'tof_1_v34_diff', 'tof_1_v35', 'tof_1_v35_diff', 'tof_1_v36', 'tof_1_v36_diff', 'tof_1_v37', 'tof_1_v37_diff', 'tof_1_v38', 'tof_1_v38_diff', 'tof_1_v39', 'tof_1_v39_diff', 'tof_1_v3_diff', 'tof_1_v4', 'tof_1_v40', 'tof_1_v40_diff', 'tof_1_v41', 'tof_1_v41_diff', 'tof_1_v42', 'tof_1_v42_diff', 'tof_1_v43', 'tof_1_v43_diff', 'tof_1_v44', 'tof_1_v44_diff', 'tof_1_v45', 'tof_1_v45_diff', 'tof_1_v46', 'tof_1_v46_diff', 'tof_1_v47', 'tof_1_v47_diff', 'tof_1_v48', 'tof_1_v48_diff', 'tof_1_v49', 'tof_1_v49_diff', 'tof_1_v4_diff', 'tof_1_v5', 'tof_1_v50', 'tof_1_v50_diff', 'tof_1_v51', 'tof_1_v51_diff', 'tof_1_v52', 'tof_1_v52_diff', 'tof_1_v53', 'tof_1_v53_diff', 'tof_1_v54', 'tof_1_v54_diff', 'tof_1_v55', 'tof_1_v55_diff', 'tof_1_v56', 'tof_1_v56_diff', 'tof_1_v57', 'tof_1_v57_diff', 'tof_1_v58', 'tof_1_v58_diff', 'tof_1_v59', 'tof_1_v59_diff', 'tof_1_v5_diff', 'tof_1_v6', 'tof_1_v60', 'tof_1_v60_diff', 'tof_1_v61', 'tof_1_v61_diff', 'tof_1_v62', 'tof_1_v62_diff', 'tof_1_v63', 'tof_1_v63_diff', 'tof_1_v6_diff', 'tof_1_v7', 'tof_1_v7_diff', 'tof_1_v8', 'tof_1_v8_diff', 'tof_1_v9', 'tof_1_v9_diff', 'tof_2_v0', 'tof_2_v0_diff', 'tof_2_v1', 'tof_2_v10', 'tof_2_v10_diff', 'tof_2_v11', 'tof_2_v11_diff', 'tof_2_v12', 'tof_2_v12_diff', 'tof_2_v13', 'tof_2_v13_diff', 'tof_2_v14', 'tof_2_v14_diff', 'tof_2_v15', 'tof_2_v15_diff', 'tof_2_v16', 'tof_2_v16_diff', 'tof_2_v17', 'tof_2_v17_diff', 'tof_2_v18', 'tof_2_v18_diff', 'tof_2_v19', 'tof_2_v19_diff', 'tof_2_v1_diff', 'tof_2_v2', 'tof_2_v20', 'tof_2_v20_diff', 'tof_2_v21', 'tof_2_v21_diff', 'tof_2_v22', 'tof_2_v22_diff', 'tof_2_v23', 'tof_2_v23_diff', 'tof_2_v24', 'tof_2_v24_diff', 'tof_2_v25', 'tof_2_v25_diff', 'tof_2_v26', 'tof_2_v26_diff', 'tof_2_v27', 'tof_2_v27_diff', 'tof_2_v28', 'tof_2_v28_diff', 'tof_2_v29', 'tof_2_v29_diff', 'tof_2_v2_diff', 'tof_2_v3', 'tof_2_v30', 'tof_2_v30_diff', 'tof_2_v31', 'tof_2_v31_diff', 'tof_2_v32', 'tof_2_v32_diff', 'tof_2_v33', 'tof_2_v33_diff', 'tof_2_v34', 'tof_2_v34_diff', 'tof_2_v35', 'tof_2_v35_diff', 'tof_2_v36', 'tof_2_v36_diff', 'tof_2_v37', 'tof_2_v37_diff', 'tof_2_v38', 'tof_2_v38_diff', 'tof_2_v39', 'tof_2_v39_diff', 'tof_2_v3_diff', 'tof_2_v4', 'tof_2_v40', 'tof_2_v40_diff', 'tof_2_v41', 'tof_2_v41_diff', 'tof_2_v42', 'tof_2_v42_diff', 'tof_2_v43', 'tof_2_v43_diff', 'tof_2_v44', 'tof_2_v44_diff', 'tof_2_v45', 'tof_2_v45_diff', 'tof_2_v46', 'tof_2_v46_diff', 'tof_2_v47', 'tof_2_v47_diff', 'tof_2_v48', 'tof_2_v48_diff', 'tof_2_v49', 'tof_2_v49_diff', 'tof_2_v4_diff', 'tof_2_v5', 'tof_2_v50', 'tof_2_v50_diff', 'tof_2_v51', 'tof_2_v51_diff', 'tof_2_v52', 'tof_2_v52_diff', 'tof_2_v53', 'tof_2_v53_diff', 'tof_2_v54', 'tof_2_v54_diff', 'tof_2_v55', 'tof_2_v55_diff', 'tof_2_v56', 'tof_2_v56_diff', 'tof_2_v57', 'tof_2_v57_diff', 'tof_2_v58', 'tof_2_v58_diff', 'tof_2_v59', 'tof_2_v59_diff', 'tof_2_v5_diff', 'tof_2_v6', 'tof_2_v60', 'tof_2_v60_diff', 'tof_2_v61', 'tof_2_v61_diff', 'tof_2_v62', 'tof_2_v62_diff', 'tof_2_v63', 'tof_2_v63_diff', 'tof_2_v6_diff', 'tof_2_v7', 'tof_2_v7_diff', 'tof_2_v8', 'tof_2_v8_diff', 'tof_2_v9', 'tof_2_v9_diff', 'tof_3_v0', 'tof_3_v0_diff', 'tof_3_v1', 'tof_3_v10', 'tof_3_v10_diff', 'tof_3_v11', 'tof_3_v11_diff', 'tof_3_v12', 'tof_3_v12_diff', 'tof_3_v13', 'tof_3_v13_diff', 'tof_3_v14', 'tof_3_v14_diff', 'tof_3_v15', 'tof_3_v15_diff', 'tof_3_v16', 'tof_3_v16_diff', 'tof_3_v17', 'tof_3_v17_diff', 'tof_3_v18', 'tof_3_v18_diff', 'tof_3_v19', 'tof_3_v19_diff', 'tof_3_v1_diff', 'tof_3_v2', 'tof_3_v20', 'tof_3_v20_diff', 'tof_3_v21', 'tof_3_v21_diff', 'tof_3_v22', 'tof_3_v22_diff', 'tof_3_v23', 'tof_3_v23_diff', 'tof_3_v24', 'tof_3_v24_diff', 'tof_3_v25', 'tof_3_v25_diff', 'tof_3_v26', 'tof_3_v26_diff', 'tof_3_v27', 'tof_3_v27_diff', 'tof_3_v28', 'tof_3_v28_diff', 'tof_3_v29', 'tof_3_v29_diff', 'tof_3_v2_diff', 'tof_3_v3', 'tof_3_v30', 'tof_3_v30_diff', 'tof_3_v31', 'tof_3_v31_diff', 'tof_3_v32', 'tof_3_v32_diff', 'tof_3_v33', 'tof_3_v33_diff', 'tof_3_v34', 'tof_3_v34_diff', 'tof_3_v35', 'tof_3_v35_diff', 'tof_3_v36', 'tof_3_v36_diff', 'tof_3_v37', 'tof_3_v37_diff', 'tof_3_v38', 'tof_3_v38_diff', 'tof_3_v39', 'tof_3_v39_diff', 'tof_3_v3_diff', 'tof_3_v4', 'tof_3_v40', 'tof_3_v40_diff', 'tof_3_v41', 'tof_3_v41_diff', 'tof_3_v42', 'tof_3_v42_diff', 'tof_3_v43', 'tof_3_v43_diff', 'tof_3_v44', 'tof_3_v44_diff', 'tof_3_v45', 'tof_3_v45_diff', 'tof_3_v46', 'tof_3_v46_diff', 'tof_3_v47', 'tof_3_v47_diff', 'tof_3_v48', 'tof_3_v48_diff', 'tof_3_v49', 'tof_3_v49_diff', 'tof_3_v4_diff', 'tof_3_v5', 'tof_3_v50', 'tof_3_v50_diff', 'tof_3_v51', 'tof_3_v51_diff', 'tof_3_v52', 'tof_3_v52_diff', 'tof_3_v53', 'tof_3_v53_diff', 'tof_3_v54', 'tof_3_v54_diff', 'tof_3_v55', 'tof_3_v55_diff', 'tof_3_v56', 'tof_3_v56_diff', 'tof_3_v57', 'tof_3_v57_diff', 'tof_3_v58', 'tof_3_v58_diff', 'tof_3_v59', 'tof_3_v59_diff', 'tof_3_v5_diff', 'tof_3_v6', 'tof_3_v60', 'tof_3_v60_diff', 'tof_3_v61', 'tof_3_v61_diff', 'tof_3_v62', 'tof_3_v62_diff', 'tof_3_v63', 'tof_3_v63_diff', 'tof_3_v6_diff', 'tof_3_v7', 'tof_3_v7_diff', 'tof_3_v8', 'tof_3_v8_diff', 'tof_3_v9', 'tof_3_v9_diff', 'tof_4_v0', 'tof_4_v0_diff', 'tof_4_v1', 'tof_4_v10', 'tof_4_v10_diff', 'tof_4_v11', 'tof_4_v11_diff', 'tof_4_v12', 'tof_4_v12_diff', 'tof_4_v13', 'tof_4_v13_diff', 'tof_4_v14', 'tof_4_v14_diff', 'tof_4_v15', 'tof_4_v15_diff', 'tof_4_v16', 'tof_4_v16_diff', 'tof_4_v17', 'tof_4_v17_diff', 'tof_4_v18', 'tof_4_v18_diff', 'tof_4_v19', 'tof_4_v19_diff', 'tof_4_v1_diff', 'tof_4_v2', 'tof_4_v20', 'tof_4_v20_diff', 'tof_4_v21', 'tof_4_v21_diff', 'tof_4_v22', 'tof_4_v22_diff', 'tof_4_v23', 'tof_4_v23_diff', 'tof_4_v24', 'tof_4_v24_diff', 'tof_4_v25', 'tof_4_v25_diff', 'tof_4_v26', 'tof_4_v26_diff', 'tof_4_v27', 'tof_4_v27_diff', 'tof_4_v28', 'tof_4_v28_diff', 'tof_4_v29', 'tof_4_v29_diff', 'tof_4_v2_diff', 'tof_4_v3', 'tof_4_v30', 'tof_4_v30_diff', 'tof_4_v31', 'tof_4_v31_diff', 'tof_4_v32', 'tof_4_v32_diff', 'tof_4_v33', 'tof_4_v33_diff', 'tof_4_v34', 'tof_4_v34_diff', 'tof_4_v35', 'tof_4_v35_diff', 'tof_4_v36', 'tof_4_v36_diff', 'tof_4_v37', 'tof_4_v37_diff', 'tof_4_v38', 'tof_4_v38_diff', 'tof_4_v39', 'tof_4_v39_diff', 'tof_4_v3_diff', 'tof_4_v4', 'tof_4_v40', 'tof_4_v40_diff', 'tof_4_v41', 'tof_4_v41_diff', 'tof_4_v42', 'tof_4_v42_diff', 'tof_4_v43', 'tof_4_v43_diff', 'tof_4_v44', 'tof_4_v44_diff', 'tof_4_v45', 'tof_4_v45_diff', 'tof_4_v46', 'tof_4_v46_diff', 'tof_4_v47', 'tof_4_v47_diff', 'tof_4_v48', 'tof_4_v48_diff', 'tof_4_v49', 'tof_4_v49_diff', 'tof_4_v4_diff', 'tof_4_v5', 'tof_4_v50', 'tof_4_v50_diff', 'tof_4_v51', 'tof_4_v51_diff', 'tof_4_v52', 'tof_4_v52_diff', 'tof_4_v53', 'tof_4_v53_diff', 'tof_4_v54', 'tof_4_v54_diff', 'tof_4_v55', 'tof_4_v55_diff', 'tof_4_v56', 'tof_4_v56_diff', 'tof_4_v57', 'tof_4_v57_diff', 'tof_4_v58', 'tof_4_v58_diff', 'tof_4_v59', 'tof_4_v59_diff', 'tof_4_v5_diff', 'tof_4_v6', 'tof_4_v60', 'tof_4_v60_diff', 'tof_4_v61', 'tof_4_v61_diff', 'tof_4_v62', 'tof_4_v62_diff', 'tof_4_v63', 'tof_4_v63_diff', 'tof_4_v6_diff', 'tof_4_v7', 'tof_4_v7_diff', 'tof_4_v8', 'tof_4_v8_diff', 'tof_4_v9', 'tof_4_v9_diff', 'tof_5_v0', 'tof_5_v0_diff', 'tof_5_v1', 'tof_5_v10', 'tof_5_v10_diff', 'tof_5_v11', 'tof_5_v11_diff', 'tof_5_v12', 'tof_5_v12_diff', 'tof_5_v13', 'tof_5_v13_diff', 'tof_5_v14', 'tof_5_v14_diff', 'tof_5_v15', 'tof_5_v15_diff', 'tof_5_v16', 'tof_5_v16_diff', 'tof_5_v17', 'tof_5_v17_diff', 'tof_5_v18', 'tof_5_v18_diff', 'tof_5_v19', 'tof_5_v19_diff', 'tof_5_v1_diff', 'tof_5_v2', 'tof_5_v20', 'tof_5_v20_diff', 'tof_5_v21', 'tof_5_v21_diff', 'tof_5_v22', 'tof_5_v22_diff', 'tof_5_v23', 'tof_5_v23_diff', 'tof_5_v24', 'tof_5_v24_diff', 'tof_5_v25', 'tof_5_v25_diff', 'tof_5_v26', 'tof_5_v26_diff', 'tof_5_v27', 'tof_5_v27_diff', 'tof_5_v28', 'tof_5_v28_diff', 'tof_5_v29', 'tof_5_v29_diff', 'tof_5_v2_diff', 'tof_5_v3', 'tof_5_v30', 'tof_5_v30_diff', 'tof_5_v31', 'tof_5_v31_diff', 'tof_5_v32', 'tof_5_v32_diff', 'tof_5_v33', 'tof_5_v33_diff', 'tof_5_v34', 'tof_5_v34_diff', 'tof_5_v35', 'tof_5_v35_diff', 'tof_5_v36', 'tof_5_v36_diff', 'tof_5_v37', 'tof_5_v37_diff', 'tof_5_v38', 'tof_5_v38_diff', 'tof_5_v39', 'tof_5_v39_diff', 'tof_5_v3_diff', 'tof_5_v4', 'tof_5_v40', 'tof_5_v40_diff', 'tof_5_v41', 'tof_5_v41_diff', 'tof_5_v42', 'tof_5_v42_diff', 'tof_5_v43', 'tof_5_v43_diff', 'tof_5_v44', 'tof_5_v44_diff', 'tof_5_v45', 'tof_5_v45_diff', 'tof_5_v46', 'tof_5_v46_diff', 'tof_5_v47', 'tof_5_v47_diff', 'tof_5_v48', 'tof_5_v48_diff', 'tof_5_v49', 'tof_5_v49_diff', 'tof_5_v4_diff', 'tof_5_v5', 'tof_5_v50', 'tof_5_v50_diff', 'tof_5_v51', 'tof_5_v51_diff', 'tof_5_v52', 'tof_5_v52_diff', 'tof_5_v53', 'tof_5_v53_diff', 'tof_5_v54', 'tof_5_v54_diff', 'tof_5_v55', 'tof_5_v55_diff', 'tof_5_v56', 'tof_5_v56_diff', 'tof_5_v57', 'tof_5_v57_diff', 'tof_5_v58', 'tof_5_v58_diff', 'tof_5_v59', 'tof_5_v59_diff', 'tof_5_v5_diff', 'tof_5_v6', 'tof_5_v60', 'tof_5_v60_diff', 'tof_5_v61', 'tof_5_v61_diff', 'tof_5_v62', 'tof_5_v62_diff', 'tof_5_v63', 'tof_5_v63_diff', 'tof_5_v6_diff', 'tof_5_v7', 'tof_5_v7_diff', 'tof_5_v8', 'tof_5_v8_diff', 'tof_5_v9', 'tof_5_v9_diff']\n",
      "non_imu_feats_idx: [46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695]\n",
      "imu_feats_idx: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45]\n"
     ]
    }
   ],
   "source": [
    "dataset_path = kagglehub.dataset_download(DATASET_HANDLE)\n",
    "meta_data_path = join(\n",
    "    dataset_path,\n",
    "    \"preprocessed_dataset\",\n",
    "    \"full_dataset_meta_data.json\"\n",
    ")\n",
    "with open(meta_data_path, \"r\") as fp:\n",
    "    meta_data = json.load(fp)\n",
    "# Convert target names into a ndarray to index it batchwise.\n",
    "is_thm_tof_feat = lambda feat: feat.startswith((\"thm\", \"tof\"))\n",
    "non_imu_feats_idx = [feat_idx for feat_idx, feat in enumerate(meta_data[\"feature_cols\"]) if is_thm_tof_feat(feat)]\n",
    "imu_feats_idx = [feat_idx for feat_idx, feat in enumerate(meta_data[\"feature_cols\"]) if not is_thm_tof_feat(feat)]\n",
    "print(meta_data[\"feature_cols\"])\n",
    "print(\"non_imu_feats_idx:\", non_imu_feats_idx)\n",
    "print(\"imu_feats_idx:\", imu_feats_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc6fe74",
   "metadata": {},
   "source": [
    "#### Compute class weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "74233c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_weighted_cross_entropy_loss(\n",
    "    dataset: Dataset[tuple[torch.Tensor, torch.Tensor]]\n",
    ") -> nn.CrossEntropyLoss:\n",
    "    \"\"\"\n",
    "    Computes class weights from a dataset with one-hot encoded targets and returns a CrossEntropyLoss with those weights.\n",
    "\n",
    "    Args:\n",
    "        dataset: A PyTorch Dataset that yields (x, y) where y is a one-hot encoded tensor of shape (num_classes,)\n",
    "\n",
    "    Returns:\n",
    "        A torch.nn.CrossEntropyLoss object with class weights based on inverse class frequency.\n",
    "    \"\"\"\n",
    "    class_counts: Counter = Counter()\n",
    "    num_samples = 0\n",
    "\n",
    "    for _, y in dataset:\n",
    "        class_idx = y.argmax().item()\n",
    "        class_counts[class_idx] += 1\n",
    "        num_samples += 1\n",
    "\n",
    "    num_classes = len(class_counts)\n",
    "    weights = torch.tensor(\n",
    "        [num_samples / class_counts[i] for i in range(num_classes)],\n",
    "        dtype=torch.float32,\n",
    "    )\n",
    "\n",
    "    # Optional: normalize weights so they sum to 1\n",
    "    weights = weights / weights.sum()\n",
    "\n",
    "    return nn.CrossEntropyLoss(weight=weights.to(device))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2161df0c",
   "metadata": {
    "papermill": {
     "duration": 0.00278,
     "end_time": "2025-06-14T10:01:12.877551",
     "exception": false,
     "start_time": "2025-06-14T10:01:12.874771",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### BFRBs indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e657c570",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T10:01:12.884365Z",
     "iopub.status.busy": "2025-06-14T10:01:12.883937Z",
     "iopub.status.idle": "2025-06-14T10:01:45.309186Z",
     "shell.execute_reply": "2025-06-14T10:01:45.308564Z"
    },
    "papermill": {
     "duration": 32.430139,
     "end_time": "2025-06-14T10:01:45.310511",
     "exception": false,
     "start_time": "2025-06-14T10:01:12.880372",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets...\n",
      "Train rows: 574945, Test rows: 107\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading datasets...\")\n",
    "competition_dataset_path = kagglehub.competition_download(COMPETITION_HANDLE)\n",
    "train_df = pd.read_csv(join(competition_dataset_path, \"train.csv\"))\n",
    "train_dem_df = pd.read_csv(join(competition_dataset_path, \"train_demographics.csv\"))\n",
    "test_df = pd.read_csv(join(competition_dataset_path, \"test.csv\"))\n",
    "test_dem_df = pd.read_csv(join(competition_dataset_path, \"test_demographics.csv\"))\n",
    "print(f\"Train rows: {len(train_df)}, Test rows: {len(test_df)}\")\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "train_df['gesture'] = label_encoder.fit_transform(train_df['gesture'].astype(str))\n",
    "gesture_classes = label_encoder.classes_\n",
    "\n",
    "bfrb_gestures = [\n",
    "    'Above ear - pull hair',\n",
    "    'Forehead - pull hairline',\n",
    "    'Forehead - scratch',\n",
    "    'Eyebrow - pull hair',\n",
    "    'Eyelash - pull hair',\n",
    "    'Neck - pinch skin',\n",
    "    'Neck - scratch',\n",
    "    'Cheek - pinch skin'\n",
    "]\n",
    "bfrb_indices = label_encoder.transform(bfrb_gestures)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de16cc1",
   "metadata": {},
   "source": [
    "### Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d3d46b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CosineAnnealingWarmupRestarts(_LRScheduler):\n",
    "    def __init__(\n",
    "        self,\n",
    "        optimizer: Optimizer,\n",
    "        warmup_steps: int,\n",
    "        max_lr: float,\n",
    "        min_lr: float,\n",
    "        cycle_length: int,\n",
    "        cycle_mult: float = 1.0,\n",
    "        gamma: float = 1.0,\n",
    "        last_epoch: int = -1,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            optimizer: Wrapped optimizer.\n",
    "            warmup_steps: Number of steps for linear warmup.\n",
    "            max_lr: Initial maximum learning rate.\n",
    "            min_lr: Minimum learning rate after decay.\n",
    "            cycle_length: Initial number of steps per cosine cycle.\n",
    "            cycle_mult: Multiplicative factor for increasing cycle lengths.\n",
    "            gamma: Multiplicative decay factor for max_lr after each cycle.\n",
    "            last_epoch: The index of last epoch. Default: -1.\n",
    "        \"\"\"\n",
    "        self.warmup_steps = warmup_steps\n",
    "        self.max_lr = max_lr\n",
    "        self.min_lr = min_lr\n",
    "        self.cycle_length = cycle_length\n",
    "        self.cycle_mult = cycle_mult\n",
    "        self.gamma = gamma\n",
    "\n",
    "        self.current_cycle = 0\n",
    "        self.cycle_step = 0\n",
    "        self.lr = max_lr\n",
    "\n",
    "        super().__init__(optimizer, last_epoch)\n",
    "\n",
    "    def get_lr(self) -> list[float]:\n",
    "        if self.last_epoch < self.warmup_steps:\n",
    "            # Linear warmup\n",
    "            scale = (self.last_epoch + 1) / self.warmup_steps\n",
    "            return [self.min_lr + scale * (self.max_lr - self.min_lr) for _ in self.base_lrs]\n",
    "\n",
    "        # Adjust for post-warmup step index\n",
    "        t = self.cycle_step\n",
    "        T = self.cycle_length\n",
    "\n",
    "        cosine_decay = 0.5 * (1 + math.cos(math.pi * t / T))\n",
    "        lr = self.min_lr + (self.max_lr - self.min_lr) * cosine_decay\n",
    "\n",
    "        return [lr for _ in self.base_lrs]\n",
    "\n",
    "    def step(self, epoch: Optional[int] = None) -> None:\n",
    "        if self.last_epoch >= self.warmup_steps:\n",
    "            self.cycle_step += 1\n",
    "            if self.cycle_step >= self.cycle_length:\n",
    "                self.current_cycle += 1\n",
    "                self.cycle_step = 0\n",
    "                self.cycle_length = max(int(self.cycle_length * self.cycle_mult), 1)\n",
    "                self.max_lr *= self.gamma\n",
    "        super().step(epoch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c54244a",
   "metadata": {},
   "source": [
    "## Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80ae01a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiScaleConvs(nn.Module):\n",
    "    def __init__(self, in_channels:int, kernel_sizes:list[int]):\n",
    "        super().__init__()\n",
    "        def mk_conv_block(k_size) -> nn.Sequential:\n",
    "            return nn.Sequential(\n",
    "                nn.Conv1d(in_channels, in_channels, k_size, padding=k_size // 2, groups=in_channels),\n",
    "                nn.BatchNorm1d(in_channels),\n",
    "                nn.ReLU(),\n",
    "            )\n",
    "        self.convs = nn.ModuleList(map(mk_conv_block, kernel_sizes))\n",
    "\n",
    "    def forward(self, x:Tensor) -> Tensor:\n",
    "        yes = torch.cat([conv(x) for conv in self.convs] + [x], dim=1)\n",
    "        # print(\"stem output shape:\", yes.shape)\n",
    "        return yes\n",
    "\n",
    "class SqueezeExcitationBlock(nn.Module):\n",
    "    # Copy/paste of https://www.kaggle.com/code/wasupandceacar/lb-0-82-5fold-single-bert-model#Model implementation\n",
    "    def __init__(self, channels:int, reduction:int=8):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(channels, channels // reduction, bias=True)\n",
    "        self.fc2 = nn.Linear(channels // reduction, channels, bias=True)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, C, L)\n",
    "        se = F.adaptive_avg_pool1d(x, 1).squeeze(-1)      # -> (B, C)\n",
    "        se = F.relu(self.fc1(se), inplace=True)          # -> (B, C//r)\n",
    "        se = self.sigmoid(self.fc2(se)).unsqueeze(-1)    # -> (B, C, 1)\n",
    "        return x * se\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_chns:int, out_chns:int, dropout_ratio:float=0.3, se_reduction:int=8, kernel_size:int=3):\n",
    "        super().__init__()\n",
    "        self.blocks = nn.Sequential(\n",
    "            nn.Conv1d(in_chns, out_chns, kernel_size=kernel_size, padding=kernel_size // 2, bias=False),\n",
    "            nn.BatchNorm1d(out_chns),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(out_chns, out_chns, kernel_size=kernel_size, padding=kernel_size // 2, bias=False),\n",
    "            nn.BatchNorm1d(out_chns),\n",
    "            SqueezeExcitationBlock(out_chns, se_reduction),\n",
    "        )\n",
    "        self.head = nn.Sequential(nn.ReLU(), nn.Dropout(dropout_ratio))\n",
    "        if in_chns == out_chns:\n",
    "            self.skip_connection = nn.Identity() \n",
    "        else:\n",
    "            # TODO: set bias to False ?\n",
    "            self.skip_connection = nn.Sequential(\n",
    "                nn.Conv1d(in_chns, out_chns, 1, bias=False),\n",
    "                nn.BatchNorm1d(out_chns)\n",
    "            )\n",
    "            self.head.insert(1, nn.MaxPool1d(2))\n",
    "\n",
    "    def forward(self, x:Tensor) -> Tensor:\n",
    "        activaition_maps = self.skip_connection(x) + self.blocks(x)\n",
    "        return self.head(activaition_maps)\n",
    "\n",
    "class MBConvBlock(nn.Module):\n",
    "    # From this schema: https://media.licdn.com/dms/image/v2/D5612AQFjbDOm5uyxdw/article-inline_image-shrink_1500_2232/article-inline_image-shrink_1500_2232/0/1683677500817?e=1758153600&v=beta&t=n48_UW5TZTyDPhRFlJXSidUQQPQpuC756M0kNeKmYTY\n",
    "    def __init__(self, in_chns:int, out_chns:int, se_reduction:int=8, expansion_ratio:int=4, dropout_ratio:float=0.3):\n",
    "        super().__init__()\n",
    "        expanded_channels = in_chns * expansion_ratio\n",
    "        self.blocks = nn.Sequential(\n",
    "            nn.Conv1d(in_chns, expanded_channels, kernel_size=1, bias=False),\n",
    "            nn.BatchNorm1d(expanded_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(\n",
    "                expanded_channels,\n",
    "                expanded_channels,\n",
    "                kernel_size=3,\n",
    "                padding=1,\n",
    "                groups=expanded_channels,\n",
    "                bias=False,\n",
    "            ),\n",
    "            nn.BatchNorm1d(expanded_channels),\n",
    "            nn.ReLU(),\n",
    "            SqueezeExcitationBlock(expanded_channels, se_reduction),\n",
    "            nn.Conv1d(expanded_channels, out_chns, kernel_size=1, bias=False)\n",
    "        )\n",
    "        self.head = nn.Sequential(\n",
    "            nn.BatchNorm1d(out_chns)\n",
    "            # nn.ReLU(),\n",
    "            # nn.Dropout(dropout_ratio),\n",
    "        )\n",
    "        if in_chns == out_chns:\n",
    "            self.skip_connection = nn.Identity() \n",
    "        else:\n",
    "            # TODO: set bias to False ?\n",
    "            self.skip_connection = nn.Sequential(\n",
    "                nn.Conv1d(in_chns, out_chns, 1, bias=False),\n",
    "                nn.BatchNorm1d(out_chns)\n",
    "            )\n",
    "            self.head.add_module(\"max_pool\", nn.MaxPool1d(2))\n",
    "            \n",
    "    def forward(self, x:Tensor) -> Tensor:\n",
    "        activaition_maps = self.skip_connection(x) + self.blocks(x)\n",
    "        return self.head(activaition_maps)\n",
    "\n",
    "class AdditiveAttentionLayer(nn.Module):\n",
    "    # Copied (and slightly modified) from https://www.kaggle.com/code/myso1987/cmi3-pyroch-baseline-model-add-aug-folds\n",
    "    def __init__(self, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.attention = nn.Linear(hidden_dim, 1, bias=True)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        # x shape: (batch, channels, seq_len)\n",
    "        x = x.swapaxes(1, 2)\n",
    "        # x shape: (batch, seq_len, hidden_dim)\n",
    "        scores = torch.tanh(self.attention(x))  # (batch, seq_len, 1)\n",
    "        weights = F.softmax(scores.squeeze(-1), dim=1)  # (batch, seq_len)\n",
    "        context = torch.sum(x * weights.unsqueeze(-1), dim=1)  # (batch, hidden_dim)\n",
    "        return context\n",
    "\n",
    "class CMIHARModule(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            imu_idx:list[int],\n",
    "            tof_thm_idx:list[int],\n",
    "            mlp_width:int,\n",
    "            n_class:int,            \n",
    "            tof_thm_dropout_ratio:float=0,\n",
    "        ):\n",
    "        super().__init__()\n",
    "        self.imu_idx = imu_idx\n",
    "        self.tof_thm_idx = tof_thm_idx\n",
    "        self.imu_branch = nn.Sequential(\n",
    "            ResidualBlock(len(imu_idx), 64),\n",
    "            ResidualBlock(64, 128),\n",
    "        )\n",
    "        self.tof_and_thm_branch = nn.Sequential(\n",
    "            nn.Conv1d(len(tof_thm_idx), 64, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.MaxPool1d(2),\n",
    "            nn.Dropout(tof_thm_dropout_ratio),\n",
    "            nn.Conv1d(64, 128, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.MaxPool1d(2),\n",
    "            nn.Dropout(tof_thm_dropout_ratio),\n",
    "        )\n",
    "        self.lstm = nn.GRU(128 * 2, mlp_width // 2, bidirectional=True)\n",
    "        self.attention = AdditiveAttentionLayer(mlp_width)\n",
    "        self.head = nn.Sequential(\n",
    "            # Head\n",
    "            nn.LazyLinear(mlp_width, bias=False),\n",
    "            nn.BatchNorm1d(mlp_width),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(mlp_width, mlp_width // 2, bias=False),\n",
    "            nn.BatchNorm1d(mlp_width // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(mlp_width // 2, n_class),\n",
    "        )\n",
    "\n",
    "    def forward(self, x:Tensor) -> Tensor:\n",
    "        imu_activation_maps = self.imu_branch(x[:, self.imu_idx])\n",
    "        tof_thm_activation_maps = self.tof_and_thm_branch(x[:, self.tof_thm_idx])\n",
    "        concatenated_activation_maps = torch.cat((imu_activation_maps, tof_thm_activation_maps), 1)\n",
    "        lstm_output, _  = self.lstm(concatenated_activation_maps.swapaxes(1, 2))\n",
    "        lstm_output = lstm_output.swapaxes(1, 2) # redundant\n",
    "        attended = self.attention(lstm_output)\n",
    "        return self.head(attended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b1c8de6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(imu_feats_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc08e41",
   "metadata": {},
   "source": [
    "### Create model function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "36e3e463",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CMIHARModule(\n",
       "  (imu_branch): Sequential(\n",
       "    (0): ResidualBlock(\n",
       "      (blocks): Sequential(\n",
       "        (0): Conv1d(46, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "        (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): SqueezeExcitationBlock(\n",
       "          (fc1): Linear(in_features=64, out_features=8, bias=True)\n",
       "          (fc2): Linear(in_features=8, out_features=64, bias=True)\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (head): Sequential(\n",
       "        (0): ReLU()\n",
       "        (1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (2): Dropout(p=0.3, inplace=False)\n",
       "      )\n",
       "      (skip_connection): Sequential(\n",
       "        (0): Conv1d(46, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): ResidualBlock(\n",
       "      (blocks): Sequential(\n",
       "        (0): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "        (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): SqueezeExcitationBlock(\n",
       "          (fc1): Linear(in_features=128, out_features=16, bias=True)\n",
       "          (fc2): Linear(in_features=16, out_features=128, bias=True)\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (head): Sequential(\n",
       "        (0): ReLU()\n",
       "        (1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (2): Dropout(p=0.3, inplace=False)\n",
       "      )\n",
       "      (skip_connection): Sequential(\n",
       "        (0): Conv1d(64, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (tof_and_thm_branch): Sequential(\n",
       "    (0): Conv1d(650, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Dropout(p=0, inplace=False)\n",
       "    (4): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "    (5): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (7): Dropout(p=0, inplace=False)\n",
       "  )\n",
       "  (lstm): GRU(256, 128, bidirectional=True)\n",
       "  (attention): AdditiveAttentionLayer(\n",
       "    (attention): Linear(in_features=256, out_features=1, bias=True)\n",
       "  )\n",
       "  (head): Sequential(\n",
       "    (0): LazyLinear(in_features=0, out_features=256, bias=False)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=128, bias=False)\n",
       "    (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=128, out_features=18, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input channels: 696\n"
     ]
    }
   ],
   "source": [
    "def mk_model() -> nn.Module:\n",
    "    return (\n",
    "        CMIHARModule(\n",
    "            imu_idx=imu_feats_idx,\n",
    "            tof_thm_idx=non_imu_feats_idx,\n",
    "            mlp_width=256,\n",
    "            n_class=18,\n",
    "        )\n",
    "        .to(device)\n",
    "    )\n",
    "\n",
    "display(mk_model())\n",
    "print(\"input channels:\", len(meta_data[\"feature_cols\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8afc6e79",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a69ec966",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(epochs:int,\n",
    "        model: nn.Module,\n",
    "        scheduler: LRScheduler,\n",
    "        optimizer: torch.optim.Optimizer,\n",
    "        train_loader: DL,\n",
    "        criterion: callable=nn.L1Loss(),\n",
    "        evaluation_func: callable=None,\n",
    "        validation_loader: DL=None,\n",
    "        save_checkpoints=True,\n",
    "    ) -> tuple[DF, str]:\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "        (training_metrics, path_to_checkpoints)\n",
    "    \"\"\"\n",
    "    # Setup\n",
    "    metrics: list[dict] = []\n",
    "    step = 0\n",
    "    model_device = next(model.parameters()).device\n",
    "    last_epoch_metric = {}\n",
    "    # Training loop\n",
    "    with Progress() as progress:\n",
    "        task: Task = progress.add_task(\n",
    "            \"training...\",\n",
    "            total=len(train_loader),\n",
    "        )\n",
    "        for epoch in range(epochs):\n",
    "            progress.update(\n",
    "                task,\n",
    "                description=f\"epoch: {epoch}\",\n",
    "                completed=0,\n",
    "            )\n",
    "            total_epoch_loss = 0\n",
    "            total_accuracy = 0\n",
    "            for batch_idx, (x, y) in enumerate(train_loader):\n",
    "                # forward\n",
    "                x = x.to(model_device)\n",
    "                y = y.to(model_device)\n",
    "                model.train()\n",
    "                optimizer.zero_grad()\n",
    "                y_pred: Tensor = model(x)\n",
    "                loss_value = criterion(y_pred, y)\n",
    "                # Verify loss value\n",
    "                if torch.isnan(loss_value).any().item():\n",
    "                    progress.print(\"Warning: Got NaN loss, stopped training.\")\n",
    "                    return DF.from_records(metrics)\n",
    "                if torch.isinf(loss_value).any().item():\n",
    "                    progress.print(\"Warning: Got infinite loss, stopped training.\")\n",
    "                    return DF.from_records(metrics)\n",
    "                # TODO: Use gradient clipping?\n",
    "                loss_value.backward()\n",
    "                optimizer.step()\n",
    "                if step > 0: # If it's not the first training step, idk why it throws an error otherwise\n",
    "                    scheduler.step()\n",
    "                # metrics\n",
    "                total_epoch_loss += loss_value.item()\n",
    "                metrics.append({\n",
    "                    \"step\": step,\n",
    "                    \"epoch\": epoch,\n",
    "                    \"batch_train_loss\": loss_value.item(),\n",
    "                    \"lr\": optimizer.state_dict()[\"param_groups\"][-1][\"lr\"],\n",
    "                })\n",
    "                step += 1\n",
    "                if \"validation_accuracy\" in last_epoch_metric:\n",
    "                    last_validation_acc = \"%.2f\" % last_epoch_metric[\"validation_accuracy\"]\n",
    "                    val_acc_str = \"val. acc: \" + last_validation_acc\n",
    "                else:\n",
    "                    val_acc_str = \"\"\n",
    "                progress.update(\n",
    "                    task,\n",
    "                    advance=1,\n",
    "                    description=f\"epoch: {epoch}, batch_loss: {(total_epoch_loss / (batch_idx+1)):.2f}, {val_acc_str}\"\n",
    "                )\n",
    "            # Post epoch evalution\n",
    "            metrics[-1][\"train_epoch_loss\"] = total_epoch_loss / len(train_loader)\n",
    "            metrics[-1][\"train_epoch_accuracy\"] = total_accuracy / len(train_loader)\n",
    "            if evaluation_func:\n",
    "                progress.update(\n",
    "                    task,\n",
    "                    completed=0,\n",
    "                    description=f\"epoch: {epoch}, evaluating...\"\n",
    "                )\n",
    "                eval_metrics = evaluation_func(model, criterion, validation_loader)\n",
    "                metrics[-1].update(eval_metrics)\n",
    "            last_epoch_metric = metrics[-1]\n",
    "\n",
    "    return DF.from_records(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a490227",
   "metadata": {},
   "source": [
    "### Create model and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "34cd5bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mk_model_and_fit(\n",
    "        train_loader:DL,\n",
    "        mk_scheduler:callable,\n",
    "        epochs:int,\n",
    "        validation_loader:Optional[DL]=None,\n",
    "        save_checkpoints=False,\n",
    "        criterion=nn.CrossEntropyLoss()\n",
    "    ) -> tuple[nn.Module, DF, list[str]]:\n",
    "    model = mk_model()\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), WARMUP_LR_INIT)\n",
    "    lr_scheduler = mk_scheduler(optimizer)\n",
    "    training_metrics = fit(\n",
    "        epochs=epochs,\n",
    "        model=model,\n",
    "        scheduler=lr_scheduler,\n",
    "        optimizer=optimizer,\n",
    "        train_loader=train_loader,\n",
    "        criterion=criterion,\n",
    "        # evaluation_func=evaluate_model if validation_loader else None,\n",
    "        validation_loader=validation_loader,\n",
    "        save_checkpoints=save_checkpoints,\n",
    "    )\n",
    "\n",
    "    return model, training_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60b2c5d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9256152c",
   "metadata": {},
   "source": [
    "## Search max learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "40b0c8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_process_mock_training_metrics(training_metrics:DF) -> DF:\n",
    "    training_metrics = (\n",
    "        training_metrics\n",
    "        .query(\"batch_train_loss.notna()\")\n",
    "        .set_index(\"lr\", drop=False)\n",
    "        .sort_index()\n",
    "    )\n",
    "    training_metrics[\"ewm_batch_train_loss\"] = (\n",
    "        training_metrics\n",
    "        .ewm(com=30, ignore_na=False)\n",
    "        [\"batch_train_loss\"]\n",
    "        .mean()\n",
    "    )\n",
    "    training_metrics[\"ewm_batch_train_loss_diff\"] = training_metrics[\"ewm_batch_train_loss\"].diff()\n",
    "    return training_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7c231028",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plt_lr_search_training_metrics(training_metrics:DF):\n",
    "    (    \n",
    "        px.line(\n",
    "            (\n",
    "                training_metrics\n",
    "                .reset_index(drop=True)\n",
    "                .melt(\n",
    "                    id_vars=\"lr\",\n",
    "                    value_vars=[\n",
    "                        \"batch_train_loss\",\n",
    "                        \"ewm_batch_train_loss\",\n",
    "                        # \"ewm_batch_train_loss_diff\",\n",
    "                    ],\n",
    "                )\n",
    "            ),\n",
    "            x=\"lr\",\n",
    "            facet_row=\"variable\",\n",
    "            y=\"value\",\n",
    "            log_x=True,\n",
    "            log_y=True,\n",
    "            height=750,\n",
    "        )\n",
    "        .update_yaxes(matches=None)\n",
    "        .show()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e9ae0c04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8aa03e9ff7764eaebba8216a954b0329",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "variable=batch_train_loss<br>lr=%{x}<br>value=%{y}<extra></extra>",
         "legendgroup": "",
         "line": {
          "color": "#636efa",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "",
         "orientation": "v",
         "showlegend": false,
         "type": "scatter",
         "x": {
          "bdata": "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",
          "dtype": "f8"
         },
         "xaxis": "x2",
         "y": {
          "bdata": "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",
          "dtype": "f8"
         },
         "yaxis": "y2"
        },
        {
         "hovertemplate": "variable=ewm_batch_train_loss<br>lr=%{x}<br>value=%{y}<extra></extra>",
         "legendgroup": "",
         "line": {
          "color": "#636efa",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "",
         "orientation": "v",
         "showlegend": false,
         "type": "scatter",
         "x": {
          "bdata": "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",
          "dtype": "f8"
         },
         "xaxis": "x",
         "y": {
          "bdata": "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",
          "dtype": "f8"
         },
         "yaxis": "y"
        }
       ],
       "layout": {
        "annotations": [
         {
          "font": {},
          "showarrow": false,
          "text": "variable=ewm_batch_train_loss",
          "textangle": 90,
          "x": 0.98,
          "xanchor": "left",
          "xref": "paper",
          "y": 0.2425,
          "yanchor": "middle",
          "yref": "paper"
         },
         {
          "font": {},
          "showarrow": false,
          "text": "variable=batch_train_loss",
          "textangle": 90,
          "x": 0.98,
          "xanchor": "left",
          "xref": "paper",
          "y": 0.7575000000000001,
          "yanchor": "middle",
          "yref": "paper"
         }
        ],
        "height": 750,
        "legend": {
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          0.98
         ],
         "title": {
          "text": "lr"
         },
         "type": "log"
        },
        "xaxis2": {
         "anchor": "y2",
         "domain": [
          0,
          0.98
         ],
         "matches": "x",
         "showticklabels": false,
         "type": "log"
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          0.485
         ],
         "title": {
          "text": "value"
         },
         "type": "log"
        },
        "yaxis2": {
         "anchor": "x2",
         "domain": [
          0.515,
          1
         ],
         "title": {
          "text": "value"
         },
         "type": "log"
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum learning rate: 0.0019571500100869057\n"
     ]
    }
   ],
   "source": [
    "train_dataset = CMIDataset(\"full_dataset\")\n",
    "full_dataset_loader = DL(train_dataset, TRAIN_BATCH_SIZE, shuffle=True)\n",
    "_, mock_training_metrics = mk_model_and_fit(\n",
    "    full_dataset_loader,\n",
    "    partial(torch.optim.lr_scheduler.ExponentialLR, gamma=MOCK_TRAINING_GAMMA),\n",
    "    MOCK_TRAINING_EPOCHS,\n",
    "    criterion= nn.CrossEntropyLoss(label_smoothing=0.1),\n",
    ")\n",
    "mock_training_metrics = post_process_mock_training_metrics(mock_training_metrics)\n",
    "plt_lr_search_training_metrics(mock_training_metrics)\n",
    "max_lr = mock_training_metrics[\"ewm_batch_train_loss\"].idxmin()\n",
    "print(\"Maximum learning rate:\", max_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1cc3c5f",
   "metadata": {
    "papermill": {
     "duration": 0.003108,
     "end_time": "2025-06-14T10:01:56.186803",
     "exception": false,
     "start_time": "2025-06-14T10:01:56.183695",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "81f397f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixup_data(x, y, alpha=0.2):\n",
    "    \"\"\"\n",
    "    Return mixed inputs and mixed targets (one-hot) for mixup.\n",
    "    x: Tensor of shape (batch_size, features, seq_len)\n",
    "    y: Tensor of shape (batch_size, num_classes)\n",
    "    \"\"\"\n",
    "    if alpha > 0:\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "    else:\n",
    "        lam = 1.0\n",
    "    batch_size = x.size(0)\n",
    "    index = torch.randperm(batch_size).to(x.device)\n",
    "\n",
    "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "    mixed_y = lam * y + (1 - lam) * y[index, :]\n",
    "    return mixed_x, mixed_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2be28a9c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T10:01:56.194003Z",
     "iopub.status.busy": "2025-06-14T10:01:56.193740Z",
     "iopub.status.idle": "2025-06-14T10:09:14.752385Z",
     "shell.execute_reply": "2025-06-14T10:09:14.751491Z"
    },
    "papermill": {
     "duration": 438.563878,
     "end_time": "2025-06-14T10:09:14.753712",
     "exception": false,
     "start_time": "2025-06-14T10:01:56.189834",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training: 1\n",
      "\n",
      "==================================================\n",
      "Fold 1/5\n",
      "Epoch 01: Binary F1 = 0.6970, Macro F1 = 0.2212, Final Metric = 0.4591\n",
      "  New best metric! Saving model...\n",
      "Epoch 02: Binary F1 = 0.8838, Macro F1 = 0.3250, Final Metric = 0.6044\n",
      "  New best metric! Saving model...\n",
      "Epoch 03: Binary F1 = 0.8951, Macro F1 = 0.3483, Final Metric = 0.6217\n",
      "  New best metric! Saving model...\n",
      "Epoch 04: Binary F1 = 0.8712, Macro F1 = 0.3935, Final Metric = 0.6324\n",
      "  New best metric! Saving model...\n",
      "Epoch 05: Binary F1 = 0.9163, Macro F1 = 0.4187, Final Metric = 0.6675\n",
      "  New best metric! Saving model...\n",
      "Epoch 06: Binary F1 = 0.9194, Macro F1 = 0.4279, Final Metric = 0.6737\n",
      "  New best metric! Saving model...\n",
      "Epoch 07: Binary F1 = 0.9130, Macro F1 = 0.4123, Final Metric = 0.6626\n",
      "Epoch 08: Binary F1 = 0.9184, Macro F1 = 0.4483, Final Metric = 0.6833\n",
      "  New best metric! Saving model...\n",
      "Epoch 09: Binary F1 = 0.9174, Macro F1 = 0.4462, Final Metric = 0.6818\n",
      "Epoch 10: Binary F1 = 0.9183, Macro F1 = 0.4249, Final Metric = 0.6716\n",
      "Epoch 11: Binary F1 = 0.9180, Macro F1 = 0.4281, Final Metric = 0.6731\n",
      "Epoch 12: Binary F1 = 0.8995, Macro F1 = 0.4386, Final Metric = 0.6691\n",
      "Epoch 13: Binary F1 = 0.9071, Macro F1 = 0.4411, Final Metric = 0.6741\n",
      "Epoch 14: Binary F1 = 0.9119, Macro F1 = 0.4446, Final Metric = 0.6783\n",
      "Epoch 15: Binary F1 = 0.8978, Macro F1 = 0.4172, Final Metric = 0.6575\n",
      "Epoch 16: Binary F1 = 0.9168, Macro F1 = 0.4377, Final Metric = 0.6772\n",
      "Early stopping triggered at epoch 16\n",
      "\n",
      "Fold 1 completed.\n",
      "Final validation metrics - Binary F1: 0.9168, Macro F1: 0.4377, Final: 0.6772\n",
      "Best validation metrics - Binary F1: 0.9184, Macro F1: 0.4483, Final: 0.6833\n",
      "training: 2\n",
      "\n",
      "==================================================\n",
      "Fold 2/5\n",
      "Epoch 01: Binary F1 = 0.7707, Macro F1 = 0.2242, Final Metric = 0.4975\n",
      "  New best metric! Saving model...\n",
      "Epoch 02: Binary F1 = 0.8736, Macro F1 = 0.3233, Final Metric = 0.5985\n",
      "  New best metric! Saving model...\n",
      "Epoch 03: Binary F1 = 0.9062, Macro F1 = 0.3715, Final Metric = 0.6388\n",
      "  New best metric! Saving model...\n",
      "Epoch 04: Binary F1 = 0.8961, Macro F1 = 0.3857, Final Metric = 0.6409\n",
      "  New best metric! Saving model...\n",
      "Epoch 05: Binary F1 = 0.8761, Macro F1 = 0.4098, Final Metric = 0.6430\n",
      "  New best metric! Saving model...\n",
      "Epoch 06: Binary F1 = 0.9177, Macro F1 = 0.3897, Final Metric = 0.6537\n",
      "  New best metric! Saving model...\n",
      "Epoch 07: Binary F1 = 0.9228, Macro F1 = 0.4374, Final Metric = 0.6801\n",
      "  New best metric! Saving model...\n",
      "Epoch 08: Binary F1 = 0.9179, Macro F1 = 0.4317, Final Metric = 0.6748\n",
      "Epoch 09: Binary F1 = 0.9244, Macro F1 = 0.4296, Final Metric = 0.6770\n",
      "Epoch 10: Binary F1 = 0.9284, Macro F1 = 0.4308, Final Metric = 0.6796\n",
      "Epoch 11: Binary F1 = 0.9141, Macro F1 = 0.4157, Final Metric = 0.6649\n",
      "Epoch 12: Binary F1 = 0.9321, Macro F1 = 0.4214, Final Metric = 0.6768\n",
      "Epoch 13: Binary F1 = 0.9221, Macro F1 = 0.4293, Final Metric = 0.6757\n",
      "Epoch 14: Binary F1 = 0.9221, Macro F1 = 0.4289, Final Metric = 0.6755\n",
      "Epoch 15: Binary F1 = 0.9268, Macro F1 = 0.4266, Final Metric = 0.6767\n",
      "Early stopping triggered at epoch 15\n",
      "\n",
      "Fold 2 completed.\n",
      "Final validation metrics - Binary F1: 0.9268, Macro F1: 0.4266, Final: 0.6767\n",
      "Best validation metrics - Binary F1: 0.9228, Macro F1: 0.4374, Final: 0.6801\n",
      "training: 3\n",
      "\n",
      "==================================================\n",
      "Fold 3/5\n",
      "Epoch 01: Binary F1 = 0.5806, Macro F1 = 0.1881, Final Metric = 0.3843\n",
      "  New best metric! Saving model...\n",
      "Epoch 02: Binary F1 = 0.8887, Macro F1 = 0.2670, Final Metric = 0.5779\n",
      "  New best metric! Saving model...\n",
      "Epoch 03: Binary F1 = 0.8849, Macro F1 = 0.3396, Final Metric = 0.6122\n",
      "  New best metric! Saving model...\n",
      "Epoch 04: Binary F1 = 0.8983, Macro F1 = 0.3533, Final Metric = 0.6258\n",
      "  New best metric! Saving model...\n",
      "Epoch 05: Binary F1 = 0.8808, Macro F1 = 0.3599, Final Metric = 0.6203\n",
      "Epoch 06: Binary F1 = 0.8972, Macro F1 = 0.3790, Final Metric = 0.6381\n",
      "  New best metric! Saving model...\n",
      "Epoch 07: Binary F1 = 0.8984, Macro F1 = 0.3659, Final Metric = 0.6321\n",
      "Epoch 08: Binary F1 = 0.9038, Macro F1 = 0.3908, Final Metric = 0.6473\n",
      "  New best metric! Saving model...\n",
      "Epoch 09: Binary F1 = 0.8946, Macro F1 = 0.3844, Final Metric = 0.6395\n",
      "Epoch 10: Binary F1 = 0.9132, Macro F1 = 0.4007, Final Metric = 0.6570\n",
      "  New best metric! Saving model...\n",
      "Epoch 11: Binary F1 = 0.9080, Macro F1 = 0.3738, Final Metric = 0.6409\n",
      "Epoch 12: Binary F1 = 0.9101, Macro F1 = 0.3728, Final Metric = 0.6414\n",
      "Epoch 13: Binary F1 = 0.9038, Macro F1 = 0.3825, Final Metric = 0.6431\n",
      "Epoch 14: Binary F1 = 0.9051, Macro F1 = 0.3921, Final Metric = 0.6486\n",
      "Epoch 15: Binary F1 = 0.9006, Macro F1 = 0.3759, Final Metric = 0.6383\n",
      "Epoch 16: Binary F1 = 0.8980, Macro F1 = 0.3843, Final Metric = 0.6411\n",
      "Epoch 17: Binary F1 = 0.9071, Macro F1 = 0.3816, Final Metric = 0.6444\n",
      "Epoch 18: Binary F1 = 0.9104, Macro F1 = 0.3731, Final Metric = 0.6417\n",
      "Early stopping triggered at epoch 18\n",
      "\n",
      "Fold 3 completed.\n",
      "Final validation metrics - Binary F1: 0.9104, Macro F1: 0.3731, Final: 0.6417\n",
      "Best validation metrics - Binary F1: 0.9132, Macro F1: 0.4007, Final: 0.6570\n",
      "training: 4\n",
      "\n",
      "==================================================\n",
      "Fold 4/5\n",
      "Epoch 01: Binary F1 = 0.7068, Macro F1 = 0.1974, Final Metric = 0.4521\n",
      "  New best metric! Saving model...\n",
      "Epoch 02: Binary F1 = 0.8811, Macro F1 = 0.2744, Final Metric = 0.5778\n",
      "  New best metric! Saving model...\n",
      "Epoch 03: Binary F1 = 0.9007, Macro F1 = 0.3303, Final Metric = 0.6155\n",
      "  New best metric! Saving model...\n",
      "Epoch 04: Binary F1 = 0.9144, Macro F1 = 0.3719, Final Metric = 0.6431\n",
      "  New best metric! Saving model...\n",
      "Epoch 05: Binary F1 = 0.9072, Macro F1 = 0.3770, Final Metric = 0.6421\n",
      "Epoch 06: Binary F1 = 0.9210, Macro F1 = 0.3920, Final Metric = 0.6565\n",
      "  New best metric! Saving model...\n",
      "Epoch 07: Binary F1 = 0.9228, Macro F1 = 0.4057, Final Metric = 0.6643\n",
      "  New best metric! Saving model...\n",
      "Epoch 08: Binary F1 = 0.9210, Macro F1 = 0.4157, Final Metric = 0.6684\n",
      "  New best metric! Saving model...\n",
      "Epoch 09: Binary F1 = 0.9199, Macro F1 = 0.4155, Final Metric = 0.6677\n",
      "Epoch 10: Binary F1 = 0.9084, Macro F1 = 0.3678, Final Metric = 0.6381\n",
      "Epoch 11: Binary F1 = 0.9215, Macro F1 = 0.3973, Final Metric = 0.6594\n",
      "Epoch 12: Binary F1 = 0.9254, Macro F1 = 0.4181, Final Metric = 0.6718\n",
      "  New best metric! Saving model...\n",
      "Epoch 13: Binary F1 = 0.9255, Macro F1 = 0.4022, Final Metric = 0.6638\n",
      "Epoch 14: Binary F1 = 0.9243, Macro F1 = 0.4120, Final Metric = 0.6682\n",
      "Epoch 15: Binary F1 = 0.9043, Macro F1 = 0.4175, Final Metric = 0.6609\n",
      "Epoch 16: Binary F1 = 0.9236, Macro F1 = 0.3878, Final Metric = 0.6557\n",
      "Epoch 17: Binary F1 = 0.9225, Macro F1 = 0.3966, Final Metric = 0.6595\n",
      "Epoch 18: Binary F1 = 0.9242, Macro F1 = 0.4111, Final Metric = 0.6676\n",
      "Epoch 19: Binary F1 = 0.9243, Macro F1 = 0.4064, Final Metric = 0.6654\n",
      "Epoch 20: Binary F1 = 0.9180, Macro F1 = 0.4052, Final Metric = 0.6616\n",
      "Early stopping triggered at epoch 20\n",
      "\n",
      "Fold 4 completed.\n",
      "Final validation metrics - Binary F1: 0.9180, Macro F1: 0.4052, Final: 0.6616\n",
      "Best validation metrics - Binary F1: 0.9254, Macro F1: 0.4181, Final: 0.6718\n",
      "\n",
      "==================================================\n",
      "Cross-Validation Results\n",
      "==================================================\n",
      "\n",
      "Best Fold-wise Metrics:\n",
      "Fold 1: Binary F1 = 0.9184, Macro F1 = 0.4483, Final = 0.6833\n",
      "Fold 2: Binary F1 = 0.9228, Macro F1 = 0.4374, Final = 0.6801\n",
      "Fold 3: Binary F1 = 0.9132, Macro F1 = 0.4007, Final = 0.6570\n",
      "Fold 4: Binary F1 = 0.9254, Macro F1 = 0.4181, Final = 0.6718\n",
      "\n",
      "Global Statistics (Best Metrics):\n",
      "Mean Best Final Metric: 0.6731 Â± 0.0102\n",
      "Mean Best Binary F1: 0.9200 Â± 0.0046\n",
      "Mean Best Macro F1: 0.4261 Â± 0.0182\n"
     ]
    }
   ],
   "source": [
    "seed_everything(seed=SEED)\n",
    "\n",
    "n_splits = 5\n",
    "\n",
    "fold_metrics = []\n",
    "best_fold_metrics = []\n",
    "best_models = []\n",
    "\n",
    "fold_patterns = join(dataset_path, \"preprocessed_dataset\", \"fold*\")\n",
    "fold_pths = glob(fold_patterns)\n",
    "all_training_metrics = {}\n",
    "\n",
    "for fold, fold_pth in enumerate(fold_pths[1:]):\n",
    "    print(\"training:\", fold + 1)\n",
    "    train_dataset = CMIDataset(fold_pth, \"train\")\n",
    "    # criterion = compute_weighted_cross_entropy_loss(train_dataset)\n",
    "    criterion = torch.nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "    train_loader = DL(train_dataset, TRAIN_BATCH_SIZE, shuffle=True, drop_last=True)\n",
    "    validation_dataset = CMIDataset(fold_pth, \"validation\")\n",
    "    validation_loader = DL(validation_dataset, VALIDATION_BATCH_SIZE, shuffle=False, drop_last=True)\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Fold {fold + 1}/{n_splits}\")\n",
    "\n",
    "    seed_everything(seed=SEED + fold)\n",
    "    model = mk_model()\n",
    "\n",
    "    # Optimizer et scheduler\n",
    "    min_lr = max_lr / 100\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        model.parameters(),\n",
    "        WARMUP_LR_INIT,\n",
    "        weight_decay=WEIGHT_DECAY,\n",
    "    )\n",
    "    steps_per_epoch = len(train_loader)\n",
    "    scheduler = CosineAnnealingWarmupRestarts(\n",
    "        optimizer,\n",
    "        warmup_steps=WARMUP_EPOCHS * steps_per_epoch,\n",
    "        cycle_mult=CYCLE_LENGTH_FACTOR,\n",
    "        max_lr = max_lr,\n",
    "        min_lr = max_lr / MAX_TO_MIN_LR_DIV_FACTOR,\n",
    "        cycle_length=INIT_CYCLE_EPOCHS * steps_per_epoch,\n",
    "        gamma=LR_CYCLE_FACTOR,\n",
    "    ) \n",
    "\n",
    "\n",
    "    # Early stopping\n",
    "    best_metric = -np.inf\n",
    "    best_binary_f1 = -np.inf\n",
    "    best_macro_f1 = -np.inf\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    for epoch in range(1, TRAINING_EPOCHS + 1):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        total = 0\n",
    "        for batch_x, batch_y in train_loader:\n",
    "            batch_x = batch_x.to(device).clone()\n",
    "            add_noise = torch.randn_like(batch_x, device=device) * 0.04\n",
    "            scale_noise = torch.rand_like(batch_x, device=device) * (1.1 - 0.9) + 0.9\n",
    "            batch_x = (add_noise + batch_x) * scale_noise\n",
    "            batch_y = batch_y.to(device)\n",
    "            batch_x = batch_x.float()\n",
    "            \n",
    "            batch_x, batch_y = mixup_data(batch_x, batch_y)\n",
    "           \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_x)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            train_loss += loss.item() * batch_x.size(0)\n",
    "            total += batch_x.size(0)\n",
    "        train_loss /= total\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        total = 0\n",
    "        all_true = []\n",
    "        all_pred = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch_x, batch_y in validation_loader:\n",
    "                batch_x = batch_x.to(device).clone()\n",
    "                batch_y = batch_y.to(device)\n",
    "                batch_x[:VALIDATION_BATCH_SIZE // 2, non_imu_feats_idx] = 0.0\n",
    "\n",
    "                outputs = model(batch_x)\n",
    "                loss = criterion(outputs, batch_y)\n",
    "                val_loss += loss.item() * batch_x.size(0)\n",
    "                total += batch_x.size(0)\n",
    "                \n",
    "                # Get predicted class indices\n",
    "                preds = torch.argmax(outputs, dim=1).cpu().numpy()\n",
    "                # Get true class indices from one-hot\n",
    "                trues = torch.argmax(batch_y, dim=1).cpu().numpy()\n",
    "                \n",
    "                all_true.append(trues)\n",
    "                all_pred.append(preds)\n",
    "\n",
    "        val_loss /= total\n",
    "        all_true = np.concatenate(all_true)\n",
    "        all_pred = np.concatenate(all_pred)\n",
    "\n",
    "        # Compute competition metrics\n",
    "        # Binary classification: BFRB (1) vs non-BFRB (0)\n",
    "        binary_true = np.isin(all_true, bfrb_indices).astype(int)\n",
    "        binary_pred = np.isin(all_pred, bfrb_indices).astype(int)\n",
    "        binary_f1 = f1_score(binary_true, binary_pred)\n",
    "        \n",
    "        # Collapse non-BFRB gestures into a single class\n",
    "        collapsed_true = np.where(\n",
    "            np.isin(all_true, bfrb_indices),\n",
    "            all_true,\n",
    "            len(bfrb_gestures)  # Single non-BFRB class\n",
    "        )\n",
    "        collapsed_pred = np.where(\n",
    "            np.isin(all_pred, bfrb_indices),\n",
    "            all_pred,\n",
    "            len(bfrb_gestures)  # Single non-BFRB class\n",
    "        )\n",
    "\n",
    "        # Macro F1 on collapsed classes\n",
    "        macro_f1 = f1_score(collapsed_true, collapsed_pred, average='macro')\n",
    "        final_metric = (binary_f1 + macro_f1) / 2\n",
    "\n",
    "        print(f\"Epoch {epoch:02d}: Binary F1 = {binary_f1:.4f}, Macro F1 = {macro_f1:.4f}, Final Metric = {final_metric:.4f}\")\n",
    "\n",
    "        if final_metric > best_metric:\n",
    "            best_metric = final_metric\n",
    "            best_binary_f1 = binary_f1\n",
    "            best_macro_f1 = macro_f1\n",
    "            epochs_no_improve = 0\n",
    "            best_model_state = model.state_dict()\n",
    "            print(f\"  New best metric! Saving model...\")\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            if epochs_no_improve >= PATIENCE:\n",
    "                print(f\"Early stopping triggered at epoch {epoch}\")\n",
    "                model.load_state_dict(best_model_state)\n",
    "                break\n",
    "\n",
    "    torch.save(best_model_state, f\"best_model_fold{fold}.pth\")\n",
    "    # Free memory used by datasets and data loaders\n",
    "    del train_dataset\n",
    "    del validation_dataset\n",
    "    del train_loader\n",
    "    del validation_loader\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    best_models.append(best_model_state)\n",
    "    fold_metrics.append({\n",
    "        'binary_f1': binary_f1,\n",
    "        'macr, drop_last=Trueo_f1': macro_f1,\n",
    "        'final_metric': final_metric\n",
    "    })\n",
    "    \n",
    "    best_fold_metrics.append({\n",
    "        'binary_f1': best_binary_f1,\n",
    "        'macro_f1': best_macro_f1,\n",
    "        'final_metric': best_metric\n",
    "    })\n",
    "    \n",
    "    print(f\"\\nFold {fold + 1} completed.\")\n",
    "    print(f\"Final validation metrics - Binary F1: {binary_f1:.4f}, Macro F1: {macro_f1:.4f}, Final: {final_metric:.4f}\")\n",
    "    print(f\"Best validation metrics - Binary F1: {best_binary_f1:.4f}, Macro F1: {best_macro_f1:.4f}, Final: {best_metric:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Cross-Validation Results\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Statistiques pour les meilleures mÃ©triques\n",
    "best_binary_f1 = [m['binary_f1'] for m in best_fold_metrics]\n",
    "best_macro_f1 = [m['macro_f1'] for m in best_fold_metrics]\n",
    "best_metrics = [m['final_metric'] for m in best_fold_metrics]\n",
    "\n",
    "print(\"\\nBest Fold-wise Metrics:\")\n",
    "for i, (bf1, mf1, fm) in enumerate(zip(best_binary_f1, best_macro_f1, best_metrics)):\n",
    "    print(f\"Fold {i+1}: Binary F1 = {bf1:.4f}, Macro F1 = {mf1:.4f}, Final = {fm:.4f}\")\n",
    "\n",
    "print(\"\\nGlobal Statistics (Best Metrics):\")\n",
    "print(f\"Mean Best Final Metric: {np.mean(best_metrics):.4f} Â± {np.std(best_metrics):.4f}\")\n",
    "print(f\"Mean Best Binary F1: {np.mean(best_binary_f1):.4f} Â± {np.std(best_binary_f1):.4f}\")\n",
    "print(f\"Mean Best Macro F1: {np.mean(best_macro_f1):.4f} Â± {np.std(best_macro_f1):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ea7558",
   "metadata": {
    "papermill": {
     "duration": 0.012909,
     "end_time": "2025-06-14T10:09:14.961270",
     "exception": false,
     "start_time": "2025-06-14T10:09:14.948361",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aea5e4f",
   "metadata": {
    "papermill": {
     "duration": 0.012906,
     "end_time": "2025-06-14T10:09:14.780212",
     "exception": false,
     "start_time": "2025-06-14T10:09:14.767306",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Reloading best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0574d4d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T10:09:14.807902Z",
     "iopub.status.busy": "2025-06-14T10:09:14.807165Z",
     "iopub.status.idle": "2025-06-14T10:09:14.933288Z",
     "shell.execute_reply": "2025-06-14T10:09:14.932459Z"
    },
    "papermill": {
     "duration": 0.141435,
     "end_time": "2025-06-14T10:09:14.934745",
     "exception": false,
     "start_time": "2025-06-14T10:09:14.793310",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_ensemble = []\n",
    "for fold in range(5):\n",
    "    model = mk_model().to(device)\n",
    "    checkpoint = torch.load(f\"best_model_fold{fold}.pth\", map_location=device, weights_only=True)\n",
    "    model.load_state_dict(checkpoint)\n",
    "    model.eval()\n",
    "    model_ensemble.append(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a826dec8",
   "metadata": {},
   "source": [
    "### Define preprocessing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481e69b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fillna_val_per_feature_col(df:DF) -> dict:\n",
    "    return {col: 1.0 if col == 'rot_w' else 0 for col in get_feature_cols(df)}\n",
    "\n",
    "def imputed_features(df:DF) -> DF:\n",
    "    # Missing ToF values are already imputed by -1 which is inconvinient since we want all missing values to be NaN.    \n",
    "    # So we replace them by NaN and then perform imputing.  \n",
    "    tof_vals_to_nan = {col: -1.0 for col in df.columns if col.startswith(\"tof\")}\n",
    "\n",
    "    df[get_feature_cols(df)] = (\n",
    "        df\n",
    "        .loc[:, get_feature_cols(df)]\n",
    "        # df.replace with np.nan sets dtype to floar64 so we set it back to float32\n",
    "        .replace(tof_vals_to_nan, value=np.nan)\n",
    "        .astype(\"float32\")\n",
    "        .groupby(df[\"sequence_id\"], observed=True, as_index=False)\n",
    "        .ffill()\n",
    "        .groupby(df[\"sequence_id\"], observed=True, as_index=False)\n",
    "        .bfill()\n",
    "        # In case there are only nan in the column in the sequence\n",
    "        .fillna(get_fillna_val_per_feature_col(df))\n",
    "    )\n",
    "    return df\n",
    "\n",
    "def norm_quat_rotations(df:DF) -> DF:\n",
    "    df[QUATERNION_COLS] /= np.linalg.norm(df[QUATERNION_COLS], axis=1, keepdims=True)\n",
    "    return df\n",
    "\n",
    "def add_linear_acc_cols(df:DF) -> DF:\n",
    "    # Vectorized version of https://www.kaggle.com/code/wasupandceacar/lb-0-82-5fold-single-bert-model#Dataset `remove_gravity_from_acc`\n",
    "    rotations:Rotation = Rotation.from_quat(df[QUATERNION_COLS])\n",
    "    gravity_sensor_frame = rotations.apply(GRAVITY_WORLD, inverse=True).astype(\"float32\")\n",
    "    df[LINEAR_ACC_COLS] = df[RAW_ACCELRATION_COLS] - gravity_sensor_frame\n",
    "    return df\n",
    "\n",
    "def add_acc_magnitude(df:DF, acc_cols:list[str], acc_mag_col_name:str) -> DF:\n",
    "    return df.assign(**{acc_mag_col_name: np.linalg.norm(df.loc[:, acc_cols], axis=1)})\n",
    "\n",
    "def add_quat_angle_mag(df:DF) -> DF:\n",
    "    return df.assign(quat_rot_mag=np.arccos(df[\"rot_w\"]) * 2)\n",
    "\n",
    "def add_angular_velocity_features(df:DF) -> DF:\n",
    "    rotations = Rotation.from_quat(df[QUATERNION_COLS])\n",
    "    delta_rotations = rotations[1:] * rotations[:-1].inv()\n",
    "    delta_rot_velocity = delta_rotations.as_rotvec()\n",
    "    # Add extra line to avoid shape mismatch\n",
    "    delta_rot_velocity = np.vstack((np.zeros((1, 3)), delta_rot_velocity))\n",
    "    delta_rot_magnitude = norm(delta_rot_velocity, axis=1, keepdims=True)\n",
    "    delta_rot_axes = delta_rot_velocity / (delta_rot_magnitude + EPSILON)\n",
    "    df[DELTA_ROTATION_ANGULAR_VELOCITY_COLS] = delta_rot_velocity\n",
    "    df[DELTA_ROTATION_AXES_COLS] = delta_rot_axes\n",
    "    df[\"delta_rot_mag\"] = delta_rot_magnitude.squeeze()\n",
    "\n",
    "    return df\n",
    "\n",
    "def rot_euler_angles(df:DF) -> ndarray:\n",
    "    df[EULER_ANGLES_COLS] = (\n",
    "        Rotation\n",
    "        .from_quat(df[QUATERNION_COLS])\n",
    "        .as_euler(\"xyz\")\n",
    "        .squeeze()\n",
    "    )\n",
    "    return df\n",
    "\n",
    "def agg_tof_cols_per_sensor(df:DF) -> DF:\n",
    "    for tof_idx in tqdm(range(1, 6)):\n",
    "        tof_name = f\"tof_{tof_idx}\"\n",
    "        tof_cols = [f\"{tof_name}_v{v_idx}\" for v_idx in range(64)]\n",
    "        if any(map(lambda col: col not in df.columns, tof_cols)):\n",
    "            print(f\"Some (or) all ToF {tof_idx} columns are not in the df. Maybe you already ran this cell?\")\n",
    "            continue\n",
    "        df = pd.concat(\n",
    "            (\n",
    "                df.drop(columns=tof_cols),\n",
    "                # For some reasons, it's faster to call all the aggregation functions seperatly than agg(list of functions)\n",
    "                df[tof_cols].mean(axis=\"columns\").to_frame(tof_name + \"_mean\"),\n",
    "                df[tof_cols].std(axis=\"columns\").to_frame(tof_name + \"_std\"),\n",
    "                df[tof_cols].median(axis=\"columns\").to_frame(tof_name + \"_median\"),\n",
    "                df[tof_cols].min(axis=\"columns\").to_frame(tof_name + \"_min\"),\n",
    "                df[tof_cols].max(axis=\"columns\").to_frame(tof_name + \"_max\"),\n",
    "            ),\n",
    "            axis=\"columns\",\n",
    "        )\n",
    "    return df\n",
    "\n",
    "def add_diff_features(df:DF) -> DF:\n",
    "    return pd.concat(\n",
    "        (\n",
    "            df,\n",
    "            df\n",
    "            .groupby(\"sequence_id\", as_index=False, observed=True)\n",
    "            [get_feature_cols(df)]\n",
    "            .diff()\n",
    "            .fillna(get_fillna_val_per_feature_col(df))\n",
    "            .add_suffix(\"_diff\")\n",
    "        ),\n",
    "        axis=\"columns\",\n",
    "    )\n",
    "\n",
    "def length_normed_sequence_feat_arr(sequence: DF) -> ndarray:\n",
    "    features = (\n",
    "        sequence\n",
    "        .loc[:, meta_data[\"feature_cols\"]]\n",
    "        .values\n",
    "    )\n",
    "    normed_sequence_len = meta_data[\"pad_seq_len\"]\n",
    "    len_diff = abs(normed_sequence_len - len(features))\n",
    "    if len(features) < normed_sequence_len:\n",
    "        padded_features = np.pad(\n",
    "            features,\n",
    "            ((len_diff // 2 + len_diff % 2, len_diff // 2), (0, 0)),\n",
    "        )\n",
    "        return padded_features\n",
    "    elif len(features) > normed_sequence_len:\n",
    "        return features[len_diff // 2:-len_diff // 2]\n",
    "    else:\n",
    "        return features\n",
    "\n",
    "def preprocess_sequence(sequence_df:pl.DataFrame) -> ndarray:\n",
    "    return (\n",
    "        sequence_df                     \n",
    "        .to_pandas()                            # Convert to pandas dataframe.\n",
    "        .pipe(imputed_features)                 # Impute missing data.\n",
    "        .pipe(norm_quat_rotations)              # Norm quaternions\n",
    "        .pipe(add_linear_acc_cols)              # Add gravity free acceleration.\n",
    "        .pipe(add_acc_magnitude, RAW_ACCELRATION_COLS, \"acc_mag\")\n",
    "        .pipe(add_acc_magnitude, LINEAR_ACC_COLS, \"linear_acc_mag\")\n",
    "        .pipe(add_quat_angle_mag)\n",
    "        .pipe(add_angular_velocity_features)\n",
    "        .pipe(rot_euler_angles)                 # Add rotation acc expressed as euler angles.\n",
    "        # .pipe(agg_tof_cols_per_sensor)          # Aggregate ToF columns.\n",
    "        .pipe(add_diff_features)                # \n",
    "        .loc[:, sorted(meta_data[\"feature_cols\"])]      # Retain only the usefull columns a.k.a features.\n",
    "        .sub(meta_data[\"mean\"])                 # Subtract features by their mean, std norm pt.1.\n",
    "        .div(meta_data[\"std\"])                  # Divide by Standard deviation, std norm pt.2.\n",
    "        .pipe(length_normed_sequence_feat_arr)  # get feature ndarray of sequence.\n",
    "        .T                                      # Transpose to swap channel and X dimensions.\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ebb0960",
   "metadata": {},
   "source": [
    "### Define prediction function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d8dfff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T10:09:14.989742Z",
     "iopub.status.busy": "2025-06-14T10:09:14.989258Z",
     "iopub.status.idle": "2025-06-14T10:09:14.995936Z",
     "shell.execute_reply": "2025-06-14T10:09:14.995244Z"
    },
    "papermill": {
     "duration": 0.021303,
     "end_time": "2025-06-14T10:09:14.997034",
     "exception": false,
     "start_time": "2025-06-14T10:09:14.975731",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict(sequence: pl.DataFrame, _: pl.DataFrame) -> str:\n",
    "    \"\"\"\n",
    "    Kaggle evaluation API will call this for each sequence.\n",
    "    sequence: polars DataFrame for a single sequence\n",
    "    demographics: unused in this model\n",
    "    Returns: predicted gesture string\n",
    "    \"\"\"\n",
    "    x_tensor = (\n",
    "        torch.unsqueeze(Tensor(preprocess_sequence(sequence)), dim=0)\n",
    "        .float()\n",
    "        .to(device)\n",
    "    )\n",
    "    print(x_tensor.shape)\n",
    "\n",
    "    all_outputs = []\n",
    "    with torch.no_grad():\n",
    "        for model_idx, model in enumerate(model_ensemble): # Only take the first one bc it's the only one that takes in the correct input shape\n",
    "            outputs = model(x_tensor)\n",
    "            all_outputs.append(outputs)\n",
    "\n",
    "    avg_outputs = torch.mean(torch.stack(all_outputs), dim=0)\n",
    "    pred_idx = torch.argmax(avg_outputs, dim=1).item()\n",
    "\n",
    "    return str(gesture_classes[pred_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cdcf446",
   "metadata": {},
   "source": [
    "### Run inference server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c386b7d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T10:09:15.023324Z",
     "iopub.status.busy": "2025-06-14T10:09:15.023122Z",
     "iopub.status.idle": "2025-06-14T10:09:16.373534Z",
     "shell.execute_reply": "2025-06-14T10:09:16.372710Z"
    },
    "papermill": {
     "duration": 1.365137,
     "end_time": "2025-06-14T10:09:16.374918",
     "exception": false,
     "start_time": "2025-06-14T10:09:15.009781",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "inference_server = kaggle_evaluation.cmi_inference_server.CMIInferenceServer(predict)\n",
    "\n",
    "if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
    "    inference_server.serve()\n",
    "else:\n",
    "    inference_server.run_local_gateway(\n",
    "        data_paths=(\n",
    "            join(competition_dataset_path, 'test.csv'),\n",
    "            join(competition_dataset_path, 'test_demographics.csv'),\n",
    "        )\n",
    "    )\n",
    "    inference_server = kaggle_evaluation.cmi_inference_server.CMIInferenceServer(predict)\n",
    "    inference_server.run_local_gateway(\n",
    "        data_paths=(\n",
    "            join(competition_dataset_path, 'train.csv'),\n",
    "            join(competition_dataset_path, 'train_demographics.csv'),\n",
    "        )\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 12518947,
     "sourceId": 102335,
     "sourceType": "competition"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 510.403331,
   "end_time": "2025-06-14T10:09:19.701325",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-06-14T10:00:49.297994",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
