{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf6438da",
   "metadata": {},
   "source": [
    "# Training & inference notebook\n",
    "Credit to [Tarun Mishra](https://www.kaggle.com/tarundirector) â€“ this code is heavily based on his [notebook](https://www.kaggle.com/code/tarundirector/sensor-pulse-viz-eda-for-bfrb-detection?scriptVersionId=243465321)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e752c660",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473b69f6",
   "metadata": {},
   "source": [
    "### imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d4b210",
   "metadata": {},
   "source": [
    "#### Training imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b842c804",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from glob import glob\n",
    "from functools import partial\n",
    "from datetime import datetime\n",
    "from os.path import join, realpath\n",
    "from typing import Optional, Literal\n",
    "from itertools import pairwise, starmap\n",
    "\n",
    "import torch\n",
    "import kagglehub\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from torch import nn, Tensor\n",
    "from pandas import DataFrame as DF\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader as DL\n",
    "from rich.progress import Progress, Task, track\n",
    "from torch.optim.lr_scheduler import ConstantLR, LRScheduler\n",
    "metric_package = kagglehub.package_import('wasupandceacar/cmi-metric', bypass_confirmation=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3ae962",
   "metadata": {},
   "source": [
    "#### inference imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "915c9ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import warnings\n",
    "from os.path import join\n",
    "from tqdm.notebook import tqdm\n",
    "from itertools import pairwise, product\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "from numpy import ndarray\n",
    "from torch import nn, Tensor\n",
    "from numpy.linalg import norm\n",
    "from pandas import DataFrame as DF\n",
    "from scipy.spatial.transform import Rotation\n",
    "# from kagglehub import competition_download, dataset_download, model_download\n",
    "import kagglehub\n",
    "metric_package = kagglehub.package_import('wasupandceacar/cmi-metric', bypass_confirmation=True)\n",
    "\n",
    "import kaggle_evaluation.cmi_inference_server"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd3c8bd",
   "metadata": {},
   "source": [
    "#### kaggle notbook Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ce2e25ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "\n",
    "def seed_everything(seed=42):\n",
    "    \"\"\"Set all random seeds for reproducibility\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'\n",
    "    torch.use_deterministic_algorithms(True, warn_only=True)\n",
    "\n",
    "SEED = 42\n",
    "seed_everything(seed=SEED)\n",
    "\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "# from tensorflow.keras.preprocessing.sequence import pad_sequences as keras_pad_sequences\n",
    "\n",
    "import kaggle_evaluation.cmi_inference_server\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e34cce",
   "metadata": {},
   "source": [
    "### Configs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b0b925",
   "metadata": {},
   "source": [
    "#### Training config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1296f174",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_HANDLE = \"mauroabidalcarrer/prepocessed-cmi-2025/versions/30\"\n",
    "NB_CROSS_VALIDATIONS = 5\n",
    "TRAINING_EPOCHS = 25\n",
    "STARTING_LR = 0.0005\n",
    "TRAIN_BATCH_SIZE = 256\n",
    "VALIDATION_BATCH_SIZE = 4 * TRAIN_BATCH_SIZE\n",
    "TARGET_NAMES = sorted([\n",
    "    \"Above ear - pull hair\",\n",
    "    \"Cheek - pinch skin\",\n",
    "    \"Eyebrow - pull hair\",\n",
    "    \"Eyelash - pull hair\",\n",
    "    \"Feel around in tray and pull out an object\",\n",
    "    \"Forehead - pull hairline\",\n",
    "    \"Forehead - scratch\",\n",
    "    \"Neck - pinch skin\",\n",
    "    \"Neck - scratch\",\n",
    "    \"Text on phone\",\n",
    "    \"Wave hello\",\n",
    "    \"Write name in air\",\n",
    "    \"Write name on leg\",\n",
    "    \"Drink from bottle/cup\",\n",
    "    \"Pinch knee/leg skin\",\n",
    "    \"Pull air toward your face\",\n",
    "    \"Scratch knee/leg skin\",\n",
    "    \"Glasses on/off\"\n",
    "])\n",
    "TARGET_NAMES_NDARRAY = np.asarray(TARGET_NAMES)\n",
    "MOCK_TRAINING_EPOCHS = 10\n",
    "MOCK_TRAINING_GAMMA = 1.01\n",
    "MAX_LR_TO_MIN_DIV_FACTOR = 10\n",
    "\n",
    "COMPETITION_HANDLE = \"cmi-detect-behavior-with-sensor-data\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1393b8af",
   "metadata": {},
   "source": [
    "#### Inference config "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3ad8c78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUATERNION_COLS = ['rot_w', 'rot_x', 'rot_y', 'rot_z']\n",
    "GRAVITY_WORLD = np.array([0, 0, 9.81], \"float32\")\n",
    "RAW_ACCELRATION_COLS = [\"acc_x\", \"acc_y\", \"acc_z\"]\n",
    "LINEAR_ACC_COLS = [\"gravity_free_\" + col for col in RAW_ACCELRATION_COLS]\n",
    "COMPETITION_HANDLE = \"cmi-detect-behavior-with-sensor-data\"\n",
    "CATEGORY_COLUMNS = [\n",
    "    'row_id',\n",
    "    'sequence_type',\n",
    "    'sequence_id',\n",
    "    'subject',\n",
    "    'orientation',\n",
    "    'behavior',\n",
    "    'phase',\n",
    "    'gesture',\n",
    "]\n",
    "META_DATA_COLUMNS = [\n",
    "    'row_id',\n",
    "    'sequence_type',\n",
    "    'sequence_id',\n",
    "    'sequence_counter',\n",
    "    'subject',\n",
    "    'orientation',\n",
    "    'behavior',\n",
    "    'phase',\n",
    "    'gesture',\n",
    "]\n",
    "DATASET_DF_DTYPES = {\n",
    "    \"acc_x\": \"float32\", \"acc_y\": \"float32\", \"acc_z\": \"float32\",\n",
    "    \"thm_1\":\"float32\", \"thm_2\":\"float32\", \"thm_3\":\"float32\", \"thm_4\":\"float32\", \"thm_5\":\"float32\",\n",
    "    \"sequence_counter\": \"int32\",\n",
    "    **{col: \"category\" for col in CATEGORY_COLUMNS},\n",
    "    **{f\"tof_{i_1}_v{i_2}\": \"float32\" for i_1, i_2 in product(range(1, 5), range(64))},\n",
    "}\n",
    "PREPROCESSED_DATASET_HANDLE = \"mauroabidalcarrer/prepocessed-cmi-2025\"\n",
    "# The quantile of the sequences len used to pad/truncate during preprocessing\n",
    "SEQUENCE_NORMED_LEN_QUANTILE = 0.95\n",
    "# SAMPLING_FREQUENCY = 10 #Hz\n",
    "N_FOLDS = 5\n",
    "VALIDATION_FRACTION = 0.2\n",
    "TARGET_NAMES = sorted([\n",
    "    \"Above ear - pull hair\",\n",
    "    \"Cheek - pinch skin\",\n",
    "    \"Eyebrow - pull hair\",\n",
    "    \"Eyelash - pull hair\",\n",
    "    \"Feel around in tray and pull out an object\",\n",
    "    \"Forehead - pull hairline\",\n",
    "    \"Forehead - scratch\",\n",
    "    \"Neck - pinch skin\",\n",
    "    \"Neck - scratch\",\n",
    "    \"Text on phone\",\n",
    "    \"Wave hello\",\n",
    "    \"Write name in air\",\n",
    "    \"Write name on leg\",\n",
    "    \"Drink from bottle/cup\",\n",
    "    \"Pinch knee/leg skin\",\n",
    "    \"Pull air toward your face\",\n",
    "    \"Scratch knee/leg skin\",\n",
    "    \"Glasses on/off\"\n",
    "])\n",
    "EPSILON=1e-8\n",
    "DELTA_ROTATION_ANGULAR_VELOCITY_COLS = [\"angular_vel_x\", \"angular_vel_y\", \"angular_vel_z\"]\n",
    "DELTA_ROTATION_AXES_COLS = [\"rotation_axis_x\", \"rotation_axis_y\", \"rotation_axis_z\"]\n",
    "EULER_ANGLES_COLS = [\"euler_x\", \"euler_y\", \"euler_z\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4bfefa",
   "metadata": {},
   "source": [
    "### Define function to get the feature columns\n",
    "Feature columns change over time so it's better to have a function to get them than manually update a variable every time we add/remove features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f3d40b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_cols(df:DF) -> list[str]:\n",
    "    return sorted(list(set(df.columns) - set(META_DATA_COLUMNS) - set(TARGET_NAMES)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eac0e5a",
   "metadata": {},
   "source": [
    "### Supress performance warngings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "086420e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    message=(\n",
    "        \"DataFrame is highly fragmented.  This is usually the result of \"\n",
    "        \"calling `frame.insert` many times.*\"\n",
    "    ),\n",
    "    category=pd.errors.PerformanceWarning,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7749c3bd",
   "metadata": {},
   "source": [
    "### device setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "aa7f99a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a563074",
   "metadata": {},
   "source": [
    "### Dataset Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2bc2e83c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/mauroabidalcarrer/prepocessed-cmi-2025?dataset_version_number=30...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 748M/748M [03:22<00:00, 3.88MB/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset_path = kagglehub.dataset_download(DATASET_HANDLE)\n",
    "\n",
    "class CMIDataset(TensorDataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        parent_dir: str,\n",
    "        split: Optional[Literal[\"train\", \"validation\"]]=None,\n",
    "        subset: Optional[int]=None,\n",
    "        force_download=False\n",
    "    ):\n",
    "        dataset_path = kagglehub.dataset_download(DATASET_HANDLE, force_download)\n",
    "        parent_dir = join(dataset_path, \"preprocessed_dataset\", parent_dir)\n",
    "        split = \"\" if split is None else split + \"_\"\n",
    "        x = np.load(join(parent_dir, f\"{split}X.npy\")).swapaxes(1, 2)\n",
    "        y = np.load(join(parent_dir, f\"{split}Y.npy\"))\n",
    "        if subset is not None:\n",
    "            x = x[:subset]\n",
    "            y = y[:subset]\n",
    "        super().__init__(\n",
    "            torch.from_numpy(x), \n",
    "            torch.from_numpy(y),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5aae295d",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_data_path = join(\n",
    "    dataset_path,\n",
    "    \"preprocessed_dataset\",\n",
    "    \"full_dataset_meta_data.json\"\n",
    ")\n",
    "with open(meta_data_path, \"r\") as fp:\n",
    "    meta_data = json.load(fp)\n",
    "# Convert target names into a ndarray to index it batchwise.\n",
    "# meta_data[\"target_names\"] = np.asarray(meta_data[\"target_names\"])\n",
    "non_imu_feats_idx = [feat_idx for feat_idx, feat in enumerate(meta_data[\"feature_cols\"]) if feat.startswith((\"thm\", \"tof\"))]\n",
    "non_imu_feats = [feat for feat in meta_data[\"feature_cols\"] if feat.startswith((\"thm\", \"tof\"))]\n",
    "imu_feats_idx = [feat_idx for feat_idx, feat in enumerate(meta_data[\"feature_cols\"]) if not feat.startswith((\"thm\", \"tof\"))]\n",
    "imu_feats = [feat for feat in meta_data[\"feature_cols\"] if not feat.startswith((\"thm\", \"tof\"))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2161df0c",
   "metadata": {
    "papermill": {
     "duration": 0.00278,
     "end_time": "2025-06-14T10:01:12.877551",
     "exception": false,
     "start_time": "2025-06-14T10:01:12.874771",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### BFRBs indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e657c570",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T10:01:12.884365Z",
     "iopub.status.busy": "2025-06-14T10:01:12.883937Z",
     "iopub.status.idle": "2025-06-14T10:01:45.309186Z",
     "shell.execute_reply": "2025-06-14T10:01:45.308564Z"
    },
    "papermill": {
     "duration": 32.430139,
     "end_time": "2025-06-14T10:01:45.310511",
     "exception": false,
     "start_time": "2025-06-14T10:01:12.880372",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets...\n",
      "Train rows: 574945, Test rows: 107\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading datasets...\")\n",
    "competition_dataset_path = kagglehub.competition_download(COMPETITION_HANDLE)\n",
    "train_df = pd.read_csv(join(competition_dataset_path, \"train.csv\"))\n",
    "train_dem_df = pd.read_csv(join(competition_dataset_path, \"train_demographics.csv\"))\n",
    "test_df = pd.read_csv(join(competition_dataset_path, \"test.csv\"))\n",
    "test_dem_df = pd.read_csv(join(competition_dataset_path, \"test_demographics.csv\"))\n",
    "print(f\"Train rows: {len(train_df)}, Test rows: {len(test_df)}\")\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "train_df['gesture'] = label_encoder.fit_transform(train_df['gesture'].astype(str))\n",
    "gesture_classes = label_encoder.classes_\n",
    "\n",
    "bfrb_gestures = [\n",
    "    'Above ear - pull hair',\n",
    "    'Forehead - pull hairline',\n",
    "    'Forehead - scratch',\n",
    "    'Eyebrow - pull hair',\n",
    "    'Eyelash - pull hair',\n",
    "    'Neck - pinch skin',\n",
    "    'Neck - scratch',\n",
    "    'Cheek - pinch skin'\n",
    "]\n",
    "bfrb_indices = label_encoder.transform(bfrb_gestures)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c54244a",
   "metadata": {},
   "source": [
    "## Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ae01a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiScaleConvs(nn.Module):\n",
    "    def __init__(self, in_channels:int, kernel_sizes:list[int]):\n",
    "        super().__init__()\n",
    "        def mk_conv_block(k_size) -> nn.Sequential:\n",
    "            return nn.Sequential(\n",
    "                nn.Conv1d(in_channels, in_channels, k_size, padding=k_size // 2, groups=in_channels),\n",
    "                nn.BatchNorm1d(in_channels),\n",
    "                nn.ReLU(),\n",
    "            )\n",
    "        self.convs = nn.ModuleList(map(mk_conv_block, kernel_sizes))\n",
    "\n",
    "    def forward(self, x:Tensor) -> Tensor:\n",
    "        yes = torch.cat([conv(x) for conv in self.convs] + [x], dim=1)\n",
    "        # print(\"stem output shape:\", yes.shape)\n",
    "        return yes\n",
    "\n",
    "class SqueezeExcitationBlock(nn.Module):\n",
    "    # Copy/paste of https://www.kaggle.com/code/wasupandceacar/lb-0-82-5fold-single-bert-model#Model implementation\n",
    "    def __init__(self, channels:int, reduction:int=8):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(channels, channels // reduction, bias=True)\n",
    "        self.fc2 = nn.Linear(channels // reduction, channels, bias=True)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, C, L)\n",
    "        se = F.adaptive_avg_pool1d(x, 1).squeeze(-1)      # -> (B, C)\n",
    "        se = F.relu(self.fc1(se), inplace=True)          # -> (B, C//r)\n",
    "        se = self.sigmoid(self.fc2(se)).unsqueeze(-1)    # -> (B, C, 1)\n",
    "        return x * se\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_chns:int, out_chns:int, dropout_ratio:float=0.3):\n",
    "        super().__init__()\n",
    "        self.blocks = nn.Sequential(\n",
    "            nn.Conv1d(in_chns, out_chns, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(out_chns),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(out_chns, out_chns, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(out_chns),\n",
    "            SqueezeExcitationBlock(out_chns),\n",
    "        )\n",
    "        self.head = nn.Sequential(nn.ReLU(), nn.Dropout(dropout_ratio))\n",
    "        if in_chns == out_chns:\n",
    "            self.skip_connection = nn.Identity() \n",
    "        else:\n",
    "            # TODO: set bias to False ?\n",
    "            self.skip_connection = nn.Sequential(\n",
    "                nn.Conv1d(in_chns, out_chns, 1),\n",
    "                nn.BatchNorm1d(out_chns)\n",
    "            )\n",
    "            self.head.add_module(\"max_pool\", nn.MaxPool1d(2))\n",
    "            \n",
    "    def forward(self, x:Tensor) -> Tensor:\n",
    "        activaition_maps = self.skip_connection(x) + self.blocks(x)\n",
    "        return self.head(activaition_maps)\n",
    "\n",
    "class MBConvBlock(nn.Module):\n",
    "    # From this schema: https://media.licdn.com/dms/image/v2/D5612AQFjbDOm5uyxdw/article-inline_image-shrink_1500_2232/article-inline_image-shrink_1500_2232/0/1683677500817?e=1758153600&v=beta&t=n48_UW5TZTyDPhRFlJXSidUQQPQpuC756M0kNeKmYTY\n",
    "    def __init__(self, in_chns:int, out_chns:int, se_reduction:int=8, expansion_ratio:int=4, dropout_ratio:float=0.3):\n",
    "        super().__init__()\n",
    "        expanded_channels = in_chns * expansion_ratio\n",
    "        self.blocks = nn.Sequential(\n",
    "            nn.Conv1d(in_chns, expanded_channels, kernel_size=1),\n",
    "            nn.BatchNorm1d(expanded_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(\n",
    "                expanded_channels,\n",
    "                expanded_channels,\n",
    "                kernel_size=3,\n",
    "                padding=1,\n",
    "                groups=expanded_channels,\n",
    "            ),\n",
    "            nn.BatchNorm1d(expanded_channels),\n",
    "            nn.ReLU(),\n",
    "            SqueezeExcitationBlock(expanded_channels, se_reduction),\n",
    "            nn.Conv1d(expanded_channels, out_chns, kernel_size=1)\n",
    "        )\n",
    "        self.head = nn.Sequential(\n",
    "            nn.BatchNorm1d(out_chns)\n",
    "            # nn.ReLU(),\n",
    "            # nn.Dropout(dropout_ratio),\n",
    "        )\n",
    "        if in_chns == out_chns:\n",
    "            self.skip_connection = nn.Identity() \n",
    "        else:\n",
    "            # TODO: set bias to False ?\n",
    "            self.skip_connection = nn.Sequential(\n",
    "                nn.Conv1d(in_chns, out_chns, 1),\n",
    "                nn.BatchNorm1d(out_chns)\n",
    "            )\n",
    "            self.head.add_module(\"max_pool\", nn.MaxPool1d(2))\n",
    "            \n",
    "    def forward(self, x:Tensor) -> Tensor:\n",
    "        activaition_maps = self.skip_connection(x) + self.blocks(x)\n",
    "        return self.head(activaition_maps)\n",
    "\n",
    "class Resnet(nn.Sequential):\n",
    "    def __init__(\n",
    "            self,\n",
    "            in_channels:int,\n",
    "            depth:int,\n",
    "            mlp_width:int,\n",
    "            n_class:int,\n",
    "            se_reduction:int=8,\n",
    "            mbconv_expansion:int=4,\n",
    "            stem_kernels_sizes:Optional[list[int]]=None,\n",
    "        ):\n",
    "        if stem_kernels_sizes:\n",
    "            stem = MultiScaleConvs(in_channels, kernel_sizes=stem_kernels_sizes)\n",
    "            body_in_channels = in_channels + in_channels * len(stem_kernels_sizes)\n",
    "        else:\n",
    "            body_in_channels = in_channels\n",
    "            stem = nn.Identity()\n",
    "        chns_at_depth = lambda depth: body_in_channels * 2 ** depth\n",
    "        blocks_chns_it = pairwise(map(chns_at_depth, range(depth)))\n",
    "        mk_mb_conv_block = partial(\n",
    "            MBConvBlock,\n",
    "            se_reduction=se_reduction,\n",
    "            expansion_ratio=mbconv_expansion\n",
    "        )\n",
    "        res_blocks = list(starmap(mk_mb_conv_block, blocks_chns_it))\n",
    "        super().__init__(\n",
    "            # Stem\n",
    "            stem,\n",
    "            # Body\n",
    "            *res_blocks,\n",
    "            # Head\n",
    "            nn.Flatten(start_dim=1),\n",
    "            nn.LazyLinear(mlp_width),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(mlp_width, n_class),\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc08e41",
   "metadata": {},
   "source": [
    "### Create model function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "36e3e463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input channels: 66\n"
     ]
    }
   ],
   "source": [
    "def mk_model() -> nn.Module:\n",
    "    nb_in_chans = len(meta_data[\"feature_cols\"])\n",
    "    return (\n",
    "        Resnet(\n",
    "            in_channels=nb_in_chans,\n",
    "            depth=4,\n",
    "            mlp_width=256,\n",
    "            n_class=18,\n",
    "            stem_kernels_sizes=[11, 31],\n",
    "        )\n",
    "        .to(device)\n",
    "    )\n",
    "\n",
    "print(\"input channels:\", len(meta_data[\"feature_cols\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8afc6e79",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a69ec966",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(epochs:int,\n",
    "        model: nn.Module,\n",
    "        scheduler: LRScheduler,\n",
    "        optimizer: torch.optim.Optimizer,\n",
    "        train_loader: DL,\n",
    "        criterion: callable=nn.L1Loss(),\n",
    "        evaluation_func: callable=None,\n",
    "        validation_loader: DL=None,\n",
    "        save_checkpoints=True,\n",
    "    ) -> tuple[DF, str]:\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "        (training_metrics, path_to_checkpoints)\n",
    "    \"\"\"\n",
    "    # Setup\n",
    "    metrics: list[dict] = []\n",
    "    step = 0\n",
    "    model_device = next(model.parameters()).device\n",
    "    last_epoch_metric = {}\n",
    "    # Training loop\n",
    "    with Progress() as progress:\n",
    "        task: Task = progress.add_task(\n",
    "            \"training...\",\n",
    "            total=len(train_loader),\n",
    "        )\n",
    "        for epoch in range(epochs):\n",
    "            progress.update(\n",
    "                task,\n",
    "                description=f\"epoch: {epoch}\",\n",
    "                completed=0,\n",
    "            )\n",
    "            total_epoch_loss = 0\n",
    "            total_accuracy = 0\n",
    "            for batch_idx, (x, y) in enumerate(train_loader):\n",
    "                # forward\n",
    "                x = x.to(model_device)\n",
    "                y = y.to(model_device)\n",
    "                model.train()\n",
    "                optimizer.zero_grad()\n",
    "                y_pred: Tensor = model(x)\n",
    "                loss_value = criterion(y_pred, y)\n",
    "                # Verify loss value\n",
    "                if torch.isnan(loss_value).any().item():\n",
    "                    progress.print(\"Warning: Got NaN loss, stopped training.\")\n",
    "                    return DF.from_records(metrics)\n",
    "                if torch.isinf(loss_value).any().item():\n",
    "                    progress.print(\"Warning: Got infinite loss, stopped training.\")\n",
    "                    return DF.from_records(metrics)\n",
    "                # TODO: Use gradient clipping?\n",
    "                loss_value.backward()\n",
    "                optimizer.step()\n",
    "                if step > 0: # If it's not the first training step, idk why it throws an error otherwise\n",
    "                    scheduler.step()\n",
    "                # metrics\n",
    "                total_epoch_loss += loss_value.item()\n",
    "                metrics.append({\n",
    "                    \"step\": step,\n",
    "                    \"epoch\": epoch,\n",
    "                    \"batch_train_loss\": loss_value.item(),\n",
    "                    \"lr\": optimizer.state_dict()[\"param_groups\"][-1][\"lr\"],\n",
    "                })\n",
    "                step += 1\n",
    "                if \"validation_accuracy\" in last_epoch_metric:\n",
    "                    last_validation_acc = \"%.2f\" % last_epoch_metric[\"validation_accuracy\"]\n",
    "                    val_acc_str = \"val. acc: \" + last_validation_acc\n",
    "                else:\n",
    "                    val_acc_str = \"\"\n",
    "                progress.update(\n",
    "                    task,\n",
    "                    advance=1,\n",
    "                    description=f\"epoch: {epoch}, batch_loss: {(total_epoch_loss / (batch_idx+1)):.2f}, {val_acc_str}\"\n",
    "                )\n",
    "            # Post epoch evalution\n",
    "            metrics[-1][\"train_epoch_loss\"] = total_epoch_loss / len(train_loader)\n",
    "            metrics[-1][\"train_epoch_accuracy\"] = total_accuracy / len(train_loader)\n",
    "            if evaluation_func:\n",
    "                progress.update(\n",
    "                    task,\n",
    "                    completed=0,\n",
    "                    description=f\"epoch: {epoch}, evaluating...\"\n",
    "                )\n",
    "                eval_metrics = evaluation_func(model, criterion, validation_loader)\n",
    "                metrics[-1].update(eval_metrics)\n",
    "            last_epoch_metric = metrics[-1]\n",
    "\n",
    "    return DF.from_records(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a490227",
   "metadata": {},
   "source": [
    "### Create model and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "34cd5bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mk_model_and_fit(\n",
    "        train_loader:DL,\n",
    "        mk_scheduler:callable,\n",
    "        epochs:int,\n",
    "        validation_loader:Optional[DL]=None,\n",
    "        save_checkpoints=False,\n",
    "    ) -> tuple[nn.Module, DF, list[str]]:\n",
    "    model = mk_model()\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), STARTING_LR)\n",
    "    lr_scheduler = mk_scheduler(optimizer)\n",
    "    training_metrics = fit(\n",
    "        epochs=epochs,\n",
    "        model=model,\n",
    "        scheduler=lr_scheduler,\n",
    "        optimizer=optimizer,\n",
    "        train_loader=train_loader,\n",
    "        criterion=nn.CrossEntropyLoss(),\n",
    "        # evaluation_func=evaluate_model if validation_loader else None,\n",
    "        validation_loader=validation_loader,\n",
    "        save_checkpoints=save_checkpoints,\n",
    "    )\n",
    "\n",
    "    return model, training_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9256152c",
   "metadata": {},
   "source": [
    "## Search max learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "40b0c8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_process_mock_training_metrics(training_metrics:DF) -> DF:\n",
    "    training_metrics = (\n",
    "        training_metrics\n",
    "        .query(\"batch_train_loss.notna()\")\n",
    "        .set_index(\"lr\", drop=False)\n",
    "        .sort_index()\n",
    "    )\n",
    "    training_metrics[\"ewm_batch_train_loss\"] = (\n",
    "        training_metrics\n",
    "        .ewm(com=30, ignore_na=False)\n",
    "        [\"batch_train_loss\"]\n",
    "        .mean()\n",
    "    )\n",
    "    training_metrics[\"ewm_batch_train_loss_diff\"] = training_metrics[\"ewm_batch_train_loss\"].diff()\n",
    "    return training_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7c231028",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plt_lr_search_training_metrics(training_metrics:DF):\n",
    "    (    \n",
    "        px.line(\n",
    "            (\n",
    "                training_metrics\n",
    "                .reset_index(drop=True)\n",
    "                .melt(\n",
    "                    id_vars=\"lr\",\n",
    "                    value_vars=[\n",
    "                        \"batch_train_loss\",\n",
    "                        \"ewm_batch_train_loss\",\n",
    "                        # \"ewm_batch_train_loss_diff\",\n",
    "                    ],\n",
    "                )\n",
    "            ),\n",
    "            x=\"lr\",\n",
    "            facet_row=\"variable\",\n",
    "            y=\"value\",\n",
    "            log_x=True,\n",
    "            log_y=True,\n",
    "            height=750,\n",
    "        )\n",
    "        .update_yaxes(matches=None)\n",
    "        .show()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e9ae0c04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d28eddb59c747d4a6800899c76b0179",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "variable=batch_train_loss<br>lr=%{x}<br>value=%{y}<extra></extra>",
         "legendgroup": "",
         "line": {
          "color": "#636efa",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "",
         "orientation": "v",
         "showlegend": false,
         "type": "scatter",
         "x": {
          "bdata": "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",
          "dtype": "f8"
         },
         "xaxis": "x2",
         "y": {
          "bdata": "AAAAAOZbB0AAAABA5xwLQAAAAEDmoA9AAAAAIGFGBUAAAABAq0MFQAAAAIDZ6wJAAAAAgCL7AUAAAACg1y8AQAAAAKAi1f4/AAAAwOWpAEAAAAAAhHj8PwAAAIDEYPs/AAAAoJNk+T8AAADAVjb6PwAAAIAxafk/AAAAQH/Z+D8AAADgY9v5PwAAAIAZLfU/AAAAwEhc9z8AAAAAweX2PwAAAEAkJfk/AAAAQAH99j8AAABAj8X1PwAAAGCNRvY/AAAAAFdL9j8AAACAkgb2PwAAAAA+8/Q/AAAAwDnX9D8AAADgL5n0PwAAAEDSDvQ/AAAAwMGO9T8AAABgkVX0PwAAAICaAfA/AAAAAGOS7z8AAAAgNy/tPwAAAAAHn+0/AAAAwMHk7z8AAACgLo7wPwAAAKCwlvE/AAAAYFmh6z8AAADARHnwPwAAAICGIe0/AAAAoDNH8D8AAAAAuYrxPwAAAOAMx+s/AAAAwABq7T8AAAAAVNfvPwAAAMCULes/AAAAwFN47D8AAACAg/PsPwAAAMCXCvI/AAAAoNL57T8AAABA1xHxPwAAAGB/4uw/AAAAABct7j8AAABgI3nvPwAAAODu8uc/AAAAQE+27T8AAADACnjvPwAAAGCgUPA/AAAAwCkP7z8AAACA723sPwAAAGCbkO8/AAAAQM437D8AAABAxNDpPwAAAACEMeY/AAAAQPUO6z8AAACA20zoPwAAAGDfXuY/AAAAYJNr5j8AAABA5RnmPwAAACDi4Oc/AAAAYAbz5z8AAAAANT3mPwAAAGA9jeM/AAAAwCBo5j8AAAAAA4/kPwAAAAAc7uc/AAAAwEiH4z8AAADAWh7nPwAAAMBM0+Y/AAAAIGS/6D8AAABAMXLoPwAAAIC6+Oc/AAAAwOeo6T8AAACg9f3nPwAAAKBZquU/AAAAQKnU5z8AAACAVDDoPwAAAEDXteY/AAAA4NgW5z8AAABAtW7jPwAAAIA7yek/AAAAgBoo7D8AAAAAs0jkPwAAAMDgQ+U/AAAAoMTO4D8AAADAoYHjPwAAAKB1P+E/AAAAQOzm3D8AAACAVV7gPwAAAKC4K+I/AAAAgPlR4D8AAAAAjQbePwAAAGCeo98/AAAAwJFz3D8AAACgi8XfPwAAACBkfOM/AAAAQE9P2z8AAACAaJ7bPwAAAABP9uA/AAAAwKzp4T8AAAAgK3DgPwAAAAAmV+E/AAAAQFmf4j8AAADAd1LkPwAAAMALiN8/AAAAAMC/4j8AAABAYJrlPwAAAAC3AuQ/AAAAQNPr5j8AAABA6xfhPwAAAADit+c/AAAAgJy34T8AAACgQAHpPwAAAEDVC+U/AAAAgEJH4z8AAABAcpHoPwAAAEA+sd0/AAAA4JPV3T8AAADAzg7gPwAAAEC89dg/AAAAQKeB3z8AAAAg1gPcPwAAAGC3S+A/AAAAwHJ24D8AAADgQo/WPwAAAAD9idw/AAAAgGqw3z8AAADAab/cPwAAAIBhEOE/AAAAAFOu4j8AAACArXrdPwAAAIDAxuA/AAAAADcM4j8AAABAco7hPwAAACANiOM/AAAAQE5D4D8AAAAguUnfPwAAAMAKL+Q/AAAAYNnf5T8AAACgwNDnPwAAAGB23+I/AAAAQBKZ6z8AAACA70jgPwAAAAAIj+w/AAAAQFNl5D8AAADA0xbpPwAAAIBfDu8/AAAAQJJT5D8AAACA/pfiPwAAAMAN+N4/AAAAwA4N4D8AAAAADOjbPwAAAGAkvN8/AAAAQClo3z8AAAAgq0jlPwAAAACT+uM/AAAAoDs75j8AAACgTirmPwAAAABMhOc/AAAAQCzG4j8AAACgQIrlPwAAAMDVCOc/AAAAACA55j8AAABAdmvnPwAAAABjAuY/AAAAICEP5z8AAAAgmdPnPwAAAMBPyOE/AAAAAC045j8AAAAAlp7nPwAAAID8Dec/AAAAQDDB4z8AAAAAJa/kPwAAAACkT/A/AAAA4Bta4T8AAABAVSjjPwAAACAoquw/AAAAwAtE5j8AAAAAmBfpPwAAAMBYO+k/AAAAYNqt2z8AAADAwQDdPwAAAOALUeQ/AAAAoD6a2T8AAABA9QbiPwAAACBXzN4/AAAAANOc4T8AAAAALfjhPwAAAIDooOI/AAAAQD4+4j8AAACAa9bfPwAAAODBnOA/AAAAADRs5z8AAABAxvTfPwAAAIBtxeU/AAAAINdB4j8AAADAa+foPwAAAECvOuA/AAAAYLW65T8AAABgWr/nPwAAAMDc/eM/AAAAoEmh5z8AAACAfxToPwAAAEBunuA/AAAAQHdG4j8AAABgrYTjPwAAAEBMJ+I/AAAAwMEb6z8AAACAnfrlPwAAAIBHEOc/AAAAoKPy5j8AAACAvqTrPwAAAEA2e98/AAAAQMqn3j8AAACg/2HgPwAAAMCEuNo/AAAAINZu4D8AAADgDbLcPwAAAGCmT9c/AAAAoMqd4D8AAACAv4jlPwAAAIC8ldk/AAAAgOlW4D8AAABAF4vjPwAAAMDOruA/AAAAQItR4z8AAABg14LrPwAAAKDEFuI/AAAAIAPe5j8AAAAA+ejhPwAAAAAdmuY/AAAAAC4V5z8AAACgsorqPwAAAIDaxvA/AAAAgOk55T8AAAAgb3roPwAAAID7U+Q/AAAAQEHH5j8AAAAgINjmPwAAAGBbAOw/AAAAgP1b6T8AAABgYvLsPwAAAABg+uY/AAAA4MZt5T8AAADAu2/gPwAAAEBnsds/AAAAwHcf3z8AAACAmnPlPwAAAMC1RuQ/AAAAwBY64j8AAACAj+vfPwAAAABFT90/AAAAIKii5z8AAABgI6HjPwAAAMBDv+Y/AAAAgFxz6D8AAACA7a3kPwAAAKCJcfA/AAAAwCpC4z8AAACA3m7oPwAAAKBEeuY/AAAAwOH26D8AAACg/oLlPwAAAIATwfE/AAAAAGgd5j8AAAAgVzLoPwAAAOAnA/I/AAAAQETw7z8AAABALWLvPwAAAACgAOo/AAAAwDEo6D8AAAAAMmTpPwAAAEC+oew/AAAAABKI6z8AAABAccToPwAAAGAvcuc/AAAAQBQH3z8AAADALivjPwAAAOCgPeI/AAAAAEN65D8AAABg4SzkPwAAAGBMYeA/AAAAIGVk4T8AAAAgqXPlPwAAAIBxleM/AAAA4HAW5D8AAABAYSjtPwAAAOADduQ/AAAAQGAL5T8AAADglVfmPwAAAECfsuQ/AAAAwEsR6z8AAABg0STjPwAAAGCSQOc/AAAAoDD74z8AAAAAAV7pPwAAAACK/uU/AAAAIJG46D8AAABgPBbqPwAAAID0kek/AAAAYBAh6D8AAAAAvILkPwAAAADtDec/AAAAoGzN5j8AAADAX7PtPwAAAEAyneU/AAAA4IqX6z8AAAAAlXTrPw==",
          "dtype": "f8"
         },
         "yaxis": "y2"
        },
        {
         "hovertemplate": "variable=ewm_batch_train_loss<br>lr=%{x}<br>value=%{y}<extra></extra>",
         "legendgroup": "",
         "line": {
          "color": "#636efa",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "",
         "orientation": "v",
         "showlegend": false,
         "type": "scatter",
         "x": {
          "bdata": "/Knx0k1iQD/OcAM+P4xAP5Oi3wictkA/zf1mRmXhQD/78DkMnAxBPwikv3JBOEE/wBMtlVZkQT94P4yR3JBBPxBpw4jUvUE/jmecnj/rQT9uDMz5HhlCP+qb+cNzR0I/WljGKT92Qj/qINVagqVCP84j0ok+1UI/KqR67HQFQz/j06S7JjZDP4fBRzNVZ0M/gVqDkgGZQz/PgagbLctDP207QRTZ/UM/qewYxQYxRD+WsUR6t2REP9jHK4PsmEQ/9g6QMqfNRD95npbe6AJFP/px0OCyOEU/cCtDlgZvRT/f63Ff5aVFP7ZCZqBQ3UU/BTS5wEkVRj/SVZwr0k1GP8IE40/rhkY/U7ALoJbARj/jPkmS1fpGP8GJjKCpNUc/iPGNSBRxRz/9CtcLF61HP7NkzG+z6Uc/tWW3/eomSD9yRdBCv2RIPy4dSNAxo0g/OxNTO0TiSD85oDId+CFJP6DuPxNPYkk/2lT2vkqjST8u6v3F7ORJP8M2NtI2J0o//f7AkSpqSj+AKg23ya1KPxbH4fgV8ko/zCdpEhE3Sz+EIDzDvHxLP0hebc8aw0s/qtyU/ywKTD95eNsg9VFMPxSgBgV1mkw/riGEgq7jTD/HF3Z0oy1NPy30vrpVeE0/0akNOsfDTT/B9enb+Q9OP5LHwI7vXE4/kcnwRaqqTj8GCdf5K/lOP+C+26d2SE8/Gzl/UoyYTz8y5WYBb+lPP/w9tWCQHVA/kKdQ0tFGUD9w3DfhfHBQP/ZWypuSmlA/HLkbExTFUD9nuPpaAvBQP4cb+IleG1E/4sltuSlHUT8v7YUFZXNRP1ElQo0RoFE/ps6CcjDNUT/1Wg7awvpRPya9mOvJKFI/AOjK0UZXUj8VYEq6OoZSPwvhwNWmtVI/fhbkV4zlUj+jaH137BVTP+LccW7IRlM/nQrKeSF4Uz9SJLrZ+KlTP1MVqtFP3FM/QrQ9qCcPVD+KCl2ngUJUPwuxPBxfdlQ/LEJmV8GqVD+O4cCsqd9UP5LZmXMZFVU/8k6tBhJLVT+dCi/ElIFVPxRa0w2juFU/gAbYSD7wVT+6Yg3eZyhWP4Rw3zkhYVY/KR1fzGuaVj/GlUsJSdRWP26zG2i6Dlc/d38HZMFJVz8a0BF8X4VXP7T9ETOWwVc/4bC9D2f+Vz+wybKc0ztYPy9ggWjdeVg/lt61BYa4WD9LNeMKz/dYPwcprRK6N1k/XLvSu0h4WT/grTipfLlZP0Eg9IFX+1k/iUlV8do9Wj/VTPKmCIFaP8MpslbixFo/5sjXuGkJWz+CJA2KoE5bP9WNbouIlFs/QA+WgiPbWz+Q66Y5cyJcP7g6WX95alw/RKQFJzizXD/UN7EIsfxcP+hjGQHmRl0/TgvA8diRXT9/uffAi91dPzv271kAKl4/sbjBrDh3Xj+K+nuuNsVePyBrMFn8E18/PUMArItjXz+sOSmr5rNfP3xMCbCHAmA/VDut7IMrYD8phnEV6VRgP2wZ8Da4fmA/FIByYPKoYD/rw/ijmNNgP3pfQBas/mA/tkHLzi0qYT+m4+bnHlZhPypws36AgmE/Fv4qs1OvYT/J3CiomdxhP3nzcINTCmI/WTO3bYI4Yj/SHKeSJ2diP/1X6yBElmI/jGA1StnFYj9aRUVD6PViP8578UNyJmM/SMcuh3hXYz/LNBhL/IhjPxUr99D+umM/Wo9LXYHtYz/e/tM3hSBkP5MdlqsLVGQ/CPrmBhaIZD/GhnObpbxkP2cpSb678WQ/lF/ex1knZT8iehsUgV1lP45uYwIzlGU/Bb+c9XDLZT9AeTpUPANmP2JMRYiWO2Y/G7Zk/4B0Zj9JR+gq/a1mP1EA0X8M6GY/ccXadrAiZz9C64WM6l1nP7HbIEG8mWc/ptPRGCfWZz+buaCbLBNoP2INgVXOUGg/W/Fb1g2PaD9fTRqy7M1oP5YLr4BsDWk/i28h3o5NaT+zh5dqVY5pP7K5YMrBz2k/omkAptURaj+cvDiqklRqP9F2FYj6l2o/cvX29A7caj+zRJ2q0SBrPzBSM2dEZms/+Dta7Wisaz+SvDQEQfNrPze0cnfOOmw/ns9cFxODbD+TTOC4EMxsP7PcmjXJFW0/lqbmaz5gbT+xZeY+cqttP0WpkZZm920/pDLBXx1Ebj8mczuMmJFuPw8qwRLa324/zSIa7+Mubz/KEyIiuH5vPzqe1bFYz28/lrev1GMQcD8awZKMgzlwPwhDa4sMY3A/yLG73v+McD+Pc7iWXrdwP6LGTsYp4nA/Qrkrg2INcT9uM8PlCTlxP6oSVwkhZXE/+Vf+C6mRcT82aKwOo75xPwNfODUQ7HE/cXRkpvEZcj+bdeWLSEhyP2JQahIWd3I/eLKjaVumcj/vu0vEGdZyP37FLVhSBnM/qzouXgY3cz8OiFISN2hzP+UdybPlmXM/J4fxhBPMcz9OlWTLwf5zPwqh/M/xMXQ/F+Dd3qRldD9p0H5H3Jl0P+W4sFyZznQ/3T+odN0DdT+LFwbpqTl1P73A3xYAcHU/8mPIXuGmdT8bwdkkT951Pz02vdBKFnY/Lt20zdVOdj+swKSK8Yd2PwApHHqfwXY/cwBfEuH7dj/QT2/NtzZ3PyzTFiklcnc/NKfwpiqudz9GD3PMyep3P4xU+SIEKHg/Wr7NN9tleD8YpDOcUKR4P++YceVl43g/gbHbrBwjeT/r492PdmN5P1uCBjB1pHk/dtAQMxrmeT/Ts+9CZyh6P91/2A1ea3o/Td1NRgCvej+YzSqjT/N6P4jKrd9NOHs/UQKEu/x9ez9rsNT6XcR7P3aTTGZzC3w/dYApyz5TfD+pE0b7wZt8P2F/Jc3+5Hw/+Xj/G/cufT9sRMzHrHl9P7XeULUhxX0/VkcrzlcRfj9U6d4AUV5+P/sj4UAPrH4/s/OlhpT6fj9Cu6zP4kl/P8UtjR78mX8/v1kEe+Lqfz/D6gD5Sx6AP7aG2kqPR4A/+lnNPjxxgD89KkXjU5uAP0MEYknXxYA/JSj/hMfwgD9EB7qsJRyBPyNU+dnyR4E/VyT0KDB0gT+0JLm43qCBP/PfNav/zYE/8xc+JZT7gT/KMZNOnSmCP9m061EcWII/Dt36XBKHgj+MQHiggLaCP9+IJ1Bo5oI/AEDgosoWgz9IsZXSqEeDP5PeXhwEeYM/w4l+wN2qgz/SUmsCN92DP7Dq1ygREIQ/HVu7fW1DhD+0Y1lOTXeEP2HsSuuxq4Q/d42GqJzghD+aLWndDhaFP721vuQJTIU/ZdvKHI+ChT9uAVLnn7mFP4Yvoqk98YU/pCCczGkphj+maLy8JWKGP2CxJOpym4Y/Tw+lyFLVhj8vbsXPxg+HP7AVz3rQSoc/i0bWSHGGhz818MO8qsKHP2l/X11+/4c/zsVYte08iD/8+lFT+nqIPw==",
          "dtype": "f8"
         },
         "xaxis": "x",
         "y": {
          "bdata": "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",
          "dtype": "f8"
         },
         "yaxis": "y"
        }
       ],
       "layout": {
        "annotations": [
         {
          "font": {},
          "showarrow": false,
          "text": "variable=ewm_batch_train_loss",
          "textangle": 90,
          "x": 0.98,
          "xanchor": "left",
          "xref": "paper",
          "y": 0.2425,
          "yanchor": "middle",
          "yref": "paper"
         },
         {
          "font": {},
          "showarrow": false,
          "text": "variable=batch_train_loss",
          "textangle": 90,
          "x": 0.98,
          "xanchor": "left",
          "xref": "paper",
          "y": 0.7575000000000001,
          "yanchor": "middle",
          "yref": "paper"
         }
        ],
        "height": 750,
        "legend": {
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          0.98
         ],
         "title": {
          "text": "lr"
         },
         "type": "log"
        },
        "xaxis2": {
         "anchor": "y2",
         "domain": [
          0,
          0.98
         ],
         "matches": "x",
         "showticklabels": false,
         "type": "log"
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          0.485
         ],
         "title": {
          "text": "value"
         },
         "type": "log"
        },
        "yaxis2": {
         "anchor": "x2",
         "domain": [
          0.515,
          1
         ],
         "title": {
          "text": "value"
         },
         "type": "log"
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum learning rate: 0.0021803856955347795\n"
     ]
    }
   ],
   "source": [
    "full_dataset = CMIDataset(\"full_dataset\")\n",
    "full_dataset_loader = DL(full_dataset, TRAIN_BATCH_SIZE, shuffle=True)\n",
    "_, mock_training_metrics = mk_model_and_fit(\n",
    "    full_dataset_loader,\n",
    "    partial(torch.optim.lr_scheduler.ExponentialLR, gamma=MOCK_TRAINING_GAMMA),\n",
    "    MOCK_TRAINING_EPOCHS\n",
    ")\n",
    "mock_training_metrics = post_process_mock_training_metrics(mock_training_metrics)\n",
    "plt_lr_search_training_metrics(mock_training_metrics)\n",
    "max_lr = mock_training_metrics[\"ewm_batch_train_loss\"].idxmin()\n",
    "# max_lr = 0.002\n",
    "print(\"Maximum learning rate:\", max_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1cc3c5f",
   "metadata": {
    "papermill": {
     "duration": 0.003108,
     "end_time": "2025-06-14T10:01:56.186803",
     "exception": false,
     "start_time": "2025-06-14T10:01:56.183695",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "2be28a9c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T10:01:56.194003Z",
     "iopub.status.busy": "2025-06-14T10:01:56.193740Z",
     "iopub.status.idle": "2025-06-14T10:09:14.752385Z",
     "shell.execute_reply": "2025-06-14T10:09:14.751491Z"
    },
    "papermill": {
     "duration": 438.563878,
     "end_time": "2025-06-14T10:09:14.753712",
     "exception": false,
     "start_time": "2025-06-14T10:01:56.189834",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training: 1\n",
      "\n",
      "==================================================\n",
      "Fold 1/5\n",
      "Epoch 01: Train Loss = 2.2839, Val Loss = 1.4809\n",
      "  Binary F1 = 0.9361, Macro F1 = 0.4518, Final Metric = 0.6939\n",
      "  New best metric! Saving model...\n",
      "Epoch 02: Train Loss = 1.1157, Val Loss = 1.2921\n",
      "  Binary F1 = 0.9538, Macro F1 = 0.5009, Final Metric = 0.7274\n",
      "  New best metric! Saving model...\n",
      "Epoch 03: Train Loss = 0.7505, Val Loss = 1.1090\n",
      "  Binary F1 = 0.9637, Macro F1 = 0.5590, Final Metric = 0.7613\n",
      "  New best metric! Saving model...\n",
      "Epoch 04: Train Loss = 0.5006, Val Loss = 1.0449\n",
      "  Binary F1 = 0.9696, Macro F1 = 0.6098, Final Metric = 0.7897\n",
      "  New best metric! Saving model...\n",
      "Epoch 05: Train Loss = 0.3618, Val Loss = 1.0621\n",
      "  Binary F1 = 0.9729, Macro F1 = 0.6033, Final Metric = 0.7881\n",
      "Epoch 06: Train Loss = 0.5068, Val Loss = 1.7822\n",
      "  Binary F1 = 0.9554, Macro F1 = 0.4778, Final Metric = 0.7166\n",
      "Epoch 07: Train Loss = 0.4111, Val Loss = 1.4175\n",
      "  Binary F1 = 0.9617, Macro F1 = 0.5641, Final Metric = 0.7629\n",
      "Epoch 08: Train Loss = 0.1903, Val Loss = 1.2961\n",
      "  Binary F1 = 0.9654, Macro F1 = 0.6111, Final Metric = 0.7882\n",
      "Epoch 09: Train Loss = 0.0528, Val Loss = 1.3370\n",
      "  Binary F1 = 0.9716, Macro F1 = 0.6243, Final Metric = 0.7980\n",
      "  New best metric! Saving model...\n",
      "Epoch 10: Train Loss = 0.0201, Val Loss = 1.3452\n",
      "  Binary F1 = 0.9712, Macro F1 = 0.6242, Final Metric = 0.7977\n",
      "Epoch 11: Train Loss = 0.0127, Val Loss = 1.5316\n",
      "  Binary F1 = 0.9703, Macro F1 = 0.6205, Final Metric = 0.7954\n",
      "Epoch 12: Train Loss = 0.0083, Val Loss = 1.6535\n",
      "  Binary F1 = 0.9730, Macro F1 = 0.6215, Final Metric = 0.7973\n",
      "Epoch 13: Train Loss = 0.0098, Val Loss = 1.6419\n",
      "  Binary F1 = 0.9714, Macro F1 = 0.6252, Final Metric = 0.7983\n",
      "  New best metric! Saving model...\n",
      "Epoch 14: Train Loss = 0.0037, Val Loss = 1.6540\n",
      "  Binary F1 = 0.9676, Macro F1 = 0.6274, Final Metric = 0.7975\n",
      "Epoch 15: Train Loss = 0.0017, Val Loss = 1.6408\n",
      "  Binary F1 = 0.9677, Macro F1 = 0.6332, Final Metric = 0.8005\n",
      "  New best metric! Saving model...\n",
      "Epoch 16: Train Loss = 0.0012, Val Loss = 1.6622\n",
      "  Binary F1 = 0.9715, Macro F1 = 0.6401, Final Metric = 0.8058\n",
      "  New best metric! Saving model...\n",
      "Epoch 17: Train Loss = 0.0007, Val Loss = 1.7064\n",
      "  Binary F1 = 0.9710, Macro F1 = 0.6358, Final Metric = 0.8034\n",
      "Epoch 18: Train Loss = 0.0005, Val Loss = 1.7225\n",
      "  Binary F1 = 0.9725, Macro F1 = 0.6344, Final Metric = 0.8035\n",
      "Epoch 19: Train Loss = 0.0005, Val Loss = 1.7235\n",
      "  Binary F1 = 0.9720, Macro F1 = 0.6364, Final Metric = 0.8042\n",
      "Epoch 20: Train Loss = 0.0005, Val Loss = 1.7317\n",
      "  Binary F1 = 0.9725, Macro F1 = 0.6389, Final Metric = 0.8057\n",
      "Epoch 21: Train Loss = 0.0004, Val Loss = 1.7569\n",
      "  Binary F1 = 0.9711, Macro F1 = 0.6387, Final Metric = 0.8049\n",
      "Epoch 22: Train Loss = 0.0004, Val Loss = 1.7619\n",
      "  Binary F1 = 0.9725, Macro F1 = 0.6426, Final Metric = 0.8075\n",
      "  New best metric! Saving model...\n",
      "Epoch 23: Train Loss = 0.0003, Val Loss = 1.7772\n",
      "  Binary F1 = 0.9734, Macro F1 = 0.6410, Final Metric = 0.8072\n",
      "Epoch 24: Train Loss = 0.0003, Val Loss = 1.7862\n",
      "  Binary F1 = 0.9734, Macro F1 = 0.6409, Final Metric = 0.8072\n",
      "Epoch 25: Train Loss = 0.0003, Val Loss = 1.7866\n",
      "  Binary F1 = 0.9729, Macro F1 = 0.6401, Final Metric = 0.8065\n",
      "\n",
      "Fold 1 completed.\n",
      "Final validation metrics - Binary F1: 0.9729, Macro F1: 0.6401, Final: 0.8065\n",
      "Best validation metrics - Binary F1: 0.9725, Macro F1: 0.6426, Final: 0.8075\n",
      "training: 2\n",
      "\n",
      "==================================================\n",
      "Fold 2/5\n",
      "Epoch 01: Train Loss = 2.6581, Val Loss = 1.9918\n",
      "  Binary F1 = 0.9150, Macro F1 = 0.3496, Final Metric = 0.6323\n",
      "  New best metric! Saving model...\n",
      "Epoch 02: Train Loss = 1.1915, Val Loss = 1.5052\n",
      "  Binary F1 = 0.9478, Macro F1 = 0.4761, Final Metric = 0.7120\n",
      "  New best metric! Saving model...\n",
      "Epoch 03: Train Loss = 0.8420, Val Loss = 1.3331\n",
      "  Binary F1 = 0.9652, Macro F1 = 0.5630, Final Metric = 0.7641\n",
      "  New best metric! Saving model...\n",
      "Epoch 04: Train Loss = 0.6132, Val Loss = 1.3383\n",
      "  Binary F1 = 0.9599, Macro F1 = 0.5661, Final Metric = 0.7630\n",
      "Epoch 05: Train Loss = 0.4327, Val Loss = 1.3562\n",
      "  Binary F1 = 0.9616, Macro F1 = 0.5696, Final Metric = 0.7656\n",
      "  New best metric! Saving model...\n",
      "Epoch 06: Train Loss = 0.6294, Val Loss = 1.8327\n",
      "  Binary F1 = 0.9228, Macro F1 = 0.4916, Final Metric = 0.7072\n",
      "Epoch 07: Train Loss = 0.5387, Val Loss = 1.5471\n",
      "  Binary F1 = 0.9566, Macro F1 = 0.5344, Final Metric = 0.7455\n",
      "Epoch 08: Train Loss = 0.2074, Val Loss = 1.6023\n",
      "  Binary F1 = 0.9635, Macro F1 = 0.5592, Final Metric = 0.7614\n",
      "Epoch 09: Train Loss = 0.0638, Val Loss = 1.6695\n",
      "  Binary F1 = 0.9621, Macro F1 = 0.5691, Final Metric = 0.7656\n",
      "  New best metric! Saving model...\n",
      "Epoch 10: Train Loss = 0.0256, Val Loss = 1.7098\n",
      "  Binary F1 = 0.9627, Macro F1 = 0.5940, Final Metric = 0.7784\n",
      "  New best metric! Saving model...\n",
      "Epoch 11: Train Loss = 0.0282, Val Loss = 1.9403\n",
      "  Binary F1 = 0.9642, Macro F1 = 0.5802, Final Metric = 0.7722\n",
      "Epoch 12: Train Loss = 0.1017, Val Loss = 2.2623\n",
      "  Binary F1 = 0.9493, Macro F1 = 0.5309, Final Metric = 0.7401\n",
      "Epoch 13: Train Loss = 0.1275, Val Loss = 1.9076\n",
      "  Binary F1 = 0.9570, Macro F1 = 0.5632, Final Metric = 0.7601\n",
      "Epoch 14: Train Loss = 0.0423, Val Loss = 1.8917\n",
      "  Binary F1 = 0.9603, Macro F1 = 0.5692, Final Metric = 0.7648\n",
      "Epoch 15: Train Loss = 0.0094, Val Loss = 1.9529\n",
      "  Binary F1 = 0.9608, Macro F1 = 0.5865, Final Metric = 0.7737\n",
      "Epoch 16: Train Loss = 0.0037, Val Loss = 2.1201\n",
      "  Binary F1 = 0.9618, Macro F1 = 0.5872, Final Metric = 0.7745\n",
      "Early stopping triggered at epoch 16\n",
      "\n",
      "Fold 2 completed.\n",
      "Final validation metrics - Binary F1: 0.9618, Macro F1: 0.5872, Final: 0.7745\n",
      "Best validation metrics - Binary F1: 0.9627, Macro F1: 0.5940, Final: 0.7784\n",
      "training: 3\n",
      "\n",
      "==================================================\n",
      "Fold 3/5\n",
      "Epoch 01: Train Loss = 2.5953, Val Loss = 2.3796\n",
      "  Binary F1 = 0.8794, Macro F1 = 0.3155, Final Metric = 0.5974\n",
      "  New best metric! Saving model...\n",
      "Epoch 02: Train Loss = 1.1805, Val Loss = 2.3323\n",
      "  Binary F1 = 0.9113, Macro F1 = 0.4932, Final Metric = 0.7023\n",
      "  New best metric! Saving model...\n",
      "Epoch 03: Train Loss = 0.7980, Val Loss = 2.4391\n",
      "  Binary F1 = 0.9322, Macro F1 = 0.5426, Final Metric = 0.7374\n",
      "  New best metric! Saving model...\n",
      "Epoch 04: Train Loss = 0.5408, Val Loss = 2.3403\n",
      "  Binary F1 = 0.9389, Macro F1 = 0.5581, Final Metric = 0.7485\n",
      "  New best metric! Saving model...\n",
      "Epoch 05: Train Loss = 0.3873, Val Loss = 2.6883\n",
      "  Binary F1 = 0.9344, Macro F1 = 0.5856, Final Metric = 0.7600\n",
      "  New best metric! Saving model...\n",
      "Epoch 06: Train Loss = 0.5782, Val Loss = 3.1184\n",
      "  Binary F1 = 0.9367, Macro F1 = 0.5211, Final Metric = 0.7289\n",
      "Epoch 07: Train Loss = 0.3974, Val Loss = 3.6496\n",
      "  Binary F1 = 0.9317, Macro F1 = 0.5471, Final Metric = 0.7394\n",
      "Epoch 08: Train Loss = 0.1781, Val Loss = 3.2838\n",
      "  Binary F1 = 0.9273, Macro F1 = 0.5762, Final Metric = 0.7518\n",
      "Epoch 09: Train Loss = 0.0514, Val Loss = 3.4119\n",
      "  Binary F1 = 0.9335, Macro F1 = 0.5942, Final Metric = 0.7639\n",
      "  New best metric! Saving model...\n",
      "Epoch 10: Train Loss = 0.0185, Val Loss = 3.4786\n",
      "  Binary F1 = 0.9368, Macro F1 = 0.6033, Final Metric = 0.7700\n",
      "  New best metric! Saving model...\n",
      "Epoch 11: Train Loss = 0.0128, Val Loss = 3.8967\n",
      "  Binary F1 = 0.9372, Macro F1 = 0.6011, Final Metric = 0.7691\n",
      "Epoch 12: Train Loss = 0.0092, Val Loss = 3.9458\n",
      "  Binary F1 = 0.9303, Macro F1 = 0.5908, Final Metric = 0.7606\n",
      "Epoch 13: Train Loss = 0.0068, Val Loss = 3.6417\n",
      "  Binary F1 = 0.9331, Macro F1 = 0.6272, Final Metric = 0.7801\n",
      "  New best metric! Saving model...\n",
      "Epoch 14: Train Loss = 0.0029, Val Loss = 3.7233\n",
      "  Binary F1 = 0.9380, Macro F1 = 0.6223, Final Metric = 0.7802\n",
      "  New best metric! Saving model...\n",
      "Epoch 15: Train Loss = 0.0016, Val Loss = 3.7917\n",
      "  Binary F1 = 0.9380, Macro F1 = 0.6246, Final Metric = 0.7813\n",
      "  New best metric! Saving model...\n",
      "Epoch 16: Train Loss = 0.0012, Val Loss = 3.9807\n",
      "  Binary F1 = 0.9370, Macro F1 = 0.6149, Final Metric = 0.7760\n",
      "Epoch 17: Train Loss = 0.0007, Val Loss = 4.0670\n",
      "  Binary F1 = 0.9361, Macro F1 = 0.6171, Final Metric = 0.7766\n",
      "Epoch 18: Train Loss = 0.0006, Val Loss = 4.0623\n",
      "  Binary F1 = 0.9371, Macro F1 = 0.6172, Final Metric = 0.7771\n",
      "Epoch 19: Train Loss = 0.0005, Val Loss = 4.1094\n",
      "  Binary F1 = 0.9344, Macro F1 = 0.6145, Final Metric = 0.7745\n",
      "Epoch 20: Train Loss = 0.0005, Val Loss = 4.1704\n",
      "  Binary F1 = 0.9361, Macro F1 = 0.6173, Final Metric = 0.7767\n",
      "Epoch 21: Train Loss = 0.0005, Val Loss = 4.1186\n",
      "  Binary F1 = 0.9364, Macro F1 = 0.6185, Final Metric = 0.7774\n",
      "Early stopping triggered at epoch 21\n",
      "\n",
      "Fold 3 completed.\n",
      "Final validation metrics - Binary F1: 0.9364, Macro F1: 0.6185, Final: 0.7774\n",
      "Best validation metrics - Binary F1: 0.9380, Macro F1: 0.6246, Final: 0.7813\n",
      "training: 4\n",
      "\n",
      "==================================================\n",
      "Fold 4/5\n",
      "Epoch 01: Train Loss = 2.6425, Val Loss = 1.6111\n",
      "  Binary F1 = 0.9385, Macro F1 = 0.3987, Final Metric = 0.6686\n",
      "  New best metric! Saving model...\n",
      "Epoch 02: Train Loss = 1.1847, Val Loss = 1.2346\n",
      "  Binary F1 = 0.9572, Macro F1 = 0.5279, Final Metric = 0.7426\n",
      "  New best metric! Saving model...\n",
      "Epoch 03: Train Loss = 0.8231, Val Loss = 1.1373\n",
      "  Binary F1 = 0.9601, Macro F1 = 0.5665, Final Metric = 0.7633\n",
      "  New best metric! Saving model...\n",
      "Epoch 04: Train Loss = 0.5746, Val Loss = 1.0794\n",
      "  Binary F1 = 0.9741, Macro F1 = 0.5937, Final Metric = 0.7839\n",
      "  New best metric! Saving model...\n",
      "Epoch 05: Train Loss = 0.4147, Val Loss = 1.1149\n",
      "  Binary F1 = 0.9706, Macro F1 = 0.5955, Final Metric = 0.7831\n",
      "Epoch 06: Train Loss = 0.6020, Val Loss = 1.3161\n",
      "  Binary F1 = 0.9713, Macro F1 = 0.5538, Final Metric = 0.7625\n",
      "Epoch 07: Train Loss = 0.4096, Val Loss = 1.2326\n",
      "  Binary F1 = 0.9690, Macro F1 = 0.5941, Final Metric = 0.7816\n",
      "Epoch 08: Train Loss = 0.2221, Val Loss = 1.3416\n",
      "  Binary F1 = 0.9772, Macro F1 = 0.5983, Final Metric = 0.7878\n",
      "  New best metric! Saving model...\n",
      "Epoch 09: Train Loss = 0.0746, Val Loss = 1.3304\n",
      "  Binary F1 = 0.9740, Macro F1 = 0.6178, Final Metric = 0.7959\n",
      "  New best metric! Saving model...\n",
      "Epoch 10: Train Loss = 0.0269, Val Loss = 1.3978\n",
      "  Binary F1 = 0.9740, Macro F1 = 0.6188, Final Metric = 0.7964\n",
      "  New best metric! Saving model...\n",
      "Epoch 11: Train Loss = 0.0353, Val Loss = 1.6066\n",
      "  Binary F1 = 0.9765, Macro F1 = 0.6067, Final Metric = 0.7916\n",
      "Epoch 12: Train Loss = 0.0464, Val Loss = 1.8283\n",
      "  Binary F1 = 0.9748, Macro F1 = 0.6001, Final Metric = 0.7874\n",
      "Epoch 13: Train Loss = 0.0376, Val Loss = 1.7680\n",
      "  Binary F1 = 0.9704, Macro F1 = 0.6068, Final Metric = 0.7886\n",
      "Epoch 14: Train Loss = 0.0119, Val Loss = 1.7055\n",
      "  Binary F1 = 0.9720, Macro F1 = 0.6193, Final Metric = 0.7956\n",
      "Epoch 15: Train Loss = 0.0039, Val Loss = 1.6977\n",
      "  Binary F1 = 0.9724, Macro F1 = 0.6137, Final Metric = 0.7930\n",
      "Epoch 16: Train Loss = 0.0019, Val Loss = 1.7947\n",
      "  Binary F1 = 0.9759, Macro F1 = 0.6269, Final Metric = 0.8014\n",
      "  New best metric! Saving model...\n",
      "Epoch 17: Train Loss = 0.0009, Val Loss = 1.8468\n",
      "  Binary F1 = 0.9740, Macro F1 = 0.6215, Final Metric = 0.7977\n",
      "Epoch 18: Train Loss = 0.0005, Val Loss = 1.8835\n",
      "  Binary F1 = 0.9730, Macro F1 = 0.6203, Final Metric = 0.7967\n",
      "Epoch 19: Train Loss = 0.0005, Val Loss = 1.8874\n",
      "  Binary F1 = 0.9745, Macro F1 = 0.6195, Final Metric = 0.7970\n",
      "Epoch 20: Train Loss = 0.0004, Val Loss = 1.8850\n",
      "  Binary F1 = 0.9745, Macro F1 = 0.6210, Final Metric = 0.7978\n",
      "Epoch 21: Train Loss = 0.0004, Val Loss = 1.9129\n",
      "  Binary F1 = 0.9730, Macro F1 = 0.6208, Final Metric = 0.7969\n",
      "Epoch 22: Train Loss = 0.0003, Val Loss = 1.9288\n",
      "  Binary F1 = 0.9740, Macro F1 = 0.6216, Final Metric = 0.7978\n",
      "Early stopping triggered at epoch 22\n",
      "\n",
      "Fold 4 completed.\n",
      "Final validation metrics - Binary F1: 0.9740, Macro F1: 0.6216, Final: 0.7978\n",
      "Best validation metrics - Binary F1: 0.9759, Macro F1: 0.6269, Final: 0.8014\n",
      "training: 5\n",
      "\n",
      "==================================================\n",
      "Fold 5/5\n",
      "Epoch 01: Train Loss = 2.8187, Val Loss = 1.8958\n",
      "  Binary F1 = 0.9074, Macro F1 = 0.2944, Final Metric = 0.6009\n",
      "  New best metric! Saving model...\n",
      "Epoch 02: Train Loss = 1.3522, Val Loss = 1.1985\n",
      "  Binary F1 = 0.9669, Macro F1 = 0.5424, Final Metric = 0.7547\n",
      "  New best metric! Saving model...\n",
      "Epoch 03: Train Loss = 0.9379, Val Loss = 1.1237\n",
      "  Binary F1 = 0.9691, Macro F1 = 0.5738, Final Metric = 0.7714\n",
      "  New best metric! Saving model...\n",
      "Epoch 04: Train Loss = 0.6742, Val Loss = 0.9771\n",
      "  Binary F1 = 0.9820, Macro F1 = 0.6284, Final Metric = 0.8052\n",
      "  New best metric! Saving model...\n",
      "Epoch 05: Train Loss = 0.4968, Val Loss = 0.9615\n",
      "  Binary F1 = 0.9814, Macro F1 = 0.6325, Final Metric = 0.8070\n",
      "  New best metric! Saving model...\n",
      "Epoch 06: Train Loss = 0.6974, Val Loss = 1.1922\n",
      "  Binary F1 = 0.9670, Macro F1 = 0.5808, Final Metric = 0.7739\n",
      "Epoch 07: Train Loss = 0.4745, Val Loss = 1.2523\n",
      "  Binary F1 = 0.9724, Macro F1 = 0.6033, Final Metric = 0.7879\n",
      "Epoch 08: Train Loss = 0.2009, Val Loss = 1.2444\n",
      "  Binary F1 = 0.9660, Macro F1 = 0.6221, Final Metric = 0.7940\n",
      "Epoch 09: Train Loss = 0.0705, Val Loss = 1.1590\n",
      "  Binary F1 = 0.9828, Macro F1 = 0.6517, Final Metric = 0.8173\n",
      "  New best metric! Saving model...\n",
      "Epoch 10: Train Loss = 0.0277, Val Loss = 1.2045\n",
      "  Binary F1 = 0.9834, Macro F1 = 0.6525, Final Metric = 0.8179\n",
      "  New best metric! Saving model...\n",
      "Epoch 11: Train Loss = 0.0447, Val Loss = 1.4086\n",
      "  Binary F1 = 0.9736, Macro F1 = 0.6187, Final Metric = 0.7961\n",
      "Epoch 12: Train Loss = 0.0739, Val Loss = 1.7051\n",
      "  Binary F1 = 0.9723, Macro F1 = 0.5941, Final Metric = 0.7832\n",
      "Epoch 13: Train Loss = 0.0966, Val Loss = 1.4826\n",
      "  Binary F1 = 0.9754, Macro F1 = 0.6331, Final Metric = 0.8042\n",
      "Epoch 14: Train Loss = 0.0301, Val Loss = 1.4246\n",
      "  Binary F1 = 0.9767, Macro F1 = 0.6499, Final Metric = 0.8133\n",
      "Epoch 15: Train Loss = 0.0075, Val Loss = 1.3911\n",
      "  Binary F1 = 0.9848, Macro F1 = 0.6610, Final Metric = 0.8229\n",
      "  New best metric! Saving model...\n",
      "Epoch 16: Train Loss = 0.0038, Val Loss = 1.4480\n",
      "  Binary F1 = 0.9839, Macro F1 = 0.6597, Final Metric = 0.8218\n",
      "Epoch 17: Train Loss = 0.0043, Val Loss = 1.6016\n",
      "  Binary F1 = 0.9800, Macro F1 = 0.6415, Final Metric = 0.8107\n",
      "Epoch 18: Train Loss = 0.0043, Val Loss = 1.6331\n",
      "  Binary F1 = 0.9791, Macro F1 = 0.6494, Final Metric = 0.8142\n",
      "Epoch 19: Train Loss = 0.0024, Val Loss = 1.5761\n",
      "  Binary F1 = 0.9820, Macro F1 = 0.6526, Final Metric = 0.8173\n",
      "Epoch 20: Train Loss = 0.0009, Val Loss = 1.5814\n",
      "  Binary F1 = 0.9820, Macro F1 = 0.6515, Final Metric = 0.8167\n",
      "Epoch 21: Train Loss = 0.0006, Val Loss = 1.6402\n",
      "  Binary F1 = 0.9810, Macro F1 = 0.6517, Final Metric = 0.8163\n",
      "Early stopping triggered at epoch 21\n",
      "\n",
      "Fold 5 completed.\n",
      "Final validation metrics - Binary F1: 0.9810, Macro F1: 0.6517, Final: 0.8163\n",
      "Best validation metrics - Binary F1: 0.9848, Macro F1: 0.6610, Final: 0.8229\n",
      "\n",
      "==================================================\n",
      "Cross-Validation Results\n",
      "==================================================\n",
      "\n",
      "Best Fold-wise Metrics:\n",
      "Fold 1: Binary F1 = 0.9725, Macro F1 = 0.6426, Final = 0.8075\n",
      "Fold 2: Binary F1 = 0.9627, Macro F1 = 0.5940, Final = 0.7784\n",
      "Fold 3: Binary F1 = 0.9380, Macro F1 = 0.6246, Final = 0.7813\n",
      "Fold 4: Binary F1 = 0.9759, Macro F1 = 0.6269, Final = 0.8014\n",
      "Fold 5: Binary F1 = 0.9848, Macro F1 = 0.6610, Final = 0.8229\n",
      "\n",
      "Global Statistics (Best Metrics):\n",
      "Mean Best Final Metric: 0.7983 Â± 0.0167\n",
      "Mean Best Binary F1: 0.9668 Â± 0.0161\n",
      "Mean Best Macro F1: 0.6298 Â± 0.0222\n"
     ]
    }
   ],
   "source": [
    "seed_everything(seed=SEED)\n",
    "\n",
    "# criterion = soft_cross_entropy\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "n_splits = 5\n",
    "batch_size = 128\n",
    "gkf = GroupKFold(n_splits=n_splits)\n",
    "\n",
    "fold_metrics = []\n",
    "best_fold_metrics = []\n",
    "best_models = []\n",
    "\n",
    "fold_patterns = join(dataset_path, \"preprocessed_dataset\", \"fold*\")\n",
    "fold_pths = glob(fold_patterns)[:NB_CROSS_VALIDATIONS]\n",
    "all_training_metrics = {}\n",
    "\n",
    "\n",
    "for fold, fold_pth in enumerate(fold_pths):\n",
    "    print(\"training:\", fold + 1)\n",
    "    train_dataset = CMIDataset(fold_pth, \"train\")\n",
    "    train_loader = DL(train_dataset, TRAIN_BATCH_SIZE, shuffle=True)\n",
    "    validation_dataset = CMIDataset(fold_pth, \"validation\")\n",
    "    validation_loader = DL(validation_dataset, VALIDATION_BATCH_SIZE, shuffle=False)\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Fold {fold + 1}/{n_splits}\")\n",
    "    \n",
    "    seed_everything(seed=SEED + fold)\n",
    "    model = mk_model()\n",
    "    \n",
    "    # Optimizer et scheduler\n",
    "    starting_lr = max_lr / 2\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), starting_lr)\n",
    "    steps_per_epoch = len(train_loader)\n",
    "    n_training_steps = TRAINING_EPOCHS * len(train_loader)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "        optimizer,\n",
    "        # T_0=n_training_steps // 5,\n",
    "        T_0=len(train_loader) * 5,\n",
    "        eta_min=starting_lr / 10,\n",
    "    )\n",
    "\n",
    "    # Early stopping\n",
    "    best_metric = -np.inf\n",
    "    best_binary_f1 = -np.inf\n",
    "    best_macro_f1 = -np.inf\n",
    "    patience = 6\n",
    "    epochs_no_improve = 0\n",
    "    \n",
    "    for epoch in range(1, TRAINING_EPOCHS + 1):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        total = 0\n",
    "        for batch_x, batch_y in train_loader:\n",
    "            batch_x = batch_x.to(device).clone()\n",
    "            batch_y = batch_y.to(device)\n",
    "            batch_x = batch_x.float()\n",
    "    \n",
    "            # TODO: Apply mixup?\n",
    "    \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_x)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "    \n",
    "            train_loss += loss.item() * batch_x.size(0)\n",
    "            total += batch_x.size(0)\n",
    "        train_loss /= total\n",
    "    \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        total = 0\n",
    "        all_true = []\n",
    "        all_pred = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch_x, batch_y in validation_loader:\n",
    "                batch_x = batch_x.to(device).clone()\n",
    "                batch_y = batch_y.to(device)\n",
    "                batch_x[VALIDATION_BATCH_SIZE // 2, non_imu_feats_idx] = 0.0\n",
    "                \n",
    "                outputs = model(batch_x)\n",
    "                loss = criterion(outputs, batch_y)\n",
    "                val_loss += loss.item() * batch_x.size(0)\n",
    "                total += batch_x.size(0)\n",
    "                \n",
    "                # Get predicted class indices\n",
    "                preds = torch.argmax(outputs, dim=1).cpu().numpy()\n",
    "                # Get true class indices from one-hot\n",
    "                trues = torch.argmax(batch_y, dim=1).cpu().numpy()\n",
    "                \n",
    "                all_true.append(trues)\n",
    "                all_pred.append(preds)\n",
    "        \n",
    "        val_loss /= total\n",
    "        all_true = np.concatenate(all_true)\n",
    "        all_pred = np.concatenate(all_pred)\n",
    "        \n",
    "        # Compute competition metrics\n",
    "        # Binary classification: BFRB (1) vs non-BFRB (0)\n",
    "        binary_true = np.isin(all_true, bfrb_indices).astype(int)\n",
    "        binary_pred = np.isin(all_pred, bfrb_indices).astype(int)\n",
    "        binary_f1 = f1_score(binary_true, binary_pred)\n",
    "        \n",
    "        # Collapse non-BFRB gestures into a single class\n",
    "        collapsed_true = np.where(\n",
    "            np.isin(all_true, bfrb_indices),\n",
    "            all_true,\n",
    "            len(bfrb_gestures)  # Single non-BFRB class\n",
    "        )\n",
    "        collapsed_pred = np.where(\n",
    "            np.isin(all_pred, bfrb_indices),\n",
    "            all_pred,\n",
    "            len(bfrb_gestures)  # Single non-BFRB class\n",
    "        )\n",
    "        \n",
    "        # Macro F1 on collapsed classes\n",
    "        macro_f1 = f1_score(collapsed_true, collapsed_pred, average='macro')\n",
    "        final_metric = (binary_f1 + macro_f1) / 2\n",
    "        \n",
    "        print(f\"Epoch {epoch:02d}: Train Loss = {train_loss:.4f}, Val Loss = {val_loss:.4f}\")\n",
    "        print(f\"  Binary F1 = {binary_f1:.4f}, Macro F1 = {macro_f1:.4f}, Final Metric = {final_metric:.4f}\")\n",
    "        \n",
    "        if final_metric > best_metric:\n",
    "            best_metric = final_metric\n",
    "            best_binary_f1 = binary_f1\n",
    "            best_macro_f1 = macro_f1\n",
    "            epochs_no_improve = 0\n",
    "            best_model_state = model.state_dict()\n",
    "            print(f\"  New best metric! Saving model...\")\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            if epochs_no_improve >= patience:\n",
    "                print(f\"Early stopping triggered at epoch {epoch}\")\n",
    "                model.load_state_dict(best_model_state)\n",
    "                break\n",
    "\n",
    "    torch.save(best_model_state, f\"best_model_fold{fold}.pth\")\n",
    "    best_models.append(best_model_state)\n",
    "\n",
    "    fold_metrics.append({\n",
    "        'binary_f1': binary_f1,\n",
    "        'macro_f1': macro_f1,\n",
    "        'final_metric': final_metric\n",
    "    })\n",
    "    \n",
    "    best_fold_metrics.append({\n",
    "        'binary_f1': best_binary_f1,\n",
    "        'macro_f1': best_macro_f1,\n",
    "        'final_metric': best_metric\n",
    "    })\n",
    "    \n",
    "    print(f\"\\nFold {fold + 1} completed.\")\n",
    "    print(f\"Final validation metrics - Binary F1: {binary_f1:.4f}, Macro F1: {macro_f1:.4f}, Final: {final_metric:.4f}\")\n",
    "    print(f\"Best validation metrics - Binary F1: {best_binary_f1:.4f}, Macro F1: {best_macro_f1:.4f}, Final: {best_metric:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Cross-Validation Results\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Statistiques pour les meilleures mÃ©triques\n",
    "best_binary_f1 = [m['binary_f1'] for m in best_fold_metrics]\n",
    "best_macro_f1 = [m['macro_f1'] for m in best_fold_metrics]\n",
    "best_metrics = [m['final_metric'] for m in best_fold_metrics]\n",
    "\n",
    "print(\"\\nBest Fold-wise Metrics:\")\n",
    "for i, (bf1, mf1, fm) in enumerate(zip(best_binary_f1, best_macro_f1, best_metrics)):\n",
    "    print(f\"Fold {i+1}: Binary F1 = {bf1:.4f}, Macro F1 = {mf1:.4f}, Final = {fm:.4f}\")\n",
    "\n",
    "print(\"\\nGlobal Statistics (Best Metrics):\")\n",
    "print(f\"Mean Best Final Metric: {np.mean(best_metrics):.4f} Â± {np.std(best_metrics):.4f}\")\n",
    "print(f\"Mean Best Binary F1: {np.mean(best_binary_f1):.4f} Â± {np.std(best_binary_f1):.4f}\")\n",
    "print(f\"Mean Best Macro F1: {np.mean(best_macro_f1):.4f} Â± {np.std(best_macro_f1):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ea7558",
   "metadata": {
    "papermill": {
     "duration": 0.012909,
     "end_time": "2025-06-14T10:09:14.961270",
     "exception": false,
     "start_time": "2025-06-14T10:09:14.948361",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aea5e4f",
   "metadata": {
    "papermill": {
     "duration": 0.012906,
     "end_time": "2025-06-14T10:09:14.780212",
     "exception": false,
     "start_time": "2025-06-14T10:09:14.767306",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Reloading best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a0574d4d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T10:09:14.807902Z",
     "iopub.status.busy": "2025-06-14T10:09:14.807165Z",
     "iopub.status.idle": "2025-06-14T10:09:14.933288Z",
     "shell.execute_reply": "2025-06-14T10:09:14.932459Z"
    },
    "papermill": {
     "duration": 0.141435,
     "end_time": "2025-06-14T10:09:14.934745",
     "exception": false,
     "start_time": "2025-06-14T10:09:14.793310",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_ensemble = []\n",
    "for fold in range(5):\n",
    "    model = mk_model().to(device)\n",
    "    checkpoint = torch.load(f\"best_model_fold{fold}.pth\", map_location=device, weights_only=True)\n",
    "    model.load_state_dict(checkpoint)\n",
    "    model.eval()\n",
    "    model_ensemble.append(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a826dec8",
   "metadata": {},
   "source": [
    "### Define preprocessing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "481e69b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fillna_val_per_feature_col(df:DF) -> dict:\n",
    "    return {col: 1.0 if col == 'rot_w' else 0 for col in get_feature_cols(df)}\n",
    "\n",
    "def imputed_features(df:DF) -> DF:\n",
    "    # Missing ToF values are already imputed by -1 which is inconvinient since we want all missing values to be NaN.    \n",
    "    # So we replace them by NaN and then perform imputing.  \n",
    "    tof_vals_to_nan = {col: -1.0 for col in df.columns if col.startswith(\"tof\")}\n",
    "\n",
    "    df[get_feature_cols(df)] = (\n",
    "        df\n",
    "        .loc[:, get_feature_cols(df)]\n",
    "        # df.replace with np.nan sets dtype to floar64 so we set it back to float32\n",
    "        .replace(tof_vals_to_nan, value=np.nan)\n",
    "        .astype(\"float32\")\n",
    "        .groupby(df[\"sequence_id\"], observed=True, as_index=False)\n",
    "        .ffill()\n",
    "        .groupby(df[\"sequence_id\"], observed=True, as_index=False)\n",
    "        .bfill()\n",
    "        # In case there are only nan in the column in the sequence\n",
    "        .fillna(get_fillna_val_per_feature_col(df))\n",
    "    )\n",
    "    return df\n",
    "\n",
    "def norm_quat_rotations(df:DF) -> DF:\n",
    "    df[QUATERNION_COLS] /= np.linalg.norm(df[QUATERNION_COLS], axis=1, keepdims=True)\n",
    "    return df\n",
    "\n",
    "def add_linear_acc_cols(df:DF) -> DF:\n",
    "    # Vectorized version of https://www.kaggle.com/code/wasupandceacar/lb-0-82-5fold-single-bert-model#Dataset `remove_gravity_from_acc`\n",
    "    rotations:Rotation = Rotation.from_quat(df[QUATERNION_COLS])\n",
    "    gravity_sensor_frame = rotations.apply(GRAVITY_WORLD, inverse=True).astype(\"float32\")\n",
    "    df[LINEAR_ACC_COLS] = df[RAW_ACCELRATION_COLS] - gravity_sensor_frame\n",
    "    return df\n",
    "\n",
    "def add_acc_magnitude(df:DF, acc_cols:list[str], acc_mag_col_name:str) -> DF:\n",
    "    return df.assign(**{acc_mag_col_name: np.linalg.norm(df.loc[:, acc_cols], axis=1)})\n",
    "\n",
    "def add_quat_angle_mag(df:DF) -> DF:\n",
    "    return df.assign(quat_rot_mag=np.arccos(df[\"rot_w\"]) * 2)\n",
    "\n",
    "def add_angular_velocity_features(df:DF) -> DF:\n",
    "    rotations = Rotation.from_quat(df[QUATERNION_COLS])\n",
    "    delta_rotations = rotations[1:] * rotations[:-1].inv()\n",
    "    delta_rot_velocity = delta_rotations.as_rotvec()\n",
    "    # Add extra line to avoid shape mismatch\n",
    "    delta_rot_velocity = np.vstack((np.zeros((1, 3)), delta_rot_velocity))\n",
    "    delta_rot_magnitude = norm(delta_rot_velocity, axis=1, keepdims=True)\n",
    "    delta_rot_axes = delta_rot_velocity / (delta_rot_magnitude + EPSILON)\n",
    "    df[DELTA_ROTATION_ANGULAR_VELOCITY_COLS] = delta_rot_velocity\n",
    "    df[DELTA_ROTATION_AXES_COLS] = delta_rot_axes\n",
    "    df[\"delta_rot_mag\"] = delta_rot_magnitude.squeeze()\n",
    "\n",
    "    return df\n",
    "\n",
    "def rot_euler_angles(df:DF) -> ndarray:\n",
    "    df[EULER_ANGLES_COLS] = (\n",
    "        Rotation\n",
    "        .from_quat(df[QUATERNION_COLS])\n",
    "        .as_euler(\"xyz\")\n",
    "        .squeeze()\n",
    "    )\n",
    "    return df\n",
    "\n",
    "def agg_tof_cols_per_sensor(df:DF) -> DF:\n",
    "    for tof_idx in tqdm(range(1, 6)):\n",
    "        tof_name = f\"tof_{tof_idx}\"\n",
    "        tof_cols = [f\"{tof_name}_v{v_idx}\" for v_idx in range(64)]\n",
    "        if any(map(lambda col: col not in df.columns, tof_cols)):\n",
    "            print(f\"Some (or) all ToF {tof_idx} columns are not in the df. Maybe you already ran this cell?\")\n",
    "            continue\n",
    "        df = pd.concat(\n",
    "            (\n",
    "                df.drop(columns=tof_cols),\n",
    "                # For some reasons, it's faster to call all the aggregation functions seperatly than agg(list of functions)\n",
    "                df[tof_cols].mean(axis=\"columns\").to_frame(tof_name + \"_mean\"),\n",
    "                df[tof_cols].std(axis=\"columns\").to_frame(tof_name + \"_std\"),\n",
    "                df[tof_cols].median(axis=\"columns\").to_frame(tof_name + \"_median\"),\n",
    "                df[tof_cols].min(axis=\"columns\").to_frame(tof_name + \"_min\"),\n",
    "                df[tof_cols].max(axis=\"columns\").to_frame(tof_name + \"_max\"),\n",
    "            ),\n",
    "            axis=\"columns\",\n",
    "        )\n",
    "    return df\n",
    "\n",
    "def add_diff_features(df:DF) -> DF:\n",
    "    return pd.concat(\n",
    "        (\n",
    "            df,\n",
    "            df\n",
    "            .groupby(\"sequence_id\", as_index=False, observed=True)\n",
    "            [get_feature_cols(df)]\n",
    "            .diff()\n",
    "            .fillna(get_fillna_val_per_feature_col(df))\n",
    "            .add_prefix(\"diff_\")\n",
    "        ),\n",
    "        axis=\"columns\",\n",
    "    )\n",
    "\n",
    "def length_normed_sequence_feat_arr(sequence: DF) -> ndarray:\n",
    "    features = (\n",
    "        sequence\n",
    "        .loc[:, meta_data[\"feature_cols\"]]\n",
    "        .values\n",
    "    )\n",
    "    normed_sequence_len = meta_data[\"pad_seq_len\"]\n",
    "    len_diff = abs(normed_sequence_len - len(features))\n",
    "    if len(features) < normed_sequence_len:\n",
    "        padded_features = np.pad(\n",
    "            features,\n",
    "            ((len_diff // 2 + len_diff % 2, len_diff // 2), (0, 0)),\n",
    "        )\n",
    "        return padded_features\n",
    "    elif len(features) > normed_sequence_len:\n",
    "        return features[len_diff // 2:-len_diff // 2]\n",
    "    else:\n",
    "        return features\n",
    "\n",
    "def preprocess_sequence(sequence_df:pl.DataFrame) -> ndarray:\n",
    "    return (\n",
    "        sequence_df                     \n",
    "        .to_pandas()                            # Convert to pandas dataframe.\n",
    "        .pipe(imputed_features)                 # Impute missing data.\n",
    "        .pipe(norm_quat_rotations)              # Norm quaternions\n",
    "        .pipe(add_linear_acc_cols)              # Add gravity free acceleration.\n",
    "        .pipe(add_acc_magnitude, RAW_ACCELRATION_COLS, \"raw_acc_mag\")\n",
    "        .pipe(add_acc_magnitude, LINEAR_ACC_COLS, \"linear_acc_mag\")\n",
    "        .pipe(add_quat_angle_mag)\n",
    "        .pipe(add_angular_velocity_features)\n",
    "        .pipe(rot_euler_angles)                 # Add rotation acc expressed as euler angles.\n",
    "        .pipe(agg_tof_cols_per_sensor)          # Aggregate ToF columns.\n",
    "        .pipe(add_diff_features)                # \n",
    "        .loc[:, sorted(meta_data[\"feature_cols\"])]      # Retain only the usefull columns a.k.a features.\n",
    "        .sub(meta_data[\"mean\"])                 # Subtract features by their mean, std norm pt.1.\n",
    "        .div(meta_data[\"std\"])                  # Divide by Standard deviation, std norm pt.2.\n",
    "        .pipe(length_normed_sequence_feat_arr)  # get feature ndarray of sequence.\n",
    "        .T                                      # Transpose to swap channel and X dimensions.\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ebb0960",
   "metadata": {},
   "source": [
    "### Define prediction function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "57d8dfff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T10:09:14.989742Z",
     "iopub.status.busy": "2025-06-14T10:09:14.989258Z",
     "iopub.status.idle": "2025-06-14T10:09:14.995936Z",
     "shell.execute_reply": "2025-06-14T10:09:14.995244Z"
    },
    "papermill": {
     "duration": 0.021303,
     "end_time": "2025-06-14T10:09:14.997034",
     "exception": false,
     "start_time": "2025-06-14T10:09:14.975731",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def predict(sequence: pl.DataFrame, demographics: pl.DataFrame) -> str:\n",
    "#     \"\"\"\n",
    "#     Kaggle evaluation API will call this for each sequence.\n",
    "#     sequence: polars DataFrame for a single sequence\n",
    "#     demographics: unused in this model\n",
    "#     Returns: predicted gesture string\n",
    "#     \"\"\"\n",
    "#     df_seq = sequence.to_pandas()\n",
    "#     df_demo = demographics.to_pandas()\n",
    "\n",
    "#     df_seq = df_seq.merge(\n",
    "#         df_demo,\n",
    "#         on='subject',\n",
    "#         how='left',\n",
    "#         validate='many_to_one',\n",
    "#     )\n",
    "#     right_handed_mask = df_seq['handedness'] == 1\n",
    "#     df_seq.loc[right_handed_mask, imu_cols] = apply_symmetry(df_seq.loc[right_handed_mask, imu_cols])\n",
    "\n",
    "#     x_tensor = preprocess_sequence(df_seq).to(device)\n",
    "\n",
    "#     all_outputs = []\n",
    "#     with torch.no_grad():\n",
    "#         for model in model_ensemble:\n",
    "#             outputs = model(x_tensor).softmax(dim=-1)\n",
    "#             all_outputs.append(outputs)\n",
    "\n",
    "#     avg_outputs = torch.mean(torch.stack(all_outputs), dim=0)\n",
    "#     pred_idx = torch.argmax(avg_outputs, dim=1).item()\n",
    "\n",
    "#     return str(gesture_classes[pred_idx])\n",
    "\n",
    "def predict(sequence: pl.DataFrame, _: pl.DataFrame) -> str:\n",
    "    \"\"\"\n",
    "    Kaggle evaluation API will call this for each sequence.\n",
    "    sequence: polars DataFrame for a single sequence\n",
    "    demographics: unused in this model\n",
    "    Returns: predicted gesture string\n",
    "    \"\"\"\n",
    "    # df_seq = sequence.to_pandas()\n",
    "    # df_demo = demographics.to_pandas()\n",
    "\n",
    "    # df_seq = df_seq.merge(\n",
    "    #     df_demo,\n",
    "    #     on='subject',\n",
    "    #     how='left',\n",
    "    #     validate='many_to_one',\n",
    "    # )\n",
    "    # right_handed_mask = df_seq['handedness'] == 1\n",
    "    # df_seq.loc[right_handed_mask, imu_cols] = apply_symmetry(df_seq.loc[right_handed_mask, imu_cols])\n",
    "    # x = torch.unsqueeze(Tensor(x), dim=0).to(device)\n",
    "\n",
    "    x_tensor = (\n",
    "        torch.unsqueeze(Tensor(preprocess_sequence(sequence)), dim=0)\n",
    "        .float()\n",
    "        .to(device)\n",
    "    )\n",
    "    print(x_tensor.shape)\n",
    "\n",
    "    all_outputs = []\n",
    "    with torch.no_grad():\n",
    "        for model_idx, model in enumerate(model_ensemble): # Only take the first one bc it's the only one that takes in the correct input shape\n",
    "            outputs = model(x_tensor)\n",
    "            all_outputs.append(outputs)\n",
    "\n",
    "    avg_outputs = torch.mean(torch.stack(all_outputs), dim=0)\n",
    "    pred_idx = torch.argmax(avg_outputs, dim=1).item()\n",
    "\n",
    "    return str(gesture_classes[pred_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cdcf446",
   "metadata": {},
   "source": [
    "### Run inference server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1c386b7d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T10:09:15.023324Z",
     "iopub.status.busy": "2025-06-14T10:09:15.023122Z",
     "iopub.status.idle": "2025-06-14T10:09:16.373534Z",
     "shell.execute_reply": "2025-06-14T10:09:16.372710Z"
    },
    "papermill": {
     "duration": 1.365137,
     "end_time": "2025-06-14T10:09:16.374918",
     "exception": false,
     "start_time": "2025-06-14T10:09:15.009781",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/repos/CMI-2025-competition/src/kaggle_evaluation/core/templates.py:136: RuntimeWarning:\n",
      "\n",
      "4865 seconds elapsed before server startup.\n",
      "                This exceeds the startup time limit of 900 seconds that the gateway will enforce\n",
      "                during the rerun on the hidden test set. Start the server before performing any time consuming steps.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 66, 127])\n",
      "torch.Size([1, 66, 127])\n",
      "torch.Size([1, 66, 127])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[79]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m      6\u001b[39m inference_server.run_local_gateway(\n\u001b[32m      7\u001b[39m     data_paths=(\n\u001b[32m      8\u001b[39m         join(competition_dataset_path, \u001b[33m'\u001b[39m\u001b[33mtest.csv\u001b[39m\u001b[33m'\u001b[39m),\n\u001b[32m      9\u001b[39m         join(competition_dataset_path, \u001b[33m'\u001b[39m\u001b[33mtest_demographics.csv\u001b[39m\u001b[33m'\u001b[39m),\n\u001b[32m     10\u001b[39m     )\n\u001b[32m     11\u001b[39m )\n\u001b[32m     12\u001b[39m inference_server = kaggle_evaluation.cmi_inference_server.CMIInferenceServer(predict)\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m \u001b[43minference_server\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_local_gateway\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata_paths\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m        \u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompetition_dataset_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtest.csv\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m        \u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompetition_dataset_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtest_demographics.csv\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/CMI-2025-competition/src/kaggle_evaluation/core/templates.py:147\u001b[39m, in \u001b[36mInferenceServer.run_local_gateway\u001b[39m\u001b[34m(self, data_paths, file_share_dir, *args, **kwargs)\u001b[39m\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    146\u001b[39m     \u001b[38;5;28mself\u001b[39m.gateway = \u001b[38;5;28mself\u001b[39m._get_gateway_for_test(data_paths, file_share_dir, *args, **kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgateway\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    148\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    149\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m err \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/CMI-2025-competition/src/kaggle_evaluation/core/templates.py:84\u001b[39m, in \u001b[36mGateway.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     82\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     83\u001b[39m     \u001b[38;5;28mself\u001b[39m.unpack_data_paths()\n\u001b[32m---> \u001b[39m\u001b[32m84\u001b[39m     predictions, row_ids = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_all_predictions\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     85\u001b[39m     \u001b[38;5;28mself\u001b[39m.write_submission(predictions, row_ids)\n\u001b[32m     86\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m kaggle_evaluation.core.base_gateway.GatewayRuntimeError \u001b[38;5;28;01mas\u001b[39;00m gre:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/CMI-2025-competition/src/kaggle_evaluation/core/templates.py:56\u001b[39m, in \u001b[36mGateway.get_all_predictions\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     54\u001b[39m all_row_ids = []\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m data_batch, row_ids \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.generate_data_batches():\n\u001b[32m---> \u001b[39m\u001b[32m56\u001b[39m     predictions = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mdata_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     57\u001b[39m     \u001b[38;5;28mself\u001b[39m.validate_prediction_batch(predictions, row_ids)\n\u001b[32m     58\u001b[39m     all_predictions.append(predictions)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/CMI-2025-competition/src/kaggle_evaluation/core/templates.py:70\u001b[39m, in \u001b[36mGateway.predict\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     63\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"self.predict will send all data in args and kwargs to the user container, and\u001b[39;00m\n\u001b[32m     64\u001b[39m \u001b[33;03minstruct the user container to generate a `predict` response.\u001b[39;00m\n\u001b[32m     65\u001b[39m \n\u001b[32m     66\u001b[39m \u001b[33;03mReturns:\u001b[39;00m\n\u001b[32m     67\u001b[39m \u001b[33;03m    Any: The prediction from the user container.\u001b[39;00m\n\u001b[32m     68\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     69\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m70\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mpredict\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     72\u001b[39m     \u001b[38;5;28mself\u001b[39m.handle_server_error(e, \u001b[33m'\u001b[39m\u001b[33mpredict\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/CMI-2025-competition/src/kaggle_evaluation/core/relay.py:311\u001b[39m, in \u001b[36mClient.send\u001b[39m\u001b[34m(self, name, *args, **kwargs)\u001b[39m\n\u001b[32m    300\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Sends a single KaggleEvaluation request.\u001b[39;00m\n\u001b[32m    301\u001b[39m \n\u001b[32m    302\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    308\u001b[39m \u001b[33;03m    The response, which is of one of several allow-listed data types.\u001b[39;00m\n\u001b[32m    309\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    310\u001b[39m request = \u001b[38;5;28mself\u001b[39m.serialize_request(name, *args, **kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m311\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_with_deadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    312\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m _deserialize(response.payload)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/CMI-2025-competition/src/kaggle_evaluation/core/relay.py:274\u001b[39m, in \u001b[36mClient._send_with_deadline\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    272\u001b[39m \u001b[38;5;28mself\u001b[39m.stub = kaggle_evaluation_grpc.KaggleEvaluationServiceStub(\u001b[38;5;28mself\u001b[39m.channel)\n\u001b[32m    273\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m274\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstub\u001b[49m\u001b[43m.\u001b[49m\u001b[43mSend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwait_for_ready\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    275\u001b[39m     \u001b[38;5;28mself\u001b[39m._made_first_connection = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    276\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/venv/CMI/lib/python3.11/site-packages/grpc/_channel.py:1178\u001b[39m, in \u001b[36m_UnaryUnaryMultiCallable.__call__\u001b[39m\u001b[34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[39m\n\u001b[32m   1166\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\n\u001b[32m   1167\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1168\u001b[39m     request: Any,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1173\u001b[39m     compression: Optional[grpc.Compression] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1174\u001b[39m ) -> Any:\n\u001b[32m   1175\u001b[39m     (\n\u001b[32m   1176\u001b[39m         state,\n\u001b[32m   1177\u001b[39m         call,\n\u001b[32m-> \u001b[39m\u001b[32m1178\u001b[39m     ) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_blocking\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1179\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwait_for_ready\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompression\u001b[49m\n\u001b[32m   1180\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1181\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _end_unary_response_blocking(state, call, \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/venv/CMI/lib/python3.11/site-packages/grpc/_channel.py:1162\u001b[39m, in \u001b[36m_UnaryUnaryMultiCallable._blocking\u001b[39m\u001b[34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[39m\n\u001b[32m   1145\u001b[39m state.target = _common.decode(\u001b[38;5;28mself\u001b[39m._target)\n\u001b[32m   1146\u001b[39m call = \u001b[38;5;28mself\u001b[39m._channel.segregated_call(\n\u001b[32m   1147\u001b[39m     cygrpc.PropagationConstants.GRPC_PROPAGATE_DEFAULTS,\n\u001b[32m   1148\u001b[39m     \u001b[38;5;28mself\u001b[39m._method,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1160\u001b[39m     \u001b[38;5;28mself\u001b[39m._registered_call_handle,\n\u001b[32m   1161\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1162\u001b[39m event = \u001b[43mcall\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnext_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1163\u001b[39m _handle_event(event, state, \u001b[38;5;28mself\u001b[39m._response_deserializer)\n\u001b[32m   1164\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m state, call\n",
      "\u001b[36mFile \u001b[39m\u001b[32msrc/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi:388\u001b[39m, in \u001b[36mgrpc._cython.cygrpc.SegregatedCall.next_event\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32msrc/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi:211\u001b[39m, in \u001b[36mgrpc._cython.cygrpc._next_call_event\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32msrc/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi:205\u001b[39m, in \u001b[36mgrpc._cython.cygrpc._next_call_event\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32msrc/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi:78\u001b[39m, in \u001b[36mgrpc._cython.cygrpc._latent_event\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32msrc/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi:61\u001b[39m, in \u001b[36mgrpc._cython.cygrpc._internal_latent_event\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32msrc/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi:42\u001b[39m, in \u001b[36mgrpc._cython.cygrpc._next\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "inference_server = kaggle_evaluation.cmi_inference_server.CMIInferenceServer(predict)\n",
    "\n",
    "if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
    "    inference_server.serve()\n",
    "else:\n",
    "    inference_server.run_local_gateway(\n",
    "        data_paths=(\n",
    "            join(competition_dataset_path, 'test.csv'),\n",
    "            join(competition_dataset_path, 'test_demographics.csv'),\n",
    "        )\n",
    "    )\n",
    "    inference_server = kaggle_evaluation.cmi_inference_server.CMIInferenceServer(predict)\n",
    "    inference_server.run_local_gateway(\n",
    "        data_paths=(\n",
    "            join(competition_dataset_path, 'test.csv'),\n",
    "            join(competition_dataset_path, 'test_demographics.csv'),\n",
    "        )\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 12518947,
     "sourceId": 102335,
     "sourceType": "competition"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 510.403331,
   "end_time": "2025-06-14T10:09:19.701325",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-06-14T10:00:49.297994",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
