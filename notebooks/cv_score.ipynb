{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e752c660",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f39a6e",
   "metadata": {},
   "source": [
    "## my setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473b69f6",
   "metadata": {},
   "source": [
    "### My imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b842c804",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from glob import glob\n",
    "from functools import partial\n",
    "from datetime import datetime\n",
    "from itertools import pairwise\n",
    "from os.path import join, realpath\n",
    "from typing import Optional, Literal\n",
    "\n",
    "import torch\n",
    "import kagglehub\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from torch import nn, Tensor\n",
    "from pandas import DataFrame as DF\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader as DL\n",
    "from rich.progress import Progress, Task, track\n",
    "from torch.optim.lr_scheduler import ConstantLR, LRScheduler\n",
    "metric_package = kagglehub.package_import('wasupandceacar/cmi-metric', bypass_confirmation=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b0b925",
   "metadata": {},
   "source": [
    "### config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1296f174",
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_CROSS_VALIDATIONS = 5\n",
    "TRAINING_EPOCHS = 60\n",
    "STARTING_LR = 0.0005\n",
    "BATCH_SIZE = 256\n",
    "TARGET_NAMES = sorted([\n",
    "    \"Above ear - pull hair\",\n",
    "    \"Cheek - pinch skin\",\n",
    "    \"Eyebrow - pull hair\",\n",
    "    \"Eyelash - pull hair\",\n",
    "    \"Feel around in tray and pull out an object\",\n",
    "    \"Forehead - pull hairline\",\n",
    "    \"Forehead - scratch\",\n",
    "    \"Neck - pinch skin\",\n",
    "    \"Neck - scratch\",\n",
    "    \"Text on phone\",\n",
    "    \"Wave hello\",\n",
    "    \"Write name in air\",\n",
    "    \"Write name on leg\",\n",
    "    \"Drink from bottle/cup\",\n",
    "    \"Pinch knee/leg skin\",\n",
    "    \"Pull air toward your face\",\n",
    "    \"Scratch knee/leg skin\",\n",
    "    \"Glasses on/off\"\n",
    "])\n",
    "TARGET_NAMES_NDARRAY = np.asarray(TARGET_NAMES)\n",
    "MOCK_TRAINING_GAMMA = 1.01\n",
    "MAX_LR_TO_MIN_DIV_FACTOR = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7749c3bd",
   "metadata": {},
   "source": [
    "### device setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa7f99a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a563074",
   "metadata": {},
   "source": [
    "### Dataset Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a94d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = kagglehub.dataset_download(\n",
    "    handle=\"mauroabidalcarrer/prepocessed-cmi-2025\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc2e83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CMIDataset(TensorDataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        parent_dir: str,\n",
    "        split: Optional[Literal[\"train\", \"validation\"]]=None,\n",
    "        subset: Optional[int]=None,\n",
    "        force_download=False\n",
    "    ):\n",
    "        dataset_path = kagglehub.dataset_download(\n",
    "            handle=\"mauroabidalcarrer/prepocessed-cmi-2025\",\n",
    "            force_download=force_download\n",
    "        )\n",
    "        parent_dir = join(dataset_path, \"preprocessed_dataset\", parent_dir)\n",
    "        split = \"\" if split is None else split + \"_\"\n",
    "        x = np.load(join(parent_dir, f\"{split}X.npy\")).swapaxes(1, 2)\n",
    "        y = np.load(join(parent_dir, f\"{split}Y.npy\"))\n",
    "        if subset is not None:\n",
    "            x = x[:subset]\n",
    "            y = y[:subset]\n",
    "        super().__init__(\n",
    "            torch.from_numpy(x), \n",
    "            torch.from_numpy(y),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aae295d",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_data_path = join(\n",
    "    dataset_path,\n",
    "    \"preprocessed_dataset\",\n",
    "    \"full_dataset_meta_data.json\"\n",
    ")\n",
    "with open(meta_data_path, \"r\") as fp:\n",
    "    meta_data = json.load(fp)\n",
    "# Convert target names into a ndarray to index it batchwise.\n",
    "# meta_data[\"target_names\"] = np.asarray(meta_data[\"target_names\"])\n",
    "non_imu_feats_idx = [feat_idx for feat_idx, feat in enumerate(meta_data[\"feature_cols\"]) if feat.startswith((\"thm\", \"tof\"))]\n",
    "non_imu_feats = [feat for feat in meta_data[\"feature_cols\"] if feat.startswith((\"thm\", \"tof\"))]\n",
    "imu_feats_idx = [feat_idx for feat_idx, feat in enumerate(meta_data[\"feature_cols\"]) if not feat.startswith((\"thm\", \"tof\"))]\n",
    "imu_feats = [feat for feat in meta_data[\"feature_cols\"] if not feat.startswith((\"thm\", \"tof\"))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770ba482",
   "metadata": {
    "papermill": {
     "duration": 0.003885,
     "end_time": "2025-06-14T10:00:53.304635",
     "exception": false,
     "start_time": "2025-06-14T10:00:53.300750",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### kaggle notbook Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2b23af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T10:00:53.312369Z",
     "iopub.status.busy": "2025-06-14T10:00:53.311611Z",
     "iopub.status.idle": "2025-06-14T10:01:12.869917Z",
     "shell.execute_reply": "2025-06-14T10:01:12.869325Z"
    },
    "papermill": {
     "duration": 19.5636,
     "end_time": "2025-06-14T10:01:12.871307",
     "exception": false,
     "start_time": "2025-06-14T10:00:53.307707",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-14 10:01:01.640826: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1749895261.806557      19 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1749895261.850009      19 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "\n",
    "def seed_everything(seed=42):\n",
    "    \"\"\"Set all random seeds for reproducibility\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'\n",
    "    torch.use_deterministic_algorithms(True, warn_only=True)\n",
    "\n",
    "SEED = 42\n",
    "seed_everything(seed=SEED)\n",
    "\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences as keras_pad_sequences\n",
    "\n",
    "import kaggle_evaluation.cmi_inference_server\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2161df0c",
   "metadata": {
    "papermill": {
     "duration": 0.00278,
     "end_time": "2025-06-14T10:01:12.877551",
     "exception": false,
     "start_time": "2025-06-14T10:01:12.874771",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **Read data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e657c570",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T10:01:12.884365Z",
     "iopub.status.busy": "2025-06-14T10:01:12.883937Z",
     "iopub.status.idle": "2025-06-14T10:01:45.309186Z",
     "shell.execute_reply": "2025-06-14T10:01:45.308564Z"
    },
    "papermill": {
     "duration": 32.430139,
     "end_time": "2025-06-14T10:01:45.310511",
     "exception": false,
     "start_time": "2025-06-14T10:01:12.880372",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets...\n",
      "Train rows: 574945, Test rows: 107\n",
      "IMU features: 7, TOF/Thermal features: 325, Total features: 332\n",
      "Total NaNs in train features: 3597807\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading datasets...\")\n",
    "train_df = pd.read_csv(join(dataset_path, \"train.csv\"))\n",
    "train_dem_df = pd.read_csv(join(dataset_path, \"train_demographics.csv\"))\n",
    "test_df = pd.read_csv(join(dataset_path, \"test.csv\"))\n",
    "test_dem_df = pd.read_csv(join(dataset_path, \"test_demographics.csv\"))\n",
    "print(f\"Train rows: {len(train_df)}, Test rows: {len(test_df)}\")\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "train_df['gesture'] = label_encoder.fit_transform(train_df['gesture'].astype(str))\n",
    "gesture_classes = label_encoder.classes_\n",
    "\n",
    "bfrb_gestures = [\n",
    "    'Above ear - pull hair',\n",
    "    'Forehead - pull hairline',\n",
    "    'Forehead - scratch',\n",
    "    'Eyebrow - pull hair',\n",
    "    'Eyelash - pull hair',\n",
    "    'Neck - pinch skin',\n",
    "    'Neck - scratch',\n",
    "    'Cheek - pinch skin'\n",
    "]\n",
    "bfrb_indices = label_encoder.transform(bfrb_gestures)\n",
    "\n",
    "# imu_cols = ['acc_x', 'acc_y', 'acc_z', 'rot_w', 'rot_x', 'rot_y', 'rot_z']\n",
    "# tof_thm_cols = [c for c in train_df.columns if c.startswith('thm_') or c.startswith('tof_')]\n",
    "\n",
    "# # Reorder so that IMU features come first\n",
    "# feature_cols = imu_cols + tof_thm_cols\n",
    "# imu_dim = len(imu_cols)\n",
    "# tof_thm_dim = len(tof_thm_cols)\n",
    "\n",
    "# print(f\"IMU features: {imu_dim}, TOF/Thermal features: {tof_thm_dim}, Total features: {len(feature_cols)}\")\n",
    "\n",
    "# # Check for missing values\n",
    "# nan_counts = train_df[feature_cols].isna().sum().sum()\n",
    "# print(\"Total NaNs in train features:\", nan_counts)\n",
    "\n",
    "\n",
    "# # to remove hand dependency in IMU data\n",
    "# # im not sure if the rotation is on the x axis but this give me the best CV\n",
    "# def apply_symmetry(data):\n",
    "#     transformed = data.copy()\n",
    "#     transformed['acc_z'] = -transformed['acc_z']\n",
    "#     transformed['acc_y'] = -transformed['acc_y']\n",
    "    \n",
    "#     transformed['rot_w'] = transformed['rot_w']\n",
    "#     transformed['rot_x'] = transformed['rot_x']\n",
    "#     transformed['rot_y'] = -transformed['rot_y']\n",
    "#     transformed['rot_z'] = -transformed['rot_z']\n",
    "#     return transformed\n",
    "\n",
    "\n",
    "# train_df = train_df.merge(\n",
    "#     train_dem_df,\n",
    "#     on='subject',\n",
    "#     how='left',\n",
    "#     validate='many_to_one'\n",
    "# )\n",
    "\n",
    "# right_handed_mask = train_df['handedness'] == 1\n",
    "# train_df.loc[right_handed_mask, imu_cols] = apply_symmetry(train_df.loc[right_handed_mask, imu_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3401f4be",
   "metadata": {
    "papermill": {
     "duration": 0.002901,
     "end_time": "2025-06-14T10:01:45.316824",
     "exception": false,
     "start_time": "2025-06-14T10:01:45.313923",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Create kaggle notebook dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc95681e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T10:01:45.324206Z",
     "iopub.status.busy": "2025-06-14T10:01:45.323690Z",
     "iopub.status.idle": "2025-06-14T10:01:56.072176Z",
     "shell.execute_reply": "2025-06-14T10:01:56.071543Z"
    },
    "papermill": {
     "duration": 10.753531,
     "end_time": "2025-06-14T10:01:56.073459",
     "exception": false,
     "start_time": "2025-06-14T10:01:45.319928",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pad/truncate all sequences to length 103 (90th percentile).\n"
     ]
    }
   ],
   "source": [
    "# sequences = train_df.groupby('sequence_id')\n",
    "# X_list = []\n",
    "# lengths = []\n",
    "# y_list = []\n",
    "\n",
    "# sequence_info = []\n",
    "# for i, (seq_id, seq) in enumerate(sequences):\n",
    "#     seq_data = seq[feature_cols].ffill().bfill().fillna(0).values\n",
    "#     X_list.append(seq_data)\n",
    "#     lengths.append(seq_data.shape[0])\n",
    "#     sequence_info.append({\n",
    "#         'sequence_id': seq_id,\n",
    "#         'subject': seq['subject'].iloc[0],\n",
    "#         'gesture': seq['gesture'].iloc[0]\n",
    "#     })\n",
    "\n",
    "# pad_len = int(np.percentile(lengths, 90))\n",
    "# print(f\"Pad/truncate all sequences to length {pad_len} (90th percentile).\")\n",
    "\n",
    "# seq_df = pd.DataFrame(sequence_info)\n",
    "# X_array = keras_pad_sequences(\n",
    "#     X_list,\n",
    "#     maxlen=pad_len,\n",
    "#     dtype='float32',\n",
    "#     padding='post',\n",
    "#     truncating='post'\n",
    "# )  # shape: (n_samples, pad_len, total_features)\n",
    "\n",
    "# y_array = seq_df['gesture'].values  # shape: (n_samples,)\n",
    "\n",
    "# num_classes = len(np.unique(y_array))\n",
    "# y_array = np.eye(num_classes)[y_array]  # shape: (n_samples, num_classes)\n",
    "\n",
    "# # Transpose to (n_samples, features, seq_len) for PyTorch\n",
    "# X_array = np.transpose(X_array, (0, 2, 1))\n",
    "\n",
    "\n",
    "# class SequenceDataset(Dataset):\n",
    "#     def __init__(self, X, y=None):\n",
    "#         \"\"\"\n",
    "#         X: np.ndarray of shape (n_samples, features, seq_len)\n",
    "#         y: np.ndarray of shape (n_samples, num_classes) or None for test\n",
    "#         \"\"\"\n",
    "#         self.X = torch.from_numpy(X).float()\n",
    "#         self.y = torch.from_numpy(y).float() if y is not None else None\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return self.X.size(0)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         if self.y is not None:\n",
    "#             return self.X[idx], self.y[idx]\n",
    "#         else:\n",
    "#             return self.X[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c54244a",
   "metadata": {},
   "source": [
    "## Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ae01a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_chns:int, out_chns:int):\n",
    "        super().__init__()\n",
    "        self.blocks = nn.Sequential(\n",
    "            nn.Conv1d(in_chns, out_chns, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(out_chns),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(out_chns, out_chns, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(out_chns),\n",
    "        )\n",
    "        if in_chns == out_chns:\n",
    "            self.skip_connection = nn.Identity() \n",
    "        else:\n",
    "            # TODO: set bias to False ?\n",
    "            self.skip_connection = nn.Sequential(\n",
    "                nn.Conv1d(in_chns, out_chns, 1),\n",
    "                nn.BatchNorm1d(out_chns)\n",
    "            )\n",
    "\n",
    "    def forward(self, x:Tensor) -> Tensor:\n",
    "        activaition_maps = self.skip_connection(x) + self.blocks(x)\n",
    "        return nn.functional.relu(activaition_maps)\n",
    "\n",
    "class Resnet(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            in_channels:int,\n",
    "            depth:int,\n",
    "            # n_res_block_per_depth:int,\n",
    "            mlp_width:int,\n",
    "            n_class:int,\n",
    "        ):\n",
    "        super().__init__()\n",
    "        chs_per_depth = [in_channels * 2 ** i for i in range(depth)]\n",
    "        blocks_chns_it = pairwise(chs_per_depth)\n",
    "        self.res_blocks = [ResidualBlock(in_chns, out_chns) for in_chns, out_chns in blocks_chns_it]\n",
    "        self.res_blocks = nn.ModuleList(self.res_blocks)\n",
    "        self.mlp_head = nn.Sequential(\n",
    "            nn.LazyLinear(mlp_width),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(mlp_width, n_class),\n",
    "            nn.Softmax(dim=1),\n",
    "        )\n",
    "        \n",
    "        \n",
    "    def forward(self, x:Tensor) -> Tensor:\n",
    "        activation_maps = x\n",
    "        for res_block in self.res_blocks:\n",
    "            activation_maps = nn.functional.max_pool1d(res_block(activation_maps), 2)\n",
    "        out = activation_maps.view(activation_maps.shape[0], -1)\n",
    "        out = self.mlp_head(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc08e41",
   "metadata": {},
   "source": [
    "### Create model function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e3e463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input channels: 66\n"
     ]
    }
   ],
   "source": [
    "def mk_model() -> nn.Module:\n",
    "    nb_in_chans = len(meta_data[\"feature_cols\"])\n",
    "    return (\n",
    "        Resnet(\n",
    "            in_channels=nb_in_chans,\n",
    "            depth=4,\n",
    "            mlp_width=256,\n",
    "            n_class=18\n",
    "        )\n",
    "        .to(device)\n",
    "    )\n",
    "\n",
    "print(\"input channels:\", len(meta_data[\"feature_cols\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1cc3c5f",
   "metadata": {
    "papermill": {
     "duration": 0.003108,
     "end_time": "2025-06-14T10:01:56.186803",
     "exception": false,
     "start_time": "2025-06-14T10:01:56.183695",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Training loop**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be28a9c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T10:01:56.194003Z",
     "iopub.status.busy": "2025-06-14T10:01:56.193740Z",
     "iopub.status.idle": "2025-06-14T10:09:14.752385Z",
     "shell.execute_reply": "2025-06-14T10:09:14.751491Z"
    },
    "papermill": {
     "duration": 438.563878,
     "end_time": "2025-06-14T10:09:14.753712",
     "exception": false,
     "start_time": "2025-06-14T10:01:56.189834",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Fold 1/5\n",
      "Train subjects: 65\n",
      "Val subjects: 16\n",
      "==================================================\n",
      "Epoch 01: Train Loss = 2.5398, Val Loss = 2.2454\n",
      "  Binary F1 = 0.8421, Macro F1 = 0.2179, Final Metric = 0.5300\n",
      "  New best metric! Saving model...\n",
      "Epoch 02: Train Loss = 2.1876, Val Loss = 1.9619\n",
      "  Binary F1 = 0.9034, Macro F1 = 0.2610, Final Metric = 0.5822\n",
      "  New best metric! Saving model...\n",
      "Epoch 03: Train Loss = 2.0925, Val Loss = 1.8313\n",
      "  Binary F1 = 0.9156, Macro F1 = 0.2893, Final Metric = 0.6024\n",
      "  New best metric! Saving model...\n",
      "Epoch 04: Train Loss = 1.9823, Val Loss = 1.7746\n",
      "  Binary F1 = 0.9256, Macro F1 = 0.3012, Final Metric = 0.6134\n",
      "  New best metric! Saving model...\n",
      "Epoch 05: Train Loss = 1.8570, Val Loss = 1.7468\n",
      "  Binary F1 = 0.9249, Macro F1 = 0.3054, Final Metric = 0.6152\n",
      "  New best metric! Saving model...\n",
      "Epoch 06: Train Loss = 1.9488, Val Loss = 1.7515\n",
      "  Binary F1 = 0.9189, Macro F1 = 0.2939, Final Metric = 0.6064\n",
      "Epoch 07: Train Loss = 1.8011, Val Loss = 1.6515\n",
      "  Binary F1 = 0.9432, Macro F1 = 0.3307, Final Metric = 0.6370\n",
      "  New best metric! Saving model...\n",
      "Epoch 08: Train Loss = 1.8426, Val Loss = 1.5484\n",
      "  Binary F1 = 0.9350, Macro F1 = 0.3587, Final Metric = 0.6468\n",
      "  New best metric! Saving model...\n",
      "Epoch 09: Train Loss = 1.6991, Val Loss = 1.5203\n",
      "  Binary F1 = 0.9358, Macro F1 = 0.3763, Final Metric = 0.6561\n",
      "  New best metric! Saving model...\n",
      "Epoch 10: Train Loss = 1.6620, Val Loss = 1.4523\n",
      "  Binary F1 = 0.9461, Macro F1 = 0.3968, Final Metric = 0.6714\n",
      "  New best metric! Saving model...\n",
      "Epoch 11: Train Loss = 1.6677, Val Loss = 1.4321\n",
      "  Binary F1 = 0.9587, Macro F1 = 0.4007, Final Metric = 0.6797\n",
      "  New best metric! Saving model...\n",
      "Epoch 12: Train Loss = 1.5515, Val Loss = 1.3641\n",
      "  Binary F1 = 0.9617, Macro F1 = 0.4219, Final Metric = 0.6918\n",
      "  New best metric! Saving model...\n",
      "Epoch 13: Train Loss = 1.5616, Val Loss = 1.3362\n",
      "  Binary F1 = 0.9646, Macro F1 = 0.4294, Final Metric = 0.6970\n",
      "  New best metric! Saving model...\n",
      "Epoch 14: Train Loss = 1.5422, Val Loss = 1.3370\n",
      "  Binary F1 = 0.9640, Macro F1 = 0.4468, Final Metric = 0.7054\n",
      "  New best metric! Saving model...\n",
      "Epoch 15: Train Loss = 1.5982, Val Loss = 1.3343\n",
      "  Binary F1 = 0.9646, Macro F1 = 0.4468, Final Metric = 0.7057\n",
      "  New best metric! Saving model...\n",
      "Epoch 16: Train Loss = 1.6260, Val Loss = 1.3942\n",
      "  Binary F1 = 0.9492, Macro F1 = 0.4016, Final Metric = 0.6754\n",
      "Epoch 17: Train Loss = 1.5795, Val Loss = 1.4120\n",
      "  Binary F1 = 0.9534, Macro F1 = 0.4177, Final Metric = 0.6855\n",
      "Epoch 18: Train Loss = 1.6096, Val Loss = 1.4409\n",
      "  Binary F1 = 0.9451, Macro F1 = 0.4193, Final Metric = 0.6822\n",
      "Epoch 19: Train Loss = 1.5846, Val Loss = 1.3785\n",
      "  Binary F1 = 0.9649, Macro F1 = 0.4170, Final Metric = 0.6909\n",
      "Epoch 20: Train Loss = 1.5017, Val Loss = 1.3151\n",
      "  Binary F1 = 0.9678, Macro F1 = 0.4433, Final Metric = 0.7055\n",
      "Epoch 21: Train Loss = 1.4694, Val Loss = 1.2992\n",
      "  Binary F1 = 0.9602, Macro F1 = 0.4434, Final Metric = 0.7018\n",
      "Epoch 22: Train Loss = 1.4481, Val Loss = 1.2746\n",
      "  Binary F1 = 0.9685, Macro F1 = 0.4564, Final Metric = 0.7125\n",
      "  New best metric! Saving model...\n",
      "Epoch 23: Train Loss = 1.4004, Val Loss = 1.3039\n",
      "  Binary F1 = 0.9585, Macro F1 = 0.4334, Final Metric = 0.6960\n",
      "Epoch 24: Train Loss = 1.4559, Val Loss = 1.2760\n",
      "  Binary F1 = 0.9670, Macro F1 = 0.4538, Final Metric = 0.7104\n",
      "Epoch 25: Train Loss = 1.4128, Val Loss = 1.2740\n",
      "  Binary F1 = 0.9655, Macro F1 = 0.4684, Final Metric = 0.7170\n",
      "  New best metric! Saving model...\n",
      "Epoch 26: Train Loss = 1.3968, Val Loss = 1.2405\n",
      "  Binary F1 = 0.9630, Macro F1 = 0.4904, Final Metric = 0.7267\n",
      "  New best metric! Saving model...\n",
      "Epoch 27: Train Loss = 1.2147, Val Loss = 1.2388\n",
      "  Binary F1 = 0.9669, Macro F1 = 0.4651, Final Metric = 0.7160\n",
      "Epoch 28: Train Loss = 1.2184, Val Loss = 1.2152\n",
      "  Binary F1 = 0.9680, Macro F1 = 0.4837, Final Metric = 0.7259\n",
      "Epoch 29: Train Loss = 1.3766, Val Loss = 1.1997\n",
      "  Binary F1 = 0.9621, Macro F1 = 0.4960, Final Metric = 0.7291\n",
      "  New best metric! Saving model...\n",
      "Epoch 30: Train Loss = 1.3380, Val Loss = 1.2094\n",
      "  Binary F1 = 0.9665, Macro F1 = 0.5000, Final Metric = 0.7332\n",
      "  New best metric! Saving model...\n",
      "Epoch 31: Train Loss = 1.3789, Val Loss = 1.2146\n",
      "  Binary F1 = 0.9671, Macro F1 = 0.5060, Final Metric = 0.7365\n",
      "  New best metric! Saving model...\n",
      "Epoch 32: Train Loss = 1.3521, Val Loss = 1.2083\n",
      "  Binary F1 = 0.9650, Macro F1 = 0.5033, Final Metric = 0.7342\n",
      "Epoch 33: Train Loss = 1.2864, Val Loss = 1.2068\n",
      "  Binary F1 = 0.9675, Macro F1 = 0.4952, Final Metric = 0.7314\n",
      "Epoch 34: Train Loss = 1.1710, Val Loss = 1.1991\n",
      "  Binary F1 = 0.9671, Macro F1 = 0.5006, Final Metric = 0.7338\n",
      "Epoch 35: Train Loss = 1.2351, Val Loss = 1.2007\n",
      "  Binary F1 = 0.9671, Macro F1 = 0.5020, Final Metric = 0.7346\n",
      "Epoch 36: Train Loss = 1.3411, Val Loss = 1.3301\n",
      "  Binary F1 = 0.9591, Macro F1 = 0.4479, Final Metric = 0.7035\n",
      "Epoch 37: Train Loss = 1.2943, Val Loss = 1.2740\n",
      "  Binary F1 = 0.9573, Macro F1 = 0.4745, Final Metric = 0.7159\n",
      "Epoch 38: Train Loss = 1.3402, Val Loss = 1.3232\n",
      "  Binary F1 = 0.9564, Macro F1 = 0.4402, Final Metric = 0.6983\n",
      "Epoch 39: Train Loss = 1.3709, Val Loss = 1.3146\n",
      "  Binary F1 = 0.9533, Macro F1 = 0.4535, Final Metric = 0.7034\n",
      "Epoch 40: Train Loss = 1.3524, Val Loss = 1.3254\n",
      "  Binary F1 = 0.9600, Macro F1 = 0.4644, Final Metric = 0.7122\n",
      "Epoch 41: Train Loss = 1.3345, Val Loss = 1.2938\n",
      "  Binary F1 = 0.9619, Macro F1 = 0.4682, Final Metric = 0.7150\n",
      "Epoch 42: Train Loss = 1.3191, Val Loss = 1.2983\n",
      "  Binary F1 = 0.9628, Macro F1 = 0.4689, Final Metric = 0.7158\n",
      "Epoch 43: Train Loss = 1.3694, Val Loss = 1.2689\n",
      "  Binary F1 = 0.9651, Macro F1 = 0.4879, Final Metric = 0.7265\n",
      "Epoch 44: Train Loss = 1.3238, Val Loss = 1.3215\n",
      "  Binary F1 = 0.9591, Macro F1 = 0.4808, Final Metric = 0.7199\n",
      "Epoch 45: Train Loss = 1.3920, Val Loss = 1.3133\n",
      "  Binary F1 = 0.9553, Macro F1 = 0.4575, Final Metric = 0.7064\n",
      "Epoch 46: Train Loss = 1.1814, Val Loss = 1.2738\n",
      "  Binary F1 = 0.9682, Macro F1 = 0.4870, Final Metric = 0.7276\n",
      "Early stopping triggered at epoch 46\n",
      "\n",
      "Fold 1 completed.\n",
      "Final validation metrics - Binary F1: 0.9682, Macro F1: 0.4870, Final: 0.7276\n",
      "Best validation metrics - Binary F1: 0.9671, Macro F1: 0.5060, Final: 0.7365\n",
      "\n",
      "==================================================\n",
      "Fold 2/5\n",
      "Train subjects: 65\n",
      "Val subjects: 16\n",
      "==================================================\n",
      "Epoch 01: Train Loss = 2.5460, Val Loss = 2.2404\n",
      "  Binary F1 = 0.8295, Macro F1 = 0.1939, Final Metric = 0.5117\n",
      "  New best metric! Saving model...\n",
      "Epoch 02: Train Loss = 2.1741, Val Loss = 2.0086\n",
      "  Binary F1 = 0.8832, Macro F1 = 0.2463, Final Metric = 0.5648\n",
      "  New best metric! Saving model...\n",
      "Epoch 03: Train Loss = 2.0280, Val Loss = 1.8544\n",
      "  Binary F1 = 0.9078, Macro F1 = 0.2874, Final Metric = 0.5976\n",
      "  New best metric! Saving model...\n",
      "Epoch 04: Train Loss = 1.8904, Val Loss = 1.7910\n",
      "  Binary F1 = 0.9084, Macro F1 = 0.2934, Final Metric = 0.6009\n",
      "  New best metric! Saving model...\n",
      "Epoch 05: Train Loss = 1.8453, Val Loss = 1.7796\n",
      "  Binary F1 = 0.9107, Macro F1 = 0.2945, Final Metric = 0.6026\n",
      "  New best metric! Saving model...\n",
      "Epoch 06: Train Loss = 1.9886, Val Loss = 1.7692\n",
      "  Binary F1 = 0.8855, Macro F1 = 0.2721, Final Metric = 0.5788\n",
      "Epoch 07: Train Loss = 1.8132, Val Loss = 1.6937\n",
      "  Binary F1 = 0.9124, Macro F1 = 0.2996, Final Metric = 0.6060\n",
      "  New best metric! Saving model...\n",
      "Epoch 08: Train Loss = 1.7712, Val Loss = 1.6696\n",
      "  Binary F1 = 0.9262, Macro F1 = 0.3223, Final Metric = 0.6242\n",
      "  New best metric! Saving model...\n",
      "Epoch 09: Train Loss = 1.6973, Val Loss = 1.6115\n",
      "  Binary F1 = 0.9318, Macro F1 = 0.3375, Final Metric = 0.6346\n",
      "  New best metric! Saving model...\n",
      "Epoch 10: Train Loss = 1.6761, Val Loss = 1.5584\n",
      "  Binary F1 = 0.9197, Macro F1 = 0.3370, Final Metric = 0.6284\n",
      "Epoch 11: Train Loss = 1.6610, Val Loss = 1.5240\n",
      "  Binary F1 = 0.9296, Macro F1 = 0.3753, Final Metric = 0.6524\n",
      "  New best metric! Saving model...\n",
      "Epoch 12: Train Loss = 1.5595, Val Loss = 1.4711\n",
      "  Binary F1 = 0.9306, Macro F1 = 0.3922, Final Metric = 0.6614\n",
      "  New best metric! Saving model...\n",
      "Epoch 13: Train Loss = 1.4525, Val Loss = 1.4587\n",
      "  Binary F1 = 0.9303, Macro F1 = 0.3782, Final Metric = 0.6542\n",
      "Epoch 14: Train Loss = 1.4470, Val Loss = 1.4513\n",
      "  Binary F1 = 0.9266, Macro F1 = 0.3906, Final Metric = 0.6586\n",
      "Epoch 15: Train Loss = 1.4699, Val Loss = 1.4493\n",
      "  Binary F1 = 0.9289, Macro F1 = 0.3891, Final Metric = 0.6590\n",
      "Epoch 16: Train Loss = 1.6001, Val Loss = 1.5382\n",
      "  Binary F1 = 0.9170, Macro F1 = 0.3561, Final Metric = 0.6366\n",
      "Epoch 17: Train Loss = 1.5716, Val Loss = 1.5335\n",
      "  Binary F1 = 0.9194, Macro F1 = 0.3724, Final Metric = 0.6459\n",
      "Epoch 18: Train Loss = 1.7092, Val Loss = 1.5170\n",
      "  Binary F1 = 0.9357, Macro F1 = 0.3989, Final Metric = 0.6673\n",
      "  New best metric! Saving model...\n",
      "Epoch 19: Train Loss = 1.5459, Val Loss = 1.5049\n",
      "  Binary F1 = 0.9325, Macro F1 = 0.3830, Final Metric = 0.6578\n",
      "Epoch 20: Train Loss = 1.5829, Val Loss = 1.4955\n",
      "  Binary F1 = 0.9366, Macro F1 = 0.4056, Final Metric = 0.6711\n",
      "  New best metric! Saving model...\n",
      "Epoch 21: Train Loss = 1.4951, Val Loss = 1.5076\n",
      "  Binary F1 = 0.9384, Macro F1 = 0.3864, Final Metric = 0.6624\n",
      "Epoch 22: Train Loss = 1.4517, Val Loss = 1.4348\n",
      "  Binary F1 = 0.9331, Macro F1 = 0.4213, Final Metric = 0.6772\n",
      "  New best metric! Saving model...\n",
      "Epoch 23: Train Loss = 1.4568, Val Loss = 1.4537\n",
      "  Binary F1 = 0.9407, Macro F1 = 0.4046, Final Metric = 0.6726\n",
      "Epoch 24: Train Loss = 1.3562, Val Loss = 1.3815\n",
      "  Binary F1 = 0.9499, Macro F1 = 0.4370, Final Metric = 0.6935\n",
      "  New best metric! Saving model...\n",
      "Epoch 25: Train Loss = 1.4067, Val Loss = 1.4121\n",
      "  Binary F1 = 0.9443, Macro F1 = 0.4242, Final Metric = 0.6842\n",
      "Epoch 26: Train Loss = 1.2334, Val Loss = 1.4221\n",
      "  Binary F1 = 0.9436, Macro F1 = 0.4188, Final Metric = 0.6812\n",
      "Epoch 27: Train Loss = 1.3715, Val Loss = 1.3952\n",
      "  Binary F1 = 0.9436, Macro F1 = 0.4302, Final Metric = 0.6869\n",
      "Epoch 28: Train Loss = 1.2762, Val Loss = 1.3734\n",
      "  Binary F1 = 0.9439, Macro F1 = 0.4356, Final Metric = 0.6897\n",
      "Epoch 29: Train Loss = 1.2079, Val Loss = 1.3752\n",
      "  Binary F1 = 0.9502, Macro F1 = 0.4430, Final Metric = 0.6966\n",
      "  New best metric! Saving model...\n",
      "Epoch 30: Train Loss = 1.3251, Val Loss = 1.3880\n",
      "  Binary F1 = 0.9473, Macro F1 = 0.4406, Final Metric = 0.6939\n",
      "Epoch 31: Train Loss = 1.2767, Val Loss = 1.3712\n",
      "  Binary F1 = 0.9513, Macro F1 = 0.4436, Final Metric = 0.6974\n",
      "  New best metric! Saving model...\n",
      "Epoch 32: Train Loss = 1.4162, Val Loss = 1.3696\n",
      "  Binary F1 = 0.9475, Macro F1 = 0.4469, Final Metric = 0.6972\n",
      "Epoch 33: Train Loss = 1.1950, Val Loss = 1.3644\n",
      "  Binary F1 = 0.9507, Macro F1 = 0.4510, Final Metric = 0.7009\n",
      "  New best metric! Saving model...\n",
      "Epoch 34: Train Loss = 1.2910, Val Loss = 1.3701\n",
      "  Binary F1 = 0.9503, Macro F1 = 0.4465, Final Metric = 0.6984\n",
      "Epoch 35: Train Loss = 1.2594, Val Loss = 1.3682\n",
      "  Binary F1 = 0.9516, Macro F1 = 0.4531, Final Metric = 0.7023\n",
      "  New best metric! Saving model...\n",
      "Epoch 36: Train Loss = 1.3241, Val Loss = 1.5135\n",
      "  Binary F1 = 0.9390, Macro F1 = 0.4014, Final Metric = 0.6702\n",
      "Epoch 37: Train Loss = 1.4082, Val Loss = 1.4659\n",
      "  Binary F1 = 0.9491, Macro F1 = 0.4254, Final Metric = 0.6872\n",
      "Epoch 38: Train Loss = 1.3370, Val Loss = 1.5261\n",
      "  Binary F1 = 0.9306, Macro F1 = 0.3888, Final Metric = 0.6597\n",
      "Epoch 39: Train Loss = 1.2989, Val Loss = 1.4444\n",
      "  Binary F1 = 0.9508, Macro F1 = 0.4307, Final Metric = 0.6907\n",
      "Epoch 40: Train Loss = 1.2846, Val Loss = 1.4582\n",
      "  Binary F1 = 0.9427, Macro F1 = 0.4237, Final Metric = 0.6832\n",
      "Epoch 41: Train Loss = 1.3310, Val Loss = 1.4539\n",
      "  Binary F1 = 0.9395, Macro F1 = 0.4227, Final Metric = 0.6811\n",
      "Epoch 42: Train Loss = 1.3492, Val Loss = 1.4347\n",
      "  Binary F1 = 0.9406, Macro F1 = 0.4362, Final Metric = 0.6884\n",
      "Epoch 43: Train Loss = 1.3059, Val Loss = 1.5039\n",
      "  Binary F1 = 0.9404, Macro F1 = 0.4038, Final Metric = 0.6721\n",
      "Epoch 44: Train Loss = 1.1710, Val Loss = 1.5311\n",
      "  Binary F1 = 0.9447, Macro F1 = 0.4255, Final Metric = 0.6851\n",
      "Epoch 45: Train Loss = 1.1949, Val Loss = 1.4539\n",
      "  Binary F1 = 0.9444, Macro F1 = 0.4339, Final Metric = 0.6892\n",
      "Epoch 46: Train Loss = 1.1332, Val Loss = 1.4212\n",
      "  Binary F1 = 0.9489, Macro F1 = 0.4438, Final Metric = 0.6963\n",
      "Epoch 47: Train Loss = 1.1575, Val Loss = 1.4461\n",
      "  Binary F1 = 0.9500, Macro F1 = 0.4383, Final Metric = 0.6941\n",
      "Epoch 48: Train Loss = 1.2417, Val Loss = 1.4153\n",
      "  Binary F1 = 0.9549, Macro F1 = 0.4437, Final Metric = 0.6993\n",
      "Epoch 49: Train Loss = 1.0687, Val Loss = 1.4689\n",
      "  Binary F1 = 0.9521, Macro F1 = 0.4421, Final Metric = 0.6971\n",
      "Epoch 50: Train Loss = 1.1047, Val Loss = 1.4759\n",
      "  Binary F1 = 0.9513, Macro F1 = 0.4283, Final Metric = 0.6898\n",
      "Early stopping triggered at epoch 50\n",
      "\n",
      "Fold 2 completed.\n",
      "Final validation metrics - Binary F1: 0.9513, Macro F1: 0.4283, Final: 0.6898\n",
      "Best validation metrics - Binary F1: 0.9516, Macro F1: 0.4531, Final: 0.7023\n",
      "\n",
      "==================================================\n",
      "Fold 3/5\n",
      "Train subjects: 65\n",
      "Val subjects: 16\n",
      "==================================================\n",
      "Epoch 01: Train Loss = 2.5713, Val Loss = 2.2015\n",
      "  Binary F1 = 0.8359, Macro F1 = 0.2504, Final Metric = 0.5432\n",
      "  New best metric! Saving model...\n",
      "Epoch 02: Train Loss = 2.1664, Val Loss = 1.9587\n",
      "  Binary F1 = 0.8550, Macro F1 = 0.2766, Final Metric = 0.5658\n",
      "  New best metric! Saving model...\n",
      "Epoch 03: Train Loss = 2.0450, Val Loss = 1.8180\n",
      "  Binary F1 = 0.8979, Macro F1 = 0.3136, Final Metric = 0.6057\n",
      "  New best metric! Saving model...\n",
      "Epoch 04: Train Loss = 1.8719, Val Loss = 1.7500\n",
      "  Binary F1 = 0.9155, Macro F1 = 0.3367, Final Metric = 0.6261\n",
      "  New best metric! Saving model...\n",
      "Epoch 05: Train Loss = 1.9455, Val Loss = 1.7421\n",
      "  Binary F1 = 0.9075, Macro F1 = 0.3252, Final Metric = 0.6163\n",
      "Epoch 06: Train Loss = 1.8998, Val Loss = 1.7570\n",
      "  Binary F1 = 0.9129, Macro F1 = 0.3346, Final Metric = 0.6238\n",
      "Epoch 07: Train Loss = 1.7917, Val Loss = 1.7130\n",
      "  Binary F1 = 0.9159, Macro F1 = 0.3223, Final Metric = 0.6191\n",
      "Epoch 08: Train Loss = 1.8076, Val Loss = 1.5904\n",
      "  Binary F1 = 0.9216, Macro F1 = 0.3717, Final Metric = 0.6466\n",
      "  New best metric! Saving model...\n",
      "Epoch 09: Train Loss = 1.6713, Val Loss = 1.5567\n",
      "  Binary F1 = 0.9221, Macro F1 = 0.3776, Final Metric = 0.6499\n",
      "  New best metric! Saving model...\n",
      "Epoch 10: Train Loss = 1.6676, Val Loss = 1.5668\n",
      "  Binary F1 = 0.9300, Macro F1 = 0.3963, Final Metric = 0.6632\n",
      "  New best metric! Saving model...\n",
      "Epoch 11: Train Loss = 1.5762, Val Loss = 1.4766\n",
      "  Binary F1 = 0.9321, Macro F1 = 0.4154, Final Metric = 0.6738\n",
      "  New best metric! Saving model...\n",
      "Epoch 12: Train Loss = 1.6379, Val Loss = 1.4808\n",
      "  Binary F1 = 0.9336, Macro F1 = 0.4004, Final Metric = 0.6670\n",
      "Epoch 13: Train Loss = 1.5120, Val Loss = 1.4373\n",
      "  Binary F1 = 0.9323, Macro F1 = 0.4325, Final Metric = 0.6824\n",
      "  New best metric! Saving model...\n",
      "Epoch 14: Train Loss = 1.5873, Val Loss = 1.4315\n",
      "  Binary F1 = 0.9363, Macro F1 = 0.4216, Final Metric = 0.6790\n",
      "Epoch 15: Train Loss = 1.5238, Val Loss = 1.4269\n",
      "  Binary F1 = 0.9367, Macro F1 = 0.4188, Final Metric = 0.6778\n",
      "Epoch 16: Train Loss = 1.6032, Val Loss = 1.5573\n",
      "  Binary F1 = 0.9157, Macro F1 = 0.3787, Final Metric = 0.6472\n",
      "Epoch 17: Train Loss = 1.7038, Val Loss = 1.5276\n",
      "  Binary F1 = 0.9151, Macro F1 = 0.4046, Final Metric = 0.6599\n",
      "Epoch 18: Train Loss = 1.5555, Val Loss = 1.4889\n",
      "  Binary F1 = 0.9405, Macro F1 = 0.4046, Final Metric = 0.6725\n",
      "Epoch 19: Train Loss = 1.5346, Val Loss = 1.4493\n",
      "  Binary F1 = 0.9299, Macro F1 = 0.4321, Final Metric = 0.6810\n",
      "Epoch 20: Train Loss = 1.4691, Val Loss = 1.4716\n",
      "  Binary F1 = 0.9413, Macro F1 = 0.4310, Final Metric = 0.6861\n",
      "  New best metric! Saving model...\n",
      "Epoch 21: Train Loss = 1.5358, Val Loss = 1.4179\n",
      "  Binary F1 = 0.9323, Macro F1 = 0.4612, Final Metric = 0.6968\n",
      "  New best metric! Saving model...\n",
      "Epoch 22: Train Loss = 1.5161, Val Loss = 1.3938\n",
      "  Binary F1 = 0.9500, Macro F1 = 0.4496, Final Metric = 0.6998\n",
      "  New best metric! Saving model...\n",
      "Epoch 23: Train Loss = 1.4192, Val Loss = 1.3839\n",
      "  Binary F1 = 0.9512, Macro F1 = 0.4581, Final Metric = 0.7046\n",
      "  New best metric! Saving model...\n",
      "Epoch 24: Train Loss = 1.4539, Val Loss = 1.3545\n",
      "  Binary F1 = 0.9504, Macro F1 = 0.4395, Final Metric = 0.6950\n",
      "Epoch 25: Train Loss = 1.3057, Val Loss = 1.3489\n",
      "  Binary F1 = 0.9523, Macro F1 = 0.4590, Final Metric = 0.7057\n",
      "  New best metric! Saving model...\n",
      "Epoch 26: Train Loss = 1.3130, Val Loss = 1.3626\n",
      "  Binary F1 = 0.9488, Macro F1 = 0.4715, Final Metric = 0.7101\n",
      "  New best metric! Saving model...\n",
      "Epoch 27: Train Loss = 1.3800, Val Loss = 1.3640\n",
      "  Binary F1 = 0.9481, Macro F1 = 0.4556, Final Metric = 0.7019\n",
      "Epoch 28: Train Loss = 1.2951, Val Loss = 1.3168\n",
      "  Binary F1 = 0.9469, Macro F1 = 0.4829, Final Metric = 0.7149\n",
      "  New best metric! Saving model...\n",
      "Epoch 29: Train Loss = 1.2756, Val Loss = 1.3185\n",
      "  Binary F1 = 0.9528, Macro F1 = 0.4788, Final Metric = 0.7158\n",
      "  New best metric! Saving model...\n",
      "Epoch 30: Train Loss = 1.2898, Val Loss = 1.3268\n",
      "  Binary F1 = 0.9509, Macro F1 = 0.4781, Final Metric = 0.7145\n",
      "Epoch 31: Train Loss = 1.5262, Val Loss = 1.3332\n",
      "  Binary F1 = 0.9510, Macro F1 = 0.4768, Final Metric = 0.7139\n",
      "Epoch 32: Train Loss = 1.2905, Val Loss = 1.3023\n",
      "  Binary F1 = 0.9537, Macro F1 = 0.4841, Final Metric = 0.7189\n",
      "  New best metric! Saving model...\n",
      "Epoch 33: Train Loss = 1.2433, Val Loss = 1.3079\n",
      "  Binary F1 = 0.9532, Macro F1 = 0.4773, Final Metric = 0.7152\n",
      "Epoch 34: Train Loss = 1.2542, Val Loss = 1.3000\n",
      "  Binary F1 = 0.9528, Macro F1 = 0.4861, Final Metric = 0.7194\n",
      "  New best metric! Saving model...\n",
      "Epoch 35: Train Loss = 1.2178, Val Loss = 1.2969\n",
      "  Binary F1 = 0.9521, Macro F1 = 0.4818, Final Metric = 0.7169\n",
      "Epoch 36: Train Loss = 1.3276, Val Loss = 1.4398\n",
      "  Binary F1 = 0.9445, Macro F1 = 0.4312, Final Metric = 0.6878\n",
      "Epoch 37: Train Loss = 1.2682, Val Loss = 1.4054\n",
      "  Binary F1 = 0.9356, Macro F1 = 0.4536, Final Metric = 0.6946\n",
      "Epoch 38: Train Loss = 1.3156, Val Loss = 1.4009\n",
      "  Binary F1 = 0.9416, Macro F1 = 0.4636, Final Metric = 0.7026\n",
      "Epoch 39: Train Loss = 1.2362, Val Loss = 1.4082\n",
      "  Binary F1 = 0.9363, Macro F1 = 0.4475, Final Metric = 0.6919\n",
      "Epoch 40: Train Loss = 1.2322, Val Loss = 1.4202\n",
      "  Binary F1 = 0.9495, Macro F1 = 0.4437, Final Metric = 0.6966\n",
      "Epoch 41: Train Loss = 1.1892, Val Loss = 1.4217\n",
      "  Binary F1 = 0.9463, Macro F1 = 0.4567, Final Metric = 0.7015\n",
      "Epoch 42: Train Loss = 1.2723, Val Loss = 1.3772\n",
      "  Binary F1 = 0.9476, Macro F1 = 0.4607, Final Metric = 0.7042\n",
      "Epoch 43: Train Loss = 1.3828, Val Loss = 1.4279\n",
      "  Binary F1 = 0.9405, Macro F1 = 0.4551, Final Metric = 0.6978\n",
      "Epoch 44: Train Loss = 1.2904, Val Loss = 1.4098\n",
      "  Binary F1 = 0.9251, Macro F1 = 0.4526, Final Metric = 0.6889\n",
      "Epoch 45: Train Loss = 1.2680, Val Loss = 1.3885\n",
      "  Binary F1 = 0.9494, Macro F1 = 0.4595, Final Metric = 0.7044\n",
      "Epoch 46: Train Loss = 1.1590, Val Loss = 1.4122\n",
      "  Binary F1 = 0.9448, Macro F1 = 0.4643, Final Metric = 0.7045\n",
      "Epoch 47: Train Loss = 1.2106, Val Loss = 1.4235\n",
      "  Binary F1 = 0.9393, Macro F1 = 0.4490, Final Metric = 0.6941\n",
      "Epoch 48: Train Loss = 1.1673, Val Loss = 1.3975\n",
      "  Binary F1 = 0.9499, Macro F1 = 0.4694, Final Metric = 0.7096\n",
      "Epoch 49: Train Loss = 1.0986, Val Loss = 1.3886\n",
      "  Binary F1 = 0.9441, Macro F1 = 0.4584, Final Metric = 0.7012\n",
      "Early stopping triggered at epoch 49\n",
      "\n",
      "Fold 3 completed.\n",
      "Final validation metrics - Binary F1: 0.9441, Macro F1: 0.4584, Final: 0.7012\n",
      "Best validation metrics - Binary F1: 0.9528, Macro F1: 0.4861, Final: 0.7194\n",
      "\n",
      "==================================================\n",
      "Fold 4/5\n",
      "Train subjects: 65\n",
      "Val subjects: 16\n",
      "==================================================\n",
      "Epoch 01: Train Loss = 2.5676, Val Loss = 2.1930\n",
      "  Binary F1 = 0.8724, Macro F1 = 0.2296, Final Metric = 0.5510\n",
      "  New best metric! Saving model...\n",
      "Epoch 02: Train Loss = 2.2141, Val Loss = 1.9006\n",
      "  Binary F1 = 0.9143, Macro F1 = 0.2793, Final Metric = 0.5968\n",
      "  New best metric! Saving model...\n",
      "Epoch 03: Train Loss = 2.0880, Val Loss = 1.7429\n",
      "  Binary F1 = 0.9387, Macro F1 = 0.3347, Final Metric = 0.6367\n",
      "  New best metric! Saving model...\n",
      "Epoch 04: Train Loss = 1.9454, Val Loss = 1.6767\n",
      "  Binary F1 = 0.9500, Macro F1 = 0.3480, Final Metric = 0.6490\n",
      "  New best metric! Saving model...\n",
      "Epoch 05: Train Loss = 1.9363, Val Loss = 1.6460\n",
      "  Binary F1 = 0.9544, Macro F1 = 0.3555, Final Metric = 0.6549\n",
      "  New best metric! Saving model...\n",
      "Epoch 06: Train Loss = 1.8864, Val Loss = 1.6433\n",
      "  Binary F1 = 0.9401, Macro F1 = 0.3506, Final Metric = 0.6453\n",
      "Epoch 07: Train Loss = 1.7418, Val Loss = 1.5545\n",
      "  Binary F1 = 0.9528, Macro F1 = 0.3535, Final Metric = 0.6531\n",
      "Epoch 08: Train Loss = 1.7791, Val Loss = 1.4717\n",
      "  Binary F1 = 0.9496, Macro F1 = 0.3625, Final Metric = 0.6561\n",
      "  New best metric! Saving model...\n",
      "Epoch 09: Train Loss = 1.6182, Val Loss = 1.4214\n",
      "  Binary F1 = 0.9574, Macro F1 = 0.3958, Final Metric = 0.6766\n",
      "  New best metric! Saving model...\n",
      "Epoch 10: Train Loss = 1.7856, Val Loss = 1.3821\n",
      "  Binary F1 = 0.9642, Macro F1 = 0.4179, Final Metric = 0.6911\n",
      "  New best metric! Saving model...\n",
      "Epoch 11: Train Loss = 1.5839, Val Loss = 1.3430\n",
      "  Binary F1 = 0.9644, Macro F1 = 0.4401, Final Metric = 0.7022\n",
      "  New best metric! Saving model...\n",
      "Epoch 12: Train Loss = 1.5580, Val Loss = 1.3091\n",
      "  Binary F1 = 0.9670, Macro F1 = 0.4385, Final Metric = 0.7027\n",
      "  New best metric! Saving model...\n",
      "Epoch 13: Train Loss = 1.5755, Val Loss = 1.2930\n",
      "  Binary F1 = 0.9631, Macro F1 = 0.4379, Final Metric = 0.7005\n",
      "Epoch 14: Train Loss = 1.5488, Val Loss = 1.2710\n",
      "  Binary F1 = 0.9651, Macro F1 = 0.4524, Final Metric = 0.7088\n",
      "  New best metric! Saving model...\n",
      "Epoch 15: Train Loss = 1.5839, Val Loss = 1.2722\n",
      "  Binary F1 = 0.9650, Macro F1 = 0.4569, Final Metric = 0.7110\n",
      "  New best metric! Saving model...\n",
      "Epoch 16: Train Loss = 1.6697, Val Loss = 1.3810\n",
      "  Binary F1 = 0.9587, Macro F1 = 0.4394, Final Metric = 0.6990\n",
      "Epoch 17: Train Loss = 1.6253, Val Loss = 1.3573\n",
      "  Binary F1 = 0.9575, Macro F1 = 0.4381, Final Metric = 0.6978\n",
      "Epoch 18: Train Loss = 1.4834, Val Loss = 1.3591\n",
      "  Binary F1 = 0.9573, Macro F1 = 0.3953, Final Metric = 0.6763\n",
      "Epoch 19: Train Loss = 1.6262, Val Loss = 1.3381\n",
      "  Binary F1 = 0.9588, Macro F1 = 0.4509, Final Metric = 0.7049\n",
      "Epoch 20: Train Loss = 1.5062, Val Loss = 1.2668\n",
      "  Binary F1 = 0.9584, Macro F1 = 0.4484, Final Metric = 0.7034\n",
      "Epoch 21: Train Loss = 1.4466, Val Loss = 1.2646\n",
      "  Binary F1 = 0.9647, Macro F1 = 0.4525, Final Metric = 0.7086\n",
      "Epoch 22: Train Loss = 1.6035, Val Loss = 1.2547\n",
      "  Binary F1 = 0.9621, Macro F1 = 0.4693, Final Metric = 0.7157\n",
      "  New best metric! Saving model...\n",
      "Epoch 23: Train Loss = 1.3391, Val Loss = 1.2394\n",
      "  Binary F1 = 0.9656, Macro F1 = 0.4958, Final Metric = 0.7307\n",
      "  New best metric! Saving model...\n",
      "Epoch 24: Train Loss = 1.4509, Val Loss = 1.2553\n",
      "  Binary F1 = 0.9615, Macro F1 = 0.4828, Final Metric = 0.7221\n",
      "Epoch 25: Train Loss = 1.4268, Val Loss = 1.2457\n",
      "  Binary F1 = 0.9661, Macro F1 = 0.4914, Final Metric = 0.7288\n",
      "Epoch 26: Train Loss = 1.4603, Val Loss = 1.2044\n",
      "  Binary F1 = 0.9638, Macro F1 = 0.4753, Final Metric = 0.7196\n",
      "Epoch 27: Train Loss = 1.2539, Val Loss = 1.1672\n",
      "  Binary F1 = 0.9629, Macro F1 = 0.5096, Final Metric = 0.7363\n",
      "  New best metric! Saving model...\n",
      "Epoch 28: Train Loss = 1.2761, Val Loss = 1.1708\n",
      "  Binary F1 = 0.9670, Macro F1 = 0.4888, Final Metric = 0.7279\n",
      "Epoch 29: Train Loss = 1.3782, Val Loss = 1.1639\n",
      "  Binary F1 = 0.9651, Macro F1 = 0.4967, Final Metric = 0.7309\n",
      "Epoch 30: Train Loss = 1.2953, Val Loss = 1.1540\n",
      "  Binary F1 = 0.9681, Macro F1 = 0.5059, Final Metric = 0.7370\n",
      "  New best metric! Saving model...\n",
      "Epoch 31: Train Loss = 1.2867, Val Loss = 1.1614\n",
      "  Binary F1 = 0.9640, Macro F1 = 0.4930, Final Metric = 0.7285\n",
      "Epoch 32: Train Loss = 1.2733, Val Loss = 1.1561\n",
      "  Binary F1 = 0.9666, Macro F1 = 0.5089, Final Metric = 0.7378\n",
      "  New best metric! Saving model...\n",
      "Epoch 33: Train Loss = 1.2327, Val Loss = 1.1516\n",
      "  Binary F1 = 0.9651, Macro F1 = 0.5128, Final Metric = 0.7390\n",
      "  New best metric! Saving model...\n",
      "Epoch 34: Train Loss = 1.2387, Val Loss = 1.1519\n",
      "  Binary F1 = 0.9676, Macro F1 = 0.5142, Final Metric = 0.7409\n",
      "  New best metric! Saving model...\n",
      "Epoch 35: Train Loss = 1.3167, Val Loss = 1.1503\n",
      "  Binary F1 = 0.9666, Macro F1 = 0.5097, Final Metric = 0.7381\n",
      "Epoch 36: Train Loss = 1.4765, Val Loss = 1.2652\n",
      "  Binary F1 = 0.9618, Macro F1 = 0.4815, Final Metric = 0.7217\n",
      "Epoch 37: Train Loss = 1.3752, Val Loss = 1.4001\n",
      "  Binary F1 = 0.9570, Macro F1 = 0.4338, Final Metric = 0.6954\n",
      "Epoch 38: Train Loss = 1.3429, Val Loss = 1.2719\n",
      "  Binary F1 = 0.9576, Macro F1 = 0.4677, Final Metric = 0.7126\n",
      "Epoch 39: Train Loss = 1.2750, Val Loss = 1.2145\n",
      "  Binary F1 = 0.9673, Macro F1 = 0.4872, Final Metric = 0.7273\n",
      "Epoch 40: Train Loss = 1.2630, Val Loss = 1.2165\n",
      "  Binary F1 = 0.9633, Macro F1 = 0.4832, Final Metric = 0.7232\n",
      "Epoch 41: Train Loss = 1.3353, Val Loss = 1.2216\n",
      "  Binary F1 = 0.9630, Macro F1 = 0.5150, Final Metric = 0.7390\n",
      "Epoch 42: Train Loss = 1.4159, Val Loss = 1.2187\n",
      "  Binary F1 = 0.9686, Macro F1 = 0.4723, Final Metric = 0.7204\n",
      "Epoch 43: Train Loss = 1.3805, Val Loss = 1.2031\n",
      "  Binary F1 = 0.9629, Macro F1 = 0.4815, Final Metric = 0.7222\n",
      "Epoch 44: Train Loss = 1.3586, Val Loss = 1.2072\n",
      "  Binary F1 = 0.9646, Macro F1 = 0.5189, Final Metric = 0.7418\n",
      "  New best metric! Saving model...\n",
      "Epoch 45: Train Loss = 1.3124, Val Loss = 1.2054\n",
      "  Binary F1 = 0.9620, Macro F1 = 0.4952, Final Metric = 0.7286\n",
      "Epoch 46: Train Loss = 1.2104, Val Loss = 1.2425\n",
      "  Binary F1 = 0.9668, Macro F1 = 0.4855, Final Metric = 0.7261\n",
      "Epoch 47: Train Loss = 1.0935, Val Loss = 1.2090\n",
      "  Binary F1 = 0.9651, Macro F1 = 0.4890, Final Metric = 0.7270\n",
      "Epoch 48: Train Loss = 1.2695, Val Loss = 1.2115\n",
      "  Binary F1 = 0.9656, Macro F1 = 0.4999, Final Metric = 0.7327\n",
      "Epoch 49: Train Loss = 1.1101, Val Loss = 1.2056\n",
      "  Binary F1 = 0.9696, Macro F1 = 0.4920, Final Metric = 0.7308\n",
      "Epoch 50: Train Loss = 1.1759, Val Loss = 1.1819\n",
      "  Binary F1 = 0.9693, Macro F1 = 0.5180, Final Metric = 0.7436\n",
      "  New best metric! Saving model...\n",
      "Epoch 51: Train Loss = 1.1210, Val Loss = 1.2385\n",
      "  Binary F1 = 0.9688, Macro F1 = 0.4991, Final Metric = 0.7339\n",
      "Epoch 52: Train Loss = 1.0254, Val Loss = 1.2245\n",
      "  Binary F1 = 0.9681, Macro F1 = 0.5013, Final Metric = 0.7347\n",
      "Epoch 53: Train Loss = 1.0750, Val Loss = 1.1966\n",
      "  Binary F1 = 0.9700, Macro F1 = 0.5093, Final Metric = 0.7396\n",
      "Epoch 54: Train Loss = 1.1949, Val Loss = 1.2176\n",
      "  Binary F1 = 0.9644, Macro F1 = 0.4960, Final Metric = 0.7302\n",
      "Epoch 55: Train Loss = 1.1301, Val Loss = 1.2184\n",
      "  Binary F1 = 0.9700, Macro F1 = 0.4948, Final Metric = 0.7324\n",
      "Epoch 56: Train Loss = 1.0710, Val Loss = 1.1960\n",
      "  Binary F1 = 0.9705, Macro F1 = 0.5173, Final Metric = 0.7439\n",
      "  New best metric! Saving model...\n",
      "Epoch 57: Train Loss = 1.0786, Val Loss = 1.1943\n",
      "  Binary F1 = 0.9696, Macro F1 = 0.5389, Final Metric = 0.7542\n",
      "  New best metric! Saving model...\n",
      "Epoch 58: Train Loss = 1.1118, Val Loss = 1.2140\n",
      "  Binary F1 = 0.9740, Macro F1 = 0.4921, Final Metric = 0.7331\n",
      "Epoch 59: Train Loss = 0.9241, Val Loss = 1.1929\n",
      "  Binary F1 = 0.9735, Macro F1 = 0.5295, Final Metric = 0.7515\n",
      "Epoch 60: Train Loss = 0.9800, Val Loss = 1.1960\n",
      "  Binary F1 = 0.9705, Macro F1 = 0.5172, Final Metric = 0.7438\n",
      "Epoch 61: Train Loss = 1.0318, Val Loss = 1.1953\n",
      "  Binary F1 = 0.9686, Macro F1 = 0.5241, Final Metric = 0.7464\n",
      "Epoch 62: Train Loss = 0.9286, Val Loss = 1.2068\n",
      "  Binary F1 = 0.9711, Macro F1 = 0.5178, Final Metric = 0.7444\n",
      "Epoch 63: Train Loss = 0.8611, Val Loss = 1.2036\n",
      "  Binary F1 = 0.9701, Macro F1 = 0.5131, Final Metric = 0.7416\n",
      "Epoch 64: Train Loss = 0.9022, Val Loss = 1.1996\n",
      "  Binary F1 = 0.9686, Macro F1 = 0.5192, Final Metric = 0.7439\n",
      "Epoch 65: Train Loss = 0.9322, Val Loss = 1.2172\n",
      "  Binary F1 = 0.9711, Macro F1 = 0.5246, Final Metric = 0.7479\n",
      "Epoch 66: Train Loss = 1.0890, Val Loss = 1.2114\n",
      "  Binary F1 = 0.9701, Macro F1 = 0.5232, Final Metric = 0.7466\n",
      "Epoch 67: Train Loss = 0.9261, Val Loss = 1.2174\n",
      "  Binary F1 = 0.9706, Macro F1 = 0.5234, Final Metric = 0.7470\n",
      "Epoch 68: Train Loss = 1.1682, Val Loss = 1.2176\n",
      "  Binary F1 = 0.9696, Macro F1 = 0.5138, Final Metric = 0.7417\n",
      "Epoch 69: Train Loss = 0.8181, Val Loss = 1.2068\n",
      "  Binary F1 = 0.9721, Macro F1 = 0.5236, Final Metric = 0.7478\n",
      "Epoch 70: Train Loss = 0.9350, Val Loss = 1.2159\n",
      "  Binary F1 = 0.9711, Macro F1 = 0.5253, Final Metric = 0.7482\n",
      "Epoch 71: Train Loss = 1.0022, Val Loss = 1.2068\n",
      "  Binary F1 = 0.9726, Macro F1 = 0.5333, Final Metric = 0.7530\n",
      "Epoch 72: Train Loss = 0.9228, Val Loss = 1.2119\n",
      "  Binary F1 = 0.9726, Macro F1 = 0.5258, Final Metric = 0.7492\n",
      "Early stopping triggered at epoch 72\n",
      "\n",
      "Fold 4 completed.\n",
      "Final validation metrics - Binary F1: 0.9726, Macro F1: 0.5258, Final: 0.7492\n",
      "Best validation metrics - Binary F1: 0.9696, Macro F1: 0.5389, Final: 0.7542\n",
      "\n",
      "==================================================\n",
      "Fold 5/5\n",
      "Train subjects: 64\n",
      "Val subjects: 17\n",
      "==================================================\n",
      "Epoch 01: Train Loss = 2.5576, Val Loss = 2.1400\n",
      "  Binary F1 = 0.8518, Macro F1 = 0.2520, Final Metric = 0.5519\n",
      "  New best metric! Saving model...\n",
      "Epoch 02: Train Loss = 2.2113, Val Loss = 1.8639\n",
      "  Binary F1 = 0.9126, Macro F1 = 0.2841, Final Metric = 0.5984\n",
      "  New best metric! Saving model...\n",
      "Epoch 03: Train Loss = 1.9878, Val Loss = 1.7248\n",
      "  Binary F1 = 0.9301, Macro F1 = 0.3310, Final Metric = 0.6305\n",
      "  New best metric! Saving model...\n",
      "Epoch 04: Train Loss = 1.9085, Val Loss = 1.6483\n",
      "  Binary F1 = 0.9401, Macro F1 = 0.3309, Final Metric = 0.6355\n",
      "  New best metric! Saving model...\n",
      "Epoch 05: Train Loss = 1.8558, Val Loss = 1.6366\n",
      "  Binary F1 = 0.9408, Macro F1 = 0.3514, Final Metric = 0.6461\n",
      "  New best metric! Saving model...\n",
      "Epoch 06: Train Loss = 1.9591, Val Loss = 1.6040\n",
      "  Binary F1 = 0.9369, Macro F1 = 0.3548, Final Metric = 0.6459\n",
      "Epoch 07: Train Loss = 1.9285, Val Loss = 1.5736\n",
      "  Binary F1 = 0.9419, Macro F1 = 0.3822, Final Metric = 0.6620\n",
      "  New best metric! Saving model...\n",
      "Epoch 08: Train Loss = 1.7754, Val Loss = 1.4989\n",
      "  Binary F1 = 0.9527, Macro F1 = 0.4016, Final Metric = 0.6771\n",
      "  New best metric! Saving model...\n",
      "Epoch 09: Train Loss = 1.7639, Val Loss = 1.4240\n",
      "  Binary F1 = 0.9573, Macro F1 = 0.4454, Final Metric = 0.7013\n",
      "  New best metric! Saving model...\n",
      "Epoch 10: Train Loss = 1.6147, Val Loss = 1.4039\n",
      "  Binary F1 = 0.9560, Macro F1 = 0.4331, Final Metric = 0.6945\n",
      "Epoch 11: Train Loss = 1.6748, Val Loss = 1.3664\n",
      "  Binary F1 = 0.9607, Macro F1 = 0.4459, Final Metric = 0.7033\n",
      "  New best metric! Saving model...\n",
      "Epoch 12: Train Loss = 1.5515, Val Loss = 1.3161\n",
      "  Binary F1 = 0.9585, Macro F1 = 0.4784, Final Metric = 0.7185\n",
      "  New best metric! Saving model...\n",
      "Epoch 13: Train Loss = 1.5513, Val Loss = 1.2969\n",
      "  Binary F1 = 0.9602, Macro F1 = 0.4815, Final Metric = 0.7209\n",
      "  New best metric! Saving model...\n",
      "Epoch 14: Train Loss = 1.5728, Val Loss = 1.2808\n",
      "  Binary F1 = 0.9623, Macro F1 = 0.4763, Final Metric = 0.7193\n",
      "Epoch 15: Train Loss = 1.5235, Val Loss = 1.2755\n",
      "  Binary F1 = 0.9644, Macro F1 = 0.4912, Final Metric = 0.7278\n",
      "  New best metric! Saving model...\n",
      "Epoch 16: Train Loss = 1.6462, Val Loss = 1.3893\n",
      "  Binary F1 = 0.9557, Macro F1 = 0.4317, Final Metric = 0.6937\n",
      "Epoch 17: Train Loss = 1.6375, Val Loss = 1.3597\n",
      "  Binary F1 = 0.9463, Macro F1 = 0.4450, Final Metric = 0.6956\n",
      "Epoch 18: Train Loss = 1.6147, Val Loss = 1.3438\n",
      "  Binary F1 = 0.9594, Macro F1 = 0.4713, Final Metric = 0.7153\n",
      "Epoch 19: Train Loss = 1.5312, Val Loss = 1.2827\n",
      "  Binary F1 = 0.9591, Macro F1 = 0.4748, Final Metric = 0.7169\n",
      "Epoch 20: Train Loss = 1.5523, Val Loss = 1.3445\n",
      "  Binary F1 = 0.9543, Macro F1 = 0.4225, Final Metric = 0.6884\n",
      "Epoch 21: Train Loss = 1.3885, Val Loss = 1.3194\n",
      "  Binary F1 = 0.9606, Macro F1 = 0.4544, Final Metric = 0.7075\n",
      "Epoch 22: Train Loss = 1.5078, Val Loss = 1.2294\n",
      "  Binary F1 = 0.9633, Macro F1 = 0.5002, Final Metric = 0.7318\n",
      "  New best metric! Saving model...\n",
      "Epoch 23: Train Loss = 1.3919, Val Loss = 1.2159\n",
      "  Binary F1 = 0.9669, Macro F1 = 0.5167, Final Metric = 0.7418\n",
      "  New best metric! Saving model...\n",
      "Epoch 24: Train Loss = 1.4054, Val Loss = 1.2124\n",
      "  Binary F1 = 0.9651, Macro F1 = 0.4932, Final Metric = 0.7291\n",
      "Epoch 25: Train Loss = 1.4276, Val Loss = 1.2206\n",
      "  Binary F1 = 0.9644, Macro F1 = 0.4824, Final Metric = 0.7234\n",
      "Epoch 26: Train Loss = 1.4408, Val Loss = 1.1840\n",
      "  Binary F1 = 0.9688, Macro F1 = 0.5119, Final Metric = 0.7404\n",
      "Epoch 27: Train Loss = 1.3348, Val Loss = 1.1831\n",
      "  Binary F1 = 0.9616, Macro F1 = 0.5085, Final Metric = 0.7350\n",
      "Epoch 28: Train Loss = 1.4473, Val Loss = 1.1586\n",
      "  Binary F1 = 0.9683, Macro F1 = 0.5264, Final Metric = 0.7474\n",
      "  New best metric! Saving model...\n",
      "Epoch 29: Train Loss = 1.2519, Val Loss = 1.1400\n",
      "  Binary F1 = 0.9678, Macro F1 = 0.5298, Final Metric = 0.7488\n",
      "  New best metric! Saving model...\n",
      "Epoch 30: Train Loss = 1.3876, Val Loss = 1.1536\n",
      "  Binary F1 = 0.9678, Macro F1 = 0.5284, Final Metric = 0.7481\n",
      "Epoch 31: Train Loss = 1.2601, Val Loss = 1.1430\n",
      "  Binary F1 = 0.9673, Macro F1 = 0.5175, Final Metric = 0.7424\n",
      "Epoch 32: Train Loss = 1.2334, Val Loss = 1.1336\n",
      "  Binary F1 = 0.9672, Macro F1 = 0.5403, Final Metric = 0.7538\n",
      "  New best metric! Saving model...\n",
      "Epoch 33: Train Loss = 1.2567, Val Loss = 1.1318\n",
      "  Binary F1 = 0.9663, Macro F1 = 0.5353, Final Metric = 0.7508\n",
      "Epoch 34: Train Loss = 1.1984, Val Loss = 1.1295\n",
      "  Binary F1 = 0.9658, Macro F1 = 0.5377, Final Metric = 0.7517\n",
      "Epoch 35: Train Loss = 1.1624, Val Loss = 1.1285\n",
      "  Binary F1 = 0.9672, Macro F1 = 0.5367, Final Metric = 0.7520\n",
      "Epoch 36: Train Loss = 1.4088, Val Loss = 1.2726\n",
      "  Binary F1 = 0.9572, Macro F1 = 0.4711, Final Metric = 0.7142\n",
      "Epoch 37: Train Loss = 1.3590, Val Loss = 1.2804\n",
      "  Binary F1 = 0.9544, Macro F1 = 0.4759, Final Metric = 0.7151\n",
      "Epoch 38: Train Loss = 1.4475, Val Loss = 1.2320\n",
      "  Binary F1 = 0.9530, Macro F1 = 0.5097, Final Metric = 0.7314\n",
      "Epoch 39: Train Loss = 1.2948, Val Loss = 1.2137\n",
      "  Binary F1 = 0.9580, Macro F1 = 0.5095, Final Metric = 0.7337\n",
      "Epoch 40: Train Loss = 1.3381, Val Loss = 1.1946\n",
      "  Binary F1 = 0.9662, Macro F1 = 0.5079, Final Metric = 0.7370\n",
      "Epoch 41: Train Loss = 1.3405, Val Loss = 1.1984\n",
      "  Binary F1 = 0.9652, Macro F1 = 0.5197, Final Metric = 0.7424\n",
      "Epoch 42: Train Loss = 1.3987, Val Loss = 1.1865\n",
      "  Binary F1 = 0.9676, Macro F1 = 0.5235, Final Metric = 0.7456\n",
      "Epoch 43: Train Loss = 1.3792, Val Loss = 1.2159\n",
      "  Binary F1 = 0.9647, Macro F1 = 0.5082, Final Metric = 0.7365\n",
      "Epoch 44: Train Loss = 1.2180, Val Loss = 1.1925\n",
      "  Binary F1 = 0.9639, Macro F1 = 0.5115, Final Metric = 0.7377\n",
      "Epoch 45: Train Loss = 1.3213, Val Loss = 1.2105\n",
      "  Binary F1 = 0.9695, Macro F1 = 0.5226, Final Metric = 0.7461\n",
      "Epoch 46: Train Loss = 1.2060, Val Loss = 1.1799\n",
      "  Binary F1 = 0.9615, Macro F1 = 0.5219, Final Metric = 0.7417\n",
      "Epoch 47: Train Loss = 1.2373, Val Loss = 1.2019\n",
      "  Binary F1 = 0.9655, Macro F1 = 0.5084, Final Metric = 0.7369\n",
      "Early stopping triggered at epoch 47\n",
      "\n",
      "Fold 5 completed.\n",
      "Final validation metrics - Binary F1: 0.9655, Macro F1: 0.5084, Final: 0.7369\n",
      "Best validation metrics - Binary F1: 0.9672, Macro F1: 0.5403, Final: 0.7538\n",
      "\n",
      "==================================================\n",
      "Cross-Validation Results\n",
      "==================================================\n",
      "\n",
      "Best Fold-wise Metrics:\n",
      "Fold 1: Binary F1 = 0.9671, Macro F1 = 0.5060, Final = 0.7365\n",
      "Fold 2: Binary F1 = 0.9516, Macro F1 = 0.4531, Final = 0.7023\n",
      "Fold 3: Binary F1 = 0.9528, Macro F1 = 0.4861, Final = 0.7194\n",
      "Fold 4: Binary F1 = 0.9696, Macro F1 = 0.5389, Final = 0.7542\n",
      "Fold 5: Binary F1 = 0.9672, Macro F1 = 0.5403, Final = 0.7538\n",
      "\n",
      "Global Statistics (Best Metrics):\n",
      "Mean Best Final Metric: 0.7333 ± 0.0201\n",
      "Mean Best Binary F1: 0.9617 ± 0.0078\n",
      "Mean Best Macro F1: 0.5049 ± 0.0330\n"
     ]
    }
   ],
   "source": [
    "seed_everything(seed=SEED)\n",
    "\n",
    "# criterion = soft_cross_entropy\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "n_splits = 5\n",
    "batch_size = 128\n",
    "gkf = GroupKFold(n_splits=n_splits)\n",
    "\n",
    "fold_metrics = []\n",
    "best_fold_metrics = []\n",
    "best_models = []\n",
    "\n",
    "fold_patterns = join(dataset_path, \"preprocessed_dataset\", \"fold*\")\n",
    "fold_pths = glob(fold_patterns)[:NB_CROSS_VALIDATIONS]\n",
    "all_training_metrics = {}\n",
    "\n",
    "\n",
    "for fold, fold_pth in enumerate(fold_pths):\n",
    "    print(\"training:\", fold + 1)\n",
    "    train_dataset = CMIDataset(fold_pth, \"train\")\n",
    "    train_loader = DL(train_dataset, BATCH_SIZE, shuffle=True)\n",
    "    validation_dataset = CMIDataset(fold_pth, \"validation\")\n",
    "    validation_loader = DL(validation_dataset, BATCH_SIZE, shuffle=False)\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Fold {fold + 1}/{n_splits}\")\n",
    "    # print(f\"Train subjects: {len(np.unique(seq_df.iloc[train_idx]['subject']))}\")\n",
    "    # print(f\"Val subjects: {len(np.unique(seq_df.iloc[val_idx]['subject']))}\")\n",
    "    # print(f\"{'='*50}\")\n",
    "    \n",
    "    # train_dataset = SequenceDataset(X_array[train_idx], y_array[train_idx])\n",
    "    # val_dataset = SequenceDataset(X_array[val_idx], y_array[val_idx])\n",
    "    \n",
    "    # train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "    # validation_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    seed_everything(seed=SEED + fold)\n",
    "    model = mk_model()\n",
    "    \n",
    "    # Optimizer et scheduler\n",
    "    # optimizer = optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), STARTING_LR)\n",
    "    steps_per_epoch = len(train_loader)\n",
    "    # scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "    #     optimizer,\n",
    "    #     T_0=5 * steps_per_epoch,\n",
    "    #     T_mult=2,\n",
    "    #     eta_min=1e-5,\n",
    "    # )\n",
    "    scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "        max_lr=0.002 / 2,\n",
    "        div_factor=MAX_LR_TO_MIN_DIV_FACTOR,\n",
    "        epochs=TRAINING_EPOCHS,\n",
    "        steps_per_epoch=len(train_loader),\n",
    "    )\n",
    "\n",
    "\n",
    "    # Early stopping\n",
    "    best_metric = -np.inf\n",
    "    best_binary_f1 = -np.inf\n",
    "    best_macro_f1 = -np.inf\n",
    "    patience = 15\n",
    "    epochs_no_improve = 0\n",
    "    \n",
    "    for epoch in range(1, TRAINING_EPOCHS + 1):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        total = 0\n",
    "        for batch_x, batch_y in train_loader:\n",
    "            batch_x = batch_x.to(device)\n",
    "            batch_y = batch_y.to(device)\n",
    "    \n",
    "            # Apply mixup\n",
    "            # mixed_x, mixed_y = mixup_data(batch_x, batch_y, alpha=0.2)\n",
    "            mixed_x, mixed_y = batch_x, batch_y #mixup_data(batch_x, batch_y, alpha=0.2)\n",
    "    \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(mixed_x)\n",
    "            loss = criterion(outputs, mixed_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "    \n",
    "            train_loss += loss.item() * batch_x.size(0)\n",
    "            total += batch_x.size(0)\n",
    "        train_loss /= total\n",
    "    \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        total = 0\n",
    "        all_true = []\n",
    "        all_pred = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch_x, batch_y in validation_loader:\n",
    "                batch_x = batch_x.to(device)\n",
    "                batch_y = batch_y.to(device)\n",
    "                \n",
    "                outputs = model(batch_x)\n",
    "                loss = criterion(outputs, batch_y)\n",
    "                val_loss += loss.item() * batch_x.size(0)\n",
    "                total += batch_x.size(0)\n",
    "                \n",
    "                # Get predicted class indices\n",
    "                preds = torch.argmax(outputs, dim=1).cpu().numpy()\n",
    "                # Get true class indices from one-hot\n",
    "                trues = torch.argmax(batch_y, dim=1).cpu().numpy()\n",
    "                \n",
    "                all_true.append(trues)\n",
    "                all_pred.append(preds)\n",
    "        \n",
    "        val_loss /= total\n",
    "        all_true = np.concatenate(all_true)\n",
    "        all_pred = np.concatenate(all_pred)\n",
    "        \n",
    "        # Compute competition metrics\n",
    "        # Binary classification: BFRB (1) vs non-BFRB (0)\n",
    "        binary_true = np.isin(all_true, bfrb_indices).astype(int)\n",
    "        binary_pred = np.isin(all_pred, bfrb_indices).astype(int)\n",
    "        binary_f1 = f1_score(binary_true, binary_pred)\n",
    "        \n",
    "        # Collapse non-BFRB gestures into a single class\n",
    "        collapsed_true = np.where(\n",
    "            np.isin(all_true, bfrb_indices),\n",
    "            all_true,\n",
    "            len(bfrb_gestures)  # Single non-BFRB class\n",
    "        )\n",
    "        collapsed_pred = np.where(\n",
    "            np.isin(all_pred, bfrb_indices),\n",
    "            all_pred,\n",
    "            len(bfrb_gestures)  # Single non-BFRB class\n",
    "        )\n",
    "        \n",
    "        # Macro F1 on collapsed classes\n",
    "        macro_f1 = f1_score(collapsed_true, collapsed_pred, average='macro')\n",
    "        final_metric = (binary_f1 + macro_f1) / 2\n",
    "        \n",
    "        print(f\"Epoch {epoch:02d}: Train Loss = {train_loss:.4f}, Val Loss = {val_loss:.4f}\")\n",
    "        print(f\"  Binary F1 = {binary_f1:.4f}, Macro F1 = {macro_f1:.4f}, Final Metric = {final_metric:.4f}\")\n",
    "        \n",
    "        if final_metric > best_metric:\n",
    "            best_metric = final_metric\n",
    "            best_binary_f1 = binary_f1\n",
    "            best_macro_f1 = macro_f1\n",
    "            epochs_no_improve = 0\n",
    "            best_model_state = model.state_dict()\n",
    "            print(f\"  New best metric! Saving model...\")\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            if epochs_no_improve >= patience:\n",
    "                print(f\"Early stopping triggered at epoch {epoch}\")\n",
    "                model.load_state_dict(best_model_state)\n",
    "                break\n",
    "\n",
    "    torch.save(best_model_state, f\"best_model_fold{fold}.pth\")\n",
    "    best_models.append(best_model_state)\n",
    "\n",
    "    fold_metrics.append({\n",
    "        'binary_f1': binary_f1,\n",
    "        'macro_f1': macro_f1,\n",
    "        'final_metric': final_metric\n",
    "    })\n",
    "    \n",
    "    best_fold_metrics.append({\n",
    "        'binary_f1': best_binary_f1,\n",
    "        'macro_f1': best_macro_f1,\n",
    "        'final_metric': best_metric\n",
    "    })\n",
    "    \n",
    "    print(f\"\\nFold {fold + 1} completed.\")\n",
    "    print(f\"Final validation metrics - Binary F1: {binary_f1:.4f}, Macro F1: {macro_f1:.4f}, Final: {final_metric:.4f}\")\n",
    "    print(f\"Best validation metrics - Binary F1: {best_binary_f1:.4f}, Macro F1: {best_macro_f1:.4f}, Final: {best_metric:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Cross-Validation Results\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Statistiques pour les meilleures métriques\n",
    "best_binary_f1 = [m['binary_f1'] for m in best_fold_metrics]\n",
    "best_macro_f1 = [m['macro_f1'] for m in best_fold_metrics]\n",
    "best_metrics = [m['final_metric'] for m in best_fold_metrics]\n",
    "\n",
    "print(\"\\nBest Fold-wise Metrics:\")\n",
    "for i, (bf1, mf1, fm) in enumerate(zip(best_binary_f1, best_macro_f1, best_metrics)):\n",
    "    print(f\"Fold {i+1}: Binary F1 = {bf1:.4f}, Macro F1 = {mf1:.4f}, Final = {fm:.4f}\")\n",
    "\n",
    "print(\"\\nGlobal Statistics (Best Metrics):\")\n",
    "print(f\"Mean Best Final Metric: {np.mean(best_metrics):.4f} ± {np.std(best_metrics):.4f}\")\n",
    "print(f\"Mean Best Binary F1: {np.mean(best_binary_f1):.4f} ± {np.std(best_binary_f1):.4f}\")\n",
    "print(f\"Mean Best Macro F1: {np.mean(best_macro_f1):.4f} ± {np.std(best_macro_f1):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aea5e4f",
   "metadata": {
    "papermill": {
     "duration": 0.012906,
     "end_time": "2025-06-14T10:09:14.780212",
     "exception": false,
     "start_time": "2025-06-14T10:09:14.767306",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Reloading best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0574d4d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T10:09:14.807902Z",
     "iopub.status.busy": "2025-06-14T10:09:14.807165Z",
     "iopub.status.idle": "2025-06-14T10:09:14.933288Z",
     "shell.execute_reply": "2025-06-14T10:09:14.932459Z"
    },
    "papermill": {
     "duration": 0.141435,
     "end_time": "2025-06-14T10:09:14.934745",
     "exception": false,
     "start_time": "2025-06-14T10:09:14.793310",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_ensemble = []\n",
    "for fold in range(5):\n",
    "    model = IMU_HARModel(\n",
    "        total_features=len(feature_cols),\n",
    "        imu_dim=imu_dim,\n",
    "        pad_len=pad_len,\n",
    "        num_classes=num_classes,\n",
    "    ).to(device)\n",
    "    checkpoint = torch.load(f\"best_model_fold{fold}.pth\", map_location=device)\n",
    "    model.load_state_dict(checkpoint)\n",
    "    model.eval()\n",
    "    model_ensemble.append(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ea7558",
   "metadata": {
    "papermill": {
     "duration": 0.012909,
     "end_time": "2025-06-14T10:09:14.961270",
     "exception": false,
     "start_time": "2025-06-14T10:09:14.948361",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Submission**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57d8dfff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T10:09:14.989742Z",
     "iopub.status.busy": "2025-06-14T10:09:14.989258Z",
     "iopub.status.idle": "2025-06-14T10:09:14.995936Z",
     "shell.execute_reply": "2025-06-14T10:09:14.995244Z"
    },
    "papermill": {
     "duration": 0.021303,
     "end_time": "2025-06-14T10:09:14.997034",
     "exception": false,
     "start_time": "2025-06-14T10:09:14.975731",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_sequence(df_seq: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Process a single sequence DataFrame (pandas):\n",
    "    - Forward/backward fill missing\n",
    "    - Scale using loaded scaler\n",
    "    - Pad/truncate to pad_len\n",
    "    - Return torch.Tensor of shape (1, features, seq_len)\n",
    "    \"\"\"\n",
    "    data = df_seq[feature_cols].ffill().bfill().fillna(0).values\n",
    "    # Pad/truncate\n",
    "    padded = keras_pad_sequences(\n",
    "        [data],\n",
    "        maxlen=pad_len,\n",
    "        dtype='float32',\n",
    "        padding='post',\n",
    "        truncating='post'\n",
    "    )[0]  # (pad_len, total_features)\n",
    "    # Transpose to (features, pad_len)\n",
    "    tensor = torch.from_numpy(padded.T).unsqueeze(0).float()  # (1, features, pad_len)\n",
    "    return tensor\n",
    "    \n",
    "def predict(sequence: pl.DataFrame, demographics: pl.DataFrame) -> str:\n",
    "    \"\"\"\n",
    "    Kaggle evaluation API will call this for each sequence.\n",
    "    sequence: polars DataFrame for a single sequence\n",
    "    demographics: unused in this model\n",
    "    Returns: predicted gesture string\n",
    "    \"\"\"\n",
    "    df_seq = sequence.to_pandas()\n",
    "    df_demo = demographics.to_pandas()\n",
    "    \n",
    "    df_seq = df_seq.merge(\n",
    "    df_demo,\n",
    "    on='subject',\n",
    "    how='left',\n",
    "    validate='many_to_one',\n",
    "    )\n",
    "    right_handed_mask = df_seq['handedness'] == 1\n",
    "    df_seq.loc[right_handed_mask, imu_cols] = apply_symmetry(df_seq.loc[right_handed_mask, imu_cols])\n",
    "\n",
    "    x_tensor = preprocess_sequence(df_seq).to(device)\n",
    "    \n",
    "    all_outputs = []\n",
    "    with torch.no_grad():\n",
    "        for model in model_ensemble:\n",
    "            outputs = model(x_tensor).softmax(dim=-1)\n",
    "            all_outputs.append(outputs)\n",
    "\n",
    "    avg_outputs = torch.mean(torch.stack(all_outputs), dim=0)\n",
    "    pred_idx = torch.argmax(avg_outputs, dim=1).item()\n",
    "    \n",
    "    return str(gesture_classes[pred_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c386b7d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T10:09:15.023324Z",
     "iopub.status.busy": "2025-06-14T10:09:15.023122Z",
     "iopub.status.idle": "2025-06-14T10:09:16.373534Z",
     "shell.execute_reply": "2025-06-14T10:09:16.372710Z"
    },
    "papermill": {
     "duration": 1.365137,
     "end_time": "2025-06-14T10:09:16.374918",
     "exception": false,
     "start_time": "2025-06-14T10:09:15.009781",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "inference_server = kaggle_evaluation.cmi_inference_server.CMIInferenceServer(predict)\n",
    "\n",
    "if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
    "    inference_server.serve()\n",
    "else:\n",
    "    inference_server.run_local_gateway(\n",
    "        data_paths=(\n",
    "            '/kaggle/input/cmi-detect-behavior-with-sensor-data/test.csv',\n",
    "            '/kaggle/input/cmi-detect-behavior-with-sensor-data/test_demographics.csv',\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99fa5737",
   "metadata": {
    "papermill": {
     "duration": 0.012902,
     "end_time": "2025-06-14T10:09:16.401287",
     "exception": false,
     "start_time": "2025-06-14T10:09:16.388385",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Credit to [Tarun Mishra](https://www.kaggle.com/tarundirector) – this code is heavily based on his [notebook](https://www.kaggle.com/code/tarundirector/sensor-pulse-viz-eda-for-bfrb-detection?scriptVersionId=243465321)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9274c0",
   "metadata": {
    "papermill": {
     "duration": 0.062114,
     "end_time": "2025-06-14T10:09:16.476401",
     "exception": false,
     "start_time": "2025-06-14T10:09:16.414287",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 12518947,
     "sourceId": 102335,
     "sourceType": "competition"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "CMI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 510.403331,
   "end_time": "2025-06-14T10:09:19.701325",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-06-14T10:00:49.297994",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
