{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf6438da",
   "metadata": {},
   "source": [
    "# Training & inference notebook\n",
    "Credit to [Tarun Mishra](https://www.kaggle.com/tarundirector) â€“ this code is heavily based on his [notebook](https://www.kaggle.com/code/tarundirector/sensor-pulse-viz-eda-for-bfrb-detection?scriptVersionId=243465321)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e752c660",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473b69f6",
   "metadata": {},
   "source": [
    "### imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d4b210",
   "metadata": {},
   "source": [
    "#### Training imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b842c804",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import json\n",
    "import math\n",
    "from glob import glob\n",
    "from functools import partial\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "from os.path import join, realpath\n",
    "from typing import Optional, Literal\n",
    "from itertools import pairwise, starmap\n",
    "\n",
    "import torch\n",
    "import kagglehub\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from torch import nn, Tensor\n",
    "from pandas import DataFrame as DF\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.optim import Optimizer\n",
    "# from timm.scheduler import CosineLRScheduler\n",
    "from torch.utils.data import DataLoader as DL\n",
    "from rich.progress import Progress, Task, track\n",
    "from torch.optim.lr_scheduler import ConstantLR, LRScheduler, _LRScheduler\n",
    "metric_package = kagglehub.package_import('wasupandceacar/cmi-metric', bypass_confirmation=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3ae962",
   "metadata": {},
   "source": [
    "#### inference imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "915c9ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import warnings\n",
    "from os.path import join\n",
    "from tqdm.notebook import tqdm\n",
    "from itertools import pairwise, product\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "from numpy import ndarray\n",
    "from torch import nn, Tensor\n",
    "from numpy.linalg import norm\n",
    "from pandas import DataFrame as DF\n",
    "from scipy.spatial.transform import Rotation\n",
    "# from kagglehub import competition_download, dataset_download, model_download\n",
    "import kagglehub\n",
    "metric_package = kagglehub.package_import('wasupandceacar/cmi-metric', bypass_confirmation=True)\n",
    "\n",
    "import training\n",
    "import kaggle_evaluation.cmi_inference_server"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd3c8bd",
   "metadata": {},
   "source": [
    "#### kaggle notbook Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ce2e25ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "\n",
    "def seed_everything(seed=42):\n",
    "    \"\"\"Set all random seeds for reproducibility\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'\n",
    "    torch.use_deterministic_algorithms(True, warn_only=True)\n",
    "\n",
    "SEED = 42\n",
    "seed_everything(seed=SEED)\n",
    "\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import kaggle_evaluation.cmi_inference_server\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e34cce",
   "metadata": {},
   "source": [
    "### Configs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b0b925",
   "metadata": {},
   "source": [
    "#### Training config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1296f174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "DATASET_HANDLE = \"mauroabidalcarrer/prepocessed-cmi-2025/versions/34\"\n",
    "COMPETITION_HANDLE = \"cmi-detect-behavior-with-sensor-data\"\n",
    "TARGET_NAMES = sorted([\n",
    "    \"Above ear - pull hair\",\n",
    "    \"Cheek - pinch skin\",\n",
    "    \"Eyebrow - pull hair\",\n",
    "    \"Eyelash - pull hair\",\n",
    "    \"Feel around in tray and pull out an object\",\n",
    "    \"Forehead - pull hairline\",\n",
    "    \"Forehead - scratch\",\n",
    "    \"Neck - pinch skin\",\n",
    "    \"Neck - scratch\",\n",
    "    \"Text on phone\",\n",
    "    \"Wave hello\",\n",
    "    \"Write name in air\",\n",
    "    \"Write name on leg\",\n",
    "    \"Drink from bottle/cup\",\n",
    "    \"Pinch knee/leg skin\",\n",
    "    \"Pull air toward your face\",\n",
    "    \"Scratch knee/leg skin\",\n",
    "    \"Glasses on/off\"\n",
    "])\n",
    "IMU_FEATS_PREFIXES = (\n",
    "    \"acc\",\n",
    "    \"linear_acc\",\n",
    "    \"rot\",\n",
    "    \"angular\",\n",
    "    \"euler\",\n",
    "    \"quat_rot_mag\",\n",
    "    \"delta_rot_mag\",\n",
    ")\n",
    "# Data augmentation\n",
    "JITTER = 0.25\n",
    "SCALING = 0.2\n",
    "MIXUP = 0.3\n",
    "# Training loop\n",
    "NB_CROSS_VALIDATIONS = 5\n",
    "TRAIN_BATCH_SIZE = 256\n",
    "VALIDATION_BATCH_SIZE = 4 * TRAIN_BATCH_SIZE\n",
    "PATIENCE = 8\n",
    "# Optimizer\n",
    "WEIGHT_DECAY = 3e-3\n",
    "# Scheduler\n",
    "TRAINING_EPOCHS = 25 # Including warmup epochs\n",
    "WARMUP_EPOCHS = 3\n",
    "WARMUP_LR_INIT = 1.822126131809773e-05\n",
    "MAX_TO_MIN_LR_DIV_FACTOR = 100\n",
    "LR_CYCLE_FACTOR = 0.5\n",
    "CYCLE_LENGTH_FACTOR = 0.9\n",
    "INIT_CYCLE_EPOCHS = 6\n",
    "# MIN_LR = 3.810323058740104e-09\n",
    "# MAX_LR = 1e-3\n",
    "# Mock training loop\n",
    "MOCK_TRAINING_EPOCHS = 15\n",
    "MOCK_TRAINING_GAMMA = 1.01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1393b8af",
   "metadata": {},
   "source": [
    "#### Preprocessing (for inference) config "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3ad8c78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUATERNION_COLS = ['rot_w', 'rot_x', 'rot_y', 'rot_z']\n",
    "GRAVITY_WORLD = np.array([0, 0, 9.81], \"float32\")\n",
    "RAW_ACCELRATION_COLS = [\"acc_x\", \"acc_y\", \"acc_z\"]\n",
    "LINEAR_ACC_COLS = [\"linear_\" + col for col in RAW_ACCELRATION_COLS] # Acceleration without gravity\n",
    "COMPETITION_HANDLE = \"cmi-detect-behavior-with-sensor-data\"\n",
    "CATEGORY_COLUMNS = [\n",
    "    'row_id',\n",
    "    'sequence_type',\n",
    "    'sequence_id',\n",
    "    'subject',\n",
    "    'orientation',\n",
    "    'behavior',\n",
    "    'phase',\n",
    "    'gesture',\n",
    "]\n",
    "META_DATA_COLUMNS = [\n",
    "    'row_id',\n",
    "    'sequence_type',\n",
    "    'sequence_id',\n",
    "    'sequence_counter',\n",
    "    'subject',\n",
    "    'orientation',\n",
    "    'behavior',\n",
    "    'phase',\n",
    "    'gesture',\n",
    "]\n",
    "DATASET_DF_DTYPES = {\n",
    "    \"acc_x\": \"float32\", \"acc_y\": \"float32\", \"acc_z\": \"float32\",\n",
    "    \"thm_1\":\"float32\", \"thm_2\":\"float32\", \"thm_3\":\"float32\", \"thm_4\":\"float32\", \"thm_5\":\"float32\",\n",
    "    \"sequence_counter\": \"int32\",\n",
    "    **{col: \"category\" for col in CATEGORY_COLUMNS},\n",
    "    **{f\"tof_{i_1}_v{i_2}\": \"float32\" for i_1, i_2 in product(range(1, 5), range(64))},\n",
    "}\n",
    "PREPROCESSED_DATASET_HANDLE = \"mauroabidalcarrer/prepocessed-cmi-2025\"\n",
    "# The quantile of the sequences len used to pad/truncate during preprocessing\n",
    "SEQUENCE_NORMED_LEN_QUANTILE = 0.95\n",
    "# SAMPLING_FREQUENCY = 10 #Hz\n",
    "N_FOLDS = 5\n",
    "VALIDATION_FRACTION = 0.2\n",
    "TARGET_NAMES = sorted([\n",
    "    \"Above ear - pull hair\",\n",
    "    \"Cheek - pinch skin\",\n",
    "    \"Eyebrow - pull hair\",\n",
    "    \"Eyelash - pull hair\",\n",
    "    \"Feel around in tray and pull out an object\",\n",
    "    \"Forehead - pull hairline\",\n",
    "    \"Forehead - scratch\",\n",
    "    \"Neck - pinch skin\",\n",
    "    \"Neck - scratch\",\n",
    "    \"Text on phone\",\n",
    "    \"Wave hello\",\n",
    "    \"Write name in air\",\n",
    "    \"Write name on leg\",\n",
    "    \"Drink from bottle/cup\",\n",
    "    \"Pinch knee/leg skin\",\n",
    "    \"Pull air toward your face\",\n",
    "    \"Scratch knee/leg skin\",\n",
    "    \"Glasses on/off\"\n",
    "])\n",
    "EPSILON=1e-8\n",
    "DELTA_ROTATION_ANGULAR_VELOCITY_COLS = [\"angular_vel_x\", \"angular_vel_y\", \"angular_vel_z\"]\n",
    "DELTA_ROTATION_AXES_COLS = [\"rotation_axis_x\", \"rotation_axis_y\", \"rotation_axis_z\"]\n",
    "EULER_ANGLES_COLS = [\"euler_x\", \"euler_y\", \"euler_z\"]\n",
    "TOF_AGG_FUNCS = [\n",
    "    \"mean\",\n",
    "    \"std\",\n",
    "    \"min\",\n",
    "    \"max\",\n",
    "    \"median\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4bfefa",
   "metadata": {},
   "source": [
    "### Define function to get the feature columns\n",
    "Feature columns change over time so it's better to have a function to get them than manually update a variable every time we add/remove features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f3d40b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_cols(df:DF) -> list[str]:\n",
    "    return sorted(list(set(df.columns) - set(META_DATA_COLUMNS) - set(TARGET_NAMES)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eac0e5a",
   "metadata": {},
   "source": [
    "### Supress performance warngings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "086420e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    message=(\n",
    "        \"DataFrame is highly fragmented.  This is usually the result of \"\n",
    "        \"calling `frame.insert` many times.*\"\n",
    "    ),\n",
    "    category=pd.errors.PerformanceWarning,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7749c3bd",
   "metadata": {},
   "source": [
    "### device setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "aa7f99a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a563074",
   "metadata": {},
   "source": [
    "### Dataset Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a7f347",
   "metadata": {},
   "source": [
    "#### Dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2bc2e83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CMIDataset(TensorDataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        parent_dir: str,\n",
    "        split: Optional[Literal[\"train\", \"validation\"]]=None,\n",
    "        subset: Optional[int]=None,\n",
    "        force_download=False\n",
    "    ):\n",
    "        dataset_path = kagglehub.dataset_download(DATASET_HANDLE, force_download)\n",
    "        parent_dir = join(dataset_path, \"preprocessed_dataset\", parent_dir)\n",
    "        split = \"\" if split is None else split + \"_\"\n",
    "        x = np.load(join(parent_dir, f\"{split}X.npy\")).swapaxes(1, 2)\n",
    "        y = np.load(join(parent_dir, f\"{split}Y.npy\"))\n",
    "        if subset is not None:\n",
    "            x = x[:subset]\n",
    "            y = y[:subset]\n",
    "        super().__init__(\n",
    "            torch.from_numpy(x).to(device),\n",
    "            torch.from_numpy(y).to(device),\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da7064d",
   "metadata": {},
   "source": [
    "#### Meta data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5aae295d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acc_mag', 'acc_mag_diff', 'acc_x', 'acc_x_diff', 'acc_y', 'acc_y_diff', 'acc_z', 'acc_z_diff', 'angular_vel_x', 'angular_vel_x_diff', 'angular_vel_y', 'angular_vel_y_diff', 'angular_vel_z', 'angular_vel_z_diff', 'delta_rot_mag', 'delta_rot_mag_diff', 'euler_x', 'euler_x_diff', 'euler_y', 'euler_y_diff', 'euler_z', 'euler_z_diff', 'linear_acc_mag', 'linear_acc_mag_diff', 'linear_acc_x', 'linear_acc_x_diff', 'linear_acc_y', 'linear_acc_y_diff', 'linear_acc_z', 'linear_acc_z_diff', 'quat_rot_mag', 'quat_rot_mag_diff', 'rot_w', 'rot_w_diff', 'rot_x', 'rot_x_diff', 'rot_y', 'rot_y_diff', 'rot_z', 'rot_z_diff', 'rotation_axis_x', 'rotation_axis_x_diff', 'rotation_axis_y', 'rotation_axis_y_diff', 'rotation_axis_z', 'rotation_axis_z_diff', 'thm_1', 'thm_1_diff', 'thm_2', 'thm_2_diff', 'thm_3', 'thm_3_diff', 'thm_4', 'thm_4_diff', 'thm_5', 'thm_5_diff', 'tof_1_v0', 'tof_1_v0_diff', 'tof_1_v1', 'tof_1_v10', 'tof_1_v10_diff', 'tof_1_v11', 'tof_1_v11_diff', 'tof_1_v12', 'tof_1_v12_diff', 'tof_1_v13', 'tof_1_v13_diff', 'tof_1_v14', 'tof_1_v14_diff', 'tof_1_v15', 'tof_1_v15_diff', 'tof_1_v16', 'tof_1_v16_diff', 'tof_1_v17', 'tof_1_v17_diff', 'tof_1_v18', 'tof_1_v18_diff', 'tof_1_v19', 'tof_1_v19_diff', 'tof_1_v1_diff', 'tof_1_v2', 'tof_1_v20', 'tof_1_v20_diff', 'tof_1_v21', 'tof_1_v21_diff', 'tof_1_v22', 'tof_1_v22_diff', 'tof_1_v23', 'tof_1_v23_diff', 'tof_1_v24', 'tof_1_v24_diff', 'tof_1_v25', 'tof_1_v25_diff', 'tof_1_v26', 'tof_1_v26_diff', 'tof_1_v27', 'tof_1_v27_diff', 'tof_1_v28', 'tof_1_v28_diff', 'tof_1_v29', 'tof_1_v29_diff', 'tof_1_v2_diff', 'tof_1_v3', 'tof_1_v30', 'tof_1_v30_diff', 'tof_1_v31', 'tof_1_v31_diff', 'tof_1_v32', 'tof_1_v32_diff', 'tof_1_v33', 'tof_1_v33_diff', 'tof_1_v34', 'tof_1_v34_diff', 'tof_1_v35', 'tof_1_v35_diff', 'tof_1_v36', 'tof_1_v36_diff', 'tof_1_v37', 'tof_1_v37_diff', 'tof_1_v38', 'tof_1_v38_diff', 'tof_1_v39', 'tof_1_v39_diff', 'tof_1_v3_diff', 'tof_1_v4', 'tof_1_v40', 'tof_1_v40_diff', 'tof_1_v41', 'tof_1_v41_diff', 'tof_1_v42', 'tof_1_v42_diff', 'tof_1_v43', 'tof_1_v43_diff', 'tof_1_v44', 'tof_1_v44_diff', 'tof_1_v45', 'tof_1_v45_diff', 'tof_1_v46', 'tof_1_v46_diff', 'tof_1_v47', 'tof_1_v47_diff', 'tof_1_v48', 'tof_1_v48_diff', 'tof_1_v49', 'tof_1_v49_diff', 'tof_1_v4_diff', 'tof_1_v5', 'tof_1_v50', 'tof_1_v50_diff', 'tof_1_v51', 'tof_1_v51_diff', 'tof_1_v52', 'tof_1_v52_diff', 'tof_1_v53', 'tof_1_v53_diff', 'tof_1_v54', 'tof_1_v54_diff', 'tof_1_v55', 'tof_1_v55_diff', 'tof_1_v56', 'tof_1_v56_diff', 'tof_1_v57', 'tof_1_v57_diff', 'tof_1_v58', 'tof_1_v58_diff', 'tof_1_v59', 'tof_1_v59_diff', 'tof_1_v5_diff', 'tof_1_v6', 'tof_1_v60', 'tof_1_v60_diff', 'tof_1_v61', 'tof_1_v61_diff', 'tof_1_v62', 'tof_1_v62_diff', 'tof_1_v63', 'tof_1_v63_diff', 'tof_1_v6_diff', 'tof_1_v7', 'tof_1_v7_diff', 'tof_1_v8', 'tof_1_v8_diff', 'tof_1_v9', 'tof_1_v9_diff', 'tof_2_v0', 'tof_2_v0_diff', 'tof_2_v1', 'tof_2_v10', 'tof_2_v10_diff', 'tof_2_v11', 'tof_2_v11_diff', 'tof_2_v12', 'tof_2_v12_diff', 'tof_2_v13', 'tof_2_v13_diff', 'tof_2_v14', 'tof_2_v14_diff', 'tof_2_v15', 'tof_2_v15_diff', 'tof_2_v16', 'tof_2_v16_diff', 'tof_2_v17', 'tof_2_v17_diff', 'tof_2_v18', 'tof_2_v18_diff', 'tof_2_v19', 'tof_2_v19_diff', 'tof_2_v1_diff', 'tof_2_v2', 'tof_2_v20', 'tof_2_v20_diff', 'tof_2_v21', 'tof_2_v21_diff', 'tof_2_v22', 'tof_2_v22_diff', 'tof_2_v23', 'tof_2_v23_diff', 'tof_2_v24', 'tof_2_v24_diff', 'tof_2_v25', 'tof_2_v25_diff', 'tof_2_v26', 'tof_2_v26_diff', 'tof_2_v27', 'tof_2_v27_diff', 'tof_2_v28', 'tof_2_v28_diff', 'tof_2_v29', 'tof_2_v29_diff', 'tof_2_v2_diff', 'tof_2_v3', 'tof_2_v30', 'tof_2_v30_diff', 'tof_2_v31', 'tof_2_v31_diff', 'tof_2_v32', 'tof_2_v32_diff', 'tof_2_v33', 'tof_2_v33_diff', 'tof_2_v34', 'tof_2_v34_diff', 'tof_2_v35', 'tof_2_v35_diff', 'tof_2_v36', 'tof_2_v36_diff', 'tof_2_v37', 'tof_2_v37_diff', 'tof_2_v38', 'tof_2_v38_diff', 'tof_2_v39', 'tof_2_v39_diff', 'tof_2_v3_diff', 'tof_2_v4', 'tof_2_v40', 'tof_2_v40_diff', 'tof_2_v41', 'tof_2_v41_diff', 'tof_2_v42', 'tof_2_v42_diff', 'tof_2_v43', 'tof_2_v43_diff', 'tof_2_v44', 'tof_2_v44_diff', 'tof_2_v45', 'tof_2_v45_diff', 'tof_2_v46', 'tof_2_v46_diff', 'tof_2_v47', 'tof_2_v47_diff', 'tof_2_v48', 'tof_2_v48_diff', 'tof_2_v49', 'tof_2_v49_diff', 'tof_2_v4_diff', 'tof_2_v5', 'tof_2_v50', 'tof_2_v50_diff', 'tof_2_v51', 'tof_2_v51_diff', 'tof_2_v52', 'tof_2_v52_diff', 'tof_2_v53', 'tof_2_v53_diff', 'tof_2_v54', 'tof_2_v54_diff', 'tof_2_v55', 'tof_2_v55_diff', 'tof_2_v56', 'tof_2_v56_diff', 'tof_2_v57', 'tof_2_v57_diff', 'tof_2_v58', 'tof_2_v58_diff', 'tof_2_v59', 'tof_2_v59_diff', 'tof_2_v5_diff', 'tof_2_v6', 'tof_2_v60', 'tof_2_v60_diff', 'tof_2_v61', 'tof_2_v61_diff', 'tof_2_v62', 'tof_2_v62_diff', 'tof_2_v63', 'tof_2_v63_diff', 'tof_2_v6_diff', 'tof_2_v7', 'tof_2_v7_diff', 'tof_2_v8', 'tof_2_v8_diff', 'tof_2_v9', 'tof_2_v9_diff', 'tof_3_v0', 'tof_3_v0_diff', 'tof_3_v1', 'tof_3_v10', 'tof_3_v10_diff', 'tof_3_v11', 'tof_3_v11_diff', 'tof_3_v12', 'tof_3_v12_diff', 'tof_3_v13', 'tof_3_v13_diff', 'tof_3_v14', 'tof_3_v14_diff', 'tof_3_v15', 'tof_3_v15_diff', 'tof_3_v16', 'tof_3_v16_diff', 'tof_3_v17', 'tof_3_v17_diff', 'tof_3_v18', 'tof_3_v18_diff', 'tof_3_v19', 'tof_3_v19_diff', 'tof_3_v1_diff', 'tof_3_v2', 'tof_3_v20', 'tof_3_v20_diff', 'tof_3_v21', 'tof_3_v21_diff', 'tof_3_v22', 'tof_3_v22_diff', 'tof_3_v23', 'tof_3_v23_diff', 'tof_3_v24', 'tof_3_v24_diff', 'tof_3_v25', 'tof_3_v25_diff', 'tof_3_v26', 'tof_3_v26_diff', 'tof_3_v27', 'tof_3_v27_diff', 'tof_3_v28', 'tof_3_v28_diff', 'tof_3_v29', 'tof_3_v29_diff', 'tof_3_v2_diff', 'tof_3_v3', 'tof_3_v30', 'tof_3_v30_diff', 'tof_3_v31', 'tof_3_v31_diff', 'tof_3_v32', 'tof_3_v32_diff', 'tof_3_v33', 'tof_3_v33_diff', 'tof_3_v34', 'tof_3_v34_diff', 'tof_3_v35', 'tof_3_v35_diff', 'tof_3_v36', 'tof_3_v36_diff', 'tof_3_v37', 'tof_3_v37_diff', 'tof_3_v38', 'tof_3_v38_diff', 'tof_3_v39', 'tof_3_v39_diff', 'tof_3_v3_diff', 'tof_3_v4', 'tof_3_v40', 'tof_3_v40_diff', 'tof_3_v41', 'tof_3_v41_diff', 'tof_3_v42', 'tof_3_v42_diff', 'tof_3_v43', 'tof_3_v43_diff', 'tof_3_v44', 'tof_3_v44_diff', 'tof_3_v45', 'tof_3_v45_diff', 'tof_3_v46', 'tof_3_v46_diff', 'tof_3_v47', 'tof_3_v47_diff', 'tof_3_v48', 'tof_3_v48_diff', 'tof_3_v49', 'tof_3_v49_diff', 'tof_3_v4_diff', 'tof_3_v5', 'tof_3_v50', 'tof_3_v50_diff', 'tof_3_v51', 'tof_3_v51_diff', 'tof_3_v52', 'tof_3_v52_diff', 'tof_3_v53', 'tof_3_v53_diff', 'tof_3_v54', 'tof_3_v54_diff', 'tof_3_v55', 'tof_3_v55_diff', 'tof_3_v56', 'tof_3_v56_diff', 'tof_3_v57', 'tof_3_v57_diff', 'tof_3_v58', 'tof_3_v58_diff', 'tof_3_v59', 'tof_3_v59_diff', 'tof_3_v5_diff', 'tof_3_v6', 'tof_3_v60', 'tof_3_v60_diff', 'tof_3_v61', 'tof_3_v61_diff', 'tof_3_v62', 'tof_3_v62_diff', 'tof_3_v63', 'tof_3_v63_diff', 'tof_3_v6_diff', 'tof_3_v7', 'tof_3_v7_diff', 'tof_3_v8', 'tof_3_v8_diff', 'tof_3_v9', 'tof_3_v9_diff', 'tof_4_v0', 'tof_4_v0_diff', 'tof_4_v1', 'tof_4_v10', 'tof_4_v10_diff', 'tof_4_v11', 'tof_4_v11_diff', 'tof_4_v12', 'tof_4_v12_diff', 'tof_4_v13', 'tof_4_v13_diff', 'tof_4_v14', 'tof_4_v14_diff', 'tof_4_v15', 'tof_4_v15_diff', 'tof_4_v16', 'tof_4_v16_diff', 'tof_4_v17', 'tof_4_v17_diff', 'tof_4_v18', 'tof_4_v18_diff', 'tof_4_v19', 'tof_4_v19_diff', 'tof_4_v1_diff', 'tof_4_v2', 'tof_4_v20', 'tof_4_v20_diff', 'tof_4_v21', 'tof_4_v21_diff', 'tof_4_v22', 'tof_4_v22_diff', 'tof_4_v23', 'tof_4_v23_diff', 'tof_4_v24', 'tof_4_v24_diff', 'tof_4_v25', 'tof_4_v25_diff', 'tof_4_v26', 'tof_4_v26_diff', 'tof_4_v27', 'tof_4_v27_diff', 'tof_4_v28', 'tof_4_v28_diff', 'tof_4_v29', 'tof_4_v29_diff', 'tof_4_v2_diff', 'tof_4_v3', 'tof_4_v30', 'tof_4_v30_diff', 'tof_4_v31', 'tof_4_v31_diff', 'tof_4_v32', 'tof_4_v32_diff', 'tof_4_v33', 'tof_4_v33_diff', 'tof_4_v34', 'tof_4_v34_diff', 'tof_4_v35', 'tof_4_v35_diff', 'tof_4_v36', 'tof_4_v36_diff', 'tof_4_v37', 'tof_4_v37_diff', 'tof_4_v38', 'tof_4_v38_diff', 'tof_4_v39', 'tof_4_v39_diff', 'tof_4_v3_diff', 'tof_4_v4', 'tof_4_v40', 'tof_4_v40_diff', 'tof_4_v41', 'tof_4_v41_diff', 'tof_4_v42', 'tof_4_v42_diff', 'tof_4_v43', 'tof_4_v43_diff', 'tof_4_v44', 'tof_4_v44_diff', 'tof_4_v45', 'tof_4_v45_diff', 'tof_4_v46', 'tof_4_v46_diff', 'tof_4_v47', 'tof_4_v47_diff', 'tof_4_v48', 'tof_4_v48_diff', 'tof_4_v49', 'tof_4_v49_diff', 'tof_4_v4_diff', 'tof_4_v5', 'tof_4_v50', 'tof_4_v50_diff', 'tof_4_v51', 'tof_4_v51_diff', 'tof_4_v52', 'tof_4_v52_diff', 'tof_4_v53', 'tof_4_v53_diff', 'tof_4_v54', 'tof_4_v54_diff', 'tof_4_v55', 'tof_4_v55_diff', 'tof_4_v56', 'tof_4_v56_diff', 'tof_4_v57', 'tof_4_v57_diff', 'tof_4_v58', 'tof_4_v58_diff', 'tof_4_v59', 'tof_4_v59_diff', 'tof_4_v5_diff', 'tof_4_v6', 'tof_4_v60', 'tof_4_v60_diff', 'tof_4_v61', 'tof_4_v61_diff', 'tof_4_v62', 'tof_4_v62_diff', 'tof_4_v63', 'tof_4_v63_diff', 'tof_4_v6_diff', 'tof_4_v7', 'tof_4_v7_diff', 'tof_4_v8', 'tof_4_v8_diff', 'tof_4_v9', 'tof_4_v9_diff', 'tof_5_v0', 'tof_5_v0_diff', 'tof_5_v1', 'tof_5_v10', 'tof_5_v10_diff', 'tof_5_v11', 'tof_5_v11_diff', 'tof_5_v12', 'tof_5_v12_diff', 'tof_5_v13', 'tof_5_v13_diff', 'tof_5_v14', 'tof_5_v14_diff', 'tof_5_v15', 'tof_5_v15_diff', 'tof_5_v16', 'tof_5_v16_diff', 'tof_5_v17', 'tof_5_v17_diff', 'tof_5_v18', 'tof_5_v18_diff', 'tof_5_v19', 'tof_5_v19_diff', 'tof_5_v1_diff', 'tof_5_v2', 'tof_5_v20', 'tof_5_v20_diff', 'tof_5_v21', 'tof_5_v21_diff', 'tof_5_v22', 'tof_5_v22_diff', 'tof_5_v23', 'tof_5_v23_diff', 'tof_5_v24', 'tof_5_v24_diff', 'tof_5_v25', 'tof_5_v25_diff', 'tof_5_v26', 'tof_5_v26_diff', 'tof_5_v27', 'tof_5_v27_diff', 'tof_5_v28', 'tof_5_v28_diff', 'tof_5_v29', 'tof_5_v29_diff', 'tof_5_v2_diff', 'tof_5_v3', 'tof_5_v30', 'tof_5_v30_diff', 'tof_5_v31', 'tof_5_v31_diff', 'tof_5_v32', 'tof_5_v32_diff', 'tof_5_v33', 'tof_5_v33_diff', 'tof_5_v34', 'tof_5_v34_diff', 'tof_5_v35', 'tof_5_v35_diff', 'tof_5_v36', 'tof_5_v36_diff', 'tof_5_v37', 'tof_5_v37_diff', 'tof_5_v38', 'tof_5_v38_diff', 'tof_5_v39', 'tof_5_v39_diff', 'tof_5_v3_diff', 'tof_5_v4', 'tof_5_v40', 'tof_5_v40_diff', 'tof_5_v41', 'tof_5_v41_diff', 'tof_5_v42', 'tof_5_v42_diff', 'tof_5_v43', 'tof_5_v43_diff', 'tof_5_v44', 'tof_5_v44_diff', 'tof_5_v45', 'tof_5_v45_diff', 'tof_5_v46', 'tof_5_v46_diff', 'tof_5_v47', 'tof_5_v47_diff', 'tof_5_v48', 'tof_5_v48_diff', 'tof_5_v49', 'tof_5_v49_diff', 'tof_5_v4_diff', 'tof_5_v5', 'tof_5_v50', 'tof_5_v50_diff', 'tof_5_v51', 'tof_5_v51_diff', 'tof_5_v52', 'tof_5_v52_diff', 'tof_5_v53', 'tof_5_v53_diff', 'tof_5_v54', 'tof_5_v54_diff', 'tof_5_v55', 'tof_5_v55_diff', 'tof_5_v56', 'tof_5_v56_diff', 'tof_5_v57', 'tof_5_v57_diff', 'tof_5_v58', 'tof_5_v58_diff', 'tof_5_v59', 'tof_5_v59_diff', 'tof_5_v5_diff', 'tof_5_v6', 'tof_5_v60', 'tof_5_v60_diff', 'tof_5_v61', 'tof_5_v61_diff', 'tof_5_v62', 'tof_5_v62_diff', 'tof_5_v63', 'tof_5_v63_diff', 'tof_5_v6_diff', 'tof_5_v7', 'tof_5_v7_diff', 'tof_5_v8', 'tof_5_v8_diff', 'tof_5_v9', 'tof_5_v9_diff']\n",
      "non_imu_feats_idx: [46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695]\n",
      "imu_feats_idx: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45]\n"
     ]
    }
   ],
   "source": [
    "dataset_path = kagglehub.dataset_download(DATASET_HANDLE)\n",
    "meta_data_path = join(\n",
    "    dataset_path,\n",
    "    \"preprocessed_dataset\",\n",
    "    \"full_dataset_meta_data.json\"\n",
    ")\n",
    "with open(meta_data_path, \"r\") as fp:\n",
    "    meta_data = json.load(fp)\n",
    "# Convert target names into a ndarray to index it batchwise.\n",
    "is_thm_tof_feat = lambda feat: feat.startswith((\"thm\", \"tof\"))\n",
    "non_imu_feats_idx = [feat_idx for feat_idx, feat in enumerate(meta_data[\"feature_cols\"]) if is_thm_tof_feat(feat)]\n",
    "imu_feats_idx = [feat_idx for feat_idx, feat in enumerate(meta_data[\"feature_cols\"]) if not is_thm_tof_feat(feat)]\n",
    "print(meta_data[\"feature_cols\"])\n",
    "print(\"non_imu_feats_idx:\", non_imu_feats_idx)\n",
    "print(\"imu_feats_idx:\", imu_feats_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc6fe74",
   "metadata": {},
   "source": [
    "#### Compute class weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "74233c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_weighted_cross_entropy_loss(\n",
    "    dataset: Dataset[tuple[torch.Tensor, torch.Tensor]]\n",
    ") -> nn.CrossEntropyLoss:\n",
    "    \"\"\"\n",
    "    Computes class weights from a dataset with one-hot encoded targets and returns a CrossEntropyLoss with those weights.\n",
    "\n",
    "    Args:\n",
    "        dataset: A PyTorch Dataset that yields (x, y) where y is a one-hot encoded tensor of shape (num_classes,)\n",
    "\n",
    "    Returns:\n",
    "        A torch.nn.CrossEntropyLoss object with class weights based on inverse class frequency.\n",
    "    \"\"\"\n",
    "    class_counts: Counter = Counter()\n",
    "    num_samples = 0\n",
    "\n",
    "    for _, y in dataset:\n",
    "        class_idx = y.argmax().item()\n",
    "        class_counts[class_idx] += 1\n",
    "        num_samples += 1\n",
    "\n",
    "    num_classes = len(class_counts)\n",
    "    weights = torch.tensor(\n",
    "        [num_samples / class_counts[i] for i in range(num_classes)],\n",
    "        dtype=torch.float32,\n",
    "    )\n",
    "\n",
    "    # Optional: normalize weights so they sum to 1\n",
    "    weights = weights / weights.sum()\n",
    "\n",
    "    return nn.CrossEntropyLoss(weight=weights.to(device))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2161df0c",
   "metadata": {
    "papermill": {
     "duration": 0.00278,
     "end_time": "2025-06-14T10:01:12.877551",
     "exception": false,
     "start_time": "2025-06-14T10:01:12.874771",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### BFRBs indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e657c570",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T10:01:12.884365Z",
     "iopub.status.busy": "2025-06-14T10:01:12.883937Z",
     "iopub.status.idle": "2025-06-14T10:01:45.309186Z",
     "shell.execute_reply": "2025-06-14T10:01:45.308564Z"
    },
    "papermill": {
     "duration": 32.430139,
     "end_time": "2025-06-14T10:01:45.310511",
     "exception": false,
     "start_time": "2025-06-14T10:01:12.880372",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets...\n",
      "Train rows: 574945, Test rows: 107\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading datasets...\")\n",
    "competition_dataset_path = kagglehub.competition_download(COMPETITION_HANDLE)\n",
    "train_df = pd.read_csv(join(competition_dataset_path, \"train.csv\"))\n",
    "train_dem_df = pd.read_csv(join(competition_dataset_path, \"train_demographics.csv\"))\n",
    "test_df = pd.read_csv(join(competition_dataset_path, \"test.csv\"))\n",
    "test_dem_df = pd.read_csv(join(competition_dataset_path, \"test_demographics.csv\"))\n",
    "print(f\"Train rows: {len(train_df)}, Test rows: {len(test_df)}\")\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "train_df['gesture'] = label_encoder.fit_transform(train_df['gesture'].astype(str))\n",
    "gesture_classes = label_encoder.classes_\n",
    "\n",
    "bfrb_gestures = [\n",
    "    'Above ear - pull hair',\n",
    "    'Forehead - pull hairline',\n",
    "    'Forehead - scratch',\n",
    "    'Eyebrow - pull hair',\n",
    "    'Eyelash - pull hair',\n",
    "    'Neck - pinch skin',\n",
    "    'Neck - scratch',\n",
    "    'Cheek - pinch skin'\n",
    "]\n",
    "bfrb_indices = label_encoder.transform(bfrb_gestures)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de16cc1",
   "metadata": {},
   "source": [
    "### Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d3d46b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CosineAnnealingWarmupRestarts(_LRScheduler):\n",
    "    def __init__(\n",
    "        self,\n",
    "        optimizer: Optimizer,\n",
    "        warmup_steps: int,\n",
    "        max_lr: float,\n",
    "        min_lr: float,\n",
    "        cycle_length: int,\n",
    "        cycle_mult: float = 1.0,\n",
    "        gamma: float = 1.0,\n",
    "        last_epoch: int = -1,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            optimizer: Wrapped optimizer.\n",
    "            warmup_steps: Number of steps for linear warmup.\n",
    "            max_lr: Initial maximum learning rate.\n",
    "            min_lr: Minimum learning rate after decay.\n",
    "            cycle_length: Initial number of steps per cosine cycle.\n",
    "            cycle_mult: Multiplicative factor for increasing cycle lengths.\n",
    "            gamma: Multiplicative decay factor for max_lr after each cycle.\n",
    "            last_epoch: The index of last epoch. Default: -1.\n",
    "        \"\"\"\n",
    "        self.warmup_steps = warmup_steps\n",
    "        self.max_lr = max_lr\n",
    "        self.min_lr = min_lr\n",
    "        self.cycle_length = cycle_length\n",
    "        self.cycle_mult = cycle_mult\n",
    "        self.gamma = gamma\n",
    "\n",
    "        self.current_cycle = 0\n",
    "        self.cycle_step = 0\n",
    "        self.lr = max_lr\n",
    "\n",
    "        super().__init__(optimizer, last_epoch)\n",
    "\n",
    "    def get_lr(self) -> list[float]:\n",
    "        if self.last_epoch < self.warmup_steps:\n",
    "            # Linear warmup\n",
    "            scale = (self.last_epoch + 1) / self.warmup_steps\n",
    "            return [self.min_lr + scale * (self.max_lr - self.min_lr) for _ in self.base_lrs]\n",
    "\n",
    "        # Adjust for post-warmup step index\n",
    "        t = self.cycle_step\n",
    "        T = self.cycle_length\n",
    "\n",
    "        cosine_decay = 0.5 * (1 + math.cos(math.pi * t / T))\n",
    "        lr = self.min_lr + (self.max_lr - self.min_lr) * cosine_decay\n",
    "\n",
    "        return [lr for _ in self.base_lrs]\n",
    "\n",
    "    def step(self, epoch: Optional[int] = None) -> None:\n",
    "        if self.last_epoch >= self.warmup_steps:\n",
    "            self.cycle_step += 1\n",
    "            if self.cycle_step >= self.cycle_length:\n",
    "                self.current_cycle += 1\n",
    "                self.cycle_step = 0\n",
    "                self.cycle_length = max(int(self.cycle_length * self.cycle_mult), 1)\n",
    "                self.max_lr *= self.gamma\n",
    "        super().step(epoch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c54244a",
   "metadata": {},
   "source": [
    "## Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "80ae01a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiScaleConvs(nn.Module):\n",
    "    def __init__(self, in_channels:int, kernel_sizes:list[int]):\n",
    "        super().__init__()\n",
    "        def mk_conv_block(k_size) -> nn.Sequential:\n",
    "            return nn.Sequential(\n",
    "                nn.Conv1d(in_channels, in_channels, k_size, padding=k_size // 2, groups=in_channels),\n",
    "                nn.BatchNorm1d(in_channels),\n",
    "                nn.ReLU(),\n",
    "            )\n",
    "        self.convs = nn.ModuleList(map(mk_conv_block, kernel_sizes))\n",
    "\n",
    "    def forward(self, x:Tensor) -> Tensor:\n",
    "        yes = torch.cat([conv(x) for conv in self.convs] + [x], dim=1)\n",
    "        # print(\"stem output shape:\", yes.shape)\n",
    "        return yes\n",
    "\n",
    "class ImuFeatureExtractor(nn.Module):\n",
    "    def __init__(self, in_channels:int, kernel_size:int=15):\n",
    "        super().__init__()\n",
    "\n",
    "        self.lpf = nn.Conv1d(\n",
    "            in_channels,\n",
    "            in_channels,\n",
    "            kernel_size=kernel_size,\n",
    "            padding=kernel_size//2,\n",
    "            groups=in_channels,\n",
    "            bias=False,\n",
    "        )\n",
    "        nn.init.kaiming_uniform_(self.lpf.weight, a=math.sqrt(5))\n",
    "\n",
    "    def forward(self, x:Tensor) -> Tensor:\n",
    "        lpf_output = self.lpf(x)\n",
    "        hpf_output = x - lpf_output\n",
    "        return torch.cat((lpf_output, hpf_output, x), dim=1)  # (B, C_out, T)\n",
    "\n",
    "class SqueezeExcitationBlock(nn.Module):\n",
    "    # Copy/paste of https://www.kaggle.com/code/wasupandceacar/lb-0-82-5fold-single-bert-model#Model implementation\n",
    "    def __init__(self, channels:int, reduction:int=8):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(channels, channels // reduction, bias=True)\n",
    "        self.fc2 = nn.Linear(channels // reduction, channels, bias=True)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, C, L)\n",
    "        se = F.adaptive_avg_pool1d(x, 1).squeeze(-1)      # -> (B, C)\n",
    "        se = F.relu(self.fc1(se), inplace=True)          # -> (B, C//r)\n",
    "        se = self.sigmoid(self.fc2(se)).unsqueeze(-1)    # -> (B, C, 1)\n",
    "        return x * se\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_chns:int, out_chns:int, dropout_ratio:float=0.3, se_reduction:int=8, kernel_size:int=3):\n",
    "        super().__init__()\n",
    "        self.blocks = nn.Sequential(\n",
    "            nn.Conv1d(in_chns, out_chns, kernel_size=kernel_size, padding=kernel_size // 2, bias=False),\n",
    "            nn.BatchNorm1d(out_chns),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(out_chns, out_chns, kernel_size=kernel_size, padding=kernel_size // 2, bias=False),\n",
    "            nn.BatchNorm1d(out_chns),\n",
    "            SqueezeExcitationBlock(out_chns, se_reduction),\n",
    "        )\n",
    "        self.head = nn.Sequential(nn.ReLU(), nn.Dropout(dropout_ratio))\n",
    "        if in_chns == out_chns:\n",
    "            self.skip_connection = nn.Identity() \n",
    "        else:\n",
    "            # TODO: set bias to False ?\n",
    "            self.skip_connection = nn.Sequential(\n",
    "                nn.Conv1d(in_chns, out_chns, 1, bias=False),\n",
    "                nn.BatchNorm1d(out_chns)\n",
    "            )\n",
    "            self.head.insert(1, nn.MaxPool1d(2))\n",
    "\n",
    "    def forward(self, x:Tensor) -> Tensor:\n",
    "        activaition_maps = self.skip_connection(x) + self.blocks(x)\n",
    "        return self.head(activaition_maps)\n",
    "\n",
    "class MBConvBlock(nn.Module):\n",
    "    # From this schema: https://media.licdn.com/dms/image/v2/D5612AQFjbDOm5uyxdw/article-inline_image-shrink_1500_2232/article-inline_image-shrink_1500_2232/0/1683677500817?e=1758153600&v=beta&t=n48_UW5TZTyDPhRFlJXSidUQQPQpuC756M0kNeKmYTY\n",
    "    def __init__(self, in_chns:int, out_chns:int, se_reduction:int=8, expansion_ratio:int=4, dropout_ratio:float=0.3):\n",
    "        super().__init__()\n",
    "        expanded_channels = in_chns * expansion_ratio\n",
    "        self.blocks = nn.Sequential(\n",
    "            nn.Conv1d(in_chns, expanded_channels, kernel_size=1, bias=False),\n",
    "            nn.BatchNorm1d(expanded_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(\n",
    "                expanded_channels,\n",
    "                expanded_channels,\n",
    "                kernel_size=3,\n",
    "                padding=1,\n",
    "                groups=expanded_channels,\n",
    "                bias=False,\n",
    "            ),\n",
    "            nn.BatchNorm1d(expanded_channels),\n",
    "            nn.ReLU(),\n",
    "            SqueezeExcitationBlock(expanded_channels, se_reduction),\n",
    "            nn.Conv1d(expanded_channels, out_chns, kernel_size=1, bias=False)\n",
    "        )\n",
    "        self.head = nn.Sequential(\n",
    "            nn.BatchNorm1d(out_chns)\n",
    "            # nn.ReLU(),\n",
    "            # nn.Dropout(dropout_ratio),\n",
    "        )\n",
    "        if in_chns == out_chns:\n",
    "            self.skip_connection = nn.Identity() \n",
    "        else:\n",
    "            # TODO: set bias to False ?\n",
    "            self.skip_connection = nn.Sequential(\n",
    "                nn.Conv1d(in_chns, out_chns, 1, bias=False),\n",
    "                nn.BatchNorm1d(out_chns)\n",
    "            )\n",
    "            self.head.add_module(\"max_pool\", nn.MaxPool1d(2))\n",
    "            \n",
    "    def forward(self, x:Tensor) -> Tensor:\n",
    "        activaition_maps = self.skip_connection(x) + self.blocks(x)\n",
    "        return self.head(activaition_maps)\n",
    "\n",
    "class AdditiveAttentionLayer(nn.Module):\n",
    "    # Copied (and slightly modified) from https://www.kaggle.com/code/myso1987/cmi3-pyroch-baseline-model-add-aug-folds\n",
    "    def __init__(self, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.attention = nn.Linear(hidden_dim, 1, bias=True)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        # x shape: (batch, channels, seq_len)\n",
    "        x = x.swapaxes(1, 2)\n",
    "        # x shape: (batch, seq_len, hidden_dim)\n",
    "        scores = torch.tanh(self.attention(x))  # (batch, seq_len, 1)\n",
    "        weights = F.softmax(scores.squeeze(-1), dim=1)  # (batch, seq_len)\n",
    "        context = torch.sum(x * weights.unsqueeze(-1), dim=1)  # (batch, hidden_dim)\n",
    "        return context\n",
    "\n",
    "class CMIHARModule(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            imu_idx:list[int],\n",
    "            tof_thm_idx:list[int],\n",
    "            mlp_width:int,\n",
    "            n_class:int,            \n",
    "            tof_thm_dropout_ratio:float=0,\n",
    "        ):\n",
    "        super().__init__()\n",
    "        self.imu_idx = imu_idx\n",
    "        self.tof_thm_idx = tof_thm_idx\n",
    "        self.imu_branch = nn.Sequential(\n",
    "            ImuFeatureExtractor(len(imu_idx)),\n",
    "            ResidualBlock(len(imu_idx) * 3, 64),\n",
    "            ResidualBlock(64, 128),\n",
    "        )\n",
    "        self.tof_and_thm_branch = nn.Sequential(\n",
    "            nn.Conv1d(len(tof_thm_idx), 64, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.MaxPool1d(2),\n",
    "            nn.Dropout(tof_thm_dropout_ratio),\n",
    "            nn.Conv1d(64, 128, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.MaxPool1d(2),\n",
    "            nn.Dropout(tof_thm_dropout_ratio),\n",
    "        )\n",
    "        self.lstm = nn.GRU(128 * 2, mlp_width // 2, bidirectional=True)\n",
    "        self.attention = AdditiveAttentionLayer(mlp_width)\n",
    "        self.head = nn.Sequential(\n",
    "            # Head\n",
    "            nn.LazyLinear(mlp_width, bias=False),\n",
    "            nn.BatchNorm1d(mlp_width),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(mlp_width, mlp_width // 2, bias=False),\n",
    "            nn.BatchNorm1d(mlp_width // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(mlp_width // 2, n_class),\n",
    "        )\n",
    "\n",
    "    def forward(self, x:Tensor) -> Tensor:\n",
    "        imu_activation_maps = self.imu_branch(x[:, self.imu_idx])\n",
    "        tof_thm_activation_maps = self.tof_and_thm_branch(x[:, self.tof_thm_idx])\n",
    "        concatenated_activation_maps = torch.cat((imu_activation_maps, tof_thm_activation_maps), 1)\n",
    "        lstm_output, _  = self.lstm(concatenated_activation_maps.swapaxes(1, 2))\n",
    "        lstm_output = lstm_output.swapaxes(1, 2) # redundant\n",
    "        attended = self.attention(lstm_output)\n",
    "        return self.head(attended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b1c8de6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(imu_feats_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc08e41",
   "metadata": {},
   "source": [
    "### Create model function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "36e3e463",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CMIHARModule(\n",
       "  (imu_branch): Sequential(\n",
       "    (0): ImuFeatureExtractor(\n",
       "      (lpf): Conv1d(46, 46, kernel_size=(15,), stride=(1,), padding=(7,), groups=46, bias=False)\n",
       "    )\n",
       "    (1): ResidualBlock(\n",
       "      (blocks): Sequential(\n",
       "        (0): Conv1d(138, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "        (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): SqueezeExcitationBlock(\n",
       "          (fc1): Linear(in_features=64, out_features=8, bias=True)\n",
       "          (fc2): Linear(in_features=8, out_features=64, bias=True)\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (head): Sequential(\n",
       "        (0): ReLU()\n",
       "        (1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (2): Dropout(p=0.3, inplace=False)\n",
       "      )\n",
       "      (skip_connection): Sequential(\n",
       "        (0): Conv1d(138, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (2): ResidualBlock(\n",
       "      (blocks): Sequential(\n",
       "        (0): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "        (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): SqueezeExcitationBlock(\n",
       "          (fc1): Linear(in_features=128, out_features=16, bias=True)\n",
       "          (fc2): Linear(in_features=16, out_features=128, bias=True)\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (head): Sequential(\n",
       "        (0): ReLU()\n",
       "        (1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (2): Dropout(p=0.3, inplace=False)\n",
       "      )\n",
       "      (skip_connection): Sequential(\n",
       "        (0): Conv1d(64, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (tof_and_thm_branch): Sequential(\n",
       "    (0): Conv1d(650, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Dropout(p=0, inplace=False)\n",
       "    (4): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "    (5): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (7): Dropout(p=0, inplace=False)\n",
       "  )\n",
       "  (lstm): GRU(256, 128, bidirectional=True)\n",
       "  (attention): AdditiveAttentionLayer(\n",
       "    (attention): Linear(in_features=256, out_features=1, bias=True)\n",
       "  )\n",
       "  (head): Sequential(\n",
       "    (0): LazyLinear(in_features=0, out_features=256, bias=False)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=128, bias=False)\n",
       "    (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=128, out_features=18, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input channels: 696\n"
     ]
    }
   ],
   "source": [
    "def mk_model() -> nn.Module:\n",
    "    return (\n",
    "        CMIHARModule(\n",
    "            imu_idx=imu_feats_idx,\n",
    "            tof_thm_idx=non_imu_feats_idx,\n",
    "            mlp_width=256,\n",
    "            n_class=18,\n",
    "        )\n",
    "        .to(device)\n",
    "    )\n",
    "\n",
    "display(mk_model())\n",
    "print(\"input channels:\", len(meta_data[\"feature_cols\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8afc6e79",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a69ec966",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(epochs:int,\n",
    "        model: nn.Module,\n",
    "        scheduler: LRScheduler,\n",
    "        optimizer: torch.optim.Optimizer,\n",
    "        train_loader: DL,\n",
    "        criterion: callable=nn.L1Loss(),\n",
    "        evaluation_func: callable=None,\n",
    "        validation_loader: DL=None,\n",
    "        save_checkpoints=True,\n",
    "    ) -> tuple[DF, str]:\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "        (training_metrics, path_to_checkpoints)\n",
    "    \"\"\"\n",
    "    # Setup\n",
    "    metrics: list[dict] = []\n",
    "    step = 0\n",
    "    model_device = next(model.parameters()).device\n",
    "    last_epoch_metric = {}\n",
    "    # Training loop\n",
    "    with Progress() as progress:\n",
    "        task: Task = progress.add_task(\n",
    "            \"training...\",\n",
    "            total=len(train_loader),\n",
    "        )\n",
    "        for epoch in range(epochs):\n",
    "            progress.update(\n",
    "                task,\n",
    "                description=f\"epoch: {epoch}\",\n",
    "                completed=0,\n",
    "            )\n",
    "            total_epoch_loss = 0\n",
    "            total_accuracy = 0\n",
    "            for batch_idx, (x, y) in enumerate(train_loader):\n",
    "                # forward\n",
    "                x = x.to(model_device)\n",
    "                y = y.to(model_device)\n",
    "                model.train()\n",
    "                optimizer.zero_grad()\n",
    "                y_pred: Tensor = model(x)\n",
    "                loss_value = criterion(y_pred, y)\n",
    "                # Verify loss value\n",
    "                if torch.isnan(loss_value).any().item():\n",
    "                    progress.print(\"Warning: Got NaN loss, stopped training.\")\n",
    "                    return DF.from_records(metrics)\n",
    "                if torch.isinf(loss_value).any().item():\n",
    "                    progress.print(\"Warning: Got infinite loss, stopped training.\")\n",
    "                    return DF.from_records(metrics)\n",
    "                # TODO: Use gradient clipping?\n",
    "                loss_value.backward()\n",
    "                optimizer.step()\n",
    "                if step > 0: # If it's not the first training step, idk why it throws an error otherwise\n",
    "                    scheduler.step()\n",
    "                # metrics\n",
    "                total_epoch_loss += loss_value.item()\n",
    "                metrics.append({\n",
    "                    \"step\": step,\n",
    "                    \"epoch\": epoch,\n",
    "                    \"batch_train_loss\": loss_value.item(),\n",
    "                    \"lr\": optimizer.state_dict()[\"param_groups\"][-1][\"lr\"],\n",
    "                })\n",
    "                step += 1\n",
    "                if \"validation_accuracy\" in last_epoch_metric:\n",
    "                    last_validation_acc = \"%.2f\" % last_epoch_metric[\"validation_accuracy\"]\n",
    "                    val_acc_str = \"val. acc: \" + last_validation_acc\n",
    "                else:\n",
    "                    val_acc_str = \"\"\n",
    "                progress.update(\n",
    "                    task,\n",
    "                    advance=1,\n",
    "                    description=f\"epoch: {epoch}, batch_loss: {(total_epoch_loss / (batch_idx+1)):.2f}, {val_acc_str}\"\n",
    "                )\n",
    "            # Post epoch evalution\n",
    "            metrics[-1][\"train_epoch_loss\"] = total_epoch_loss / len(train_loader)\n",
    "            metrics[-1][\"train_epoch_accuracy\"] = total_accuracy / len(train_loader)\n",
    "            if evaluation_func:\n",
    "                progress.update(\n",
    "                    task,\n",
    "                    completed=0,\n",
    "                    description=f\"epoch: {epoch}, evaluating...\"\n",
    "                )\n",
    "                eval_metrics = evaluation_func(model, criterion, validation_loader)\n",
    "                metrics[-1].update(eval_metrics)\n",
    "            last_epoch_metric = metrics[-1]\n",
    "\n",
    "    return DF.from_records(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a490227",
   "metadata": {},
   "source": [
    "### Create model and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "34cd5bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mk_model_and_fit(\n",
    "        train_loader:DL,\n",
    "        mk_scheduler:callable,\n",
    "        epochs:int,\n",
    "        validation_loader:Optional[DL]=None,\n",
    "        save_checkpoints=False,\n",
    "        criterion=nn.CrossEntropyLoss()\n",
    "    ) -> tuple[nn.Module, DF, list[str]]:\n",
    "    model = mk_model()\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), WARMUP_LR_INIT)\n",
    "    lr_scheduler = mk_scheduler(optimizer)\n",
    "    training_metrics = fit(\n",
    "        epochs=epochs,\n",
    "        model=model,\n",
    "        scheduler=lr_scheduler,\n",
    "        optimizer=optimizer,\n",
    "        train_loader=train_loader,\n",
    "        criterion=criterion,\n",
    "        # evaluation_func=evaluate_model if validation_loader else None,\n",
    "        validation_loader=validation_loader,\n",
    "        save_checkpoints=save_checkpoints,\n",
    "    )\n",
    "\n",
    "    return model, training_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60b2c5d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9256152c",
   "metadata": {},
   "source": [
    "## Search max learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "40b0c8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_process_mock_training_metrics(training_metrics:DF) -> DF:\n",
    "    training_metrics = (\n",
    "        training_metrics\n",
    "        .query(\"batch_train_loss.notna()\")\n",
    "        .set_index(\"lr\", drop=False)\n",
    "        .sort_index()\n",
    "    )\n",
    "    training_metrics[\"ewm_batch_train_loss\"] = (\n",
    "        training_metrics\n",
    "        .ewm(com=30, ignore_na=False)\n",
    "        [\"batch_train_loss\"]\n",
    "        .mean()\n",
    "    )\n",
    "    training_metrics[\"ewm_batch_train_loss_diff\"] = training_metrics[\"ewm_batch_train_loss\"].diff()\n",
    "    return training_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7c231028",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plt_lr_search_training_metrics(training_metrics:DF):\n",
    "    (    \n",
    "        px.line(\n",
    "            (\n",
    "                training_metrics\n",
    "                .reset_index(drop=True)\n",
    "                .melt(\n",
    "                    id_vars=\"lr\",\n",
    "                    value_vars=[\n",
    "                        \"batch_train_loss\",\n",
    "                        \"ewm_batch_train_loss\",\n",
    "                        # \"ewm_batch_train_loss_diff\",\n",
    "                    ],\n",
    "                )\n",
    "            ),\n",
    "            x=\"lr\",\n",
    "            facet_row=\"variable\",\n",
    "            y=\"value\",\n",
    "            log_x=True,\n",
    "            log_y=True,\n",
    "            height=750,\n",
    "        )\n",
    "        .update_yaxes(matches=None)\n",
    "        .show()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e9ae0c04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d322b8ecf74a4559a8cfca8578b6a6c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "variable=batch_train_loss<br>lr=%{x}<br>value=%{y}<extra></extra>",
         "legendgroup": "",
         "line": {
          "color": "#636efa",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "",
         "orientation": "v",
         "showlegend": false,
         "type": "scatter",
         "x": {
          "bdata": "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",
          "dtype": "f8"
         },
         "xaxis": "x2",
         "y": {
          "bdata": "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",
          "dtype": "f8"
         },
         "yaxis": "y2"
        },
        {
         "hovertemplate": "variable=ewm_batch_train_loss<br>lr=%{x}<br>value=%{y}<extra></extra>",
         "legendgroup": "",
         "line": {
          "color": "#636efa",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "",
         "orientation": "v",
         "showlegend": false,
         "type": "scatter",
         "x": {
          "bdata": "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",
          "dtype": "f8"
         },
         "xaxis": "x",
         "y": {
          "bdata": "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",
          "dtype": "f8"
         },
         "yaxis": "y"
        }
       ],
       "layout": {
        "annotations": [
         {
          "font": {},
          "showarrow": false,
          "text": "variable=ewm_batch_train_loss",
          "textangle": 90,
          "x": 0.98,
          "xanchor": "left",
          "xref": "paper",
          "y": 0.2425,
          "yanchor": "middle",
          "yref": "paper"
         },
         {
          "font": {},
          "showarrow": false,
          "text": "variable=batch_train_loss",
          "textangle": 90,
          "x": 0.98,
          "xanchor": "left",
          "xref": "paper",
          "y": 0.7575000000000001,
          "yanchor": "middle",
          "yref": "paper"
         }
        ],
        "height": 750,
        "legend": {
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          0.98
         ],
         "title": {
          "text": "lr"
         },
         "type": "log"
        },
        "xaxis2": {
         "anchor": "y2",
         "domain": [
          0,
          0.98
         ],
         "matches": "x",
         "showticklabels": false,
         "type": "log"
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          0.485
         ],
         "title": {
          "text": "value"
         },
         "type": "log"
        },
        "yaxis2": {
         "anchor": "x2",
         "domain": [
          0.515,
          1
         ],
         "title": {
          "text": "value"
         },
         "type": "log"
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum learning rate: 0.002056984330154654\n"
     ]
    }
   ],
   "source": [
    "train_dataset = CMIDataset(\"full_dataset\")\n",
    "full_dataset_loader = DL(train_dataset, TRAIN_BATCH_SIZE, shuffle=True)\n",
    "_, mock_training_metrics = mk_model_and_fit(\n",
    "    full_dataset_loader,\n",
    "    partial(torch.optim.lr_scheduler.ExponentialLR, gamma=MOCK_TRAINING_GAMMA),\n",
    "    MOCK_TRAINING_EPOCHS,\n",
    "    criterion= nn.CrossEntropyLoss(label_smoothing=0.1),\n",
    ")\n",
    "mock_training_metrics = post_process_mock_training_metrics(mock_training_metrics)\n",
    "plt_lr_search_training_metrics(mock_training_metrics)\n",
    "max_lr = mock_training_metrics[\"ewm_batch_train_loss\"].idxmin()\n",
    "print(\"Maximum learning rate:\", max_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1cc3c5f",
   "metadata": {
    "papermill": {
     "duration": 0.003108,
     "end_time": "2025-06-14T10:01:56.186803",
     "exception": false,
     "start_time": "2025-06-14T10:01:56.183695",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "81f397f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixup_data(x, y, alpha=0.2):\n",
    "    \"\"\"\n",
    "    Return mixed inputs and mixed targets (one-hot) for mixup.\n",
    "    x: Tensor of shape (batch_size, features, seq_len)\n",
    "    y: Tensor of shape (batch_size, num_classes)\n",
    "    \"\"\"\n",
    "    if alpha > 0:\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "    else:\n",
    "        lam = 1.0\n",
    "    batch_size = x.size(0)\n",
    "    index = torch.randperm(batch_size).to(x.device)\n",
    "\n",
    "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "    mixed_y = lam * y + (1 - lam) * y[index, :]\n",
    "    return mixed_x, mixed_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be28a9c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T10:01:56.194003Z",
     "iopub.status.busy": "2025-06-14T10:01:56.193740Z",
     "iopub.status.idle": "2025-06-14T10:09:14.752385Z",
     "shell.execute_reply": "2025-06-14T10:09:14.751491Z"
    },
    "papermill": {
     "duration": 438.563878,
     "end_time": "2025-06-14T10:09:14.753712",
     "exception": false,
     "start_time": "2025-06-14T10:01:56.189834",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training: 1\n",
      "\n",
      "==================================================\n",
      "Fold 1/5\n",
      "Epoch 01: Binary F1 = 0.8023, Macro F1 = 0.2454, Final Metric = 0.5239\n",
      "  New best metric! Saving model...\n",
      "Epoch 02: Binary F1 = 0.9262, Macro F1 = 0.3530, Final Metric = 0.6396\n",
      "  New best metric! Saving model...\n",
      "Epoch 03: Binary F1 = 0.9594, Macro F1 = 0.4270, Final Metric = 0.6932\n",
      "  New best metric! Saving model...\n",
      "Epoch 04: Binary F1 = 0.9328, Macro F1 = 0.4936, Final Metric = 0.7132\n",
      "  New best metric! Saving model...\n",
      "Epoch 05: Binary F1 = 0.9680, Macro F1 = 0.5231, Final Metric = 0.7456\n",
      "  New best metric! Saving model...\n",
      "Epoch 06: Binary F1 = 0.9720, Macro F1 = 0.5569, Final Metric = 0.7645\n",
      "  New best metric! Saving model...\n",
      "Epoch 07: Binary F1 = 0.9711, Macro F1 = 0.5365, Final Metric = 0.7538\n",
      "Epoch 08: Binary F1 = 0.9711, Macro F1 = 0.5711, Final Metric = 0.7711\n",
      "  New best metric! Saving model...\n",
      "Epoch 09: Binary F1 = 0.9734, Macro F1 = 0.5808, Final Metric = 0.7771\n",
      "  New best metric! Saving model...\n",
      "Epoch 10: Binary F1 = 0.9750, Macro F1 = 0.5592, Final Metric = 0.7671\n",
      "Epoch 11: Binary F1 = 0.9653, Macro F1 = 0.5732, Final Metric = 0.7692\n",
      "Epoch 12: Binary F1 = 0.9765, Macro F1 = 0.5704, Final Metric = 0.7735\n",
      "Epoch 13: Binary F1 = 0.9829, Macro F1 = 0.5677, Final Metric = 0.7753\n",
      "Epoch 14: Binary F1 = 0.9783, Macro F1 = 0.5979, Final Metric = 0.7881\n",
      "  New best metric! Saving model...\n",
      "Epoch 15: Binary F1 = 0.9799, Macro F1 = 0.5707, Final Metric = 0.7753\n",
      "Epoch 16: Binary F1 = 0.9782, Macro F1 = 0.5778, Final Metric = 0.7780\n",
      "Epoch 17: Binary F1 = 0.9814, Macro F1 = 0.5893, Final Metric = 0.7853\n",
      "Epoch 18: Binary F1 = 0.9798, Macro F1 = 0.5915, Final Metric = 0.7856\n",
      "Epoch 19: Binary F1 = 0.9814, Macro F1 = 0.5929, Final Metric = 0.7871\n",
      "Epoch 20: Binary F1 = 0.9806, Macro F1 = 0.5987, Final Metric = 0.7896\n",
      "  New best metric! Saving model...\n",
      "Epoch 21: Binary F1 = 0.9806, Macro F1 = 0.5882, Final Metric = 0.7844\n",
      "Epoch 22: Binary F1 = 0.9790, Macro F1 = 0.5991, Final Metric = 0.7890\n",
      "Epoch 23: Binary F1 = 0.9798, Macro F1 = 0.5912, Final Metric = 0.7855\n",
      "Epoch 24: Binary F1 = 0.9821, Macro F1 = 0.5976, Final Metric = 0.7899\n",
      "  New best metric! Saving model...\n",
      "Epoch 25: Binary F1 = 0.9790, Macro F1 = 0.5873, Final Metric = 0.7832\n",
      "\n",
      "Fold 1 completed.\n",
      "Final validation metrics - Binary F1: 0.9790, Macro F1: 0.5873, Final: 0.7832\n",
      "Best validation metrics - Binary F1: 0.9821, Macro F1: 0.5976, Final: 0.7899\n",
      "training: 2\n",
      "\n",
      "==================================================\n",
      "Fold 2/5\n",
      "Epoch 01: Binary F1 = 0.7626, Macro F1 = 0.2320, Final Metric = 0.4973\n",
      "  New best metric! Saving model...\n",
      "Epoch 02: Binary F1 = 0.8753, Macro F1 = 0.3086, Final Metric = 0.5919\n",
      "  New best metric! Saving model...\n",
      "Epoch 03: Binary F1 = 0.8941, Macro F1 = 0.3896, Final Metric = 0.6419\n",
      "  New best metric! Saving model...\n",
      "Epoch 04: Binary F1 = 0.8871, Macro F1 = 0.4346, Final Metric = 0.6608\n",
      "  New best metric! Saving model...\n",
      "Epoch 05: Binary F1 = 0.9376, Macro F1 = 0.4637, Final Metric = 0.7007\n",
      "  New best metric! Saving model...\n",
      "Epoch 06: Binary F1 = 0.9230, Macro F1 = 0.4480, Final Metric = 0.6855\n",
      "Epoch 07: Binary F1 = 0.9331, Macro F1 = 0.4919, Final Metric = 0.7125\n",
      "  New best metric! Saving model...\n",
      "Epoch 08: Binary F1 = 0.9449, Macro F1 = 0.5067, Final Metric = 0.7258\n",
      "  New best metric! Saving model...\n",
      "Epoch 09: Binary F1 = 0.9393, Macro F1 = 0.5061, Final Metric = 0.7227\n",
      "Epoch 10: Binary F1 = 0.9195, Macro F1 = 0.4659, Final Metric = 0.6927\n",
      "Epoch 11: Binary F1 = 0.9292, Macro F1 = 0.4806, Final Metric = 0.7049\n",
      "Epoch 12: Binary F1 = 0.9348, Macro F1 = 0.5154, Final Metric = 0.7251\n",
      "Epoch 13: Binary F1 = 0.9285, Macro F1 = 0.5153, Final Metric = 0.7219\n",
      "Epoch 14: Binary F1 = 0.9319, Macro F1 = 0.5119, Final Metric = 0.7219\n",
      "Epoch 15: Binary F1 = 0.9375, Macro F1 = 0.5150, Final Metric = 0.7262\n",
      "  New best metric! Saving model...\n",
      "Epoch 16: Binary F1 = 0.9418, Macro F1 = 0.5286, Final Metric = 0.7352\n",
      "  New best metric! Saving model...\n",
      "Epoch 17: Binary F1 = 0.9418, Macro F1 = 0.5348, Final Metric = 0.7383\n",
      "  New best metric! Saving model...\n",
      "Epoch 18: Binary F1 = 0.9353, Macro F1 = 0.5424, Final Metric = 0.7389\n",
      "  New best metric! Saving model...\n",
      "Epoch 19: Binary F1 = 0.9326, Macro F1 = 0.5490, Final Metric = 0.7408\n",
      "  New best metric! Saving model...\n",
      "Epoch 20: Binary F1 = 0.9336, Macro F1 = 0.5449, Final Metric = 0.7393\n",
      "Epoch 21: Binary F1 = 0.9353, Macro F1 = 0.5339, Final Metric = 0.7346\n",
      "Epoch 22: Binary F1 = 0.9334, Macro F1 = 0.5254, Final Metric = 0.7294\n",
      "Epoch 23: Binary F1 = 0.9346, Macro F1 = 0.5435, Final Metric = 0.7391\n",
      "Epoch 24: Binary F1 = 0.9353, Macro F1 = 0.5346, Final Metric = 0.7349\n",
      "Epoch 25: Binary F1 = 0.9378, Macro F1 = 0.5328, Final Metric = 0.7353\n",
      "\n",
      "Fold 2 completed.\n",
      "Final validation metrics - Binary F1: 0.9378, Macro F1: 0.5328, Final: 0.7353\n",
      "Best validation metrics - Binary F1: 0.9326, Macro F1: 0.5490, Final: 0.7408\n",
      "training: 3\n",
      "\n",
      "==================================================\n",
      "Fold 3/5\n",
      "Epoch 01: Binary F1 = 0.8360, Macro F1 = 0.1922, Final Metric = 0.5141\n",
      "  New best metric! Saving model...\n",
      "Epoch 02: Binary F1 = 0.8728, Macro F1 = 0.3529, Final Metric = 0.6128\n",
      "  New best metric! Saving model...\n",
      "Epoch 03: Binary F1 = 0.9233, Macro F1 = 0.3807, Final Metric = 0.6520\n",
      "  New best metric! Saving model...\n",
      "Epoch 04: Binary F1 = 0.9371, Macro F1 = 0.4698, Final Metric = 0.7034\n",
      "  New best metric! Saving model...\n",
      "Epoch 05: Binary F1 = 0.9470, Macro F1 = 0.4438, Final Metric = 0.6954\n",
      "Epoch 06: Binary F1 = 0.9443, Macro F1 = 0.4979, Final Metric = 0.7211\n",
      "  New best metric! Saving model...\n",
      "Epoch 07: Binary F1 = 0.9745, Macro F1 = 0.5844, Final Metric = 0.7794\n",
      "  New best metric! Saving model...\n",
      "Epoch 08: Binary F1 = 0.9672, Macro F1 = 0.5782, Final Metric = 0.7727\n"
     ]
    }
   ],
   "source": [
    "seed_everything(seed=SEED)\n",
    "\n",
    "n_splits = 5\n",
    "\n",
    "fold_metrics = []\n",
    "best_fold_metrics = []\n",
    "best_models = []\n",
    "\n",
    "fold_patterns = join(dataset_path, \"preprocessed_dataset\", \"fold*\")\n",
    "fold_pths = glob(fold_patterns)\n",
    "all_training_metrics = {}\n",
    "\n",
    "for fold, fold_pth in enumerate(fold_pths):\n",
    "    print(\"training:\", fold + 1)\n",
    "    train_dataset = CMIDataset(fold_pth, \"train\")\n",
    "    # criterion = compute_weighted_cross_entropy_loss(train_dataset)\n",
    "    criterion = torch.nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "    train_loader = DL(train_dataset, TRAIN_BATCH_SIZE, shuffle=True, drop_last=True)\n",
    "    validation_dataset = CMIDataset(fold_pth, \"validation\")\n",
    "    validation_loader = DL(validation_dataset, VALIDATION_BATCH_SIZE, shuffle=False, drop_last=True)\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Fold {fold + 1}/{n_splits}\")\n",
    "\n",
    "    seed_everything(seed=SEED + fold)\n",
    "    model = mk_model()\n",
    "\n",
    "    # Optimizer et scheduler\n",
    "    min_lr = max_lr / 100\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        model.parameters(),\n",
    "        WARMUP_LR_INIT,\n",
    "        weight_decay=WEIGHT_DECAY,\n",
    "    )\n",
    "    steps_per_epoch = len(train_loader)\n",
    "    scheduler = CosineAnnealingWarmupRestarts(\n",
    "        optimizer,\n",
    "        warmup_steps=WARMUP_EPOCHS * steps_per_epoch,\n",
    "        cycle_mult=CYCLE_LENGTH_FACTOR,\n",
    "        max_lr = max_lr,\n",
    "        min_lr = max_lr / MAX_TO_MIN_LR_DIV_FACTOR,\n",
    "        cycle_length=INIT_CYCLE_EPOCHS * steps_per_epoch,\n",
    "        gamma=LR_CYCLE_FACTOR,\n",
    "    ) \n",
    "\n",
    "\n",
    "    # Early stopping\n",
    "    best_metric = -np.inf\n",
    "    best_binary_f1 = -np.inf\n",
    "    best_macro_f1 = -np.inf\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    for epoch in range(1, TRAINING_EPOCHS + 1):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        total = 0\n",
    "        for batch_x, batch_y in train_loader:\n",
    "            batch_x = batch_x.to(device).clone()\n",
    "            add_noise = torch.randn_like(batch_x, device=device) * 0.04\n",
    "            scale_noise = torch.rand_like(batch_x, device=device) * (1.1 - 0.9) + 0.9\n",
    "            batch_x = (add_noise + batch_x) * scale_noise\n",
    "            batch_x[:TRAIN_BATCH_SIZE // 2, non_imu_feats_idx] = 0.0\n",
    "            batch_y = batch_y.to(device)\n",
    "            batch_x = batch_x.float()\n",
    "            \n",
    "            batch_x, batch_y = mixup_data(batch_x, batch_y)\n",
    "           \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_x)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            train_loss += loss.item() * batch_x.size(0)\n",
    "            total += batch_x.size(0)\n",
    "        train_loss /= total\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        total = 0\n",
    "        all_true = []\n",
    "        all_pred = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch_x, batch_y in validation_loader:\n",
    "                batch_x = batch_x.to(device).clone()\n",
    "                batch_y = batch_y.to(device)\n",
    "                batch_x[:VALIDATION_BATCH_SIZE // 2, non_imu_feats_idx] = 0.0\n",
    "\n",
    "                outputs = model(batch_x)\n",
    "                loss = criterion(outputs, batch_y)\n",
    "                val_loss += loss.item() * batch_x.size(0)\n",
    "                total += batch_x.size(0)\n",
    "\n",
    "                # Get predicted class indices\n",
    "                preds = torch.argmax(outputs, dim=1).cpu().numpy()\n",
    "                # Get true class indices from one-hot\n",
    "                trues = torch.argmax(batch_y, dim=1).cpu().numpy()\n",
    "\n",
    "                all_true.append(trues)\n",
    "                all_pred.append(preds)\n",
    "\n",
    "        val_loss /= total\n",
    "        all_true = np.concatenate(all_true)\n",
    "        all_pred = np.concatenate(all_pred)\n",
    "\n",
    "        # Compute competition metrics\n",
    "        # Binary classification: BFRB (1) vs non-BFRB (0)\n",
    "        binary_true = np.isin(all_true, bfrb_indices).astype(int)\n",
    "        binary_pred = np.isin(all_pred, bfrb_indices).astype(int)\n",
    "        binary_f1 = f1_score(binary_true, binary_pred)\n",
    "\n",
    "        # Collapse non-BFRB gestures into a single class\n",
    "        collapsed_true = np.where(\n",
    "            np.isin(all_true, bfrb_indices),\n",
    "            all_true,\n",
    "            len(bfrb_gestures)  # Single non-BFRB class\n",
    "        )\n",
    "        collapsed_pred = np.where(\n",
    "            np.isin(all_pred, bfrb_indices),\n",
    "            all_pred,\n",
    "            len(bfrb_gestures)  # Single non-BFRB class\n",
    "        )\n",
    "\n",
    "        # Macro F1 on collapsed classes\n",
    "        macro_f1 = f1_score(collapsed_true, collapsed_pred, average='macro')\n",
    "        final_metric = (binary_f1 + macro_f1) / 2\n",
    "\n",
    "        print(f\"Epoch {epoch:02d}: Binary F1 = {binary_f1:.4f}, Macro F1 = {macro_f1:.4f}, Final Metric = {final_metric:.4f}\")\n",
    "\n",
    "        if final_metric > best_metric:\n",
    "            best_metric = final_metric\n",
    "            best_binary_f1 = binary_f1\n",
    "            best_macro_f1 = macro_f1\n",
    "            epochs_no_improve = 0\n",
    "            best_model_state = model.state_dict()\n",
    "            print(f\"  New best metric! Saving model...\")\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            if epochs_no_improve >= PATIENCE:\n",
    "                print(f\"Early stopping triggered at epoch {epoch}\")\n",
    "                model.load_state_dict(best_model_state)\n",
    "                break\n",
    "\n",
    "    torch.save(best_model_state, f\"best_model_fold{fold}.pth\")\n",
    "    # Free memory used by datasets and data loaders\n",
    "    del train_dataset\n",
    "    del validation_dataset\n",
    "    del train_loader\n",
    "    del validation_loader\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    best_models.append(best_model_state)\n",
    "    fold_metrics.append({\n",
    "        'binary_f1': binary_f1,\n",
    "        'macr, drop_last=Trueo_f1': macro_f1,\n",
    "        'final_metric': final_metric\n",
    "    })\n",
    "    \n",
    "    best_fold_metrics.append({\n",
    "        'binary_f1': best_binary_f1,\n",
    "        'macro_f1': best_macro_f1,\n",
    "        'final_metric': best_metric\n",
    "    })\n",
    "    \n",
    "    print(f\"\\nFold {fold + 1} completed.\")\n",
    "    print(f\"Final validation metrics - Binary F1: {binary_f1:.4f}, Macro F1: {macro_f1:.4f}, Final: {final_metric:.4f}\")\n",
    "    print(f\"Best validation metrics - Binary F1: {best_binary_f1:.4f}, Macro F1: {best_macro_f1:.4f}, Final: {best_metric:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Cross-Validation Results\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Statistiques pour les meilleures mÃ©triques\n",
    "best_binary_f1 = [m['binary_f1'] for m in best_fold_metrics]\n",
    "best_macro_f1 = [m['macro_f1'] for m in best_fold_metrics]\n",
    "best_metrics = [m['final_metric'] for m in best_fold_metrics]\n",
    "\n",
    "print(\"\\nBest Fold-wise Metrics:\")\n",
    "for i, (bf1, mf1, fm) in enumerate(zip(best_binary_f1, best_macro_f1, best_metrics)):\n",
    "    print(f\"Fold {i+1}: Binary F1 = {bf1:.4f}, Macro F1 = {mf1:.4f}, Final = {fm:.4f}\")\n",
    "\n",
    "print(\"\\nGlobal Statistics (Best Metrics):\")\n",
    "print(f\"Mean Best Final Metric: {np.mean(best_metrics):.4f} Â± {np.std(best_metrics):.4f}\")\n",
    "print(f\"Mean Best Binary F1: {np.mean(best_binary_f1):.4f} Â± {np.std(best_binary_f1):.4f}\")\n",
    "print(f\"Mean Best Macro F1: {np.mean(best_macro_f1):.4f} Â± {np.std(best_macro_f1):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ea7558",
   "metadata": {
    "papermill": {
     "duration": 0.012909,
     "end_time": "2025-06-14T10:09:14.961270",
     "exception": false,
     "start_time": "2025-06-14T10:09:14.948361",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aea5e4f",
   "metadata": {
    "papermill": {
     "duration": 0.012906,
     "end_time": "2025-06-14T10:09:14.780212",
     "exception": false,
     "start_time": "2025-06-14T10:09:14.767306",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Reloading best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0574d4d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T10:09:14.807902Z",
     "iopub.status.busy": "2025-06-14T10:09:14.807165Z",
     "iopub.status.idle": "2025-06-14T10:09:14.933288Z",
     "shell.execute_reply": "2025-06-14T10:09:14.932459Z"
    },
    "papermill": {
     "duration": 0.141435,
     "end_time": "2025-06-14T10:09:14.934745",
     "exception": false,
     "start_time": "2025-06-14T10:09:14.793310",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for CMIHARModule:\n\tMissing key(s) in state_dict: \"imu_branch.0.lpf.weight\", \"imu_branch.2.blocks.0.weight\", \"imu_branch.2.blocks.1.weight\", \"imu_branch.2.blocks.1.bias\", \"imu_branch.2.blocks.1.running_mean\", \"imu_branch.2.blocks.1.running_var\", \"imu_branch.2.blocks.3.weight\", \"imu_branch.2.blocks.4.weight\", \"imu_branch.2.blocks.4.bias\", \"imu_branch.2.blocks.4.running_mean\", \"imu_branch.2.blocks.4.running_var\", \"imu_branch.2.blocks.5.fc1.weight\", \"imu_branch.2.blocks.5.fc1.bias\", \"imu_branch.2.blocks.5.fc2.weight\", \"imu_branch.2.blocks.5.fc2.bias\", \"imu_branch.2.skip_connection.0.weight\", \"imu_branch.2.skip_connection.1.weight\", \"imu_branch.2.skip_connection.1.bias\", \"imu_branch.2.skip_connection.1.running_mean\", \"imu_branch.2.skip_connection.1.running_var\", \"head.1.weight\", \"head.1.bias\", \"head.1.running_mean\", \"head.1.running_var\", \"head.3.weight\", \"head.4.running_mean\", \"head.4.running_var\", \"head.6.weight\", \"head.6.bias\". \n\tUnexpected key(s) in state_dict: \"imu_branch.0.blocks.0.weight\", \"imu_branch.0.blocks.0.bias\", \"imu_branch.0.blocks.1.weight\", \"imu_branch.0.blocks.1.bias\", \"imu_branch.0.blocks.1.running_mean\", \"imu_branch.0.blocks.1.running_var\", \"imu_branch.0.blocks.1.num_batches_tracked\", \"imu_branch.0.blocks.3.weight\", \"imu_branch.0.blocks.3.bias\", \"imu_branch.0.blocks.4.weight\", \"imu_branch.0.blocks.4.bias\", \"imu_branch.0.blocks.4.running_mean\", \"imu_branch.0.blocks.4.running_var\", \"imu_branch.0.blocks.4.num_batches_tracked\", \"imu_branch.0.blocks.5.fc1.weight\", \"imu_branch.0.blocks.5.fc1.bias\", \"imu_branch.0.blocks.5.fc2.weight\", \"imu_branch.0.blocks.5.fc2.bias\", \"imu_branch.0.skip_connection.0.weight\", \"imu_branch.0.skip_connection.0.bias\", \"imu_branch.0.skip_connection.1.weight\", \"imu_branch.0.skip_connection.1.bias\", \"imu_branch.0.skip_connection.1.running_mean\", \"imu_branch.0.skip_connection.1.running_var\", \"imu_branch.0.skip_connection.1.num_batches_tracked\", \"imu_branch.1.blocks.0.bias\", \"imu_branch.1.blocks.3.bias\", \"imu_branch.1.skip_connection.0.bias\", \"head.0.bias\", \"head.2.weight\", \"head.2.bias\". \n\tsize mismatch for imu_branch.1.blocks.0.weight: copying a param with shape torch.Size([128, 64, 3]) from checkpoint, the shape in current model is torch.Size([64, 138, 3]).\n\tsize mismatch for imu_branch.1.blocks.1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for imu_branch.1.blocks.1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for imu_branch.1.blocks.1.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for imu_branch.1.blocks.1.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for imu_branch.1.blocks.3.weight: copying a param with shape torch.Size([128, 128, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).\n\tsize mismatch for imu_branch.1.blocks.4.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for imu_branch.1.blocks.4.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for imu_branch.1.blocks.4.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for imu_branch.1.blocks.4.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for imu_branch.1.blocks.5.fc1.weight: copying a param with shape torch.Size([16, 128]) from checkpoint, the shape in current model is torch.Size([8, 64]).\n\tsize mismatch for imu_branch.1.blocks.5.fc1.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([8]).\n\tsize mismatch for imu_branch.1.blocks.5.fc2.weight: copying a param with shape torch.Size([128, 16]) from checkpoint, the shape in current model is torch.Size([64, 8]).\n\tsize mismatch for imu_branch.1.blocks.5.fc2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for imu_branch.1.skip_connection.0.weight: copying a param with shape torch.Size([128, 64, 1]) from checkpoint, the shape in current model is torch.Size([64, 138, 1]).\n\tsize mismatch for imu_branch.1.skip_connection.1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for imu_branch.1.skip_connection.1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for imu_branch.1.skip_connection.1.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for imu_branch.1.skip_connection.1.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for head.4.weight: copying a param with shape torch.Size([18, 128]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for head.4.bias: copying a param with shape torch.Size([18]) from checkpoint, the shape in current model is torch.Size([128]).",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m model = mk_model()\n\u001b[32m      4\u001b[39m checkpoint = torch.load(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mbest_model_fold\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.pth\u001b[39m\u001b[33m\"\u001b[39m, map_location=device, weights_only=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m model.eval()\n\u001b[32m      7\u001b[39m model_ensemble.append(model)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/venv/CMI/lib/python3.11/site-packages/torch/nn/modules/module.py:2584\u001b[39m, in \u001b[36mModule.load_state_dict\u001b[39m\u001b[34m(self, state_dict, strict, assign)\u001b[39m\n\u001b[32m   2576\u001b[39m         error_msgs.insert(\n\u001b[32m   2577\u001b[39m             \u001b[32m0\u001b[39m,\n\u001b[32m   2578\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[33m\"\u001b[39m.format(\n\u001b[32m   2579\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m.join(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)\n\u001b[32m   2580\u001b[39m             ),\n\u001b[32m   2581\u001b[39m         )\n\u001b[32m   2583\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) > \u001b[32m0\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m2584\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   2585\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m\"\u001b[39m.format(\n\u001b[32m   2586\u001b[39m             \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m, \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[33m\"\u001b[39m.join(error_msgs)\n\u001b[32m   2587\u001b[39m         )\n\u001b[32m   2588\u001b[39m     )\n\u001b[32m   2589\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[31mRuntimeError\u001b[39m: Error(s) in loading state_dict for CMIHARModule:\n\tMissing key(s) in state_dict: \"imu_branch.0.lpf.weight\", \"imu_branch.2.blocks.0.weight\", \"imu_branch.2.blocks.1.weight\", \"imu_branch.2.blocks.1.bias\", \"imu_branch.2.blocks.1.running_mean\", \"imu_branch.2.blocks.1.running_var\", \"imu_branch.2.blocks.3.weight\", \"imu_branch.2.blocks.4.weight\", \"imu_branch.2.blocks.4.bias\", \"imu_branch.2.blocks.4.running_mean\", \"imu_branch.2.blocks.4.running_var\", \"imu_branch.2.blocks.5.fc1.weight\", \"imu_branch.2.blocks.5.fc1.bias\", \"imu_branch.2.blocks.5.fc2.weight\", \"imu_branch.2.blocks.5.fc2.bias\", \"imu_branch.2.skip_connection.0.weight\", \"imu_branch.2.skip_connection.1.weight\", \"imu_branch.2.skip_connection.1.bias\", \"imu_branch.2.skip_connection.1.running_mean\", \"imu_branch.2.skip_connection.1.running_var\", \"head.1.weight\", \"head.1.bias\", \"head.1.running_mean\", \"head.1.running_var\", \"head.3.weight\", \"head.4.running_mean\", \"head.4.running_var\", \"head.6.weight\", \"head.6.bias\". \n\tUnexpected key(s) in state_dict: \"imu_branch.0.blocks.0.weight\", \"imu_branch.0.blocks.0.bias\", \"imu_branch.0.blocks.1.weight\", \"imu_branch.0.blocks.1.bias\", \"imu_branch.0.blocks.1.running_mean\", \"imu_branch.0.blocks.1.running_var\", \"imu_branch.0.blocks.1.num_batches_tracked\", \"imu_branch.0.blocks.3.weight\", \"imu_branch.0.blocks.3.bias\", \"imu_branch.0.blocks.4.weight\", \"imu_branch.0.blocks.4.bias\", \"imu_branch.0.blocks.4.running_mean\", \"imu_branch.0.blocks.4.running_var\", \"imu_branch.0.blocks.4.num_batches_tracked\", \"imu_branch.0.blocks.5.fc1.weight\", \"imu_branch.0.blocks.5.fc1.bias\", \"imu_branch.0.blocks.5.fc2.weight\", \"imu_branch.0.blocks.5.fc2.bias\", \"imu_branch.0.skip_connection.0.weight\", \"imu_branch.0.skip_connection.0.bias\", \"imu_branch.0.skip_connection.1.weight\", \"imu_branch.0.skip_connection.1.bias\", \"imu_branch.0.skip_connection.1.running_mean\", \"imu_branch.0.skip_connection.1.running_var\", \"imu_branch.0.skip_connection.1.num_batches_tracked\", \"imu_branch.1.blocks.0.bias\", \"imu_branch.1.blocks.3.bias\", \"imu_branch.1.skip_connection.0.bias\", \"head.0.bias\", \"head.2.weight\", \"head.2.bias\". \n\tsize mismatch for imu_branch.1.blocks.0.weight: copying a param with shape torch.Size([128, 64, 3]) from checkpoint, the shape in current model is torch.Size([64, 138, 3]).\n\tsize mismatch for imu_branch.1.blocks.1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for imu_branch.1.blocks.1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for imu_branch.1.blocks.1.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for imu_branch.1.blocks.1.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for imu_branch.1.blocks.3.weight: copying a param with shape torch.Size([128, 128, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).\n\tsize mismatch for imu_branch.1.blocks.4.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for imu_branch.1.blocks.4.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for imu_branch.1.blocks.4.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for imu_branch.1.blocks.4.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for imu_branch.1.blocks.5.fc1.weight: copying a param with shape torch.Size([16, 128]) from checkpoint, the shape in current model is torch.Size([8, 64]).\n\tsize mismatch for imu_branch.1.blocks.5.fc1.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([8]).\n\tsize mismatch for imu_branch.1.blocks.5.fc2.weight: copying a param with shape torch.Size([128, 16]) from checkpoint, the shape in current model is torch.Size([64, 8]).\n\tsize mismatch for imu_branch.1.blocks.5.fc2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for imu_branch.1.skip_connection.0.weight: copying a param with shape torch.Size([128, 64, 1]) from checkpoint, the shape in current model is torch.Size([64, 138, 1]).\n\tsize mismatch for imu_branch.1.skip_connection.1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for imu_branch.1.skip_connection.1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for imu_branch.1.skip_connection.1.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for imu_branch.1.skip_connection.1.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for head.4.weight: copying a param with shape torch.Size([18, 128]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for head.4.bias: copying a param with shape torch.Size([18]) from checkpoint, the shape in current model is torch.Size([128])."
     ]
    }
   ],
   "source": [
    "model_ensemble = []\n",
    "for fold in range(5):\n",
    "    model = mk_model()\n",
    "    checkpoint = torch.load(f\"best_model_fold{fold}.pth\", map_location=device, weights_only=True)\n",
    "    model.load_state_dict(checkpoint)\n",
    "    model.eval()\n",
    "    model_ensemble.append(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a826dec8",
   "metadata": {},
   "source": [
    "### Define preprocessing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481e69b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fillna_val_per_feature_col(df:DF) -> dict:\n",
    "    return {col: 1.0 if col == 'rot_w' else 0 for col in get_feature_cols(df)}\n",
    "\n",
    "def imputed_features(df:DF) -> DF:\n",
    "    # Missing ToF values are already imputed by -1 which is inconvinient since we want all missing values to be NaN.    \n",
    "    # So we replace them by NaN and then perform imputing.  \n",
    "    tof_vals_to_nan = {col: -1.0 for col in df.columns if col.startswith(\"tof\")}\n",
    "\n",
    "    df[get_feature_cols(df)] = (\n",
    "        df\n",
    "        .loc[:, get_feature_cols(df)]\n",
    "        # df.replace with np.nan sets dtype to floar64 so we set it back to float32\n",
    "        .replace(tof_vals_to_nan, value=np.nan)\n",
    "        .astype(\"float32\")\n",
    "        .groupby(df[\"sequence_id\"], observed=True, as_index=False)\n",
    "        .ffill()\n",
    "        .groupby(df[\"sequence_id\"], observed=True, as_index=False)\n",
    "        .bfill()\n",
    "        # In case there are only nan in the column in the sequence\n",
    "        .fillna(get_fillna_val_per_feature_col(df))\n",
    "    )\n",
    "    return df\n",
    "\n",
    "def norm_quat_rotations(df:DF) -> DF:\n",
    "    df[QUATERNION_COLS] /= np.linalg.norm(df[QUATERNION_COLS], axis=1, keepdims=True)\n",
    "    return df\n",
    "\n",
    "def add_linear_acc_cols(df:DF) -> DF:\n",
    "    # Vectorized version of https://www.kaggle.com/code/wasupandceacar/lb-0-82-5fold-single-bert-model#Dataset `remove_gravity_from_acc`\n",
    "    rotations:Rotation = Rotation.from_quat(df[QUATERNION_COLS])\n",
    "    gravity_sensor_frame = rotations.apply(GRAVITY_WORLD, inverse=True).astype(\"float32\")\n",
    "    df[LINEAR_ACC_COLS] = df[RAW_ACCELRATION_COLS] - gravity_sensor_frame\n",
    "    return df\n",
    "\n",
    "def add_acc_magnitude(df:DF, acc_cols:list[str], acc_mag_col_name:str) -> DF:\n",
    "    return df.assign(**{acc_mag_col_name: np.linalg.norm(df.loc[:, acc_cols], axis=1)})\n",
    "\n",
    "def add_quat_angle_mag(df:DF) -> DF:\n",
    "    return df.assign(quat_rot_mag=np.arccos(df[\"rot_w\"]) * 2)\n",
    "\n",
    "def add_angular_velocity_features(df:DF) -> DF:\n",
    "    rotations = Rotation.from_quat(df[QUATERNION_COLS])\n",
    "    delta_rotations = rotations[1:] * rotations[:-1].inv()\n",
    "    delta_rot_velocity = delta_rotations.as_rotvec()\n",
    "    # Add extra line to avoid shape mismatch\n",
    "    delta_rot_velocity = np.vstack((np.zeros((1, 3)), delta_rot_velocity))\n",
    "    delta_rot_magnitude = norm(delta_rot_velocity, axis=1, keepdims=True)\n",
    "    delta_rot_axes = delta_rot_velocity / (delta_rot_magnitude + EPSILON)\n",
    "    df[DELTA_ROTATION_ANGULAR_VELOCITY_COLS] = delta_rot_velocity\n",
    "    df[DELTA_ROTATION_AXES_COLS] = delta_rot_axes\n",
    "    df[\"delta_rot_mag\"] = delta_rot_magnitude.squeeze()\n",
    "\n",
    "    return df\n",
    "\n",
    "def rot_euler_angles(df:DF) -> ndarray:\n",
    "    df[EULER_ANGLES_COLS] = (\n",
    "        Rotation\n",
    "        .from_quat(df[QUATERNION_COLS])\n",
    "        .as_euler(\"xyz\")\n",
    "        .squeeze()\n",
    "    )\n",
    "    return df\n",
    "\n",
    "def agg_tof_cols_per_sensor(df:DF) -> DF:\n",
    "    for tof_idx in tqdm(range(1, 6)):\n",
    "        tof_name = f\"tof_{tof_idx}\"\n",
    "        tof_cols = [f\"{tof_name}_v{v_idx}\" for v_idx in range(64)]\n",
    "        if any(map(lambda col: col not in df.columns, tof_cols)):\n",
    "            print(f\"Some (or) all ToF {tof_idx} columns are not in the df. Maybe you already ran this cell?\")\n",
    "            continue\n",
    "        df = pd.concat(\n",
    "            (\n",
    "                df.drop(columns=tof_cols),\n",
    "                # For some reasons, it's faster to call all the aggregation functions seperatly than agg(list of functions)\n",
    "                df[tof_cols].mean(axis=\"columns\").to_frame(tof_name + \"_mean\"),\n",
    "                df[tof_cols].std(axis=\"columns\").to_frame(tof_name + \"_std\"),\n",
    "                df[tof_cols].median(axis=\"columns\").to_frame(tof_name + \"_median\"),\n",
    "                df[tof_cols].min(axis=\"columns\").to_frame(tof_name + \"_min\"),\n",
    "                df[tof_cols].max(axis=\"columns\").to_frame(tof_name + \"_max\"),\n",
    "            ),\n",
    "            axis=\"columns\",\n",
    "        )\n",
    "    return df\n",
    "\n",
    "def add_diff_features(df:DF) -> DF:\n",
    "    return pd.concat(\n",
    "        (\n",
    "            df,\n",
    "            df\n",
    "            .groupby(\"sequence_id\", as_index=False, observed=True)\n",
    "            [get_feature_cols(df)]\n",
    "            .diff()\n",
    "            .fillna(get_fillna_val_per_feature_col(df))\n",
    "            .add_suffix(\"_diff\")\n",
    "        ),\n",
    "        axis=\"columns\",\n",
    "    )\n",
    "\n",
    "def length_normed_sequence_feat_arr(sequence: DF) -> ndarray:\n",
    "    features = (\n",
    "        sequence\n",
    "        .loc[:, meta_data[\"feature_cols\"]]\n",
    "        .values\n",
    "    )\n",
    "    normed_sequence_len = meta_data[\"pad_seq_len\"]\n",
    "    len_diff = abs(normed_sequence_len - len(features))\n",
    "    if len(features) < normed_sequence_len:\n",
    "        padded_features = np.pad(\n",
    "            features,\n",
    "            ((len_diff // 2 + len_diff % 2, len_diff // 2), (0, 0)),\n",
    "        )\n",
    "        return padded_features\n",
    "    elif len(features) > normed_sequence_len:\n",
    "        return features[len_diff // 2:-len_diff // 2]\n",
    "    else:\n",
    "        return features\n",
    "\n",
    "def preprocess_sequence(sequence_df:pl.DataFrame) -> ndarray:\n",
    "    return (\n",
    "        sequence_df                     \n",
    "        .to_pandas()                            # Convert to pandas dataframe.\n",
    "        .pipe(imputed_features)                 # Impute missing data.\n",
    "        .pipe(norm_quat_rotations)              # Norm quaternions\n",
    "        .pipe(add_linear_acc_cols)              # Add gravity free acceleration.\n",
    "        .pipe(add_acc_magnitude, RAW_ACCELRATION_COLS, \"acc_mag\")\n",
    "        .pipe(add_acc_magnitude, LINEAR_ACC_COLS, \"linear_acc_mag\")\n",
    "        .pipe(add_quat_angle_mag)\n",
    "        .pipe(add_angular_velocity_features)\n",
    "        .pipe(rot_euler_angles)                 # Add rotation acc expressed as euler angles.\n",
    "        # .pipe(agg_tof_cols_per_sensor)          # Aggregate ToF columns.\n",
    "        .pipe(add_diff_features)                # \n",
    "        .loc[:, sorted(meta_data[\"feature_cols\"])]      # Retain only the usefull columns a.k.a features.\n",
    "        .sub(meta_data[\"mean\"])                 # Subtract features by their mean, std norm pt.1.\n",
    "        .div(meta_data[\"std\"])                  # Divide by Standard deviation, std norm pt.2.\n",
    "        .pipe(length_normed_sequence_feat_arr)  # get feature ndarray of sequence.\n",
    "        .T                                      # Transpose to swap channel and X dimensions.\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ebb0960",
   "metadata": {},
   "source": [
    "### Define prediction function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d8dfff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T10:09:14.989742Z",
     "iopub.status.busy": "2025-06-14T10:09:14.989258Z",
     "iopub.status.idle": "2025-06-14T10:09:14.995936Z",
     "shell.execute_reply": "2025-06-14T10:09:14.995244Z"
    },
    "papermill": {
     "duration": 0.021303,
     "end_time": "2025-06-14T10:09:14.997034",
     "exception": false,
     "start_time": "2025-06-14T10:09:14.975731",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict(sequence: pl.DataFrame, _: pl.DataFrame) -> str:\n",
    "    \"\"\"\n",
    "    Kaggle evaluation API will call this for each sequence.\n",
    "    sequence: polars DataFrame for a single sequence\n",
    "    demographics: unused in this model\n",
    "    Returns: predicted gesture string\n",
    "    \"\"\"\n",
    "    x_tensor = (\n",
    "        torch.unsqueeze(Tensor(preprocess_sequence(sequence)), dim=0)\n",
    "        .float()\n",
    "        .to(device)\n",
    "    )\n",
    "    print(x_tensor.shape)\n",
    "\n",
    "    all_outputs = []\n",
    "    with torch.no_grad():\n",
    "        for model_idx, model in enumerate(model_ensemble): # Only take the first one bc it's the only one that takes in the correct input shape\n",
    "            outputs = model(x_tensor)\n",
    "            all_outputs.append(outputs)\n",
    "\n",
    "    avg_outputs = torch.mean(torch.stack(all_outputs), dim=0)\n",
    "    pred_idx = torch.argmax(avg_outputs, dim=1).item()\n",
    "\n",
    "    return str(gesture_classes[pred_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cdcf446",
   "metadata": {},
   "source": [
    "### Run inference server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c386b7d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T10:09:15.023324Z",
     "iopub.status.busy": "2025-06-14T10:09:15.023122Z",
     "iopub.status.idle": "2025-06-14T10:09:16.373534Z",
     "shell.execute_reply": "2025-06-14T10:09:16.372710Z"
    },
    "papermill": {
     "duration": 1.365137,
     "end_time": "2025-06-14T10:09:16.374918",
     "exception": false,
     "start_time": "2025-06-14T10:09:15.009781",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "inference_server = kaggle_evaluation.cmi_inference_server.CMIInferenceServer(predict)\n",
    "\n",
    "if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
    "    inference_server.serve()\n",
    "else:\n",
    "    inference_server.run_local_gateway(\n",
    "        data_paths=(\n",
    "            join(competition_dataset_path, 'test.csv'),\n",
    "            join(competition_dataset_path, 'test_demographics.csv'),\n",
    "        )\n",
    "    )\n",
    "    inference_server = kaggle_evaluation.cmi_inference_server.CMIInferenceServer(predict)\n",
    "    inference_server.run_local_gateway(\n",
    "        data_paths=(\n",
    "            join(competition_dataset_path, 'train.csv'),\n",
    "            join(competition_dataset_path, 'train_demographics.csv'),\n",
    "        )\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 12518947,
     "sourceId": 102335,
     "sourceType": "competition"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "CMI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 510.403331,
   "end_time": "2025-06-14T10:09:19.701325",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-06-14T10:00:49.297994",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
