{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a0d2e35",
   "metadata": {
    "papermill": {
     "duration": 0.008511,
     "end_time": "2025-08-02T11:24:41.877382",
     "exception": false,
     "start_time": "2025-08-02T11:24:41.868871",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training & inference notebook\n",
    "Credit to [Tarun Mishra](https://www.kaggle.com/tarundirector) – this code is heavily based on his [notebook](https://www.kaggle.com/code/tarundirector/sensor-pulse-viz-eda-for-bfrb-detection?scriptVersionId=243465321)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8a75d1",
   "metadata": {
    "papermill": {
     "duration": 0.006874,
     "end_time": "2025-08-02T11:24:41.891565",
     "exception": false,
     "start_time": "2025-08-02T11:24:41.884691",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1bea84",
   "metadata": {
    "papermill": {
     "duration": 0.007515,
     "end_time": "2025-08-02T11:24:41.906119",
     "exception": false,
     "start_time": "2025-08-02T11:24:41.898604",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ab5e25",
   "metadata": {
    "papermill": {
     "duration": 0.006871,
     "end_time": "2025-08-02T11:24:41.920015",
     "exception": false,
     "start_time": "2025-08-02T11:24:41.913144",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Training imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c926412",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-02T11:24:41.935331Z",
     "iopub.status.busy": "2025-08-02T11:24:41.934781Z",
     "iopub.status.idle": "2025-08-02T11:24:50.078572Z",
     "shell.execute_reply": "2025-08-02T11:24:50.077751Z"
    },
    "papermill": {
     "duration": 8.15299,
     "end_time": "2025-08-02T11:24:50.079989",
     "exception": false,
     "start_time": "2025-08-02T11:24:41.926999",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import gc\n",
    "import json \n",
    "import math\n",
    "from glob import glob\n",
    "from functools import partial\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "from operator import methodcaller\n",
    "from os.path import join, realpath\n",
    "from typing import Optional, Literal\n",
    "from itertools import pairwise, starmap\n",
    "\n",
    "import torch\n",
    "import optuna\n",
    "import kagglehub\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from torch import nn, Tensor\n",
    "from pandas import DataFrame as DF\n",
    "from optuna.trial import TrialState\n",
    "from torch.optim import Optimizer\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader as DL\n",
    "# from timm.scheduler import CosineLRScheduler\n",
    "from rich.progress import Progress, Task, track\n",
    "from torch.optim.lr_scheduler import ConstantLR, LRScheduler, _LRScheduler\n",
    "metric_package = kagglehub.package_import('wasupandceacar/cmi-metric', bypass_confirmation=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee204ed9",
   "metadata": {
    "papermill": {
     "duration": 0.006875,
     "end_time": "2025-08-02T11:24:50.094215",
     "exception": false,
     "start_time": "2025-08-02T11:24:50.087340",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### inference imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4278a02",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-02T11:24:50.109063Z",
     "iopub.status.busy": "2025-08-02T11:24:50.108650Z",
     "iopub.status.idle": "2025-08-02T11:24:51.160561Z",
     "shell.execute_reply": "2025-08-02T11:24:51.159974Z"
    },
    "papermill": {
     "duration": 1.060762,
     "end_time": "2025-08-02T11:24:51.161865",
     "exception": false,
     "start_time": "2025-08-02T11:24:50.101103",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import warnings\n",
    "from os.path import join\n",
    "from tqdm.notebook import tqdm\n",
    "from itertools import pairwise, product\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "from numpy import ndarray\n",
    "from torch import nn, Tensor\n",
    "from numpy.linalg import norm\n",
    "from pandas import DataFrame as DF\n",
    "from scipy.spatial.transform import Rotation\n",
    "# from kagglehub import competition_download, dataset_download, model_download\n",
    "import kagglehub\n",
    "metric_package = kagglehub.package_import('wasupandceacar/cmi-metric', bypass_confirmation=True)\n",
    "\n",
    "import kaggle_evaluation.cmi_inference_server"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff09f2c",
   "metadata": {
    "papermill": {
     "duration": 0.006973,
     "end_time": "2025-08-02T11:24:51.176305",
     "exception": false,
     "start_time": "2025-08-02T11:24:51.169332",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### kaggle notbook Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d6a0b2b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-02T11:24:51.191571Z",
     "iopub.status.busy": "2025-08-02T11:24:51.191172Z",
     "iopub.status.idle": "2025-08-02T11:24:51.211064Z",
     "shell.execute_reply": "2025-08-02T11:24:51.210366Z"
    },
    "papermill": {
     "duration": 0.028768,
     "end_time": "2025-08-02T11:24:51.212242",
     "exception": false,
     "start_time": "2025-08-02T11:24:51.183474",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "\n",
    "def seed_everything(seed=42):\n",
    "    \"\"\"Set all random seeds for reproducibility\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'\n",
    "    torch.use_deterministic_algorithms(True, warn_only=True)\n",
    "\n",
    "SEED = 42\n",
    "seed_everything(seed=SEED)\n",
    "\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import kaggle_evaluation.cmi_inference_server\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d32d892",
   "metadata": {
    "papermill": {
     "duration": 0.006769,
     "end_time": "2025-08-02T11:24:51.225973",
     "exception": false,
     "start_time": "2025-08-02T11:24:51.219204",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Configs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85a8694",
   "metadata": {
    "papermill": {
     "duration": 0.006774,
     "end_time": "2025-08-02T11:24:51.239642",
     "exception": false,
     "start_time": "2025-08-02T11:24:51.232868",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Training config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "315f4a8d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-02T11:24:51.254502Z",
     "iopub.status.busy": "2025-08-02T11:24:51.254086Z",
     "iopub.status.idle": "2025-08-02T11:24:51.259267Z",
     "shell.execute_reply": "2025-08-02T11:24:51.258717Z"
    },
    "papermill": {
     "duration": 0.013777,
     "end_time": "2025-08-02T11:24:51.260297",
     "exception": false,
     "start_time": "2025-08-02T11:24:51.246520",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Dataset\n",
    "DATASET_HANDLE = \"mauroabidalcarrer/prepocessed-cmi-2025/versions/35\"\n",
    "COMPETITION_HANDLE = \"cmi-detect-behavior-with-sensor-data\"\n",
    "TARGET_NAMES = sorted([\n",
    "    \"Above ear - pull hair\",\n",
    "    \"Cheek - pinch skin\",\n",
    "    \"Eyebrow - pull hair\",\n",
    "    \"Eyelash - pull hair\",\n",
    "    \"Feel around in tray and pull out an object\",\n",
    "    \"Forehead - pull hairline\",\n",
    "    \"Forehead - scratch\",\n",
    "    \"Neck - pinch skin\",\n",
    "    \"Neck - scratch\",\n",
    "    \"Text on phone\",\n",
    "    \"Wave hello\",\n",
    "    \"Write name in air\",\n",
    "    \"Write name on leg\",\n",
    "    \"Drink from bottle/cup\",\n",
    "    \"Pinch knee/leg skin\",\n",
    "    \"Pull air toward your face\",\n",
    "    \"Scratch knee/leg skin\",\n",
    "    \"Glasses on/off\"\n",
    "])\n",
    "IMU_FEATS_PREFIXES = (\n",
    "    \"acc\",\n",
    "    \"linear_acc\",\n",
    "    \"rot\",\n",
    "    \"angular\",\n",
    "    \"euler\",\n",
    "    \"quat_rot_mag\",\n",
    "    \"delta_rot_mag\",\n",
    ")\n",
    "# Data augmentation\n",
    "JITTER = 0.25\n",
    "SCALING = 0.2\n",
    "MIXUP = 0.3\n",
    "# Training loop\n",
    "NB_CROSS_VALIDATIONS = 5\n",
    "TRAIN_BATCH_SIZE = 256\n",
    "VALIDATION_BATCH_SIZE = 4 * TRAIN_BATCH_SIZE\n",
    "PATIENCE = 8\n",
    "# Optimizer\n",
    "WEIGHT_DECAY = 3e-3\n",
    "# Scheduler\n",
    "TRAINING_EPOCHS = 25 # Including warmup epochs\n",
    "WARMUP_EPOCHS = 3\n",
    "WARMUP_LR_INIT = 1.822126131809773e-05\n",
    "MAX_TO_MIN_LR_DIV_FACTOR = 100\n",
    "LR_CYCLE_FACTOR = 0.5\n",
    "CYCLE_LENGTH_FACTOR = 0.9\n",
    "INIT_CYCLE_EPOCHS = 6\n",
    "# MIN_LR = 3.810323058740104e-09\n",
    "# MAX_LR = 1e-3\n",
    "# Mock training loop\n",
    "MOCK_TRAINING_EPOCHS = 15\n",
    "MOCK_TRAINING_GAMMA = 1.01\n",
    "CHANNELS_DIMENSION = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5b1887",
   "metadata": {
    "papermill": {
     "duration": 0.006754,
     "end_time": "2025-08-02T11:24:51.273987",
     "exception": false,
     "start_time": "2025-08-02T11:24:51.267233",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Preprocessing (for inference) config "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c199973",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-02T11:24:51.288765Z",
     "iopub.status.busy": "2025-08-02T11:24:51.288386Z",
     "iopub.status.idle": "2025-08-02T11:24:51.295185Z",
     "shell.execute_reply": "2025-08-02T11:24:51.294653Z"
    },
    "papermill": {
     "duration": 0.015378,
     "end_time": "2025-08-02T11:24:51.296287",
     "exception": false,
     "start_time": "2025-08-02T11:24:51.280909",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "QUATERNION_COLS = ['rot_w', 'rot_x', 'rot_y', 'rot_z']\n",
    "GRAVITY_WORLD = np.array([0, 0, 9.81], \"float32\")\n",
    "RAW_ACCELRATION_COLS = [\"acc_x\", \"acc_y\", \"acc_z\"]\n",
    "LINEAR_ACC_COLS = [\"linear_\" + col for col in RAW_ACCELRATION_COLS] # Acceleration without gravity\n",
    "COMPETITION_HANDLE = \"cmi-detect-behavior-with-sensor-data\"\n",
    "CATEGORY_COLUMNS = [\n",
    "    'row_id',\n",
    "    'sequence_type',\n",
    "    'sequence_id',\n",
    "    'subject',\n",
    "    'orientation',\n",
    "    'behavior',\n",
    "    'phase',\n",
    "    'gesture',\n",
    "]\n",
    "META_DATA_COLUMNS = [\n",
    "    'row_id',\n",
    "    'sequence_type',\n",
    "    'sequence_id',\n",
    "    'sequence_counter',\n",
    "    'subject',\n",
    "    'orientation',\n",
    "    'behavior',\n",
    "    'phase',\n",
    "    'gesture',\n",
    "]\n",
    "DATASET_DF_DTYPES = {\n",
    "    \"acc_x\": \"float32\", \"acc_y\": \"float32\", \"acc_z\": \"float32\",\n",
    "    \"thm_1\":\"float32\", \"thm_2\":\"float32\", \"thm_3\":\"float32\", \"thm_4\":\"float32\", \"thm_5\":\"float32\",\n",
    "    \"sequence_counter\": \"int32\",\n",
    "    **{col: \"category\" for col in CATEGORY_COLUMNS},\n",
    "    **{f\"tof_{i_1}_v{i_2}\": \"float32\" for i_1, i_2 in product(range(1, 5), range(64))},\n",
    "}\n",
    "PREPROCESSED_DATASET_HANDLE = \"mauroabidalcarrer/prepocessed-cmi-2025\"\n",
    "# The quantile of the sequences len used to pad/truncate during preprocessing\n",
    "SEQUENCE_NORMED_LEN_QUANTILE = 0.95\n",
    "# SAMPLING_FREQUENCY = 10 #Hz\n",
    "N_FOLDS = 5\n",
    "VALIDATION_FRACTION = 0.2\n",
    "TARGET_NAMES = sorted([\n",
    "    \"Above ear - pull hair\",\n",
    "    \"Cheek - pinch skin\",\n",
    "    \"Eyebrow - pull hair\",\n",
    "    \"Eyelash - pull hair\",\n",
    "    \"Feel around in tray and pull out an object\",\n",
    "    \"Forehead - pull hairline\",\n",
    "    \"Forehead - scratch\",\n",
    "    \"Neck - pinch skin\",\n",
    "    \"Neck - scratch\",\n",
    "    \"Text on phone\",\n",
    "    \"Wave hello\",\n",
    "    \"Write name in air\",\n",
    "    \"Write name on leg\",\n",
    "    \"Drink from bottle/cup\",\n",
    "    \"Pinch knee/leg skin\",\n",
    "    \"Pull air toward your face\",\n",
    "    \"Scratch knee/leg skin\",\n",
    "    \"Glasses on/off\"\n",
    "])\n",
    "EPSILON=1e-8\n",
    "DELTA_ROTATION_ANGULAR_VELOCITY_COLS = [\"angular_vel_x\", \"angular_vel_y\", \"angular_vel_z\"]\n",
    "DELTA_ROTATION_AXES_COLS = [\"rotation_axis_x\", \"rotation_axis_y\", \"rotation_axis_z\"]\n",
    "EULER_ANGLES_COLS = [\"euler_x\", \"euler_y\", \"euler_z\"]\n",
    "TOF_AGG_FUNCS = [\n",
    "    \"mean\",\n",
    "    \"std\",\n",
    "    \"min\",\n",
    "    \"max\",\n",
    "    \"median\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9071fd",
   "metadata": {
    "papermill": {
     "duration": 0.006946,
     "end_time": "2025-08-02T11:24:51.310233",
     "exception": false,
     "start_time": "2025-08-02T11:24:51.303287",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Define function to get the feature columns\n",
    "Feature columns change over time so it's better to have a function to get them than manually update a variable every time we add/remove features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18d58772",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-02T11:24:51.370165Z",
     "iopub.status.busy": "2025-08-02T11:24:51.369888Z",
     "iopub.status.idle": "2025-08-02T11:24:51.373542Z",
     "shell.execute_reply": "2025-08-02T11:24:51.372994Z"
    },
    "papermill": {
     "duration": 0.012679,
     "end_time": "2025-08-02T11:24:51.374550",
     "exception": false,
     "start_time": "2025-08-02T11:24:51.361871",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_feature_cols(df:DF) -> list[str]:\n",
    "    return sorted(list(set(df.columns) - set(META_DATA_COLUMNS) - set(TARGET_NAMES)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35036a5",
   "metadata": {
    "papermill": {
     "duration": 0.006863,
     "end_time": "2025-08-02T11:24:51.388547",
     "exception": false,
     "start_time": "2025-08-02T11:24:51.381684",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Supress performance warngings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b96515f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-02T11:24:51.403658Z",
     "iopub.status.busy": "2025-08-02T11:24:51.402937Z",
     "iopub.status.idle": "2025-08-02T11:24:51.406433Z",
     "shell.execute_reply": "2025-08-02T11:24:51.405940Z"
    },
    "papermill": {
     "duration": 0.011979,
     "end_time": "2025-08-02T11:24:51.407463",
     "exception": false,
     "start_time": "2025-08-02T11:24:51.395484",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    message=(\n",
    "        \"DataFrame is highly fragmented.  This is usually the result of \"\n",
    "        \"calling `frame.insert` many times.*\"\n",
    "    ),\n",
    "    category=pd.errors.PerformanceWarning,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37a42bf",
   "metadata": {
    "papermill": {
     "duration": 0.006809,
     "end_time": "2025-08-02T11:24:51.421256",
     "exception": false,
     "start_time": "2025-08-02T11:24:51.414447",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### device setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf88774f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-02T11:24:51.435856Z",
     "iopub.status.busy": "2025-08-02T11:24:51.435651Z",
     "iopub.status.idle": "2025-08-02T11:24:51.489135Z",
     "shell.execute_reply": "2025-08-02T11:24:51.488505Z"
    },
    "papermill": {
     "duration": 0.062045,
     "end_time": "2025-08-02T11:24:51.490238",
     "exception": false,
     "start_time": "2025-08-02T11:24:51.428193",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4888397a",
   "metadata": {
    "papermill": {
     "duration": 0.00725,
     "end_time": "2025-08-02T11:24:51.504769",
     "exception": false,
     "start_time": "2025-08-02T11:24:51.497519",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Dataset Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64f7616",
   "metadata": {
    "papermill": {
     "duration": 0.007032,
     "end_time": "2025-08-02T11:24:51.518918",
     "exception": false,
     "start_time": "2025-08-02T11:24:51.511886",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef222587",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-02T11:24:51.534263Z",
     "iopub.status.busy": "2025-08-02T11:24:51.533771Z",
     "iopub.status.idle": "2025-08-02T11:24:51.538733Z",
     "shell.execute_reply": "2025-08-02T11:24:51.538254Z"
    },
    "papermill": {
     "duration": 0.013617,
     "end_time": "2025-08-02T11:24:51.539757",
     "exception": false,
     "start_time": "2025-08-02T11:24:51.526140",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CMIDataset(TensorDataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        parent_dir: str,\n",
    "        split: Optional[Literal[\"train\", \"validation\"]]=None,\n",
    "        subset: Optional[int]=None,\n",
    "        force_download=False\n",
    "    ):\n",
    "        dataset_path = kagglehub.dataset_download(DATASET_HANDLE, force_download)\n",
    "        parent_dir = join(\n",
    "            dataset_path,\n",
    "            # \"preprocessed_dataset\",\n",
    "            parent_dir,\n",
    "        )\n",
    "        split = \"\" if split is None else split + \"_\"\n",
    "        x = np.load(join(parent_dir, f\"{split}X.npy\")).swapaxes(1, 2)\n",
    "        y = np.load(join(parent_dir, f\"{split}Y.npy\"))\n",
    "        if subset is not None:\n",
    "            x = x[:subset]\n",
    "            y = y[:subset]\n",
    "        super().__init__(\n",
    "            torch.from_numpy(x).to(device),\n",
    "            torch.from_numpy(y).to(device),\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d2261e",
   "metadata": {
    "papermill": {
     "duration": 0.00713,
     "end_time": "2025-08-02T11:24:51.554030",
     "exception": false,
     "start_time": "2025-08-02T11:24:51.546900",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Meta data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "890b47f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-02T11:24:51.568885Z",
     "iopub.status.busy": "2025-08-02T11:24:51.568712Z",
     "iopub.status.idle": "2025-08-02T11:24:51.754759Z",
     "shell.execute_reply": "2025-08-02T11:24:51.753849Z"
    },
    "papermill": {
     "duration": 0.194808,
     "end_time": "2025-08-02T11:24:51.755943",
     "exception": false,
     "start_time": "2025-08-02T11:24:51.561135",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acc_mag', 'acc_mag_diff', 'acc_x', 'acc_x_diff', 'acc_y', 'acc_y_diff', 'acc_z', 'acc_z_diff', 'angular_vel_x', 'angular_vel_x_diff', 'angular_vel_y', 'angular_vel_y_diff', 'angular_vel_z', 'angular_vel_z_diff', 'delta_rot_mag', 'delta_rot_mag_diff', 'euler_x', 'euler_x_diff', 'euler_y', 'euler_y_diff', 'euler_z', 'euler_z_diff', 'linear_acc_mag', 'linear_acc_mag_diff', 'linear_acc_x', 'linear_acc_x_diff', 'linear_acc_y', 'linear_acc_y_diff', 'linear_acc_z', 'linear_acc_z_diff', 'quat_rot_mag', 'quat_rot_mag_diff', 'rot_w', 'rot_w_diff', 'rot_x', 'rot_x_diff', 'rot_y', 'rot_y_diff', 'rot_z', 'rot_z_diff', 'rotation_axis_x', 'rotation_axis_x_diff', 'rotation_axis_y', 'rotation_axis_y_diff', 'rotation_axis_z', 'rotation_axis_z_diff', 'thm_1', 'thm_1_diff', 'thm_2', 'thm_2_diff', 'thm_3', 'thm_3_diff', 'thm_4', 'thm_4_diff', 'thm_5', 'thm_5_diff', 'tof_1_v00', 'tof_1_v00_diff', 'tof_1_v01', 'tof_1_v01_diff', 'tof_1_v02', 'tof_1_v02_diff', 'tof_1_v03', 'tof_1_v03_diff', 'tof_1_v04', 'tof_1_v04_diff', 'tof_1_v05', 'tof_1_v05_diff', 'tof_1_v06', 'tof_1_v06_diff', 'tof_1_v07', 'tof_1_v07_diff', 'tof_1_v08', 'tof_1_v08_diff', 'tof_1_v09', 'tof_1_v09_diff', 'tof_1_v10', 'tof_1_v10_diff', 'tof_1_v11', 'tof_1_v11_diff', 'tof_1_v12', 'tof_1_v12_diff', 'tof_1_v13', 'tof_1_v13_diff', 'tof_1_v14', 'tof_1_v14_diff', 'tof_1_v15', 'tof_1_v15_diff', 'tof_1_v16', 'tof_1_v16_diff', 'tof_1_v17', 'tof_1_v17_diff', 'tof_1_v18', 'tof_1_v18_diff', 'tof_1_v19', 'tof_1_v19_diff', 'tof_1_v20', 'tof_1_v20_diff', 'tof_1_v21', 'tof_1_v21_diff', 'tof_1_v22', 'tof_1_v22_diff', 'tof_1_v23', 'tof_1_v23_diff', 'tof_1_v24', 'tof_1_v24_diff', 'tof_1_v25', 'tof_1_v25_diff', 'tof_1_v26', 'tof_1_v26_diff', 'tof_1_v27', 'tof_1_v27_diff', 'tof_1_v28', 'tof_1_v28_diff', 'tof_1_v29', 'tof_1_v29_diff', 'tof_1_v30', 'tof_1_v30_diff', 'tof_1_v31', 'tof_1_v31_diff', 'tof_1_v32', 'tof_1_v32_diff', 'tof_1_v33', 'tof_1_v33_diff', 'tof_1_v34', 'tof_1_v34_diff', 'tof_1_v35', 'tof_1_v35_diff', 'tof_1_v36', 'tof_1_v36_diff', 'tof_1_v37', 'tof_1_v37_diff', 'tof_1_v38', 'tof_1_v38_diff', 'tof_1_v39', 'tof_1_v39_diff', 'tof_1_v40', 'tof_1_v40_diff', 'tof_1_v41', 'tof_1_v41_diff', 'tof_1_v42', 'tof_1_v42_diff', 'tof_1_v43', 'tof_1_v43_diff', 'tof_1_v44', 'tof_1_v44_diff', 'tof_1_v45', 'tof_1_v45_diff', 'tof_1_v46', 'tof_1_v46_diff', 'tof_1_v47', 'tof_1_v47_diff', 'tof_1_v48', 'tof_1_v48_diff', 'tof_1_v49', 'tof_1_v49_diff', 'tof_1_v50', 'tof_1_v50_diff', 'tof_1_v51', 'tof_1_v51_diff', 'tof_1_v52', 'tof_1_v52_diff', 'tof_1_v53', 'tof_1_v53_diff', 'tof_1_v54', 'tof_1_v54_diff', 'tof_1_v55', 'tof_1_v55_diff', 'tof_1_v56', 'tof_1_v56_diff', 'tof_1_v57', 'tof_1_v57_diff', 'tof_1_v58', 'tof_1_v58_diff', 'tof_1_v59', 'tof_1_v59_diff', 'tof_1_v60', 'tof_1_v60_diff', 'tof_1_v61', 'tof_1_v61_diff', 'tof_1_v62', 'tof_1_v62_diff', 'tof_1_v63', 'tof_1_v63_diff', 'tof_2_v00', 'tof_2_v00_diff', 'tof_2_v01', 'tof_2_v01_diff', 'tof_2_v02', 'tof_2_v02_diff', 'tof_2_v03', 'tof_2_v03_diff', 'tof_2_v04', 'tof_2_v04_diff', 'tof_2_v05', 'tof_2_v05_diff', 'tof_2_v06', 'tof_2_v06_diff', 'tof_2_v07', 'tof_2_v07_diff', 'tof_2_v08', 'tof_2_v08_diff', 'tof_2_v09', 'tof_2_v09_diff', 'tof_2_v10', 'tof_2_v10_diff', 'tof_2_v11', 'tof_2_v11_diff', 'tof_2_v12', 'tof_2_v12_diff', 'tof_2_v13', 'tof_2_v13_diff', 'tof_2_v14', 'tof_2_v14_diff', 'tof_2_v15', 'tof_2_v15_diff', 'tof_2_v16', 'tof_2_v16_diff', 'tof_2_v17', 'tof_2_v17_diff', 'tof_2_v18', 'tof_2_v18_diff', 'tof_2_v19', 'tof_2_v19_diff', 'tof_2_v20', 'tof_2_v20_diff', 'tof_2_v21', 'tof_2_v21_diff', 'tof_2_v22', 'tof_2_v22_diff', 'tof_2_v23', 'tof_2_v23_diff', 'tof_2_v24', 'tof_2_v24_diff', 'tof_2_v25', 'tof_2_v25_diff', 'tof_2_v26', 'tof_2_v26_diff', 'tof_2_v27', 'tof_2_v27_diff', 'tof_2_v28', 'tof_2_v28_diff', 'tof_2_v29', 'tof_2_v29_diff', 'tof_2_v30', 'tof_2_v30_diff', 'tof_2_v31', 'tof_2_v31_diff', 'tof_2_v32', 'tof_2_v32_diff', 'tof_2_v33', 'tof_2_v33_diff', 'tof_2_v34', 'tof_2_v34_diff', 'tof_2_v35', 'tof_2_v35_diff', 'tof_2_v36', 'tof_2_v36_diff', 'tof_2_v37', 'tof_2_v37_diff', 'tof_2_v38', 'tof_2_v38_diff', 'tof_2_v39', 'tof_2_v39_diff', 'tof_2_v40', 'tof_2_v40_diff', 'tof_2_v41', 'tof_2_v41_diff', 'tof_2_v42', 'tof_2_v42_diff', 'tof_2_v43', 'tof_2_v43_diff', 'tof_2_v44', 'tof_2_v44_diff', 'tof_2_v45', 'tof_2_v45_diff', 'tof_2_v46', 'tof_2_v46_diff', 'tof_2_v47', 'tof_2_v47_diff', 'tof_2_v48', 'tof_2_v48_diff', 'tof_2_v49', 'tof_2_v49_diff', 'tof_2_v50', 'tof_2_v50_diff', 'tof_2_v51', 'tof_2_v51_diff', 'tof_2_v52', 'tof_2_v52_diff', 'tof_2_v53', 'tof_2_v53_diff', 'tof_2_v54', 'tof_2_v54_diff', 'tof_2_v55', 'tof_2_v55_diff', 'tof_2_v56', 'tof_2_v56_diff', 'tof_2_v57', 'tof_2_v57_diff', 'tof_2_v58', 'tof_2_v58_diff', 'tof_2_v59', 'tof_2_v59_diff', 'tof_2_v60', 'tof_2_v60_diff', 'tof_2_v61', 'tof_2_v61_diff', 'tof_2_v62', 'tof_2_v62_diff', 'tof_2_v63', 'tof_2_v63_diff', 'tof_3_v00', 'tof_3_v00_diff', 'tof_3_v01', 'tof_3_v01_diff', 'tof_3_v02', 'tof_3_v02_diff', 'tof_3_v03', 'tof_3_v03_diff', 'tof_3_v04', 'tof_3_v04_diff', 'tof_3_v05', 'tof_3_v05_diff', 'tof_3_v06', 'tof_3_v06_diff', 'tof_3_v07', 'tof_3_v07_diff', 'tof_3_v08', 'tof_3_v08_diff', 'tof_3_v09', 'tof_3_v09_diff', 'tof_3_v10', 'tof_3_v10_diff', 'tof_3_v11', 'tof_3_v11_diff', 'tof_3_v12', 'tof_3_v12_diff', 'tof_3_v13', 'tof_3_v13_diff', 'tof_3_v14', 'tof_3_v14_diff', 'tof_3_v15', 'tof_3_v15_diff', 'tof_3_v16', 'tof_3_v16_diff', 'tof_3_v17', 'tof_3_v17_diff', 'tof_3_v18', 'tof_3_v18_diff', 'tof_3_v19', 'tof_3_v19_diff', 'tof_3_v20', 'tof_3_v20_diff', 'tof_3_v21', 'tof_3_v21_diff', 'tof_3_v22', 'tof_3_v22_diff', 'tof_3_v23', 'tof_3_v23_diff', 'tof_3_v24', 'tof_3_v24_diff', 'tof_3_v25', 'tof_3_v25_diff', 'tof_3_v26', 'tof_3_v26_diff', 'tof_3_v27', 'tof_3_v27_diff', 'tof_3_v28', 'tof_3_v28_diff', 'tof_3_v29', 'tof_3_v29_diff', 'tof_3_v30', 'tof_3_v30_diff', 'tof_3_v31', 'tof_3_v31_diff', 'tof_3_v32', 'tof_3_v32_diff', 'tof_3_v33', 'tof_3_v33_diff', 'tof_3_v34', 'tof_3_v34_diff', 'tof_3_v35', 'tof_3_v35_diff', 'tof_3_v36', 'tof_3_v36_diff', 'tof_3_v37', 'tof_3_v37_diff', 'tof_3_v38', 'tof_3_v38_diff', 'tof_3_v39', 'tof_3_v39_diff', 'tof_3_v40', 'tof_3_v40_diff', 'tof_3_v41', 'tof_3_v41_diff', 'tof_3_v42', 'tof_3_v42_diff', 'tof_3_v43', 'tof_3_v43_diff', 'tof_3_v44', 'tof_3_v44_diff', 'tof_3_v45', 'tof_3_v45_diff', 'tof_3_v46', 'tof_3_v46_diff', 'tof_3_v47', 'tof_3_v47_diff', 'tof_3_v48', 'tof_3_v48_diff', 'tof_3_v49', 'tof_3_v49_diff', 'tof_3_v50', 'tof_3_v50_diff', 'tof_3_v51', 'tof_3_v51_diff', 'tof_3_v52', 'tof_3_v52_diff', 'tof_3_v53', 'tof_3_v53_diff', 'tof_3_v54', 'tof_3_v54_diff', 'tof_3_v55', 'tof_3_v55_diff', 'tof_3_v56', 'tof_3_v56_diff', 'tof_3_v57', 'tof_3_v57_diff', 'tof_3_v58', 'tof_3_v58_diff', 'tof_3_v59', 'tof_3_v59_diff', 'tof_3_v60', 'tof_3_v60_diff', 'tof_3_v61', 'tof_3_v61_diff', 'tof_3_v62', 'tof_3_v62_diff', 'tof_3_v63', 'tof_3_v63_diff', 'tof_4_v00', 'tof_4_v00_diff', 'tof_4_v01', 'tof_4_v01_diff', 'tof_4_v02', 'tof_4_v02_diff', 'tof_4_v03', 'tof_4_v03_diff', 'tof_4_v04', 'tof_4_v04_diff', 'tof_4_v05', 'tof_4_v05_diff', 'tof_4_v06', 'tof_4_v06_diff', 'tof_4_v07', 'tof_4_v07_diff', 'tof_4_v08', 'tof_4_v08_diff', 'tof_4_v09', 'tof_4_v09_diff', 'tof_4_v10', 'tof_4_v10_diff', 'tof_4_v11', 'tof_4_v11_diff', 'tof_4_v12', 'tof_4_v12_diff', 'tof_4_v13', 'tof_4_v13_diff', 'tof_4_v14', 'tof_4_v14_diff', 'tof_4_v15', 'tof_4_v15_diff', 'tof_4_v16', 'tof_4_v16_diff', 'tof_4_v17', 'tof_4_v17_diff', 'tof_4_v18', 'tof_4_v18_diff', 'tof_4_v19', 'tof_4_v19_diff', 'tof_4_v20', 'tof_4_v20_diff', 'tof_4_v21', 'tof_4_v21_diff', 'tof_4_v22', 'tof_4_v22_diff', 'tof_4_v23', 'tof_4_v23_diff', 'tof_4_v24', 'tof_4_v24_diff', 'tof_4_v25', 'tof_4_v25_diff', 'tof_4_v26', 'tof_4_v26_diff', 'tof_4_v27', 'tof_4_v27_diff', 'tof_4_v28', 'tof_4_v28_diff', 'tof_4_v29', 'tof_4_v29_diff', 'tof_4_v30', 'tof_4_v30_diff', 'tof_4_v31', 'tof_4_v31_diff', 'tof_4_v32', 'tof_4_v32_diff', 'tof_4_v33', 'tof_4_v33_diff', 'tof_4_v34', 'tof_4_v34_diff', 'tof_4_v35', 'tof_4_v35_diff', 'tof_4_v36', 'tof_4_v36_diff', 'tof_4_v37', 'tof_4_v37_diff', 'tof_4_v38', 'tof_4_v38_diff', 'tof_4_v39', 'tof_4_v39_diff', 'tof_4_v40', 'tof_4_v40_diff', 'tof_4_v41', 'tof_4_v41_diff', 'tof_4_v42', 'tof_4_v42_diff', 'tof_4_v43', 'tof_4_v43_diff', 'tof_4_v44', 'tof_4_v44_diff', 'tof_4_v45', 'tof_4_v45_diff', 'tof_4_v46', 'tof_4_v46_diff', 'tof_4_v47', 'tof_4_v47_diff', 'tof_4_v48', 'tof_4_v48_diff', 'tof_4_v49', 'tof_4_v49_diff', 'tof_4_v50', 'tof_4_v50_diff', 'tof_4_v51', 'tof_4_v51_diff', 'tof_4_v52', 'tof_4_v52_diff', 'tof_4_v53', 'tof_4_v53_diff', 'tof_4_v54', 'tof_4_v54_diff', 'tof_4_v55', 'tof_4_v55_diff', 'tof_4_v56', 'tof_4_v56_diff', 'tof_4_v57', 'tof_4_v57_diff', 'tof_4_v58', 'tof_4_v58_diff', 'tof_4_v59', 'tof_4_v59_diff', 'tof_4_v60', 'tof_4_v60_diff', 'tof_4_v61', 'tof_4_v61_diff', 'tof_4_v62', 'tof_4_v62_diff', 'tof_4_v63', 'tof_4_v63_diff', 'tof_5_v00', 'tof_5_v00_diff', 'tof_5_v01', 'tof_5_v01_diff', 'tof_5_v02', 'tof_5_v02_diff', 'tof_5_v03', 'tof_5_v03_diff', 'tof_5_v04', 'tof_5_v04_diff', 'tof_5_v05', 'tof_5_v05_diff', 'tof_5_v06', 'tof_5_v06_diff', 'tof_5_v07', 'tof_5_v07_diff', 'tof_5_v08', 'tof_5_v08_diff', 'tof_5_v09', 'tof_5_v09_diff', 'tof_5_v10', 'tof_5_v10_diff', 'tof_5_v11', 'tof_5_v11_diff', 'tof_5_v12', 'tof_5_v12_diff', 'tof_5_v13', 'tof_5_v13_diff', 'tof_5_v14', 'tof_5_v14_diff', 'tof_5_v15', 'tof_5_v15_diff', 'tof_5_v16', 'tof_5_v16_diff', 'tof_5_v17', 'tof_5_v17_diff', 'tof_5_v18', 'tof_5_v18_diff', 'tof_5_v19', 'tof_5_v19_diff', 'tof_5_v20', 'tof_5_v20_diff', 'tof_5_v21', 'tof_5_v21_diff', 'tof_5_v22', 'tof_5_v22_diff', 'tof_5_v23', 'tof_5_v23_diff', 'tof_5_v24', 'tof_5_v24_diff', 'tof_5_v25', 'tof_5_v25_diff', 'tof_5_v26', 'tof_5_v26_diff', 'tof_5_v27', 'tof_5_v27_diff', 'tof_5_v28', 'tof_5_v28_diff', 'tof_5_v29', 'tof_5_v29_diff', 'tof_5_v30', 'tof_5_v30_diff', 'tof_5_v31', 'tof_5_v31_diff', 'tof_5_v32', 'tof_5_v32_diff', 'tof_5_v33', 'tof_5_v33_diff', 'tof_5_v34', 'tof_5_v34_diff', 'tof_5_v35', 'tof_5_v35_diff', 'tof_5_v36', 'tof_5_v36_diff', 'tof_5_v37', 'tof_5_v37_diff', 'tof_5_v38', 'tof_5_v38_diff', 'tof_5_v39', 'tof_5_v39_diff', 'tof_5_v40', 'tof_5_v40_diff', 'tof_5_v41', 'tof_5_v41_diff', 'tof_5_v42', 'tof_5_v42_diff', 'tof_5_v43', 'tof_5_v43_diff', 'tof_5_v44', 'tof_5_v44_diff', 'tof_5_v45', 'tof_5_v45_diff', 'tof_5_v46', 'tof_5_v46_diff', 'tof_5_v47', 'tof_5_v47_diff', 'tof_5_v48', 'tof_5_v48_diff', 'tof_5_v49', 'tof_5_v49_diff', 'tof_5_v50', 'tof_5_v50_diff', 'tof_5_v51', 'tof_5_v51_diff', 'tof_5_v52', 'tof_5_v52_diff', 'tof_5_v53', 'tof_5_v53_diff', 'tof_5_v54', 'tof_5_v54_diff', 'tof_5_v55', 'tof_5_v55_diff', 'tof_5_v56', 'tof_5_v56_diff', 'tof_5_v57', 'tof_5_v57_diff', 'tof_5_v58', 'tof_5_v58_diff', 'tof_5_v59', 'tof_5_v59_diff', 'tof_5_v60', 'tof_5_v60_diff', 'tof_5_v61', 'tof_5_v61_diff', 'tof_5_v62', 'tof_5_v62_diff', 'tof_5_v63', 'tof_5_v63_diff']\n",
      "tof_feats_idx: [56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695]\n",
      "thm_feats_idx: [46, 47, 48, 49, 50, 51, 52, 53, 54, 55]\n",
      "imu_feats_idx: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45]\n"
     ]
    }
   ],
   "source": [
    "dataset_path = kagglehub.dataset_download(DATASET_HANDLE)\n",
    "meta_data_path = join(\n",
    "    dataset_path,\n",
    "    # \"preprocessed_dataset\",\n",
    "    \"full_dataset_meta_data.json\"\n",
    ")\n",
    "with open(meta_data_path, \"r\") as fp:\n",
    "    meta_data = json.load(fp)\n",
    "# Convert target names into a ndarray to index it batchwise.\n",
    "def get_sensor_indices(sensor_prefix: str) -> list[int]:\n",
    "    is_sensor_feat = methodcaller(\"startswith\", sensor_prefix)\n",
    "    return [feat_idx for feat_idx, feat in enumerate(meta_data[\"feature_cols\"]) if is_sensor_feat(feat)]\n",
    "\n",
    "tof_idx = get_sensor_indices(\"tof\")\n",
    "thm_idx = get_sensor_indices(\"thm\")\n",
    "imu_idx = list(filter(lambda idx: idx not in tof_idx + thm_idx, range(len(meta_data[\"feature_cols\"]))))\n",
    "\n",
    "print(meta_data[\"feature_cols\"])\n",
    "print(\"tof_feats_idx:\", tof_idx)\n",
    "print(\"thm_feats_idx:\", thm_idx)\n",
    "print(\"imu_feats_idx:\", imu_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ddefc4c",
   "metadata": {
    "papermill": {
     "duration": 0.007225,
     "end_time": "2025-08-02T11:24:51.770769",
     "exception": false,
     "start_time": "2025-08-02T11:24:51.763544",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Compute class weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e063e9f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-02T11:24:51.786019Z",
     "iopub.status.busy": "2025-08-02T11:24:51.785779Z",
     "iopub.status.idle": "2025-08-02T11:24:51.790604Z",
     "shell.execute_reply": "2025-08-02T11:24:51.789911Z"
    },
    "papermill": {
     "duration": 0.013633,
     "end_time": "2025-08-02T11:24:51.791639",
     "exception": false,
     "start_time": "2025-08-02T11:24:51.778006",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_weighted_cross_entropy_loss(\n",
    "    dataset: Dataset[tuple[torch.Tensor, torch.Tensor]]\n",
    ") -> nn.CrossEntropyLoss:\n",
    "    \"\"\"\n",
    "    Computes class weights from a dataset with one-hot encoded targets and returns a CrossEntropyLoss with those weights.\n",
    "\n",
    "    Args:\n",
    "        dataset: A PyTorch Dataset that yields (x, y) where y is a one-hot encoded tensor of shape (num_classes,)\n",
    "\n",
    "    Returns:\n",
    "        A torch.nn.CrossEntropyLoss object with class weights based on inverse class frequency.\n",
    "    \"\"\"\n",
    "    class_counts: Counter = Counter()\n",
    "    num_samples = 0\n",
    "\n",
    "    for _, y in dataset:\n",
    "        class_idx = y.argmax().item()\n",
    "        class_counts[class_idx] += 1\n",
    "        num_samples += 1\n",
    "\n",
    "    num_classes = len(class_counts)\n",
    "    weights = torch.tensor(\n",
    "        [num_samples / class_counts[i] for i in range(num_classes)],\n",
    "        dtype=torch.float32,\n",
    "    )\n",
    "\n",
    "    # Optional: normalize weights so they sum to 1\n",
    "    weights = weights / weights.sum()\n",
    "\n",
    "    return nn.CrossEntropyLoss(weight=weights.to(device))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21991d61",
   "metadata": {
    "papermill": {
     "duration": 0.007201,
     "end_time": "2025-08-02T11:24:51.806304",
     "exception": false,
     "start_time": "2025-08-02T11:24:51.799103",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### BFRBs indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e2b8864b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-02T11:24:51.821785Z",
     "iopub.status.busy": "2025-08-02T11:24:51.821390Z",
     "iopub.status.idle": "2025-08-02T11:25:20.508716Z",
     "shell.execute_reply": "2025-08-02T11:25:20.507884Z"
    },
    "papermill": {
     "duration": 28.696544,
     "end_time": "2025-08-02T11:25:20.510088",
     "exception": false,
     "start_time": "2025-08-02T11:24:51.813544",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets...\n",
      "Train rows: 574945, Test rows: 107\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading datasets...\")\n",
    "competition_dataset_path = kagglehub.competition_download(COMPETITION_HANDLE)\n",
    "train_df = pd.read_csv(join(competition_dataset_path, \"train.csv\"))\n",
    "train_dem_df = pd.read_csv(join(competition_dataset_path, \"train_demographics.csv\"))\n",
    "test_df = pd.read_csv(join(competition_dataset_path, \"test.csv\"))\n",
    "test_dem_df = pd.read_csv(join(competition_dataset_path, \"test_demographics.csv\"))\n",
    "print(f\"Train rows: {len(train_df)}, Test rows: {len(test_df)}\")\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "train_df['gesture'] = label_encoder.fit_transform(train_df['gesture'].astype(str))\n",
    "gesture_classes = label_encoder.classes_\n",
    "\n",
    "bfrb_gestures = [\n",
    "    'Above ear - pull hair',\n",
    "    'Forehead - pull hairline',\n",
    "    'Forehead - scratch',\n",
    "    'Eyebrow - pull hair',\n",
    "    'Eyelash - pull hair',\n",
    "    'Neck - pinch skin',\n",
    "    'Neck - scratch',\n",
    "    'Cheek - pinch skin'\n",
    "]\n",
    "bfrb_indices = label_encoder.transform(bfrb_gestures)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e5953f",
   "metadata": {
    "papermill": {
     "duration": 0.008669,
     "end_time": "2025-08-02T11:25:20.526925",
     "exception": false,
     "start_time": "2025-08-02T11:25:20.518256",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a54f9ce8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-02T11:25:20.542848Z",
     "iopub.status.busy": "2025-08-02T11:25:20.542635Z",
     "iopub.status.idle": "2025-08-02T11:25:20.549658Z",
     "shell.execute_reply": "2025-08-02T11:25:20.549107Z"
    },
    "papermill": {
     "duration": 0.016225,
     "end_time": "2025-08-02T11:25:20.550737",
     "exception": false,
     "start_time": "2025-08-02T11:25:20.534512",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CosineAnnealingWarmupRestarts(_LRScheduler):\n",
    "    def __init__(\n",
    "        self,\n",
    "        optimizer: Optimizer,\n",
    "        warmup_steps: int,\n",
    "        max_lr: float,\n",
    "        min_lr: float,\n",
    "        cycle_length: int,\n",
    "        cycle_mult: float = 1.0,\n",
    "        gamma: float = 1.0,\n",
    "        last_epoch: int = -1,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            optimizer: Wrapped optimizer.\n",
    "            warmup_steps: Number of steps for linear warmup.\n",
    "            max_lr: Initial maximum learning rate.\n",
    "            min_lr: Minimum learning rate after decay.\n",
    "            cycle_length: Initial number of steps per cosine cycle.\n",
    "            cycle_mult: Multiplicative factor for increasing cycle lengths.\n",
    "            gamma: Multiplicative decay factor for max_lr after each cycle.\n",
    "            last_epoch: The index of last epoch. Default: -1.\n",
    "        \"\"\"\n",
    "        self.warmup_steps = warmup_steps\n",
    "        self.max_lr = max_lr\n",
    "        self.min_lr = min_lr\n",
    "        self.cycle_length = cycle_length\n",
    "        self.cycle_mult = cycle_mult\n",
    "        self.gamma = gamma\n",
    "\n",
    "        self.current_cycle = 0\n",
    "        self.cycle_step = 0\n",
    "        self.lr = max_lr\n",
    "\n",
    "        super().__init__(optimizer, last_epoch)\n",
    "\n",
    "    def get_lr(self) -> list[float]:\n",
    "        if self.last_epoch < self.warmup_steps:\n",
    "            # Linear warmup\n",
    "            scale = (self.last_epoch + 1) / self.warmup_steps\n",
    "            return [self.min_lr + scale * (self.max_lr - self.min_lr) for _ in self.base_lrs]\n",
    "\n",
    "        # Adjust for post-warmup step index\n",
    "        t = self.cycle_step\n",
    "        T = self.cycle_length\n",
    "\n",
    "        cosine_decay = 0.5 * (1 + math.cos(math.pi * t / T))\n",
    "        lr = self.min_lr + (self.max_lr - self.min_lr) * cosine_decay\n",
    "\n",
    "        return [lr for _ in self.base_lrs]\n",
    "\n",
    "    def step(self, epoch: Optional[int] = None) -> None:\n",
    "        if self.last_epoch >= self.warmup_steps:\n",
    "            self.cycle_step += 1\n",
    "            if self.cycle_step >= self.cycle_length:\n",
    "                self.current_cycle += 1\n",
    "                self.cycle_step = 0\n",
    "                self.cycle_length = max(int(self.cycle_length * self.cycle_mult), 1)\n",
    "                self.max_lr *= self.gamma\n",
    "        super().step(epoch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86df0ba2",
   "metadata": {
    "papermill": {
     "duration": 0.007266,
     "end_time": "2025-08-02T11:25:20.565558",
     "exception": false,
     "start_time": "2025-08-02T11:25:20.558292",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f99a499a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-02T11:25:20.581200Z",
     "iopub.status.busy": "2025-08-02T11:25:20.581013Z",
     "iopub.status.idle": "2025-08-02T11:25:20.601366Z",
     "shell.execute_reply": "2025-08-02T11:25:20.600664Z"
    },
    "papermill": {
     "duration": 0.029642,
     "end_time": "2025-08-02T11:25:20.602493",
     "exception": false,
     "start_time": "2025-08-02T11:25:20.572851",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MultiScaleConvs(nn.Module):\n",
    "    def __init__(self, in_channels:int, kernel_sizes:list[int]):\n",
    "        super().__init__()\n",
    "        def mk_conv_block(k_size) -> nn.Sequential:\n",
    "            return nn.Sequential(\n",
    "                nn.Conv1d(in_channels, in_channels, k_size, padding=k_size // 2, groups=in_channels),\n",
    "                nn.BatchNorm1d(in_channels),\n",
    "                nn.ReLU(),\n",
    "            )\n",
    "        self.convs = nn.ModuleList(map(mk_conv_block, kernel_sizes))\n",
    "\n",
    "    def forward(self, x:Tensor) -> Tensor:\n",
    "        yes = torch.cat([conv(x) for conv in self.convs] + [x], dim=1)\n",
    "        # print(\"stem output shape:\", yes.shape)\n",
    "        return yes\n",
    "\n",
    "class ImuFeatureExtractor(nn.Module):\n",
    "    def __init__(self, in_channels:int, kernel_size:int=15):\n",
    "        super().__init__()\n",
    "\n",
    "        self.lpf = nn.Conv1d(\n",
    "            in_channels,\n",
    "            in_channels,\n",
    "            kernel_size=kernel_size,\n",
    "            padding=kernel_size//2,\n",
    "            groups=in_channels,\n",
    "            bias=False,\n",
    "        )\n",
    "        nn.init.kaiming_uniform_(self.lpf.weight, a=math.sqrt(5))\n",
    "\n",
    "    def forward(self, x:Tensor) -> Tensor:\n",
    "        lpf_output = self.lpf(x)\n",
    "        hpf_output = x - lpf_output\n",
    "        return torch.cat((lpf_output, hpf_output, x), dim=1)  # (B, C_out, T)\n",
    "\n",
    "class SqueezeExcitationBlock(nn.Module):\n",
    "    # Copy/paste of https://www.kaggle.com/code/wasupandceacar/lb-0-82-5fold-single-bert-model#Model implementation\n",
    "    def __init__(self, channels:int, reduction:int=8):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(channels, channels // reduction, bias=True)\n",
    "        self.fc2 = nn.Linear(channels // reduction, channels, bias=True)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, C, L)\n",
    "        se = F.adaptive_avg_pool1d(x, 1).squeeze(-1)      # -> (B, C)\n",
    "        se = F.relu(self.fc1(se), inplace=True)          # -> (B, C//r)\n",
    "        se = self.sigmoid(self.fc2(se)).unsqueeze(-1)    # -> (B, C, 1)\n",
    "        return x * se\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_chns:int, out_chns:int, dropout_ratio:float=0.3, se_reduction:int=8, kernel_size:int=3):\n",
    "        super().__init__()\n",
    "        self.blocks = nn.Sequential(\n",
    "            nn.Conv1d(in_chns, out_chns, kernel_size=kernel_size, padding=kernel_size // 2, bias=False),\n",
    "            nn.BatchNorm1d(out_chns),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(out_chns, out_chns, kernel_size=kernel_size, padding=kernel_size // 2, bias=False),\n",
    "            nn.BatchNorm1d(out_chns),\n",
    "            SqueezeExcitationBlock(out_chns, se_reduction),\n",
    "        )\n",
    "        self.head = nn.Sequential(nn.ReLU(), nn.Dropout(dropout_ratio))\n",
    "        if in_chns == out_chns:\n",
    "            self.skip_connection = nn.Identity() \n",
    "        else:\n",
    "            # TODO: set bias to False ?\n",
    "            self.skip_connection = nn.Sequential(\n",
    "                nn.Conv1d(in_chns, out_chns, 1, bias=False),\n",
    "                nn.BatchNorm1d(out_chns)\n",
    "            )\n",
    "            self.head.insert(1, nn.MaxPool1d(2))\n",
    "\n",
    "    def forward(self, x:Tensor) -> Tensor:\n",
    "        activaition_maps = self.skip_connection(x) + self.blocks(x)\n",
    "        return self.head(activaition_maps)\n",
    "\n",
    "class MBConvBlock(nn.Module):\n",
    "    # From this schema: https://media.licdn.com/dms/image/v2/D5612AQFjbDOm5uyxdw/article-inline_image-shrink_1500_2232/article-inline_image-shrink_1500_2232/0/1683677500817?e=1758153600&v=beta&t=n48_UW5TZTyDPhRFlJXSidUQQPQpuC756M0kNeKmYTY\n",
    "    def __init__(self, in_chns:int, out_chns:int, se_reduction:int=8, expansion_ratio:int=4, dropout_ratio:float=0.3):\n",
    "        super().__init__()\n",
    "        expanded_channels = in_chns * expansion_ratio\n",
    "        self.blocks = nn.Sequential(\n",
    "            nn.Conv1d(in_chns, expanded_channels, kernel_size=1, bias=False),\n",
    "            nn.BatchNorm1d(expanded_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(\n",
    "                expanded_channels,\n",
    "                expanded_channels,\n",
    "                kernel_size=3,\n",
    "                padding=1,\n",
    "                groups=expanded_channels,\n",
    "                bias=False,\n",
    "            ),\n",
    "            nn.BatchNorm1d(expanded_channels),\n",
    "            nn.ReLU(),\n",
    "            SqueezeExcitationBlock(expanded_channels, se_reduction),\n",
    "            nn.Conv1d(expanded_channels, out_chns, kernel_size=1, bias=False)\n",
    "        )\n",
    "        self.head = nn.Sequential(\n",
    "            nn.BatchNorm1d(out_chns)\n",
    "            # nn.ReLU(),\n",
    "            # nn.Dropout(dropout_ratio),\n",
    "        )\n",
    "        if in_chns == out_chns:\n",
    "            self.skip_connection = nn.Identity() \n",
    "        else:\n",
    "            # TODO: set bias to False ?\n",
    "            self.skip_connection = nn.Sequential(\n",
    "                nn.Conv1d(in_chns, out_chns, 1, bias=False),\n",
    "                nn.BatchNorm1d(out_chns)\n",
    "            )\n",
    "            self.head.add_module(\"max_pool\", nn.MaxPool1d(2))\n",
    "            \n",
    "    def forward(self, x:Tensor) -> Tensor:\n",
    "        activaition_maps = self.skip_connection(x) + self.blocks(x)\n",
    "        return self.head(activaition_maps)\n",
    "\n",
    "class AdditiveAttentionLayer(nn.Module):\n",
    "    # Copied (and slightly modified) from https://www.kaggle.com/code/myso1987/cmi3-pyroch-baseline-model-add-aug-folds\n",
    "    def __init__(self, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.attention = nn.Linear(hidden_dim, 1, bias=True)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        # x shape: (batch, channels, seq_len)\n",
    "        x = x.swapaxes(1, 2)\n",
    "        # x shape: (batch, seq_len, hidden_dim)\n",
    "        scores = torch.tanh(self.attention(x))  # (batch, seq_len, 1)\n",
    "        weights = F.softmax(scores.squeeze(-1), dim=1)  # (batch, seq_len)\n",
    "        context = torch.sum(x * weights.unsqueeze(-1), dim=1)  # (batch, hidden_dim)\n",
    "        return context\n",
    "\n",
    "class AlexNet(nn.Sequential):\n",
    "    def __init__(self, channels:list[int], dropout_ratio:float):\n",
    "        def mk_conv_block(in_channels:int, out_channels:int) -> nn.Module:\n",
    "            return nn.Sequential(\n",
    "                nn.Conv1d(in_channels, out_channels, 3, padding=1, bias=False),\n",
    "                nn.BatchNorm1d(out_channels),\n",
    "                nn.MaxPool1d(2),\n",
    "                nn.Dropout(dropout_ratio),\n",
    "            )\n",
    "        return super().__init__(*list(starmap(mk_conv_block, pairwise(channels))))\n",
    "\n",
    "class CMIHARModule(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            imu_idx:list[int],\n",
    "            thm_idx:list[int],\n",
    "            tof_idx:list[int],\n",
    "            mlp_width:int,\n",
    "            n_class:int,            \n",
    "            tof_dropout_ratio:float=0,\n",
    "            thm_dropout_ratio:float=0,\n",
    "        ):\n",
    "        super().__init__()\n",
    "        self.imu_idx = imu_idx\n",
    "        self.tof_idx = tof_idx\n",
    "        self.thm_idx = thm_idx\n",
    "        self.imu_branch = nn.Sequential(\n",
    "            # ImuFeatureExtractor(len(imu_idx)),\n",
    "            ResidualBlock(len(imu_idx), 219),\n",
    "            ResidualBlock(219, 500),\n",
    "        )\n",
    "        self.tof_branch = AlexNet([len(tof_idx), 82, 500], tof_dropout_ratio)\n",
    "        self.thm_branch = AlexNet([len(thm_idx), 82, 500], thm_dropout_ratio)\n",
    "        self.rnn = nn.GRU(500 * 3, mlp_width // 2, bidirectional=True)\n",
    "        self.attention = AdditiveAttentionLayer(mlp_width)\n",
    "        self.head = nn.Sequential(\n",
    "            # Head\n",
    "            nn.LazyLinear(mlp_width, bias=False),\n",
    "            nn.BatchNorm1d(mlp_width),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(mlp_width, mlp_width // 2, bias=False),\n",
    "            nn.BatchNorm1d(mlp_width // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(mlp_width // 2, n_class),\n",
    "        )\n",
    "\n",
    "    def forward(self, x:Tensor) -> Tensor:\n",
    "        concatenated_activation_maps = torch.cat(\n",
    "            (\n",
    "                self.imu_branch(x[:, self.imu_idx]),\n",
    "                self.thm_branch(x[:, self.thm_idx]),\n",
    "                self.tof_branch(x[:, self.tof_idx]),\n",
    "            ),\n",
    "            dim=CHANNELS_DIMENSION,\n",
    "        )\n",
    "        lstm_output, _  = self.rnn(concatenated_activation_maps.swapaxes(1, 2))\n",
    "        lstm_output = lstm_output.swapaxes(1, 2) # redundant\n",
    "        attended = self.attention(lstm_output)\n",
    "        return self.head(attended)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999a5ac6",
   "metadata": {
    "papermill": {
     "duration": 0.007331,
     "end_time": "2025-08-02T11:25:20.617266",
     "exception": false,
     "start_time": "2025-08-02T11:25:20.609935",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Create model function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d55cb1b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-02T11:25:20.632982Z",
     "iopub.status.busy": "2025-08-02T11:25:20.632760Z",
     "iopub.status.idle": "2025-08-02T11:25:20.929218Z",
     "shell.execute_reply": "2025-08-02T11:25:20.928490Z"
    },
    "papermill": {
     "duration": 0.305529,
     "end_time": "2025-08-02T11:25:20.930258",
     "exception": false,
     "start_time": "2025-08-02T11:25:20.624729",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CMIHARModule(\n",
       "  (imu_branch): Sequential(\n",
       "    (0): ResidualBlock(\n",
       "      (blocks): Sequential(\n",
       "        (0): Conv1d(46, 219, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "        (1): BatchNorm1d(219, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv1d(219, 219, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "        (4): BatchNorm1d(219, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): SqueezeExcitationBlock(\n",
       "          (fc1): Linear(in_features=219, out_features=27, bias=True)\n",
       "          (fc2): Linear(in_features=27, out_features=219, bias=True)\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (head): Sequential(\n",
       "        (0): ReLU()\n",
       "        (1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (2): Dropout(p=0.3, inplace=False)\n",
       "      )\n",
       "      (skip_connection): Sequential(\n",
       "        (0): Conv1d(46, 219, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        (1): BatchNorm1d(219, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): ResidualBlock(\n",
       "      (blocks): Sequential(\n",
       "        (0): Conv1d(219, 500, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "        (1): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv1d(500, 500, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "        (4): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): SqueezeExcitationBlock(\n",
       "          (fc1): Linear(in_features=500, out_features=62, bias=True)\n",
       "          (fc2): Linear(in_features=62, out_features=500, bias=True)\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (head): Sequential(\n",
       "        (0): ReLU()\n",
       "        (1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (2): Dropout(p=0.3, inplace=False)\n",
       "      )\n",
       "      (skip_connection): Sequential(\n",
       "        (0): Conv1d(219, 500, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        (1): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (tof_branch): AlexNet(\n",
       "    (0): Sequential(\n",
       "      (0): Conv1d(640, 82, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "      (1): BatchNorm1d(82, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (3): Dropout(p=0, inplace=False)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Conv1d(82, 500, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "      (1): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (3): Dropout(p=0, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (thm_branch): AlexNet(\n",
       "    (0): Sequential(\n",
       "      (0): Conv1d(10, 82, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "      (1): BatchNorm1d(82, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (3): Dropout(p=0, inplace=False)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Conv1d(82, 500, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "      (1): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (3): Dropout(p=0, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (rnn): GRU(1500, 128, bidirectional=True)\n",
       "  (attention): AdditiveAttentionLayer(\n",
       "    (attention): Linear(in_features=256, out_features=1, bias=True)\n",
       "  )\n",
       "  (head): Sequential(\n",
       "    (0): LazyLinear(in_features=0, out_features=256, bias=False)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=128, bias=False)\n",
       "    (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=128, out_features=18, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input channels: 696\n"
     ]
    }
   ],
   "source": [
    "def mk_model() -> nn.Module:\n",
    "    return (\n",
    "        CMIHARModule(\n",
    "            imu_idx=imu_idx,\n",
    "            thm_idx=thm_idx,\n",
    "            tof_idx=tof_idx,\n",
    "            mlp_width=256,\n",
    "            n_class=18,\n",
    "        )\n",
    "        .to(device)\n",
    "    )\n",
    "\n",
    "display(mk_model())\n",
    "print(\"input channels:\", len(meta_data[\"feature_cols\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91839897",
   "metadata": {
    "papermill": {
     "duration": 0.007408,
     "end_time": "2025-08-02T11:25:20.945773",
     "exception": false,
     "start_time": "2025-08-02T11:25:20.938365",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "23ef1199",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-02T11:25:20.961733Z",
     "iopub.status.busy": "2025-08-02T11:25:20.961500Z",
     "iopub.status.idle": "2025-08-02T11:25:20.970861Z",
     "shell.execute_reply": "2025-08-02T11:25:20.970195Z"
    },
    "papermill": {
     "duration": 0.018784,
     "end_time": "2025-08-02T11:25:20.972026",
     "exception": false,
     "start_time": "2025-08-02T11:25:20.953242",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fit(epochs:int,\n",
    "        model: nn.Module,\n",
    "        scheduler: LRScheduler,\n",
    "        optimizer: torch.optim.Optimizer,\n",
    "        train_loader: DL,\n",
    "        criterion: callable=nn.L1Loss(),\n",
    "        evaluation_func: callable=None,\n",
    "        validation_loader: DL=None,\n",
    "        save_checkpoints=True,\n",
    "    ) -> tuple[DF, str]:\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "        (training_metrics, path_to_checkpoints)\n",
    "    \"\"\"\n",
    "    # Setup\n",
    "    metrics: list[dict] = []\n",
    "    step = 0\n",
    "    model_device = next(model.parameters()).device\n",
    "    last_epoch_metric = {}\n",
    "    # Training loop\n",
    "    with Progress() as progress:\n",
    "        task: Task = progress.add_task(\n",
    "            \"training...\",\n",
    "            total=len(train_loader),\n",
    "        )\n",
    "        for epoch in range(epochs):\n",
    "            progress.update(\n",
    "                task,\n",
    "                description=f\"epoch: {epoch}\",\n",
    "                completed=0,\n",
    "            )\n",
    "            total_epoch_loss = 0\n",
    "            total_accuracy = 0\n",
    "            for batch_idx, (x, y) in enumerate(train_loader):\n",
    "                # forward\n",
    "                x = x.to(model_device)\n",
    "                y = y.to(model_device)\n",
    "                model.train()\n",
    "                optimizer.zero_grad()\n",
    "                y_pred: Tensor = model(x)\n",
    "                loss_value = criterion(y_pred, y)\n",
    "                # Verify loss value\n",
    "                if torch.isnan(loss_value).any().item():\n",
    "                    progress.print(\"Warning: Got NaN loss, stopped training.\")\n",
    "                    return DF.from_records(metrics)\n",
    "                if torch.isinf(loss_value).any().item():\n",
    "                    progress.print(\"Warning: Got infinite loss, stopped training.\")\n",
    "                    return DF.from_records(metrics)\n",
    "                # TODO: Use gradient clipping?\n",
    "                loss_value.backward()\n",
    "                optimizer.step()\n",
    "                if step > 0: # If it's not the first training step, idk why it throws an error otherwise\n",
    "                    scheduler.step()\n",
    "                # metrics\n",
    "                total_epoch_loss += loss_value.item()\n",
    "                metrics.append({\n",
    "                    \"step\": step,\n",
    "                    \"epoch\": epoch,\n",
    "                    \"batch_train_loss\": loss_value.item(),\n",
    "                    \"lr\": optimizer.state_dict()[\"param_groups\"][-1][\"lr\"],\n",
    "                })\n",
    "                step += 1\n",
    "                if \"validation_accuracy\" in last_epoch_metric:\n",
    "                    last_validation_acc = \"%.2f\" % last_epoch_metric[\"validation_accuracy\"]\n",
    "                    val_acc_str = \"val. acc: \" + last_validation_acc\n",
    "                else:\n",
    "                    val_acc_str = \"\"\n",
    "                progress.update(\n",
    "                    task,\n",
    "                    advance=1,\n",
    "                    description=f\"epoch: {epoch}, batch_loss: {(total_epoch_loss / (batch_idx+1)):.2f}, {val_acc_str}\"\n",
    "                )\n",
    "            # Post epoch evalution\n",
    "            metrics[-1][\"train_epoch_loss\"] = total_epoch_loss / len(train_loader)\n",
    "            metrics[-1][\"train_epoch_accuracy\"] = total_accuracy / len(train_loader)\n",
    "            if evaluation_func:\n",
    "                progress.update(\n",
    "                    task,\n",
    "                    completed=0,\n",
    "                    description=f\"epoch: {epoch}, evaluating...\"\n",
    "                )\n",
    "                eval_metrics = evaluation_func(model, criterion, validation_loader)\n",
    "                metrics[-1].update(eval_metrics)\n",
    "            last_epoch_metric = metrics[-1]\n",
    "\n",
    "    return DF.from_records(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70d9df6",
   "metadata": {
    "papermill": {
     "duration": 0.007315,
     "end_time": "2025-08-02T11:25:20.986925",
     "exception": false,
     "start_time": "2025-08-02T11:25:20.979610",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Create model and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "49435f16",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-02T11:25:21.002597Z",
     "iopub.status.busy": "2025-08-02T11:25:21.002413Z",
     "iopub.status.idle": "2025-08-02T11:25:21.007129Z",
     "shell.execute_reply": "2025-08-02T11:25:21.006417Z"
    },
    "papermill": {
     "duration": 0.013904,
     "end_time": "2025-08-02T11:25:21.008277",
     "exception": false,
     "start_time": "2025-08-02T11:25:20.994373",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def mk_model_and_fit(\n",
    "        train_loader:DL,\n",
    "        mk_scheduler:callable,\n",
    "        epochs:int,\n",
    "        validation_loader:Optional[DL]=None,\n",
    "        save_checkpoints=False,\n",
    "        criterion=nn.CrossEntropyLoss()\n",
    "    ) -> tuple[nn.Module, DF, list[str]]:\n",
    "    model = mk_model()\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), WARMUP_LR_INIT)\n",
    "    lr_scheduler = mk_scheduler(optimizer)\n",
    "    training_metrics = fit(\n",
    "        epochs=epochs,\n",
    "        model=model,\n",
    "        scheduler=lr_scheduler,\n",
    "        optimizer=optimizer,\n",
    "        train_loader=train_loader,\n",
    "        criterion=criterion,\n",
    "        # evaluation_func=evaluate_model if validation_loader else None,\n",
    "        validation_loader=validation_loader,\n",
    "        save_checkpoints=save_checkpoints,\n",
    "    )\n",
    "\n",
    "    return model, training_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37b0121",
   "metadata": {
    "papermill": {
     "duration": 0.007861,
     "end_time": "2025-08-02T11:25:21.023870",
     "exception": false,
     "start_time": "2025-08-02T11:25:21.016009",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Search max learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "733b978d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-02T11:25:21.039874Z",
     "iopub.status.busy": "2025-08-02T11:25:21.039666Z",
     "iopub.status.idle": "2025-08-02T11:25:21.043476Z",
     "shell.execute_reply": "2025-08-02T11:25:21.042941Z"
    },
    "papermill": {
     "duration": 0.013336,
     "end_time": "2025-08-02T11:25:21.044812",
     "exception": false,
     "start_time": "2025-08-02T11:25:21.031476",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def post_process_mock_training_metrics(training_metrics:DF) -> DF:\n",
    "    training_metrics = (\n",
    "        training_metrics\n",
    "        .query(\"batch_train_loss.notna()\")\n",
    "        .set_index(\"lr\", drop=False)\n",
    "        .sort_index()\n",
    "    )\n",
    "    training_metrics[\"ewm_batch_train_loss\"] = (\n",
    "        training_metrics\n",
    "        .ewm(com=30, ignore_na=False)\n",
    "        [\"batch_train_loss\"]\n",
    "        .mean()\n",
    "    )\n",
    "    training_metrics[\"ewm_batch_train_loss_diff\"] = training_metrics[\"ewm_batch_train_loss\"].diff()\n",
    "    return training_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aedb492d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-02T11:25:21.061355Z",
     "iopub.status.busy": "2025-08-02T11:25:21.060916Z",
     "iopub.status.idle": "2025-08-02T11:25:21.064563Z",
     "shell.execute_reply": "2025-08-02T11:25:21.064101Z"
    },
    "papermill": {
     "duration": 0.013084,
     "end_time": "2025-08-02T11:25:21.065622",
     "exception": false,
     "start_time": "2025-08-02T11:25:21.052538",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plt_lr_search_training_metrics(training_metrics:DF):\n",
    "    (    \n",
    "        px.line(\n",
    "            (\n",
    "                training_metrics\n",
    "                .reset_index(drop=True)\n",
    "                .melt(\n",
    "                    id_vars=\"lr\",\n",
    "                    value_vars=[\n",
    "                        \"batch_train_loss\",\n",
    "                        \"ewm_batch_train_loss\",\n",
    "                        # \"ewm_batch_train_loss_diff\",\n",
    "                    ],\n",
    "                )\n",
    "            ),\n",
    "            x=\"lr\",\n",
    "            facet_row=\"variable\",\n",
    "            y=\"value\",\n",
    "            log_x=True,\n",
    "            log_y=True,\n",
    "            height=750,\n",
    "        )\n",
    "        .update_yaxes(matches=None)\n",
    "        .show()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4345ef27",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-02T11:25:21.081550Z",
     "iopub.status.busy": "2025-08-02T11:25:21.081354Z",
     "iopub.status.idle": "2025-08-02T11:26:29.317239Z",
     "shell.execute_reply": "2025-08-02T11:26:29.316530Z"
    },
    "papermill": {
     "duration": 68.246145,
     "end_time": "2025-08-02T11:26:29.319409",
     "exception": false,
     "start_time": "2025-08-02T11:25:21.073264",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f82f6965842469988401e5a9260b41f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<html>\n",
       "<head><meta charset=\"utf-8\" /></head>\n",
       "<body>\n",
       "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
       "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"ee35027e-c7ca-4ad7-981d-0b03683276b4\" class=\"plotly-graph-div\" style=\"height:750px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"ee35027e-c7ca-4ad7-981d-0b03683276b4\")) {                    Plotly.newPlot(                        \"ee35027e-c7ca-4ad7-981d-0b03683276b4\",                        [{\"hovertemplate\":\"variable=batch_train_loss\\u003cbr\\u003elr=%{x}\\u003cbr\\u003evalue=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"line\":{\"color\":\"#636efa\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"x\":[0.00001822126131809773,0.000018403473931278706,0.00001858750867059149,0.000018773383757297405,0.00001896111759487038,0.000019150728770819084,0.000019342236058527274,0.000019535658419112548,0.000019731015003303675,0.000019928325153336713,0.00002012760840487008,0.000020328884488918778,0.000020532173333807966,0.000020737495067146046,0.000020944870017817505,0.00002115431871799568,0.000021365861905175638,0.000021579520524227394,0.00002179531572946967,0.000022013268886764367,0.00002223340157563201,0.00002245573559138833,0.000022680292947302212,0.000022907095876775235,0.000023136166835542987,0.000023367528503898416,0.0000236012037889374,0.000023837215826826773,0.00002407558798509504,0.00002431634386494599,0.00002455950730359545,0.000024805102376631404,0.00002505315340039772,0.000025303684934401698,0.000025556721783745715,0.000025812289001583172,0.000026070411891599003,0.000026331116010514992,0.00002659442717062014,0.000026860371442326343,0.000027128975156749605,0.000027400264908317103,0.000027674267557400273,0.000027951010232974275,0.000028230520335304018,0.000028512825538657058,0.00002879795379404363,0.000029085933331984066,0.000029376792665303907,0.000029670560591956945,0.000029967266197876516,0.00003026693885985528,0.00003056960824845383,0.00003087530433093837,0.00003118405737424775,0.00003149589794799023,0.000031810856927470134,0.00003212896549674484,0.00003245025515171229,0.00003277475770322941,0.000033102505280261705,0.000033433530333064325,0.000033767865636394966,0.000034105544292758914,0.0000344465997356865,0.00003479106573304337,0.00003513897639037381,0.000035490366154277546,0.00003584526981582032,0.00003620372251397852,0.00003656575973911831,0.00003693141733650949,0.000037300731509874584,0.00003767373882497333,0.00003805047621322307,0.0000384309809753553,0.00003881529078510885,0.00003920344369295994,0.00003959547812988954,0.000039991432911188434,0.00004039134724030032,0.00004079526071270332,0.00004120321331983036,0.000041615245453028664,0.00004203139790755895,0.00004245171188663454,0.00004287622900550088,0.00004330499129555589,0.00004373804120851145,0.000044175421620596566,0.00004461717583680253,0.00004506334759517056,0.000045513981071122266,0.00004596912088183349,0.00004642881209065182,0.000046893100211558344,0.00004736203121367393,0.00004783565152581067,0.00004831400804106878,0.000048797148121479465,0.00004928511960269426,0.0000497779707987212,0.00005027575050670841,0.000050778508011775496,0.000051286293091893254,0.000051799156022812186,0.000052317147583040306,0.00005284031905887071,0.00005336872224945942,0.00005390240947195401,0.00005444143356667355,0.00005498584790234029,0.00005553570638136369,0.00005609106344517733,0.0000566519740796291,0.000057218493820425395,0.00005779067875862965,0.000058368585546215946,0.00005895227140167811,0.00005954179411569489,0.00006013721205685184,0.00006073858417742036,0.00006134597001919457,0.00006195942971938652,0.00006257902401658039,0.00006320481425674619,0.00006383686239931365,0.00006447523102330679,0.00006511998333353986,0.00006577118316687527,0.00006642889499854402,0.00006709318394852947,0.00006776411578801477,0.00006844175694589491,0.00006912617451535386,0.0000698174362605074,0.00007051561062311247,0.00007122076672934359,0.00007193297439663703,0.0000726523041406034,0.00007337882718200944,0.00007411261545382954,0.00007485374160836784,0.00007560227902445152,0.00007635830181469604,0.000077121884832843,0.00007789310368117143,0.00007867203471798315,0.00007945875506516298,0.0000802533426158146,0.00008105587604197274,0.00008186643480239247,0.0000826850991504164,0.00008351195014192057,0.00008434706964333977,0.00008519054033977317,0.0000860424457431709,0.00008690287020060262,0.00008777189890260865,0.00008864961789163473,0.00008953611407055108,0.00009043147521125659,0.00009133578996336915,0.00009224914786300284,0.00009317163934163286,0.0000941033557350492,0.00009504438929239969,0.00009599483318532369,0.00009695478151717692,0.0000979243293323487,0.00009890357262567218,0.0000998926083519289,0.00010089153443544819,0.00010190044977980267,0.00010291945427760071,0.00010394864882037671,0.00010498813530858048,0.00010603801666166629,0.00010709839682828294,0.00010816938079656578,0.00010925107460453143,0.00011034358535057675,0.00011144702120408252,0.00011256149141612335,0.00011368710633028458,0.00011482397739358743,0.00011597221716752331,0.00011713193933919855,0.00011830325873259054,0.00011948629131991645,0.00012068115423311561,0.00012188796577544676,0.00012310684543320123,0.00012433791388753325,0.00012558129302640857,0.00012683710595667267,0.00012810547701623938,0.00012938653178640178,0.0001306803971042658,0.00013198720107530847,0.00013330707308606155,0.00013464014381692216,0.00013598654525509137,0.0001373464107076423,0.00013871987481471872,0.00014010707356286591,0.00014150814429849458,0.00014292322574147953,0.00014435245799889433,0.00014579598257888327,0.00014725394240467212,0.00014872648182871884,0.00015021374664700603,0.00015171588411347608,0.00015323304295461083,0.00015476537338415694,0.0001563130271179985,0.0001578761573891785,0.00015945491896307028,0.00016104946815270098,0.00016265996283422798,0.00016428656246257026,0.00016592942808719597,0.00016758872236806793,0.0001692646095917486,0.0001709572556876661,0.00017266682824454275,0.00017439349652698818,0.00017613743149225806,0.00017789880580718065,0.00017967779386525245,0.00018147457180390497,0.000183289317521944,0.00018512221069716346,0.0001869734328041351,0.00018884316713217643,0.0001907315988034982,0.00019263891479153318,0.0001945653039394485,0.00019651095697884299,0.0001984760665486314,0.00020046082721411772,0.0002024654354862589,0.00020449008984112148,0.0002065349907395327,0.00020860034064692804,0.0002106863440533973,0.0002127932074939313,0.00021492113956887062,0.00021707035096455932,0.00021924105447420492,0.00022143346501894698,0.00022364779966913646,0.00022588427766582784,0.00022814312044248613,0.000230424551646911,0.00023272879716338012,0.00023505608513501393,0.00023740664598636407,0.00023978071244622773,0.00024217851957069,0.0002446003047663969,0.00024704630781406087,0.0002495167708922015,0.00025201193860112354,0.00025453205798713476,0.0002570773785670061,0.0002596481523526762,0.00026224463387620296,0.000264867080214965,0.00026751575101711467,0.0002701909085272858,0.00027289281761255866,0.00027562174578868426,0.0002783779632465711,0.0002811617428790368,0.00028397336030782717,0.00028681309391090544,0.0002896812248500145,0.0002925780370985146,0.00029550381746949977,0.00029845885564419475,0.0003014434442006367,0.0003044578786426431,0.00030750245742906953,0.0003105774820033602,0.0003136832568233938,0.00031682008939162777,0.00031998829028554403,0.00032318817318839946,0.00032642005492028344,0.0003296842554694863,0.00033298109802418115,0.000336310909004423,0.0003396740180944672,0.00034307075827541187,0.000346501465858166,0.00034996648051674765,0.0003534661453219151,0.0003570008067751343,0.0003605708148428856,0.00036417652299131444,0.0003678182882212276,0.00037149647110343986,0.00037521143581447427,0.000378963550172619,0.0003827531856743452,0.00038658071753108867,0.00039044652470639955,0.00039435098995346357,0.00039829449985299823,0.0004022774448515282,0.0004063002193000435,0.00041036322149304397,0.00041446685370797443,0.00041861152224505416,0.0004227976374675047,0.00042702561384217976,0.00043129586998060155,0.0004356088286804076,0.0004399649169672117,0.0004443645661368838,0.00044880821179825263,0.00045329629391623516,0.0004578292568553975,0.0004624075494239515,0.000467031624918191,0.0004717019411673729,0.00047641896057904663,0.0004811831501848371,0.00048599498168668546,0.0004908549315035523,0.0004957634808185878,0.0005007211156267738,0.0005057283267830415,0.0005107856100508719,0.0005158934661513806,0.0005210524008128944,0.0005262629248210234,0.0005315255540692336,0.0005368408096099259,0.0005422092177060252,0.0005476313098830855,0.0005531076229819163,0.0005586386992117355,0.0005642250862038529,0.0005698673370658914,0.0005755660104365503,0.0005813216705409157,0.0005871348872463249,0.0005930062361187881,0.000598936298479976,0.0006049256614647757,0.0006109749180794235,0.0006170846672602177,0.0006232555139328199,0.000629488069072148,0.0006357829497628696,0.0006421407792604983,0.0006485621870531032,0.0006550478089236343,0.0006615982870128706,0.0006682142698829993,0.0006748964125818293,0.0006816453767076476,0.0006884618304747242,0.0006953464487794714,0.0007022999132672662,0.0007093229123999388,0.0007164161415239382,0.0007235803029391776,0.0007308161059685693,0.000738124267028255,0.0007455055096985375,0.000752960564795523,0.0007604901704434782,0.000768095072147913,0.0007757760228693921,0.000783533783098086,0.0007913691209290669,0.0007992828121383575,0.0008072756402597412,0.0008153483966623385,0.0008235018806289619,0.0008317368994352516,0.0008400542684296041,0.0008484548111139001,0.0008569393592250392,0.0008655087528172896,0.0008741638403454624,0.000882905478748917,0.0008917345335364062,0.0009006518788717702,0.0009096583976604879,0.0009187549816370928,0.0009279425314534638,0.0009372219567679984,0.0009465941763356784,0.0009560601180990352,0.0009656207192800256,0.0009752769264728258,0.000985029695737554,0.0009948799926949297,0.001004828792621879,0.0010148770805480979,0.001025025851353579,0.0010352761098671147,0.0010456288709657859,0.0010560851596754437,0.001066646011272198,0.00107731247138492,0.0010880855960987692,0.0010989664520597569,0.0011099561165803544,0.001121055677746158,0.0011322662345236195,0.0011435888968688557,0.0011550247858375443,0.0011665750336959197,0.0011782407840328789,0.0011900231918732078,0.0012019234237919398,0.0012139426580298593,0.001226082084610158,0.0012383429054562596,0.0012507263345108222,0.0012632335978559305,0.0012758659338344897,0.0012886245931728346,0.0013015108391045628,0.0013145259474956084,0.0013276712069705645,0.0013409479190402702,0.0013543573982306729,0.0013679009722129796,0.0013815799819351094,0.0013953957817544604,0.001409349739572005,0.001423443236967725,0.0014376776693374024,0.0014520544460307765,0.0014665749904910843,0.0014812407403959952,0.001496053147799955,0.0015110136792779545,0.001526123816070734,0.0015413850542314415,0.001556798904773756,0.0015723668938214936,0.0015880905627597085,0.0016039714683873055,0.0016200111830711786,0.0016362112949018905,0.0016525734078509094,0.0016690991419294184,0.0016857901333487127,0.0017026480346821998,0.0017196745150290218,0.001736871260179312,0.0017542399727811051,0.0017717823725089162,0.0017895001962340055,0.0018073951981963455,0.001825469150178309,0.001843723841680092,0.0018621610800968929,0.0018807826908978618,0.0018995905178068404,0.001918586422984909,0.001937772287214758,0.0019571500100869057,0.0019767215101877747,0.0019964887252896524,0.002016453612542549,0.0020366181486679742,0.002056984330154654,0.0020775541734562005,0.0020983297151907624,0.00211931301234267,0.002140506142466097],\"xaxis\":\"x2\",\"y\":[3.0357413291931152,3.0113396644592285,2.9736175537109375,2.9899606704711914,2.9518117904663086,2.9351043701171875,2.906397819519043,2.93119478225708,2.9401533603668213,2.939129114151001,2.9456796646118164,2.9180617332458496,2.9410741329193115,2.9090261459350586,2.940230369567871,2.865690231323242,2.9173903465270996,2.873964786529541,2.8954434394836426,2.8184263706207275,2.864138603210449,2.8536715507507324,2.8442811965942383,2.8338632583618164,2.8392677307128906,2.8013596534729004,2.8675875663757324,2.7680985927581787,2.8354721069335938,2.8015406131744385,2.795370578765869,2.7891311645507812,2.771878242492676,2.7800772190093994,2.754422664642334,2.7526440620422363,2.7655787467956543,2.747626543045044,2.7688798904418945,2.727449893951416,2.733588933944702,2.725600481033325,2.7393124103546143,2.7463326454162598,2.7323648929595947,2.7090933322906494,2.6934404373168945,2.6737418174743652,2.704596757888794,2.632631301879883,2.6737864017486572,2.711702346801758,2.670073986053467,2.652141571044922,2.6540114879608154,2.6193597316741943,2.624765396118164,2.604612350463867,2.6457135677337646,2.598520517349243,2.635183572769165,2.6548190116882324,2.6112241744995117,2.6294007301330566,2.5728981494903564,2.5799002647399902,2.550426483154297,2.581393241882324,2.5920569896698,2.5640015602111816,2.5387182235717773,2.5004494190216064,2.5327212810516357,2.52205753326416,2.4977214336395264,2.5478827953338623,2.519392967224121,2.5180764198303223,2.5134103298187256,2.4604034423828125,2.475463390350342,2.4957852363586426,2.446445941925049,2.515531063079834,2.4833908081054688,2.4794106483459473,2.4639556407928467,2.4530599117279053,2.4404730796813965,2.4254064559936523,2.440821647644043,2.4108400344848633,2.4010446071624756,2.3664846420288086,2.375079870223999,2.489675760269165,2.4342947006225586,2.3924074172973633,2.359102725982666,2.4009218215942383,2.387850284576416,2.3893184661865234,2.335968494415283,2.3455371856689453,2.328441619873047,2.2758045196533203,2.3665809631347656,2.302900791168213,2.2881245613098145,2.28647518157959,2.275050640106201,2.2830302715301514,2.2281103134155273,2.28712797164917,2.2790133953094482,2.280885696411133,2.296579360961914,2.2406556606292725,2.281337261199951,2.2492544651031494,2.206942081451416,2.190155506134033,2.266280174255371,2.2139077186584473,2.236278533935547,2.2304365634918213,2.2396633625030518,2.177339792251587,2.143047332763672,2.1839842796325684,2.236079692840576,2.1581337451934814,2.155620574951172,2.1941471099853516,2.118527889251709,2.1181411743164062,2.152147054672241,2.1681480407714844,2.073688507080078,2.155961751937866,2.1146931648254395,2.1382501125335693,2.1004514694213867,2.049085855484009,2.139164924621582,2.087947368621826,2.0776028633117676,2.126067638397217,2.166661500930786,2.0643436908721924,2.1251564025878906,2.0368165969848633,1.9753915071487427,2.0574393272399902,1.9842257499694824,2.0874853134155273,2.0649783611297607,2.068694829940796,2.0015993118286133,2.013183355331421,2.0229597091674805,1.954154372215271,1.9911386966705322,1.942368745803833,2.0015010833740234,1.9689031839370728,1.9749841690063477,1.9492987394332886,1.943126916885376,1.975142240524292,1.9181115627288818,2.0131683349609375,1.9663763046264648,1.9485145807266235,1.8932238817214966,1.926250696182251,1.9128520488739014,1.9232852458953857,1.856062412261963,1.9188098907470703,1.9142506122589111,1.875571846961975,1.9358032941818237,1.8749229907989502,1.9111571311950684,1.9015947580337524,1.9041156768798828,1.9023226499557495,1.8496720790863037,1.8596138954162598,1.8817769289016724,1.8975391387939453,1.870386004447937,1.8840306997299194,1.7996041774749756,1.7910292148590088,1.72683846950531,1.7539737224578857,1.7811779975891113,1.6993420124053955,1.7599055767059326,1.8083443641662598,1.798935890197754,1.7777471542358398,1.835736632347107,1.730867624282837,1.7488386631011963,1.787826418876648,1.7222617864608765,1.7430611848831177,1.7757503986358643,1.8133444786071777,1.744856595993042,1.6916747093200684,1.706416368484497,1.7504267692565918,1.723348617553711,1.757422685623169,1.6877944469451904,1.6972596645355225,1.7068052291870117,1.66045081615448,1.6177513599395752,1.724832534790039,1.5929419994354248,1.6532090902328491,1.6570854187011719,1.6581382751464844,1.5956306457519531,1.6515012979507446,1.596832275390625,1.6175752878189087,1.5990638732910156,1.6375715732574463,1.5986313819885254,1.6847074031829834,1.5537261962890625,1.5671846866607666,1.534296989440918,1.5637561082839966,1.5953700542449951,1.6274833679199219,1.5800113677978516,1.606148362159729,1.6482338905334473,1.5571742057800293,1.5049641132354736,1.5579948425292969,1.4985755681991577,1.5498727560043335,1.4982062578201294,1.5289307832717896,1.5441393852233887,1.5921990871429443,1.5199568271636963,1.5823302268981934,1.4392530918121338,1.449454665184021,1.4720745086669922,1.513014554977417,1.4616060256958008,1.4788131713867188,1.4734156131744385,1.504634141921997,1.4573969841003418,1.4546747207641602,1.4130487442016602,1.442824125289917,1.4000928401947021,1.4233877658843994,1.4675158262252808,1.4271953105926514,1.4694957733154297,1.434875726699829,1.390852451324463,1.4515411853790283,1.4294320344924927,1.4253450632095337,1.4244208335876465,1.4271304607391357,1.3763985633850098,1.3344919681549072,1.424134612083435,1.3848326206207275,1.4026148319244385,1.428002119064331,1.4522887468338013,1.3561023473739624,1.3328447341918945,1.3230440616607666,1.3185999393463135,1.2818936109542847,1.3430542945861816,1.4160348176956177,1.3036680221557617,1.3247828483581543,1.3209260702133179,1.321892261505127,1.2488439083099365,1.2521705627441406,1.4096276760101318,1.3116230964660645,1.3210822343826294,1.2689998149871826,1.2295461893081665,1.2542674541473389,1.2507468461990356,1.3003990650177002,1.3557673692703247,1.2753013372421265,1.316438913345337,1.3187661170959473,1.346238374710083,1.2924259901046753,1.2191965579986572,1.2732070684432983,1.3748416900634766,1.2481303215026855,1.3434604406356812,1.2739802598953247,1.1617014408111572,1.2261826992034912,1.1448103189468384,1.2758798599243164,1.276322841644287,1.1951894760131836,1.27406644821167,1.182713508605957,1.1314878463745117,1.1735105514526367,1.1375980377197266,1.1933642625808716,1.1818910837173462,1.1918179988861084,1.155435562133789,1.1878952980041504,1.1817080974578857,1.270856261253357,1.17063570022583,1.2161948680877686,1.2401645183563232,1.2328094244003296,1.1670589447021484,1.175661563873291,1.259809970855713,1.2211239337921143,1.2284510135650635,1.2167478799819946,1.2586584091186523,1.222656488418579,1.2202765941619873,1.2973082065582275,1.124261498451233,1.1510268449783325,1.1023900508880615,1.215541124343872,1.071713924407959,1.062392234802246,1.2320287227630615,1.182981014251709,1.1031640768051147,1.0654356479644775,1.073648452758789,1.0939863920211792,1.1579277515411377,1.1440750360488892,1.2024564743041992,1.1983391046524048,1.1185643672943115,1.1405185461044312,1.0994751453399658,1.1585898399353027,1.2255804538726807,1.1674878597259521,1.1416022777557373,1.1111642122268677,1.157515287399292,1.1170305013656616,1.1503736972808838,1.2020127773284912,1.115210771560669,1.202415108680725,1.2071409225463867,1.1087429523468018,1.022505283355713,1.0464746952056885,1.1490323543548584,1.0597022771835327,1.0631176233291626,1.0362441539764404,1.0565240383148193,1.0780620574951172,1.0206589698791504,1.0621981620788574,1.0844337940216064,1.0970003604888916,1.0095158815383911,1.106989860534668,1.115909457206726,1.1376363039016724,1.1107232570648193,1.135343313217163,1.1012122631072998,1.0689606666564941,1.0774989128112793,1.0672327280044556,1.0663392543792725,1.1179587841033936,1.1180411577224731,1.1331865787506104,1.0970414876937866,1.1035043001174927,1.1559813022613525,1.1681081056594849,1.1130592823028564,1.0924407243728638,1.0197523832321167,0.9262802004814148,0.9604349136352539,1.1105256080627441,1.028519868850708,1.018606185913086,1.0480597019195557,1.0254372358322144,1.0734620094299316,0.9926043748855591,1.009568214416504,1.045696496963501,1.0057122707366943,1.0943197011947632,1.1843879222869873,1.114058017730713,1.0914076566696167,1.0687775611877441,1.0466794967651367,1.0300376415252686,1.0030720233917236,1.124760627746582,1.0994110107421875,1.055319905281067,1.0996752977371216,1.079748272895813,1.07388436794281,1.1102221012115479,1.033965826034546,1.1466419696807861,1.1785515546798706,1.1220370531082153,0.9611226320266724,1.0112769603729248,1.01964271068573,0.9881757497787476,1.0259759426116943,1.1022918224334717,1.0142358541488647,1.0602290630340576,1.0432169437408447,1.0171452760696411,1.107588529586792,1.0510460138320923,1.0362019538879395,1.08708655834198,1.0557498931884766,1.0911579132080078,1.112971544265747,1.0275673866271973,1.0402522087097168,1.0404363870620728,1.0191830396652222,1.0966684818267822,1.0785865783691406,1.042250633239746,1.1784672737121582,1.1013094186782837,1.0671696662902832,1.1296004056930542,1.1839823722839355,1.083914041519165,1.0949649810791016,1.05653715133667],\"yaxis\":\"y2\",\"type\":\"scatter\"},{\"hovertemplate\":\"variable=ewm_batch_train_loss\\u003cbr\\u003elr=%{x}\\u003cbr\\u003evalue=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"line\":{\"color\":\"#636efa\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"x\":[0.00001822126131809773,0.000018403473931278706,0.00001858750867059149,0.000018773383757297405,0.00001896111759487038,0.000019150728770819084,0.000019342236058527274,0.000019535658419112548,0.000019731015003303675,0.000019928325153336713,0.00002012760840487008,0.000020328884488918778,0.000020532173333807966,0.000020737495067146046,0.000020944870017817505,0.00002115431871799568,0.000021365861905175638,0.000021579520524227394,0.00002179531572946967,0.000022013268886764367,0.00002223340157563201,0.00002245573559138833,0.000022680292947302212,0.000022907095876775235,0.000023136166835542987,0.000023367528503898416,0.0000236012037889374,0.000023837215826826773,0.00002407558798509504,0.00002431634386494599,0.00002455950730359545,0.000024805102376631404,0.00002505315340039772,0.000025303684934401698,0.000025556721783745715,0.000025812289001583172,0.000026070411891599003,0.000026331116010514992,0.00002659442717062014,0.000026860371442326343,0.000027128975156749605,0.000027400264908317103,0.000027674267557400273,0.000027951010232974275,0.000028230520335304018,0.000028512825538657058,0.00002879795379404363,0.000029085933331984066,0.000029376792665303907,0.000029670560591956945,0.000029967266197876516,0.00003026693885985528,0.00003056960824845383,0.00003087530433093837,0.00003118405737424775,0.00003149589794799023,0.000031810856927470134,0.00003212896549674484,0.00003245025515171229,0.00003277475770322941,0.000033102505280261705,0.000033433530333064325,0.000033767865636394966,0.000034105544292758914,0.0000344465997356865,0.00003479106573304337,0.00003513897639037381,0.000035490366154277546,0.00003584526981582032,0.00003620372251397852,0.00003656575973911831,0.00003693141733650949,0.000037300731509874584,0.00003767373882497333,0.00003805047621322307,0.0000384309809753553,0.00003881529078510885,0.00003920344369295994,0.00003959547812988954,0.000039991432911188434,0.00004039134724030032,0.00004079526071270332,0.00004120321331983036,0.000041615245453028664,0.00004203139790755895,0.00004245171188663454,0.00004287622900550088,0.00004330499129555589,0.00004373804120851145,0.000044175421620596566,0.00004461717583680253,0.00004506334759517056,0.000045513981071122266,0.00004596912088183349,0.00004642881209065182,0.000046893100211558344,0.00004736203121367393,0.00004783565152581067,0.00004831400804106878,0.000048797148121479465,0.00004928511960269426,0.0000497779707987212,0.00005027575050670841,0.000050778508011775496,0.000051286293091893254,0.000051799156022812186,0.000052317147583040306,0.00005284031905887071,0.00005336872224945942,0.00005390240947195401,0.00005444143356667355,0.00005498584790234029,0.00005553570638136369,0.00005609106344517733,0.0000566519740796291,0.000057218493820425395,0.00005779067875862965,0.000058368585546215946,0.00005895227140167811,0.00005954179411569489,0.00006013721205685184,0.00006073858417742036,0.00006134597001919457,0.00006195942971938652,0.00006257902401658039,0.00006320481425674619,0.00006383686239931365,0.00006447523102330679,0.00006511998333353986,0.00006577118316687527,0.00006642889499854402,0.00006709318394852947,0.00006776411578801477,0.00006844175694589491,0.00006912617451535386,0.0000698174362605074,0.00007051561062311247,0.00007122076672934359,0.00007193297439663703,0.0000726523041406034,0.00007337882718200944,0.00007411261545382954,0.00007485374160836784,0.00007560227902445152,0.00007635830181469604,0.000077121884832843,0.00007789310368117143,0.00007867203471798315,0.00007945875506516298,0.0000802533426158146,0.00008105587604197274,0.00008186643480239247,0.0000826850991504164,0.00008351195014192057,0.00008434706964333977,0.00008519054033977317,0.0000860424457431709,0.00008690287020060262,0.00008777189890260865,0.00008864961789163473,0.00008953611407055108,0.00009043147521125659,0.00009133578996336915,0.00009224914786300284,0.00009317163934163286,0.0000941033557350492,0.00009504438929239969,0.00009599483318532369,0.00009695478151717692,0.0000979243293323487,0.00009890357262567218,0.0000998926083519289,0.00010089153443544819,0.00010190044977980267,0.00010291945427760071,0.00010394864882037671,0.00010498813530858048,0.00010603801666166629,0.00010709839682828294,0.00010816938079656578,0.00010925107460453143,0.00011034358535057675,0.00011144702120408252,0.00011256149141612335,0.00011368710633028458,0.00011482397739358743,0.00011597221716752331,0.00011713193933919855,0.00011830325873259054,0.00011948629131991645,0.00012068115423311561,0.00012188796577544676,0.00012310684543320123,0.00012433791388753325,0.00012558129302640857,0.00012683710595667267,0.00012810547701623938,0.00012938653178640178,0.0001306803971042658,0.00013198720107530847,0.00013330707308606155,0.00013464014381692216,0.00013598654525509137,0.0001373464107076423,0.00013871987481471872,0.00014010707356286591,0.00014150814429849458,0.00014292322574147953,0.00014435245799889433,0.00014579598257888327,0.00014725394240467212,0.00014872648182871884,0.00015021374664700603,0.00015171588411347608,0.00015323304295461083,0.00015476537338415694,0.0001563130271179985,0.0001578761573891785,0.00015945491896307028,0.00016104946815270098,0.00016265996283422798,0.00016428656246257026,0.00016592942808719597,0.00016758872236806793,0.0001692646095917486,0.0001709572556876661,0.00017266682824454275,0.00017439349652698818,0.00017613743149225806,0.00017789880580718065,0.00017967779386525245,0.00018147457180390497,0.000183289317521944,0.00018512221069716346,0.0001869734328041351,0.00018884316713217643,0.0001907315988034982,0.00019263891479153318,0.0001945653039394485,0.00019651095697884299,0.0001984760665486314,0.00020046082721411772,0.0002024654354862589,0.00020449008984112148,0.0002065349907395327,0.00020860034064692804,0.0002106863440533973,0.0002127932074939313,0.00021492113956887062,0.00021707035096455932,0.00021924105447420492,0.00022143346501894698,0.00022364779966913646,0.00022588427766582784,0.00022814312044248613,0.000230424551646911,0.00023272879716338012,0.00023505608513501393,0.00023740664598636407,0.00023978071244622773,0.00024217851957069,0.0002446003047663969,0.00024704630781406087,0.0002495167708922015,0.00025201193860112354,0.00025453205798713476,0.0002570773785670061,0.0002596481523526762,0.00026224463387620296,0.000264867080214965,0.00026751575101711467,0.0002701909085272858,0.00027289281761255866,0.00027562174578868426,0.0002783779632465711,0.0002811617428790368,0.00028397336030782717,0.00028681309391090544,0.0002896812248500145,0.0002925780370985146,0.00029550381746949977,0.00029845885564419475,0.0003014434442006367,0.0003044578786426431,0.00030750245742906953,0.0003105774820033602,0.0003136832568233938,0.00031682008939162777,0.00031998829028554403,0.00032318817318839946,0.00032642005492028344,0.0003296842554694863,0.00033298109802418115,0.000336310909004423,0.0003396740180944672,0.00034307075827541187,0.000346501465858166,0.00034996648051674765,0.0003534661453219151,0.0003570008067751343,0.0003605708148428856,0.00036417652299131444,0.0003678182882212276,0.00037149647110343986,0.00037521143581447427,0.000378963550172619,0.0003827531856743452,0.00038658071753108867,0.00039044652470639955,0.00039435098995346357,0.00039829449985299823,0.0004022774448515282,0.0004063002193000435,0.00041036322149304397,0.00041446685370797443,0.00041861152224505416,0.0004227976374675047,0.00042702561384217976,0.00043129586998060155,0.0004356088286804076,0.0004399649169672117,0.0004443645661368838,0.00044880821179825263,0.00045329629391623516,0.0004578292568553975,0.0004624075494239515,0.000467031624918191,0.0004717019411673729,0.00047641896057904663,0.0004811831501848371,0.00048599498168668546,0.0004908549315035523,0.0004957634808185878,0.0005007211156267738,0.0005057283267830415,0.0005107856100508719,0.0005158934661513806,0.0005210524008128944,0.0005262629248210234,0.0005315255540692336,0.0005368408096099259,0.0005422092177060252,0.0005476313098830855,0.0005531076229819163,0.0005586386992117355,0.0005642250862038529,0.0005698673370658914,0.0005755660104365503,0.0005813216705409157,0.0005871348872463249,0.0005930062361187881,0.000598936298479976,0.0006049256614647757,0.0006109749180794235,0.0006170846672602177,0.0006232555139328199,0.000629488069072148,0.0006357829497628696,0.0006421407792604983,0.0006485621870531032,0.0006550478089236343,0.0006615982870128706,0.0006682142698829993,0.0006748964125818293,0.0006816453767076476,0.0006884618304747242,0.0006953464487794714,0.0007022999132672662,0.0007093229123999388,0.0007164161415239382,0.0007235803029391776,0.0007308161059685693,0.000738124267028255,0.0007455055096985375,0.000752960564795523,0.0007604901704434782,0.000768095072147913,0.0007757760228693921,0.000783533783098086,0.0007913691209290669,0.0007992828121383575,0.0008072756402597412,0.0008153483966623385,0.0008235018806289619,0.0008317368994352516,0.0008400542684296041,0.0008484548111139001,0.0008569393592250392,0.0008655087528172896,0.0008741638403454624,0.000882905478748917,0.0008917345335364062,0.0009006518788717702,0.0009096583976604879,0.0009187549816370928,0.0009279425314534638,0.0009372219567679984,0.0009465941763356784,0.0009560601180990352,0.0009656207192800256,0.0009752769264728258,0.000985029695737554,0.0009948799926949297,0.001004828792621879,0.0010148770805480979,0.001025025851353579,0.0010352761098671147,0.0010456288709657859,0.0010560851596754437,0.001066646011272198,0.00107731247138492,0.0010880855960987692,0.0010989664520597569,0.0011099561165803544,0.001121055677746158,0.0011322662345236195,0.0011435888968688557,0.0011550247858375443,0.0011665750336959197,0.0011782407840328789,0.0011900231918732078,0.0012019234237919398,0.0012139426580298593,0.001226082084610158,0.0012383429054562596,0.0012507263345108222,0.0012632335978559305,0.0012758659338344897,0.0012886245931728346,0.0013015108391045628,0.0013145259474956084,0.0013276712069705645,0.0013409479190402702,0.0013543573982306729,0.0013679009722129796,0.0013815799819351094,0.0013953957817544604,0.001409349739572005,0.001423443236967725,0.0014376776693374024,0.0014520544460307765,0.0014665749904910843,0.0014812407403959952,0.001496053147799955,0.0015110136792779545,0.001526123816070734,0.0015413850542314415,0.001556798904773756,0.0015723668938214936,0.0015880905627597085,0.0016039714683873055,0.0016200111830711786,0.0016362112949018905,0.0016525734078509094,0.0016690991419294184,0.0016857901333487127,0.0017026480346821998,0.0017196745150290218,0.001736871260179312,0.0017542399727811051,0.0017717823725089162,0.0017895001962340055,0.0018073951981963455,0.001825469150178309,0.001843723841680092,0.0018621610800968929,0.0018807826908978618,0.0018995905178068404,0.001918586422984909,0.001937772287214758,0.0019571500100869057,0.0019767215101877747,0.0019964887252896524,0.002016453612542549,0.0020366181486679742,0.002056984330154654,0.0020775541734562005,0.0020983297151907624,0.00211931301234267,0.002140506142466097],\"xaxis\":\"x\",\"y\":[3.0357413291931152,3.023340483180812,3.0062198327972403,3.0019529860917378,2.9912565592114575,2.9811142742473598,2.9693624288618357,2.9640263538748006,2.961012856639694,2.9584877531727605,2.9571232904611358,2.953249713986228,2.9521180295245206,2.9483419331387974,2.9476684184659194,2.941190555716526,2.9393938929987358,2.9346593707527235,2.931931075670624,2.924318478651228,2.92041807606151,2.9162284631800364,2.9118461145237196,2.907228442544855,2.903309850271003,2.8975770576241144,2.895930190135299,2.889065864424968,2.886248383671589,2.881883862711947,2.877510571175574,2.8731232019254476,2.8681830369376815,2.863953918807879,2.8587778538506434,2.8538364544284875,2.8497852660814726,2.845159114026693,2.841749304167877,2.8367027255963637,2.832203531831682,2.827604406298482,2.823836280083148,2.8205626902113456,2.8168742118581047,2.8124094527747534,2.8075259952374116,2.8020822536848944,2.7981486920929135,2.7915236393058964,2.786847376841374,2.7838848819697692,2.779429958075772,2.7744815524026687,2.7698290009277735,2.764054616907039,2.758741779321221,2.7528972907133453,2.74885583288528,2.743218019621864,2.739187689300663,2.7360560418381987,2.7314448700726683,2.7276930179244494,2.722027228609558,2.7168476084368405,2.7108079007234585,2.70613008971397,2.7020227819458364,2.697071755612972,2.6914118307885246,2.684610087601059,2.6792181947429463,2.6736571791843335,2.667451222056711,2.6632462475408722,2.658201903283866,2.6533020355722092,2.648423561482806,2.6418837971890468,2.6361098941087127,2.6312532086268563,2.62487197497347,2.621105083545689,2.6163710853881743,2.6116729488463717,2.6066161608846556,2.601369849653165,2.595883211444844,2.5900805824300264,2.5850091832927102,2.579101561030863,2.573072082624388,2.566087693610973,2.559640022388145,2.557281837223567,2.55314247771574,2.547740198654191,2.541408682849762,2.5366994686640876,2.5317162356603315,2.526954796285106,2.5205761968667804,2.5147368659612743,2.508528867023572,2.500781943996748,2.4963192608359384,2.4898937729364787,2.4831973138701904,2.476674431302505,2.4699950302886537,2.4638066380367016,2.4560118246148472,2.4504311339821667,2.444771163715616,2.43936401057364,2.434656509005242,2.4282649937181593,2.423427667264276,2.417697145021674,2.4107674898137574,2.40351824727848,2.3990113575158287,2.3929361005839715,2.3877973595973336,2.3826383591333875,2.377953456870891,2.3713832377089843,2.3639087798498455,2.358021848952842,2.3540338740877442,2.347630045235236,2.3413561043562017,2.336548031806041,2.3294300300063853,2.322534485089728,2.3169758826909725,2.3121223982121566,2.3043494813602514,2.299513711759431,2.2934926334684254,2.2884367646320407,2.2823164379626117,2.274725311822755,2.270314406564562,2.2643821546755434,2.258308022607403,2.2540086438573876,2.251169547671917,2.245098526251145,2.241201858643406,2.2345633366531104,2.22614719465759,2.220669886596055,2.2129950350081247,2.2089218762045837,2.204251396841572,2.1998538746717435,2.1934235715451322,2.1875785878731446,2.1822410978634523,2.1748469916542827,2.1688924957014994,2.1615513677293814,2.156365272415957,2.1502918345434336,2.1446129742521403,2.138286885483187,2.1319666226464773,2.1268885039848224,2.120128943854586,2.116666297453886,2.1118015042293155,2.1065165967429627,2.0996139566361194,2.094004109680245,2.088142816710637,2.0828092630685484,2.075474129496116,2.070406592201985,2.065355941869158,2.05921816156975,2.0552271494018735,2.049396908198955,2.0449271900726744,2.040293158346681,2.035890770456078,2.0315730420994025,2.0256933040360687,2.020325332497565,2.0158474953171157,2.012024045063334,2.007446906627444,2.0034588502988937,1.9968718827922323,1.9902210382545005,1.9817115052860164,1.974353979044999,1.9681133466122829,1.9594309852944682,1.952985832572459,1.9483137709222127,1.9434889255732641,1.9381357554825536,1.934828575351581,1.9282415133679094,1.9224477905339563,1.918100420871026,1.9117763660690787,1.9063283722904851,1.902112008926272,1.8992457965147873,1.8942608818272229,1.8877199801436308,1.8818663981371357,1.8776228472831467,1.8726422124490463,1.8689225287588496,1.863075238040037,1.8577224068415124,1.8528506390294024,1.8466399099622939,1.8392514773555702,1.835558158339553,1.827726935880205,1.8220939207243014,1.8167679482286028,1.8116479616615415,1.8046758390270787,1.799732102064128,1.7931835843350776,1.7875159846760824,1.7814339599822846,1.7767910774757745,1.771041401476106,1.7682552196574626,1.7613320089802391,1.7550666351798005,1.7479422199623464,1.7419984607635297,1.7372667620323325,1.7337240941494918,1.7287639009131057,1.7248072345906733,1.7223363251334745,1.7170068416732023,1.710164674895046,1.7052545269626809,1.698585566246023,1.6937870575338585,1.6874763178501189,1.6823606265577449,1.6779007638495078,1.675135525810759,1.6701285911386585,1.6672957451172223,1.6599379200097593,1.6531466990804542,1.647304463097731,1.6429716710622968,1.6371200430049095,1.6320124208197588,1.6268954747931175,1.6229508745088683,1.61760952706932,1.6123527089991305,1.6059225348734767,1.600660492852648,1.594189612953388,1.588679088407973,1.5847700554368112,1.5796863187212682,1.576131324530963,1.5715741211035361,1.565743682558111,1.5620592985186927,1.5577805135867469,1.5535079325543248,1.5493433895049076,1.5454006310097033,1.5399484081458055,1.5333201419091547,1.529797699343849,1.5251209841476487,1.5211688273962027,1.5181631955112056,1.516038039361671,1.5108784148221568,1.5051349526290152,1.4992606171763778,1.4934324350007833,1.4866081278884362,1.4819770477331546,1.479849740620672,1.4741661015332206,1.4693469932871863,1.4645589392505882,1.4599565257313505,1.4531460652141186,1.4466626380134822,1.4454679000323438,1.4411501096266515,1.437276764760594,1.4318482216156387,1.4253220535834932,1.4198039210547742,1.4143502353542363,1.410674240030612,1.4089029801841169,1.4045930838344223,1.401749294960583,1.399072321733114,1.3973679413898785,1.3939826028396076,1.388344159072909,1.3846299419155759,1.3843141821922622,1.3799210243161364,1.3787448427442701,1.3753652463318586,1.3684726804965806,1.3638825618653698,1.3568155376657112,1.3542046458349657,1.351692270422511,1.34664367815985,1.3443024255729856,1.3390897686412415,1.332392794154375,1.3272674581005643,1.3211489713810425,1.317026806856857,1.3126675110317556,1.3087690713465083,1.303822745218924,1.3000830887650372,1.2962644800018779,1.2954448474428215,1.2914186860258299,1.288992076319448,1.287416971860315,1.285655414321117,1.2818296718361493,1.2784048509158332,1.277805008745496,1.2759765653511188,1.274443465491058,1.2725822969597544,1.2721331344736366,1.2705370970796686,1.268915774260647,1.2698316680697954,1.2651358120058598,1.2614548441009037,1.2563236765681363,1.2550080991595611,1.249095335097332,1.2430726063901396,1.2427163493288722,1.2407893886376424,1.23634983034682,1.2308364310431863,1.2257658167600396,1.2215148397156972,1.2194636303137953,1.217031725250133,1.216561553072135,1.2159737287765426,1.212831473830261,1.2104987861850933,1.2069173597584097,1.2053583996466106,1.2060107271590828,1.2047680481488268,1.2027304333421096,1.199776671213057,1.1984133949338291,1.1957881294311536,1.1943231418779487,1.1945711955964262,1.1920111723097735,1.1923467843794104,1.1928240163202792,1.190111714708125,1.1847050378346442,1.1802459803192833,1.1792390860550532,1.1753830484583703,1.1717615726758819,1.1673900308262624,1.1638136988171912,1.1610475096008737,1.156518835561448,1.1534762257349156,1.1512490452365571,1.1494990836478582,1.144983486453962,1.1437578829836166,1.1428595447996834,1.142691052818653,1.1416598315919917,1.1414560725506249,1.1401578827809027,1.137861194335037,1.1359140206365015,1.1336984914045378,1.1315256093140378,1.131087969113444,1.130667103599192,1.1307483771090339,1.1296610565696998,1.128817289086592,1.1296935487277793,1.130932729559774,1.130356166035351,1.1291330858151365,1.1256046719869985,1.1191748431526103,1.114054194736789,1.113940369241287,1.1111848664427206,1.1081984544713492,1.1062584928747061,1.1036513531617438,1.102677502500357,1.099126753401123,1.0962377658733224,1.094607401049784,1.0917398139706491,1.0918230362018089,1.0948090024440544,1.0954299388587443,1.0953001877318735,1.094444618568863,1.0929038072037274,1.0908758651216022,1.088043481435665,1.089227906196007,1.0895563936234949,1.0884519901748664,1.0888140325442817,1.0885215885361392,1.0880494198978523,1.0887646680223397,1.0869969626284817,1.0889209959710318,1.091812305562766,1.0927872978257804,1.0885400488273869,1.086047690161635,1.0839055932396655,1.0808175326433693,1.0790484484675924,1.0797982349814645,1.0776833187694526,1.0771202780811835,1.0760266217950956,1.0741272229750727,1.075206620276468,1.0744272456556834,1.0731941713918405,1.0736423130244837,1.073065138043838,1.0736487760964317,1.074917252792015,1.0733898374013282,1.0723208813979304,1.0712923490998945,1.0696114032820612,1.07048421244435,1.070745579138372,1.069826387160641,1.073330932532136,1.0742334645038094,1.074005600006092,1.0757989811333957,1.0792887685071866,1.0794379708856843,1.079938842257852,1.0791839488920556],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,0.98],\"title\":{\"text\":\"lr\"},\"type\":\"log\"},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,0.485],\"title\":{\"text\":\"value\"},\"type\":\"log\"},\"xaxis2\":{\"anchor\":\"y2\",\"domain\":[0.0,0.98],\"matches\":\"x\",\"showticklabels\":false,\"type\":\"log\"},\"yaxis2\":{\"anchor\":\"x2\",\"domain\":[0.515,1.0],\"title\":{\"text\":\"value\"},\"type\":\"log\"},\"annotations\":[{\"font\":{},\"showarrow\":false,\"text\":\"variable=ewm_batch_train_loss\",\"textangle\":90,\"x\":0.98,\"xanchor\":\"left\",\"xref\":\"paper\",\"y\":0.2425,\"yanchor\":\"middle\",\"yref\":\"paper\"},{\"font\":{},\"showarrow\":false,\"text\":\"variable=batch_train_loss\",\"textangle\":90,\"x\":0.98,\"xanchor\":\"left\",\"xref\":\"paper\",\"y\":0.7575000000000001,\"yanchor\":\"middle\",\"yref\":\"paper\"}],\"legend\":{\"tracegroupgap\":0},\"margin\":{\"t\":60},\"height\":750},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('ee35027e-c7ca-4ad7-981d-0b03683276b4');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                            </script>        </div>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum learning rate: 0.001918586422984909\n"
     ]
    }
   ],
   "source": [
    "train_dataset = CMIDataset(\"full_dataset\")\n",
    "full_dataset_loader = DL(train_dataset, TRAIN_BATCH_SIZE, shuffle=True)\n",
    "_, mock_training_metrics = mk_model_and_fit(\n",
    "    full_dataset_loader,\n",
    "    partial(torch.optim.lr_scheduler.ExponentialLR, gamma=MOCK_TRAINING_GAMMA),\n",
    "    MOCK_TRAINING_EPOCHS,\n",
    "    criterion= nn.CrossEntropyLoss(label_smoothing=0.1),\n",
    ")\n",
    "mock_training_metrics = post_process_mock_training_metrics(mock_training_metrics)\n",
    "plt_lr_search_training_metrics(mock_training_metrics)\n",
    "max_lr = mock_training_metrics[\"ewm_batch_train_loss\"].idxmin()\n",
    "print(\"Maximum learning rate:\", max_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21c1bcb",
   "metadata": {
    "papermill": {
     "duration": 0.015047,
     "end_time": "2025-08-02T11:26:29.351055",
     "exception": false,
     "start_time": "2025-08-02T11:26:29.336008",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eccfd5f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-02T11:26:30.302707Z",
     "iopub.status.busy": "2025-08-02T11:26:30.302531Z",
     "iopub.status.idle": "2025-08-02T11:26:30.306635Z",
     "shell.execute_reply": "2025-08-02T11:26:30.306194Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.941075,
     "end_time": "2025-08-02T11:26:30.307624",
     "exception": false,
     "start_time": "2025-08-02T11:26:29.366549",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def mixup_data(x, y, alpha=0.2):\n",
    "    \"\"\"\n",
    "    Return mixed inputs and mixed targets (one-hot) for mixup.\n",
    "    x: Tensor of shape (batch_size, features, seq_len)\n",
    "    y: Tensor of shape (batch_size, num_classes)\n",
    "    \"\"\"\n",
    "    if alpha > 0:\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "    else:\n",
    "        lam = 1.0\n",
    "    batch_size = x.size(0)\n",
    "    index = torch.randperm(batch_size).to(x.device)\n",
    "\n",
    "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "    mixed_y = lam * y + (1 - lam) * y[index, :]\n",
    "    return mixed_x, mixed_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "941ea005",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-02T11:26:30.326271Z",
     "iopub.status.busy": "2025-08-02T11:26:30.326049Z",
     "iopub.status.idle": "2025-08-02T11:26:30.343798Z",
     "shell.execute_reply": "2025-08-02T11:26:30.343286Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.027971,
     "end_time": "2025-08-02T11:26:30.344749",
     "exception": false,
     "start_time": "2025-08-02T11:26:30.316778",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_on_all_folds(lr_scheduler_kw:dict, optimizer_kw:dict) -> float:\n",
    "    seed_everything(seed=SEED)\n",
    "    n_splits = 5\n",
    "\n",
    "    fold_metrics = []\n",
    "    best_fold_metrics = []\n",
    "    best_models = []\n",
    "\n",
    "    fold_patterns = join(\n",
    "        dataset_path,\n",
    "        # \"preprocessed_dataset\",\n",
    "        \"fold*\",\n",
    "    )\n",
    "    fold_pths = glob(fold_patterns)\n",
    "    # all_training_metrics = {}\n",
    "\n",
    "    for fold, fold_pth in enumerate(fold_pths):\n",
    "        print(\"training:\", fold + 1)\n",
    "        train_dataset = CMIDataset(fold_pth, \"train\")\n",
    "        # criterion = compute_weighted_cross_entropy_loss(train_dataset)\n",
    "        criterion = torch.nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "        train_loader = DL(train_dataset, TRAIN_BATCH_SIZE, shuffle=True, drop_last=True)\n",
    "        validation_dataset = CMIDataset(fold_pth, \"validation\")\n",
    "        validation_loader = DL(validation_dataset, VALIDATION_BATCH_SIZE, shuffle=False, drop_last=True)\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"Fold {fold + 1}/{n_splits}\")\n",
    "\n",
    "        seed_everything(seed=SEED + fold)\n",
    "        model = mk_model()\n",
    "\n",
    "        # Optimizer et scheduler\n",
    "        # min_lr = max_lr / 100\n",
    "        optimizer = torch.optim.AdamW(\n",
    "            model.parameters(),\n",
    "            WARMUP_LR_INIT,\n",
    "            # weight_decay=WEIGHT_DECAY,\n",
    "            weight_decay=optimizer_kw[\"weight_decay\"],\n",
    "            betas=(optimizer_kw[\"beta_0\"], optimizer_kw[\"beta_1\"]),\n",
    "        )\n",
    "        steps_per_epoch = len(train_loader)\n",
    "        scheduler = CosineAnnealingWarmupRestarts(\n",
    "            optimizer,\n",
    "            warmup_steps=lr_scheduler_kw[\"warmup_epochs\"] * steps_per_epoch,\n",
    "            cycle_mult=lr_scheduler_kw[\"cycle_mult\"],\n",
    "            max_lr=lr_scheduler_kw[\"max_lr\"],\n",
    "            min_lr=lr_scheduler_kw[\"max_lr\"] / lr_scheduler_kw[\"max_to_min_div_factor\"],\n",
    "            cycle_length=lr_scheduler_kw[\"init_cycle_epochs\"] * steps_per_epoch,\n",
    "            gamma=lr_scheduler_kw[\"lr_cycle_factor\"],\n",
    "        ) \n",
    "\n",
    "\n",
    "        # Early stopping\n",
    "        best_metric = -np.inf\n",
    "        best_binary_f1 = -np.inf\n",
    "        best_macro_f1 = -np.inf\n",
    "        epochs_no_improve = 0\n",
    "\n",
    "        for epoch in range(1, TRAINING_EPOCHS + 1):\n",
    "            # Training phase\n",
    "            model.train()\n",
    "            train_loss = 0.0\n",
    "            total = 0\n",
    "            for batch_x, batch_y in train_loader:\n",
    "                batch_x = batch_x.to(device).clone()\n",
    "                add_noise = torch.randn_like(batch_x, device=device) * 0.04\n",
    "                scale_noise = torch.rand_like(batch_x, device=device) * (1.1 - 0.9) + 0.9\n",
    "                batch_x = (add_noise + batch_x) * scale_noise\n",
    "                batch_x[:TRAIN_BATCH_SIZE // 2, tof_idx + thm_idx] = 0.0\n",
    "                batch_y = batch_y.to(device)\n",
    "                batch_x = batch_x.float()\n",
    "                \n",
    "                batch_x, batch_y = mixup_data(batch_x, batch_y)\n",
    "            \n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(batch_x)\n",
    "                loss = criterion(outputs, batch_y)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                scheduler.step()\n",
    "\n",
    "                train_loss += loss.item() * batch_x.size(0)\n",
    "                total += batch_x.size(0)\n",
    "            train_loss /= total\n",
    "\n",
    "            # Validation phase\n",
    "            model.eval()\n",
    "            val_loss = 0.0\n",
    "            total = 0\n",
    "            all_true = []\n",
    "            all_pred = []\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for batch_x, batch_y in validation_loader:\n",
    "                    batch_x = batch_x.to(device).clone()\n",
    "                    batch_y = batch_y.to(device)\n",
    "                    batch_x[:VALIDATION_BATCH_SIZE // 2, tof_idx + thm_idx] = 0.0\n",
    "\n",
    "                    outputs = model(batch_x)\n",
    "                    loss = criterion(outputs, batch_y)\n",
    "                    val_loss += loss.item() * batch_x.size(0)\n",
    "                    total += batch_x.size(0)\n",
    "\n",
    "                    # Get predicted class indices\n",
    "                    preds = torch.argmax(outputs, dim=1).cpu().numpy()\n",
    "                    # Get true class indices from one-hot\n",
    "                    trues = torch.argmax(batch_y, dim=1).cpu().numpy()\n",
    "\n",
    "                    all_true.append(trues)\n",
    "                    all_pred.append(preds)\n",
    "\n",
    "            val_loss /= total\n",
    "            all_true = np.concatenate(all_true)\n",
    "            all_pred = np.concatenate(all_pred)\n",
    "\n",
    "            # Compute competition metrics\n",
    "            # Binary classification: BFRB (1) vs non-BFRB (0)\n",
    "            binary_true = np.isin(all_true, bfrb_indices).astype(int)\n",
    "            binary_pred = np.isin(all_pred, bfrb_indices).astype(int)\n",
    "            binary_f1 = f1_score(binary_true, binary_pred)\n",
    "\n",
    "            # Collapse non-BFRB gestures into a single class\n",
    "            collapsed_true = np.where(\n",
    "                np.isin(all_true, bfrb_indices),\n",
    "                all_true,\n",
    "                len(bfrb_gestures)  # Single non-BFRB class\n",
    "            )\n",
    "            collapsed_pred = np.where(\n",
    "                np.isin(all_pred, bfrb_indices),\n",
    "                all_pred,\n",
    "                len(bfrb_gestures)  # Single non-BFRB class\n",
    "            )\n",
    "\n",
    "            # Macro F1 on collapsed classes\n",
    "            macro_f1 = f1_score(collapsed_true, collapsed_pred, average='macro')\n",
    "            final_metric = (binary_f1 + macro_f1) / 2\n",
    "\n",
    "            print(f\"Epoch {epoch:02d}: Binary F1 = {binary_f1:.4f}, Macro F1 = {macro_f1:.4f}, Final Metric = {final_metric:.4f}\")\n",
    "\n",
    "            if final_metric > best_metric:\n",
    "                best_metric = final_metric\n",
    "                best_binary_f1 = binary_f1\n",
    "                best_macro_f1 = macro_f1\n",
    "                epochs_no_improve = 0\n",
    "                best_model_state = model.state_dict()\n",
    "                print(f\"  New best metric! Saving model...\")\n",
    "            else:\n",
    "                epochs_no_improve += 1\n",
    "                if epochs_no_improve >= PATIENCE:\n",
    "                    print(f\"Early stopping triggered at epoch {epoch}\")\n",
    "                    model.load_state_dict(best_model_state)\n",
    "                    break\n",
    "\n",
    "        torch.save(best_model_state, f\"best_model_fold{fold}.pth\")\n",
    "        # Free memory used by datasets and data loaders\n",
    "        del train_dataset\n",
    "        del validation_dataset\n",
    "        del train_loader\n",
    "        del validation_loader\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        best_models.append(best_model_state)\n",
    "        fold_metrics.append({\n",
    "            'binary_f1': binary_f1,\n",
    "            'macr, drop_last=Trueo_f1': macro_f1,\n",
    "            'final_metric': final_metric\n",
    "        })\n",
    "        \n",
    "        best_fold_metrics.append({\n",
    "            'binary_f1': best_binary_f1,\n",
    "            'macro_f1': best_macro_f1,\n",
    "            'final_metric': best_metric\n",
    "        })\n",
    "        \n",
    "        print(f\"\\nFold {fold + 1} completed.\")\n",
    "        print(f\"Final validation metrics - Binary F1: {binary_f1:.4f}, Macro F1: {macro_f1:.4f}, Final: {final_metric:.4f}\")\n",
    "        print(f\"Best validation metrics - Binary F1: {best_binary_f1:.4f}, Macro F1: {best_macro_f1:.4f}, Final: {best_metric:.4f}\")\n",
    "\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"Cross-Validation Results\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "    # Statistiques pour les meilleures métriques\n",
    "    best_binary_f1 = [m['binary_f1'] for m in best_fold_metrics]\n",
    "    best_macro_f1 = [m['macro_f1'] for m in best_fold_metrics]\n",
    "    best_metrics = [m['final_metric'] for m in best_fold_metrics]\n",
    "\n",
    "    print(\"\\nBest Fold-wise Metrics:\")\n",
    "    for i, (bf1, mf1, fm) in enumerate(zip(best_binary_f1, best_macro_f1, best_metrics)):\n",
    "        print(f\"Fold {i+1}: Binary F1 = {bf1:.4f}, Macro F1 = {mf1:.4f}, Final = {fm:.4f}\")\n",
    "\n",
    "    print(\"\\nGlobal Statistics (Best Metrics):\")\n",
    "    print(f\"Mean Best Final Metric: {np.mean(best_metrics):.4f} ± {np.std(best_metrics):.4f}\")\n",
    "    print(f\"Mean Best Binary F1: {np.mean(best_binary_f1):.4f} ± {np.std(best_binary_f1):.4f}\")\n",
    "    print(f\"Mean Best Macro F1: {np.mean(best_macro_f1):.4f} ± {np.std(best_macro_f1):.4f}\")\n",
    "    \n",
    "    return np.mean(best_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8f14d2b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-02T11:26:30.362466Z",
     "iopub.status.busy": "2025-08-02T11:26:30.361893Z",
     "iopub.status.idle": "2025-08-02T11:26:30.366500Z",
     "shell.execute_reply": "2025-08-02T11:26:30.365927Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.014357,
     "end_time": "2025-08-02T11:26:30.367454",
     "exception": false,
     "start_time": "2025-08-02T11:26:30.353097",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(trial: optuna.trial.Trial) -> float:\n",
    "    return train_on_all_folds(\n",
    "        lr_scheduler_kw={\n",
    "            \"warmup_epochs\": trial.suggest_int(\"warmup_epochs\", 1, 10),\n",
    "            \"cycle_mult\": trial.suggest_float(\"cycle_mult\", 0.5, 2),\n",
    "            \"max_lr\": trial.suggest_float(\"max_lr\", max_lr / 3, max_lr * 3),\n",
    "            \"max_to_min_div_factor\": trial.suggest_float(\"max_to_min_div_factor\", 100, 300, step=25),\n",
    "            \"init_cycle_epochs\": trial.suggest_int(\"init_cycle_epochs\", 2, 10),\n",
    "            \"lr_cycle_factor\": trial.suggest_float(\"lr_cycle_factor\", 0.3, 1),\n",
    "        },\n",
    "        optimizer_kw={\n",
    "            \"weight_decay\": trial.suggest_float(\"weight_decay\", 5e-4, 1e-3),\n",
    "            \"beta_0\":trial.suggest_float(\"beta_0\", 0.8, 0.999),\n",
    "            \"beta_1\":trial.suggest_float(\"beta_1\", 0.99, 0.9999),\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d0936698",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-02T11:26:30.385055Z",
     "iopub.status.busy": "2025-08-02T11:26:30.384637Z",
     "iopub.status.idle": "2025-08-02T11:33:13.504786Z",
     "shell.execute_reply": "2025-08-02T11:33:13.503986Z"
    },
    "papermill": {
     "duration": 403.130501,
     "end_time": "2025-08-02T11:33:13.506236",
     "exception": false,
     "start_time": "2025-08-02T11:26:30.375735",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training: 1\n",
      "\n",
      "==================================================\n",
      "Fold 1/5\n",
      "Epoch 01: Binary F1 = 0.8486, Macro F1 = 0.3027, Final Metric = 0.5757\n",
      "  New best metric! Saving model...\n",
      "Epoch 02: Binary F1 = 0.9183, Macro F1 = 0.3747, Final Metric = 0.6465\n",
      "  New best metric! Saving model...\n",
      "Epoch 03: Binary F1 = 0.9395, Macro F1 = 0.4549, Final Metric = 0.6972\n",
      "  New best metric! Saving model...\n",
      "Epoch 04: Binary F1 = 0.9482, Macro F1 = 0.4601, Final Metric = 0.7042\n",
      "  New best metric! Saving model...\n",
      "Epoch 05: Binary F1 = 0.9391, Macro F1 = 0.4664, Final Metric = 0.7028\n",
      "Epoch 06: Binary F1 = 0.9427, Macro F1 = 0.5013, Final Metric = 0.7220\n",
      "  New best metric! Saving model...\n",
      "Epoch 07: Binary F1 = 0.9473, Macro F1 = 0.4615, Final Metric = 0.7044\n",
      "Epoch 08: Binary F1 = 0.9562, Macro F1 = 0.4961, Final Metric = 0.7262\n",
      "  New best metric! Saving model...\n",
      "Epoch 09: Binary F1 = 0.9497, Macro F1 = 0.5265, Final Metric = 0.7381\n",
      "  New best metric! Saving model...\n",
      "Epoch 10: Binary F1 = 0.9508, Macro F1 = 0.5596, Final Metric = 0.7552\n",
      "  New best metric! Saving model...\n",
      "Epoch 11: Binary F1 = 0.9626, Macro F1 = 0.5774, Final Metric = 0.7700\n",
      "  New best metric! Saving model...\n",
      "Epoch 12: Binary F1 = 0.9627, Macro F1 = 0.6065, Final Metric = 0.7846\n",
      "  New best metric! Saving model...\n",
      "Epoch 13: Binary F1 = 0.9650, Macro F1 = 0.6151, Final Metric = 0.7901\n",
      "  New best metric! Saving model...\n",
      "Epoch 14: Binary F1 = 0.9678, Macro F1 = 0.5942, Final Metric = 0.7810\n",
      "Epoch 15: Binary F1 = 0.9672, Macro F1 = 0.5995, Final Metric = 0.7833\n",
      "Epoch 16: Binary F1 = 0.9690, Macro F1 = 0.6182, Final Metric = 0.7936\n",
      "  New best metric! Saving model...\n",
      "Epoch 17: Binary F1 = 0.9675, Macro F1 = 0.6230, Final Metric = 0.7953\n",
      "  New best metric! Saving model...\n",
      "Epoch 18: Binary F1 = 0.9676, Macro F1 = 0.6046, Final Metric = 0.7861\n",
      "Epoch 19: Binary F1 = 0.9645, Macro F1 = 0.6022, Final Metric = 0.7834\n",
      "Epoch 20: Binary F1 = 0.9652, Macro F1 = 0.6178, Final Metric = 0.7915\n",
      "Epoch 21: Binary F1 = 0.9723, Macro F1 = 0.6276, Final Metric = 0.7999\n",
      "  New best metric! Saving model...\n",
      "Epoch 22: Binary F1 = 0.9683, Macro F1 = 0.6252, Final Metric = 0.7967\n",
      "Epoch 23: Binary F1 = 0.9706, Macro F1 = 0.6214, Final Metric = 0.7960\n",
      "Epoch 24: Binary F1 = 0.9690, Macro F1 = 0.6165, Final Metric = 0.7928\n",
      "Epoch 25: Binary F1 = 0.9691, Macro F1 = 0.6181, Final Metric = 0.7936\n",
      "\n",
      "Fold 1 completed.\n",
      "Final validation metrics - Binary F1: 0.9691, Macro F1: 0.6181, Final: 0.7936\n",
      "Best validation metrics - Binary F1: 0.9723, Macro F1: 0.6276, Final: 0.7999\n",
      "training: 2\n",
      "\n",
      "==================================================\n",
      "Fold 2/5\n",
      "Epoch 01: Binary F1 = 0.8157, Macro F1 = 0.2761, Final Metric = 0.5459\n",
      "  New best metric! Saving model...\n",
      "Epoch 02: Binary F1 = 0.9009, Macro F1 = 0.3604, Final Metric = 0.6306\n",
      "  New best metric! Saving model...\n",
      "Epoch 03: Binary F1 = 0.9313, Macro F1 = 0.4160, Final Metric = 0.6737\n",
      "  New best metric! Saving model...\n",
      "Epoch 04: Binary F1 = 0.9091, Macro F1 = 0.4550, Final Metric = 0.6820\n",
      "  New best metric! Saving model...\n",
      "Epoch 05: Binary F1 = 0.9565, Macro F1 = 0.4714, Final Metric = 0.7139\n",
      "  New best metric! Saving model...\n",
      "Epoch 06: Binary F1 = 0.9527, Macro F1 = 0.5321, Final Metric = 0.7424\n",
      "  New best metric! Saving model...\n",
      "Epoch 07: Binary F1 = 0.8870, Macro F1 = 0.4866, Final Metric = 0.6868\n",
      "Epoch 08: Binary F1 = 0.9500, Macro F1 = 0.5327, Final Metric = 0.7414\n",
      "Epoch 09: Binary F1 = 0.9696, Macro F1 = 0.5606, Final Metric = 0.7651\n",
      "  New best metric! Saving model...\n",
      "Epoch 10: Binary F1 = 0.9077, Macro F1 = 0.4798, Final Metric = 0.6937\n",
      "Epoch 11: Binary F1 = 0.9606, Macro F1 = 0.5812, Final Metric = 0.7709\n",
      "  New best metric! Saving model...\n",
      "Epoch 12: Binary F1 = 0.9724, Macro F1 = 0.6067, Final Metric = 0.7895\n",
      "  New best metric! Saving model...\n",
      "Epoch 13: Binary F1 = 0.9715, Macro F1 = 0.6251, Final Metric = 0.7983\n",
      "  New best metric! Saving model...\n",
      "Epoch 14: Binary F1 = 0.9619, Macro F1 = 0.5785, Final Metric = 0.7702\n",
      "Epoch 15: Binary F1 = 0.9596, Macro F1 = 0.6091, Final Metric = 0.7843\n",
      "Epoch 16: Binary F1 = 0.9678, Macro F1 = 0.6148, Final Metric = 0.7913\n",
      "Epoch 17: Binary F1 = 0.9701, Macro F1 = 0.6153, Final Metric = 0.7927\n",
      "Epoch 18: Binary F1 = 0.9669, Macro F1 = 0.6005, Final Metric = 0.7837\n",
      "Epoch 19: Binary F1 = 0.9722, Macro F1 = 0.6297, Final Metric = 0.8010\n",
      "  New best metric! Saving model...\n",
      "Epoch 20: Binary F1 = 0.9723, Macro F1 = 0.6171, Final Metric = 0.7947\n",
      "Epoch 21: Binary F1 = 0.9715, Macro F1 = 0.6334, Final Metric = 0.8024\n",
      "  New best metric! Saving model...\n",
      "Epoch 22: Binary F1 = 0.9700, Macro F1 = 0.6317, Final Metric = 0.8009\n",
      "Epoch 23: Binary F1 = 0.9709, Macro F1 = 0.6243, Final Metric = 0.7976\n",
      "Epoch 24: Binary F1 = 0.9693, Macro F1 = 0.6349, Final Metric = 0.8021\n",
      "Epoch 25: Binary F1 = 0.9693, Macro F1 = 0.6377, Final Metric = 0.8035\n",
      "  New best metric! Saving model...\n",
      "\n",
      "Fold 2 completed.\n",
      "Final validation metrics - Binary F1: 0.9693, Macro F1: 0.6377, Final: 0.8035\n",
      "Best validation metrics - Binary F1: 0.9693, Macro F1: 0.6377, Final: 0.8035\n",
      "training: 3\n",
      "\n",
      "==================================================\n",
      "Fold 3/5\n",
      "Epoch 01: Binary F1 = 0.7225, Macro F1 = 0.2702, Final Metric = 0.4963\n",
      "  New best metric! Saving model...\n",
      "Epoch 02: Binary F1 = 0.9141, Macro F1 = 0.3973, Final Metric = 0.6557\n",
      "  New best metric! Saving model...\n",
      "Epoch 03: Binary F1 = 0.9192, Macro F1 = 0.4138, Final Metric = 0.6665\n",
      "  New best metric! Saving model...\n",
      "Epoch 04: Binary F1 = 0.9394, Macro F1 = 0.4899, Final Metric = 0.7146\n",
      "  New best metric! Saving model...\n",
      "Epoch 05: Binary F1 = 0.9476, Macro F1 = 0.4720, Final Metric = 0.7098\n",
      "Epoch 06: Binary F1 = 0.8887, Macro F1 = 0.3890, Final Metric = 0.6388\n",
      "Epoch 07: Binary F1 = 0.9455, Macro F1 = 0.4492, Final Metric = 0.6973\n",
      "Epoch 08: Binary F1 = 0.9597, Macro F1 = 0.5234, Final Metric = 0.7416\n",
      "  New best metric! Saving model...\n",
      "Epoch 09: Binary F1 = 0.9573, Macro F1 = 0.4900, Final Metric = 0.7236\n",
      "Epoch 10: Binary F1 = 0.9491, Macro F1 = 0.5035, Final Metric = 0.7263\n",
      "Epoch 11: Binary F1 = 0.9595, Macro F1 = 0.5236, Final Metric = 0.7416\n",
      "Epoch 12: Binary F1 = 0.9609, Macro F1 = 0.5776, Final Metric = 0.7693\n",
      "  New best metric! Saving model...\n",
      "Epoch 13: Binary F1 = 0.9721, Macro F1 = 0.5858, Final Metric = 0.7790\n",
      "  New best metric! Saving model...\n",
      "Epoch 14: Binary F1 = 0.9600, Macro F1 = 0.5446, Final Metric = 0.7523\n",
      "Epoch 15: Binary F1 = 0.9642, Macro F1 = 0.5545, Final Metric = 0.7593\n",
      "Epoch 16: Binary F1 = 0.9729, Macro F1 = 0.5803, Final Metric = 0.7766\n",
      "Epoch 17: Binary F1 = 0.9699, Macro F1 = 0.5981, Final Metric = 0.7840\n",
      "  New best metric! Saving model...\n",
      "Epoch 18: Binary F1 = 0.9556, Macro F1 = 0.5957, Final Metric = 0.7757\n",
      "Epoch 19: Binary F1 = 0.9691, Macro F1 = 0.5804, Final Metric = 0.7747\n",
      "Epoch 20: Binary F1 = 0.9608, Macro F1 = 0.6077, Final Metric = 0.7842\n",
      "  New best metric! Saving model...\n",
      "Epoch 21: Binary F1 = 0.9664, Macro F1 = 0.5932, Final Metric = 0.7798\n",
      "Epoch 22: Binary F1 = 0.9697, Macro F1 = 0.5906, Final Metric = 0.7802\n",
      "Epoch 23: Binary F1 = 0.9659, Macro F1 = 0.5893, Final Metric = 0.7776\n",
      "Epoch 24: Binary F1 = 0.9672, Macro F1 = 0.5998, Final Metric = 0.7835\n",
      "Epoch 25: Binary F1 = 0.9680, Macro F1 = 0.5995, Final Metric = 0.7838\n",
      "\n",
      "Fold 3 completed.\n",
      "Final validation metrics - Binary F1: 0.9680, Macro F1: 0.5995, Final: 0.7838\n",
      "Best validation metrics - Binary F1: 0.9608, Macro F1: 0.6077, Final: 0.7842\n",
      "training: 4\n",
      "\n",
      "==================================================\n",
      "Fold 4/5\n",
      "Epoch 01: Binary F1 = 0.8130, Macro F1 = 0.2548, Final Metric = 0.5339\n",
      "  New best metric! Saving model...\n",
      "Epoch 02: Binary F1 = 0.9219, Macro F1 = 0.3505, Final Metric = 0.6362\n",
      "  New best metric! Saving model...\n",
      "Epoch 03: Binary F1 = 0.9441, Macro F1 = 0.4200, Final Metric = 0.6821\n",
      "  New best metric! Saving model...\n",
      "Epoch 04: Binary F1 = 0.9492, Macro F1 = 0.3666, Final Metric = 0.6579\n",
      "Epoch 05: Binary F1 = 0.9515, Macro F1 = 0.4314, Final Metric = 0.6915\n",
      "  New best metric! Saving model...\n",
      "Epoch 06: Binary F1 = 0.9021, Macro F1 = 0.4357, Final Metric = 0.6689\n",
      "Epoch 07: Binary F1 = 0.9435, Macro F1 = 0.4835, Final Metric = 0.7135\n",
      "  New best metric! Saving model...\n",
      "Epoch 08: Binary F1 = 0.9436, Macro F1 = 0.4828, Final Metric = 0.7132\n",
      "Epoch 09: Binary F1 = 0.9604, Macro F1 = 0.5095, Final Metric = 0.7349\n",
      "  New best metric! Saving model...\n",
      "Epoch 10: Binary F1 = 0.9592, Macro F1 = 0.5338, Final Metric = 0.7465\n",
      "  New best metric! Saving model...\n",
      "Epoch 11: Binary F1 = 0.9693, Macro F1 = 0.5645, Final Metric = 0.7669\n",
      "  New best metric! Saving model...\n",
      "Epoch 12: Binary F1 = 0.9799, Macro F1 = 0.5726, Final Metric = 0.7762\n",
      "  New best metric! Saving model...\n",
      "Epoch 13: Binary F1 = 0.9783, Macro F1 = 0.5806, Final Metric = 0.7795\n",
      "  New best metric! Saving model...\n",
      "Epoch 14: Binary F1 = 0.9651, Macro F1 = 0.5697, Final Metric = 0.7674\n",
      "Epoch 15: Binary F1 = 0.9736, Macro F1 = 0.5945, Final Metric = 0.7840\n",
      "  New best metric! Saving model...\n",
      "Epoch 16: Binary F1 = 0.9789, Macro F1 = 0.5878, Final Metric = 0.7833\n",
      "Epoch 17: Binary F1 = 0.9773, Macro F1 = 0.5917, Final Metric = 0.7845\n",
      "  New best metric! Saving model...\n",
      "Epoch 18: Binary F1 = 0.9784, Macro F1 = 0.5840, Final Metric = 0.7812\n",
      "Epoch 19: Binary F1 = 0.9790, Macro F1 = 0.6103, Final Metric = 0.7946\n",
      "  New best metric! Saving model...\n",
      "Epoch 20: Binary F1 = 0.9766, Macro F1 = 0.6048, Final Metric = 0.7907\n",
      "Epoch 21: Binary F1 = 0.9760, Macro F1 = 0.5917, Final Metric = 0.7838\n",
      "Epoch 22: Binary F1 = 0.9760, Macro F1 = 0.6033, Final Metric = 0.7896\n",
      "Epoch 23: Binary F1 = 0.9758, Macro F1 = 0.6025, Final Metric = 0.7892\n",
      "Epoch 24: Binary F1 = 0.9775, Macro F1 = 0.6015, Final Metric = 0.7895\n",
      "Epoch 25: Binary F1 = 0.9774, Macro F1 = 0.6071, Final Metric = 0.7922\n",
      "\n",
      "Fold 4 completed.\n",
      "Final validation metrics - Binary F1: 0.9774, Macro F1: 0.6071, Final: 0.7922\n",
      "Best validation metrics - Binary F1: 0.9790, Macro F1: 0.6103, Final: 0.7946\n",
      "training: 5\n",
      "\n",
      "==================================================\n",
      "Fold 5/5\n",
      "Epoch 01: Binary F1 = 0.7230, Macro F1 = 0.2409, Final Metric = 0.4819\n",
      "  New best metric! Saving model...\n",
      "Epoch 02: Binary F1 = 0.8990, Macro F1 = 0.3558, Final Metric = 0.6274\n",
      "  New best metric! Saving model...\n",
      "Epoch 03: Binary F1 = 0.8681, Macro F1 = 0.3900, Final Metric = 0.6290\n",
      "  New best metric! Saving model...\n",
      "Epoch 04: Binary F1 = 0.9111, Macro F1 = 0.4232, Final Metric = 0.6672\n",
      "  New best metric! Saving model...\n",
      "Epoch 05: Binary F1 = 0.9318, Macro F1 = 0.4480, Final Metric = 0.6899\n",
      "  New best metric! Saving model...\n",
      "Epoch 06: Binary F1 = 0.9380, Macro F1 = 0.4539, Final Metric = 0.6960\n",
      "  New best metric! Saving model...\n",
      "Epoch 07: Binary F1 = 0.9376, Macro F1 = 0.4369, Final Metric = 0.6873\n",
      "Epoch 08: Binary F1 = 0.8913, Macro F1 = 0.4458, Final Metric = 0.6685\n",
      "Epoch 09: Binary F1 = 0.9379, Macro F1 = 0.4238, Final Metric = 0.6809\n",
      "Epoch 10: Binary F1 = 0.9473, Macro F1 = 0.5094, Final Metric = 0.7283\n",
      "  New best metric! Saving model...\n",
      "Epoch 11: Binary F1 = 0.9332, Macro F1 = 0.5523, Final Metric = 0.7428\n",
      "  New best metric! Saving model...\n",
      "Epoch 12: Binary F1 = 0.9554, Macro F1 = 0.5675, Final Metric = 0.7614\n",
      "  New best metric! Saving model...\n",
      "Epoch 13: Binary F1 = 0.9541, Macro F1 = 0.5869, Final Metric = 0.7705\n",
      "  New best metric! Saving model...\n",
      "Epoch 14: Binary F1 = 0.9443, Macro F1 = 0.5325, Final Metric = 0.7384\n",
      "Epoch 15: Binary F1 = 0.9575, Macro F1 = 0.5580, Final Metric = 0.7578\n",
      "Epoch 16: Binary F1 = 0.9557, Macro F1 = 0.5939, Final Metric = 0.7748\n",
      "  New best metric! Saving model...\n",
      "Epoch 17: Binary F1 = 0.9586, Macro F1 = 0.5895, Final Metric = 0.7740\n",
      "Epoch 18: Binary F1 = 0.9543, Macro F1 = 0.5794, Final Metric = 0.7668\n",
      "Epoch 19: Binary F1 = 0.9584, Macro F1 = 0.5947, Final Metric = 0.7766\n",
      "  New best metric! Saving model...\n",
      "Epoch 20: Binary F1 = 0.9641, Macro F1 = 0.6082, Final Metric = 0.7861\n",
      "  New best metric! Saving model...\n",
      "Epoch 21: Binary F1 = 0.9590, Macro F1 = 0.5799, Final Metric = 0.7695\n",
      "Epoch 22: Binary F1 = 0.9674, Macro F1 = 0.6088, Final Metric = 0.7881\n",
      "  New best metric! Saving model...\n",
      "Epoch 23: Binary F1 = 0.9633, Macro F1 = 0.5989, Final Metric = 0.7811\n",
      "Epoch 24: Binary F1 = 0.9641, Macro F1 = 0.6047, Final Metric = 0.7844\n",
      "Epoch 25: Binary F1 = 0.9641, Macro F1 = 0.6019, Final Metric = 0.7830\n",
      "\n",
      "Fold 5 completed.\n",
      "Final validation metrics - Binary F1: 0.9641, Macro F1: 0.6019, Final: 0.7830\n",
      "Best validation metrics - Binary F1: 0.9674, Macro F1: 0.6088, Final: 0.7881\n",
      "\n",
      "==================================================\n",
      "Cross-Validation Results\n",
      "==================================================\n",
      "\n",
      "Best Fold-wise Metrics:\n",
      "Fold 1: Binary F1 = 0.9723, Macro F1 = 0.6276, Final = 0.7999\n",
      "Fold 2: Binary F1 = 0.9693, Macro F1 = 0.6377, Final = 0.8035\n",
      "Fold 3: Binary F1 = 0.9608, Macro F1 = 0.6077, Final = 0.7842\n",
      "Fold 4: Binary F1 = 0.9790, Macro F1 = 0.6103, Final = 0.7946\n",
      "Fold 5: Binary F1 = 0.9674, Macro F1 = 0.6088, Final = 0.7881\n",
      "\n",
      "Global Statistics (Best Metrics):\n",
      "Mean Best Final Metric: 0.7941 ± 0.0072\n",
      "Mean Best Binary F1: 0.9697 ± 0.0060\n",
      "Mean Best Macro F1: 0.6184 ± 0.0121\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7940788237643376"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_on_all_folds(\n",
    "        lr_scheduler_kw={\n",
    "            \"warmup_epochs\": 8,\n",
    "            \"cycle_mult\": 0.7994284370327427,\n",
    "            \"max_lr\": 0.005581907927062619,\n",
    "            \"max_to_min_div_factor\": 275.0,\n",
    "            \"init_cycle_epochs\": 5,\n",
    "            \"lr_cycle_factor\": 0.5033112105827083,\n",
    "        },\n",
    "        optimizer_kw={\n",
    "            \"weight_decay\": 0.0006702308864102119,\n",
    "            \"beta_0\": 0.9089203414971434,\n",
    "            \"beta_1\": 0.9969898035522793,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "df9ccf8c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-02T11:33:13.535922Z",
     "iopub.status.busy": "2025-08-02T11:33:13.535715Z",
     "iopub.status.idle": "2025-08-02T11:33:13.539697Z",
     "shell.execute_reply": "2025-08-02T11:33:13.538846Z"
    },
    "papermill": {
     "duration": 0.01955,
     "end_time": "2025-08-02T11:33:13.541052",
     "exception": false,
     "start_time": "2025-08-02T11:33:13.521502",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# study = optuna.create_study(direction=\"maximize\")\n",
    "# study.optimize(objective, n_trials=100, timeout=60 * 60 * 2)\n",
    "\n",
    "# pruned_trials = study.get_trials(deepcopy=False, states=[TrialState.PRUNED])\n",
    "# complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])\n",
    "\n",
    "# print(\"Study statistics: \")\n",
    "# print(\"  Number of finished trials: \", len(study.trials))\n",
    "# print(\"  Number of pruned trials: \", len(pruned_trials))\n",
    "# print(\"  Number of complete trials: \", len(complete_trials))\n",
    "\n",
    "# print(\"Best trial:\")\n",
    "# trial = study.best_trial\n",
    "\n",
    "# print(\"  Value: \", trial.value)\n",
    "\n",
    "# print(\"  Params: \")\n",
    "# for key, value in trial.params.items():\n",
    "#     print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2b2f05",
   "metadata": {
    "papermill": {
     "duration": 0.023297,
     "end_time": "2025-08-02T11:33:13.582486",
     "exception": false,
     "start_time": "2025-08-02T11:33:13.559189",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338e1e1b",
   "metadata": {
    "papermill": {
     "duration": 0.017349,
     "end_time": "2025-08-02T11:33:13.615231",
     "exception": false,
     "start_time": "2025-08-02T11:33:13.597882",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Reloading best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2486858b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-02T11:33:13.644699Z",
     "iopub.status.busy": "2025-08-02T11:33:13.644430Z",
     "iopub.status.idle": "2025-08-02T11:33:13.934618Z",
     "shell.execute_reply": "2025-08-02T11:33:13.933984Z"
    },
    "papermill": {
     "duration": 0.305935,
     "end_time": "2025-08-02T11:33:13.935976",
     "exception": false,
     "start_time": "2025-08-02T11:33:13.630041",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_ensemble = []\n",
    "for fold in range(5):\n",
    "    model = mk_model()\n",
    "    checkpoint = torch.load(f\"best_model_fold{fold}.pth\", map_location=device, weights_only=True)\n",
    "    model.load_state_dict(checkpoint)\n",
    "    model.eval()\n",
    "    model_ensemble.append(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf8ae42",
   "metadata": {
    "papermill": {
     "duration": 0.013809,
     "end_time": "2025-08-02T11:33:13.964329",
     "exception": false,
     "start_time": "2025-08-02T11:33:13.950520",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Define preprocessing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2ab2d57b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-02T11:33:13.993213Z",
     "iopub.status.busy": "2025-08-02T11:33:13.992841Z",
     "iopub.status.idle": "2025-08-02T11:33:14.011288Z",
     "shell.execute_reply": "2025-08-02T11:33:14.010718Z"
    },
    "papermill": {
     "duration": 0.03452,
     "end_time": "2025-08-02T11:33:14.012421",
     "exception": false,
     "start_time": "2025-08-02T11:33:13.977901",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_fillna_val_per_feature_col(df:DF) -> dict:\n",
    "    return {col: 1.0 if col == 'rot_w' else 0 for col in get_feature_cols(df)}\n",
    "\n",
    "def imputed_features(df:DF) -> DF:\n",
    "    # Missing ToF values are already imputed by -1 which is inconvinient since we want all missing values to be NaN.    \n",
    "    # So we replace them by NaN and then perform imputing.  \n",
    "    tof_vals_to_nan = {col: -1.0 for col in df.columns if col.startswith(\"tof\")}\n",
    "\n",
    "    df[get_feature_cols(df)] = (\n",
    "        df\n",
    "        .loc[:, get_feature_cols(df)]\n",
    "        # df.replace with np.nan sets dtype to floar64 so we set it back to float32\n",
    "        .replace(tof_vals_to_nan, value=np.nan)\n",
    "        .astype(\"float32\")\n",
    "        .groupby(df[\"sequence_id\"], observed=True, as_index=False)\n",
    "        .ffill()\n",
    "        .groupby(df[\"sequence_id\"], observed=True, as_index=False)\n",
    "        .bfill()\n",
    "        # In case there are only nan in the column in the sequence\n",
    "        .fillna(get_fillna_val_per_feature_col(df))\n",
    "    )\n",
    "    return df\n",
    "\n",
    "def standardize_tof_cols_names(df: DF) -> DF:\n",
    "    renamed_cols = {}\n",
    "    pattern = re.compile(r\"^(tof_\\d_v)(\\d)$\")  # match 'tof_X_vY' where Y is a single digit\n",
    "\n",
    "    for col in df.columns:\n",
    "        match = pattern.match(col)\n",
    "        if match:\n",
    "            prefix, version = match.groups()\n",
    "            new_col = f\"{prefix}0{version}\"\n",
    "            renamed_cols[col] = new_col\n",
    "\n",
    "    return df.rename(columns=renamed_cols)\n",
    "\n",
    "def norm_quat_rotations(df:DF) -> DF:\n",
    "    df[QUATERNION_COLS] /= np.linalg.norm(df[QUATERNION_COLS], axis=1, keepdims=True)\n",
    "    return df\n",
    "\n",
    "def add_linear_acc_cols(df:DF) -> DF:\n",
    "    # Vectorized version of https://www.kaggle.com/code/wasupandceacar/lb-0-82-5fold-single-bert-model#Dataset `remove_gravity_from_acc`\n",
    "    rotations:Rotation = Rotation.from_quat(df[QUATERNION_COLS])\n",
    "    gravity_sensor_frame = rotations.apply(GRAVITY_WORLD, inverse=True).astype(\"float32\")\n",
    "    df[LINEAR_ACC_COLS] = df[RAW_ACCELRATION_COLS] - gravity_sensor_frame\n",
    "    return df\n",
    "\n",
    "def add_acc_magnitude(df:DF, acc_cols:list[str], acc_mag_col_name:str) -> DF:\n",
    "    return df.assign(**{acc_mag_col_name: np.linalg.norm(df.loc[:, acc_cols], axis=1)})\n",
    "\n",
    "def add_quat_angle_mag(df:DF) -> DF:\n",
    "    return df.assign(quat_rot_mag=np.arccos(df[\"rot_w\"]) * 2)\n",
    "\n",
    "def add_angular_velocity_features(df:DF) -> DF:\n",
    "    rotations = Rotation.from_quat(df[QUATERNION_COLS])\n",
    "    delta_rotations = rotations[1:] * rotations[:-1].inv()\n",
    "    delta_rot_velocity = delta_rotations.as_rotvec()\n",
    "    # Add extra line to avoid shape mismatch\n",
    "    delta_rot_velocity = np.vstack((np.zeros((1, 3)), delta_rot_velocity))\n",
    "    delta_rot_magnitude = norm(delta_rot_velocity, axis=1, keepdims=True)\n",
    "    delta_rot_axes = delta_rot_velocity / (delta_rot_magnitude + EPSILON)\n",
    "    df[DELTA_ROTATION_ANGULAR_VELOCITY_COLS] = delta_rot_velocity\n",
    "    df[DELTA_ROTATION_AXES_COLS] = delta_rot_axes\n",
    "    df[\"delta_rot_mag\"] = delta_rot_magnitude.squeeze()\n",
    "\n",
    "    return df\n",
    "\n",
    "def rot_euler_angles(df:DF) -> ndarray:\n",
    "    df[EULER_ANGLES_COLS] = (\n",
    "        Rotation\n",
    "        .from_quat(df[QUATERNION_COLS])\n",
    "        .as_euler(\"xyz\")\n",
    "        .squeeze()\n",
    "    )\n",
    "    return df\n",
    "\n",
    "def agg_tof_cols_per_sensor(df:DF) -> DF:\n",
    "    for tof_idx in tqdm(range(1, 6)):\n",
    "        tof_name = f\"tof_{tof_idx}\"\n",
    "        tof_cols = [f\"{tof_name}_v{v_idx}\" for v_idx in range(64)]\n",
    "        if any(map(lambda col: col not in df.columns, tof_cols)):\n",
    "            print(f\"Some (or) all ToF {tof_idx} columns are not in the df. Maybe you already ran this cell?\")\n",
    "            continue\n",
    "        df = pd.concat(\n",
    "            (\n",
    "                df.drop(columns=tof_cols),\n",
    "                # For some reasons, it's faster to call all the aggregation functions seperatly than agg(list of functions)\n",
    "                df[tof_cols].mean(axis=\"columns\").to_frame(tof_name + \"_mean\"),\n",
    "                df[tof_cols].std(axis=\"columns\").to_frame(tof_name + \"_std\"),\n",
    "                df[tof_cols].median(axis=\"columns\").to_frame(tof_name + \"_median\"),\n",
    "                df[tof_cols].min(axis=\"columns\").to_frame(tof_name + \"_min\"),\n",
    "                df[tof_cols].max(axis=\"columns\").to_frame(tof_name + \"_max\"),\n",
    "            ),\n",
    "            axis=\"columns\",\n",
    "        )\n",
    "    return df\n",
    "\n",
    "def add_diff_features(df:DF) -> DF:\n",
    "    return pd.concat(\n",
    "        (\n",
    "            df,\n",
    "            df\n",
    "            .groupby(\"sequence_id\", as_index=False, observed=True)\n",
    "            [get_feature_cols(df)]\n",
    "            .diff()\n",
    "            .fillna(get_fillna_val_per_feature_col(df))\n",
    "            .add_suffix(\"_diff\")\n",
    "        ),\n",
    "        axis=\"columns\",\n",
    "    )\n",
    "\n",
    "def length_normed_sequence_feat_arr(sequence: DF) -> ndarray:\n",
    "    features = (\n",
    "        sequence\n",
    "        .loc[:, meta_data[\"feature_cols\"]]\n",
    "        .values\n",
    "    )\n",
    "    normed_sequence_len = meta_data[\"pad_seq_len\"]\n",
    "    len_diff = abs(normed_sequence_len - len(features))\n",
    "    if len(features) < normed_sequence_len:\n",
    "        padded_features = np.pad(\n",
    "            features,\n",
    "            ((len_diff // 2 + len_diff % 2, len_diff // 2), (0, 0)),\n",
    "        )\n",
    "        return padded_features\n",
    "    elif len(features) > normed_sequence_len:\n",
    "        return features[len_diff // 2:-len_diff // 2]\n",
    "    else:\n",
    "        return features\n",
    "\n",
    "def preprocess_sequence(sequence_df:pl.DataFrame) -> ndarray:\n",
    "    return (\n",
    "        sequence_df                     \n",
    "        .to_pandas()                            # Convert to pandas dataframe.\n",
    "        .pipe(imputed_features)                 # Impute missing data.\n",
    "        .pipe(standardize_tof_cols_names)\n",
    "        .pipe(norm_quat_rotations)              # Norm quaternions\n",
    "        .pipe(add_linear_acc_cols)              # Add gravity free acceleration.\n",
    "        .pipe(add_acc_magnitude, RAW_ACCELRATION_COLS, \"acc_mag\")\n",
    "        .pipe(add_acc_magnitude, LINEAR_ACC_COLS, \"linear_acc_mag\")\n",
    "        .pipe(add_quat_angle_mag)\n",
    "        .pipe(add_angular_velocity_features)\n",
    "        .pipe(rot_euler_angles)                 # Add rotation acc expressed as euler angles.\n",
    "        # .pipe(agg_tof_cols_per_sensor)          # Aggregate ToF columns.\n",
    "        .pipe(add_diff_features)                # \n",
    "        .loc[:, sorted(meta_data[\"feature_cols\"])]      # Retain only the usefull columns a.k.a features.\n",
    "        .sub(meta_data[\"mean\"])                 # Subtract features by their mean, std norm pt.1.\n",
    "        .div(meta_data[\"std\"])                  # Divide by Standard deviation, std norm pt.2.\n",
    "        .pipe(length_normed_sequence_feat_arr)  # get feature ndarray of sequence.\n",
    "        .T                                      # Transpose to swap channel and X dimensions.\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6df209",
   "metadata": {
    "papermill": {
     "duration": 0.013789,
     "end_time": "2025-08-02T11:33:14.040022",
     "exception": false,
     "start_time": "2025-08-02T11:33:14.026233",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Define prediction function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "95f9148b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-02T11:33:14.068055Z",
     "iopub.status.busy": "2025-08-02T11:33:14.067800Z",
     "iopub.status.idle": "2025-08-02T11:33:14.073586Z",
     "shell.execute_reply": "2025-08-02T11:33:14.072760Z"
    },
    "papermill": {
     "duration": 0.02134,
     "end_time": "2025-08-02T11:33:14.074819",
     "exception": false,
     "start_time": "2025-08-02T11:33:14.053479",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict(sequence: pl.DataFrame, _: pl.DataFrame) -> str:\n",
    "    \"\"\"\n",
    "    Kaggle evaluation API will call this for each sequence.\n",
    "    sequence: polars DataFrame for a single sequence\n",
    "    demographics: unused in this model\n",
    "    Returns: predicted gesture string\n",
    "    \"\"\"\n",
    "    x_tensor = (\n",
    "        torch.unsqueeze(Tensor(preprocess_sequence(sequence)), dim=0)\n",
    "        .float()\n",
    "        .to(device)\n",
    "    )\n",
    "    print(x_tensor.shape)\n",
    "\n",
    "    all_outputs = []\n",
    "    with torch.no_grad():\n",
    "        for model_idx, model in enumerate(model_ensemble): # Only take the first one bc it's the only one that takes in the correct input shape\n",
    "            outputs = model(x_tensor)\n",
    "            all_outputs.append(outputs)\n",
    "\n",
    "    avg_outputs = torch.mean(torch.stack(all_outputs), dim=0)\n",
    "    pred_idx = torch.argmax(avg_outputs, dim=1).item()\n",
    "\n",
    "    return str(gesture_classes[pred_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac4beee",
   "metadata": {
    "papermill": {
     "duration": 0.015954,
     "end_time": "2025-08-02T11:33:14.106655",
     "exception": false,
     "start_time": "2025-08-02T11:33:14.090701",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Run inference server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a5eebc2a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-02T11:33:14.139851Z",
     "iopub.status.busy": "2025-08-02T11:33:14.139570Z",
     "iopub.status.idle": "2025-08-02T11:33:16.046743Z",
     "shell.execute_reply": "2025-08-02T11:33:16.045996Z"
    },
    "papermill": {
     "duration": 1.924797,
     "end_time": "2025-08-02T11:33:16.047890",
     "exception": false,
     "start_time": "2025-08-02T11:33:14.123093",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 696, 127])\n",
      "torch.Size([1, 696, 127])\n"
     ]
    }
   ],
   "source": [
    "inference_server = kaggle_evaluation.cmi_inference_server.CMIInferenceServer(predict)\n",
    "\n",
    "if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
    "    inference_server.serve()\n",
    "else:\n",
    "    inference_server.run_local_gateway(\n",
    "        data_paths=(\n",
    "            join(competition_dataset_path, 'test.csv'),\n",
    "            join(competition_dataset_path, 'test_demographics.csv'),\n",
    "        )\n",
    "    )\n",
    "    inference_server = kaggle_evaluation.cmi_inference_server.CMIInferenceServer(predict)\n",
    "    # inference_server.run_local_gateway(\n",
    "    #     data_paths=(\n",
    "    #         join(competition_dataset_path, 'train.csv'),\n",
    "    #         join(competition_dataset_path, 'train_demographics.csv'),\n",
    "    #     )\n",
    "    # )"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 12518947,
     "isSourceIdPinned": false,
     "sourceId": 102335,
     "sourceType": "competition"
    },
    {
     "datasetId": 7827890,
     "sourceId": 12633323,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 251413288,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 520.311851,
   "end_time": "2025-08-02T11:33:18.085561",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-08-02T11:24:37.773710",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "425cbf555f1849f7a521e356d70d429b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7f82f6965842469988401e5a9260b41f": {
      "model_module": "@jupyter-widgets/output",
      "model_module_version": "1.0.0",
      "model_name": "OutputModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/output",
       "_model_module_version": "1.0.0",
       "_model_name": "OutputModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/output",
       "_view_module_version": "1.0.0",
       "_view_name": "OutputView",
       "layout": "IPY_MODEL_425cbf555f1849f7a521e356d70d429b",
       "msg_id": "",
       "outputs": [
        {
         "data": {
          "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">epoch: 14, batch_loss: 1.06,  <span style=\"color: #f92672; text-decoration-color: #f92672\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸</span><span style=\"color: #3a3a3a; text-decoration-color: #3a3a3a\">━</span> <span style=\"color: #800080; text-decoration-color: #800080\"> 97%</span> <span style=\"color: #008080; text-decoration-color: #008080\">0:00:00</span>\n</pre>\n",
          "text/plain": "epoch: 14, batch_loss: 1.06,  \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━\u001b[0m \u001b[35m 97%\u001b[0m \u001b[36m0:00:00\u001b[0m\n"
         },
         "metadata": {},
         "output_type": "display_data"
        }
       ],
       "tabbable": null,
       "tooltip": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
