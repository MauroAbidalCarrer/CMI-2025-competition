{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf6438da",
   "metadata": {},
   "source": [
    "# Training & inference notebook\n",
    "Credit to [Tarun Mishra](https://www.kaggle.com/tarundirector) â€“ this code is heavily based on his [notebook](https://www.kaggle.com/code/tarundirector/sensor-pulse-viz-eda-for-bfrb-detection?scriptVersionId=243465321)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e752c660",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473b69f6",
   "metadata": {},
   "source": [
    "### imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d4b210",
   "metadata": {},
   "source": [
    "#### Training imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b842c804",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import json\n",
    "import math\n",
    "from glob import glob\n",
    "from functools import partial\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "from os.path import join, realpath\n",
    "from typing import Optional, Literal\n",
    "from itertools import pairwise, starmap\n",
    "\n",
    "import torch\n",
    "import kagglehub\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from torch import nn, Tensor\n",
    "from pandas import DataFrame as DF\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.optim import Optimizer\n",
    "# from timm.scheduler import CosineLRScheduler\n",
    "from torch.utils.data import DataLoader as DL\n",
    "from rich.progress import Progress, Task, track\n",
    "from torch.optim.lr_scheduler import ConstantLR, LRScheduler, _LRScheduler\n",
    "metric_package = kagglehub.package_import('wasupandceacar/cmi-metric', bypass_confirmation=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3ae962",
   "metadata": {},
   "source": [
    "#### inference imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "915c9ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import warnings\n",
    "from os.path import join\n",
    "from tqdm.notebook import tqdm\n",
    "from itertools import pairwise, product\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "from numpy import ndarray\n",
    "from torch import nn, Tensor\n",
    "from numpy.linalg import norm\n",
    "from pandas import DataFrame as DF\n",
    "from scipy.spatial.transform import Rotation\n",
    "# from kagglehub import competition_download, dataset_download, model_download\n",
    "import kagglehub\n",
    "metric_package = kagglehub.package_import('wasupandceacar/cmi-metric', bypass_confirmation=True)\n",
    "\n",
    "import training\n",
    "import kaggle_evaluation.cmi_inference_server"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd3c8bd",
   "metadata": {},
   "source": [
    "#### kaggle notbook Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ce2e25ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "\n",
    "def seed_everything(seed=42):\n",
    "    \"\"\"Set all random seeds for reproducibility\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'\n",
    "    torch.use_deterministic_algorithms(True, warn_only=True)\n",
    "\n",
    "SEED = 42\n",
    "seed_everything(seed=SEED)\n",
    "\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import kaggle_evaluation.cmi_inference_server\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e34cce",
   "metadata": {},
   "source": [
    "### Configs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b0b925",
   "metadata": {},
   "source": [
    "#### Training config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1296f174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "DATASET_HANDLE = \"mauroabidalcarrer/prepocessed-cmi-2025/versions/34\"\n",
    "COMPETITION_HANDLE = \"cmi-detect-behavior-with-sensor-data\"\n",
    "TARGET_NAMES = sorted([\n",
    "    \"Above ear - pull hair\",\n",
    "    \"Cheek - pinch skin\",\n",
    "    \"Eyebrow - pull hair\",\n",
    "    \"Eyelash - pull hair\",\n",
    "    \"Feel around in tray and pull out an object\",\n",
    "    \"Forehead - pull hairline\",\n",
    "    \"Forehead - scratch\",\n",
    "    \"Neck - pinch skin\",\n",
    "    \"Neck - scratch\",\n",
    "    \"Text on phone\",\n",
    "    \"Wave hello\",\n",
    "    \"Write name in air\",\n",
    "    \"Write name on leg\",\n",
    "    \"Drink from bottle/cup\",\n",
    "    \"Pinch knee/leg skin\",\n",
    "    \"Pull air toward your face\",\n",
    "    \"Scratch knee/leg skin\",\n",
    "    \"Glasses on/off\"\n",
    "])\n",
    "IMU_FEATS_PREFIXES = (\n",
    "    \"acc\",\n",
    "    \"linear_acc\",\n",
    "    \"rot\",\n",
    "    \"angular\",\n",
    "    \"euler\",\n",
    "    \"quat_rot_mag\",\n",
    "    \"delta_rot_mag\",\n",
    ")\n",
    "# Data augmentation\n",
    "JITTER = 0.25\n",
    "SCALING = 0.2\n",
    "MIXUP = 0.3\n",
    "# Training loop\n",
    "NB_CROSS_VALIDATIONS = 5\n",
    "STARTING_LR = 0.0005\n",
    "TRAIN_BATCH_SIZE = 256\n",
    "VALIDATION_BATCH_SIZE = 4 * TRAIN_BATCH_SIZE\n",
    "TRAINING_EPOCHS = 25\n",
    "PATIENCE = 12\n",
    "WARMUP_EPOCHS = 5\n",
    "MAX_LR_TO_MIN_DIV_FACTOR = 100\n",
    "WARMUP_LR_INT = 1.822126131809773e-05\n",
    "MIN_LR = 3.810323058740104e-09\n",
    "# Mock training loop\n",
    "MOCK_TRAINING_EPOCHS = 15\n",
    "MOCK_TRAINING_GAMMA = 1.01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1393b8af",
   "metadata": {},
   "source": [
    "#### Preprocessing (for inference) config "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3ad8c78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUATERNION_COLS = ['rot_w', 'rot_x', 'rot_y', 'rot_z']\n",
    "GRAVITY_WORLD = np.array([0, 0, 9.81], \"float32\")\n",
    "RAW_ACCELRATION_COLS = [\"acc_x\", \"acc_y\", \"acc_z\"]\n",
    "LINEAR_ACC_COLS = [\"linear_\" + col for col in RAW_ACCELRATION_COLS] # Acceleration without gravity\n",
    "COMPETITION_HANDLE = \"cmi-detect-behavior-with-sensor-data\"\n",
    "CATEGORY_COLUMNS = [\n",
    "    'row_id',\n",
    "    'sequence_type',\n",
    "    'sequence_id',\n",
    "    'subject',\n",
    "    'orientation',\n",
    "    'behavior',\n",
    "    'phase',\n",
    "    'gesture',\n",
    "]\n",
    "META_DATA_COLUMNS = [\n",
    "    'row_id',\n",
    "    'sequence_type',\n",
    "    'sequence_id',\n",
    "    'sequence_counter',\n",
    "    'subject',\n",
    "    'orientation',\n",
    "    'behavior',\n",
    "    'phase',\n",
    "    'gesture',\n",
    "]\n",
    "DATASET_DF_DTYPES = {\n",
    "    \"acc_x\": \"float32\", \"acc_y\": \"float32\", \"acc_z\": \"float32\",\n",
    "    \"thm_1\":\"float32\", \"thm_2\":\"float32\", \"thm_3\":\"float32\", \"thm_4\":\"float32\", \"thm_5\":\"float32\",\n",
    "    \"sequence_counter\": \"int32\",\n",
    "    **{col: \"category\" for col in CATEGORY_COLUMNS},\n",
    "    **{f\"tof_{i_1}_v{i_2}\": \"float32\" for i_1, i_2 in product(range(1, 5), range(64))},\n",
    "}\n",
    "PREPROCESSED_DATASET_HANDLE = \"mauroabidalcarrer/prepocessed-cmi-2025\"\n",
    "# The quantile of the sequences len used to pad/truncate during preprocessing\n",
    "SEQUENCE_NORMED_LEN_QUANTILE = 0.95\n",
    "# SAMPLING_FREQUENCY = 10 #Hz\n",
    "N_FOLDS = 5\n",
    "VALIDATION_FRACTION = 0.2\n",
    "TARGET_NAMES = sorted([\n",
    "    \"Above ear - pull hair\",\n",
    "    \"Cheek - pinch skin\",\n",
    "    \"Eyebrow - pull hair\",\n",
    "    \"Eyelash - pull hair\",\n",
    "    \"Feel around in tray and pull out an object\",\n",
    "    \"Forehead - pull hairline\",\n",
    "    \"Forehead - scratch\",\n",
    "    \"Neck - pinch skin\",\n",
    "    \"Neck - scratch\",\n",
    "    \"Text on phone\",\n",
    "    \"Wave hello\",\n",
    "    \"Write name in air\",\n",
    "    \"Write name on leg\",\n",
    "    \"Drink from bottle/cup\",\n",
    "    \"Pinch knee/leg skin\",\n",
    "    \"Pull air toward your face\",\n",
    "    \"Scratch knee/leg skin\",\n",
    "    \"Glasses on/off\"\n",
    "])\n",
    "EPSILON=1e-8\n",
    "DELTA_ROTATION_ANGULAR_VELOCITY_COLS = [\"angular_vel_x\", \"angular_vel_y\", \"angular_vel_z\"]\n",
    "DELTA_ROTATION_AXES_COLS = [\"rotation_axis_x\", \"rotation_axis_y\", \"rotation_axis_z\"]\n",
    "EULER_ANGLES_COLS = [\"euler_x\", \"euler_y\", \"euler_z\"]\n",
    "TOF_AGG_FUNCS = [\n",
    "    \"mean\",\n",
    "    \"std\",\n",
    "    \"min\",\n",
    "    \"max\",\n",
    "    \"median\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4bfefa",
   "metadata": {},
   "source": [
    "### Define function to get the feature columns\n",
    "Feature columns change over time so it's better to have a function to get them than manually update a variable every time we add/remove features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f3d40b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_cols(df:DF) -> list[str]:\n",
    "    return sorted(list(set(df.columns) - set(META_DATA_COLUMNS) - set(TARGET_NAMES)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eac0e5a",
   "metadata": {},
   "source": [
    "### Supress performance warngings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "086420e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    message=(\n",
    "        \"DataFrame is highly fragmented.  This is usually the result of \"\n",
    "        \"calling `frame.insert` many times.*\"\n",
    "    ),\n",
    "    category=pd.errors.PerformanceWarning,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7749c3bd",
   "metadata": {},
   "source": [
    "### device setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aa7f99a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a563074",
   "metadata": {},
   "source": [
    "### Dataset Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a7f347",
   "metadata": {},
   "source": [
    "#### Dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc2e83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CMIDataset(TensorDataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        parent_dir: str,\n",
    "        split: Optional[Literal[\"train\", \"validation\"]]=None,\n",
    "        subset: Optional[int]=None,\n",
    "        force_download=False\n",
    "    ):\n",
    "        dataset_path = kagglehub.dataset_download(DATASET_HANDLE, force_download)\n",
    "        parent_dir = join(dataset_path, \"preprocessed_dataset\", parent_dir)\n",
    "        split = \"\" if split is None else split + \"_\"\n",
    "        x = np.load(join(parent_dir, f\"{split}X.npy\")).swapaxes(1, 2)\n",
    "        y = np.load(join(parent_dir, f\"{split}Y.npy\"))\n",
    "        if subset is not None:\n",
    "            x = x[:subset]\n",
    "            y = y[:subset]\n",
    "        super().__init__(\n",
    "            torch.from_numpy(x).to(device),\n",
    "            torch.from_numpy(y).to(device),\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da7064d",
   "metadata": {},
   "source": [
    "#### Meta data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aae295d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acc_mag', 'acc_mag_diff', 'acc_x', 'acc_x_diff', 'acc_y', 'acc_y_diff', 'acc_z', 'acc_z_diff', 'angular_vel_x', 'angular_vel_x_diff', 'angular_vel_y', 'angular_vel_y_diff', 'angular_vel_z', 'angular_vel_z_diff', 'delta_rot_mag', 'delta_rot_mag_diff', 'euler_x', 'euler_x_diff', 'euler_y', 'euler_y_diff', 'euler_z', 'euler_z_diff', 'linear_acc_mag', 'linear_acc_mag_diff', 'linear_acc_x', 'linear_acc_x_diff', 'linear_acc_y', 'linear_acc_y_diff', 'linear_acc_z', 'linear_acc_z_diff', 'quat_rot_mag', 'quat_rot_mag_diff', 'rot_w', 'rot_w_diff', 'rot_x', 'rot_x_diff', 'rot_y', 'rot_y_diff', 'rot_z', 'rot_z_diff', 'rotation_axis_x', 'rotation_axis_x_diff', 'rotation_axis_y', 'rotation_axis_y_diff', 'rotation_axis_z', 'rotation_axis_z_diff', 'thm_1', 'thm_1_diff', 'thm_2', 'thm_2_diff', 'thm_3', 'thm_3_diff', 'thm_4', 'thm_4_diff', 'thm_5', 'thm_5_diff', 'tof_1_v0', 'tof_1_v0_diff', 'tof_1_v1', 'tof_1_v10', 'tof_1_v10_diff', 'tof_1_v11', 'tof_1_v11_diff', 'tof_1_v12', 'tof_1_v12_diff', 'tof_1_v13', 'tof_1_v13_diff', 'tof_1_v14', 'tof_1_v14_diff', 'tof_1_v15', 'tof_1_v15_diff', 'tof_1_v16', 'tof_1_v16_diff', 'tof_1_v17', 'tof_1_v17_diff', 'tof_1_v18', 'tof_1_v18_diff', 'tof_1_v19', 'tof_1_v19_diff', 'tof_1_v1_diff', 'tof_1_v2', 'tof_1_v20', 'tof_1_v20_diff', 'tof_1_v21', 'tof_1_v21_diff', 'tof_1_v22', 'tof_1_v22_diff', 'tof_1_v23', 'tof_1_v23_diff', 'tof_1_v24', 'tof_1_v24_diff', 'tof_1_v25', 'tof_1_v25_diff', 'tof_1_v26', 'tof_1_v26_diff', 'tof_1_v27', 'tof_1_v27_diff', 'tof_1_v28', 'tof_1_v28_diff', 'tof_1_v29', 'tof_1_v29_diff', 'tof_1_v2_diff', 'tof_1_v3', 'tof_1_v30', 'tof_1_v30_diff', 'tof_1_v31', 'tof_1_v31_diff', 'tof_1_v32', 'tof_1_v32_diff', 'tof_1_v33', 'tof_1_v33_diff', 'tof_1_v34', 'tof_1_v34_diff', 'tof_1_v35', 'tof_1_v35_diff', 'tof_1_v36', 'tof_1_v36_diff', 'tof_1_v37', 'tof_1_v37_diff', 'tof_1_v38', 'tof_1_v38_diff', 'tof_1_v39', 'tof_1_v39_diff', 'tof_1_v3_diff', 'tof_1_v4', 'tof_1_v40', 'tof_1_v40_diff', 'tof_1_v41', 'tof_1_v41_diff', 'tof_1_v42', 'tof_1_v42_diff', 'tof_1_v43', 'tof_1_v43_diff', 'tof_1_v44', 'tof_1_v44_diff', 'tof_1_v45', 'tof_1_v45_diff', 'tof_1_v46', 'tof_1_v46_diff', 'tof_1_v47', 'tof_1_v47_diff', 'tof_1_v48', 'tof_1_v48_diff', 'tof_1_v49', 'tof_1_v49_diff', 'tof_1_v4_diff', 'tof_1_v5', 'tof_1_v50', 'tof_1_v50_diff', 'tof_1_v51', 'tof_1_v51_diff', 'tof_1_v52', 'tof_1_v52_diff', 'tof_1_v53', 'tof_1_v53_diff', 'tof_1_v54', 'tof_1_v54_diff', 'tof_1_v55', 'tof_1_v55_diff', 'tof_1_v56', 'tof_1_v56_diff', 'tof_1_v57', 'tof_1_v57_diff', 'tof_1_v58', 'tof_1_v58_diff', 'tof_1_v59', 'tof_1_v59_diff', 'tof_1_v5_diff', 'tof_1_v6', 'tof_1_v60', 'tof_1_v60_diff', 'tof_1_v61', 'tof_1_v61_diff', 'tof_1_v62', 'tof_1_v62_diff', 'tof_1_v63', 'tof_1_v63_diff', 'tof_1_v6_diff', 'tof_1_v7', 'tof_1_v7_diff', 'tof_1_v8', 'tof_1_v8_diff', 'tof_1_v9', 'tof_1_v9_diff', 'tof_2_v0', 'tof_2_v0_diff', 'tof_2_v1', 'tof_2_v10', 'tof_2_v10_diff', 'tof_2_v11', 'tof_2_v11_diff', 'tof_2_v12', 'tof_2_v12_diff', 'tof_2_v13', 'tof_2_v13_diff', 'tof_2_v14', 'tof_2_v14_diff', 'tof_2_v15', 'tof_2_v15_diff', 'tof_2_v16', 'tof_2_v16_diff', 'tof_2_v17', 'tof_2_v17_diff', 'tof_2_v18', 'tof_2_v18_diff', 'tof_2_v19', 'tof_2_v19_diff', 'tof_2_v1_diff', 'tof_2_v2', 'tof_2_v20', 'tof_2_v20_diff', 'tof_2_v21', 'tof_2_v21_diff', 'tof_2_v22', 'tof_2_v22_diff', 'tof_2_v23', 'tof_2_v23_diff', 'tof_2_v24', 'tof_2_v24_diff', 'tof_2_v25', 'tof_2_v25_diff', 'tof_2_v26', 'tof_2_v26_diff', 'tof_2_v27', 'tof_2_v27_diff', 'tof_2_v28', 'tof_2_v28_diff', 'tof_2_v29', 'tof_2_v29_diff', 'tof_2_v2_diff', 'tof_2_v3', 'tof_2_v30', 'tof_2_v30_diff', 'tof_2_v31', 'tof_2_v31_diff', 'tof_2_v32', 'tof_2_v32_diff', 'tof_2_v33', 'tof_2_v33_diff', 'tof_2_v34', 'tof_2_v34_diff', 'tof_2_v35', 'tof_2_v35_diff', 'tof_2_v36', 'tof_2_v36_diff', 'tof_2_v37', 'tof_2_v37_diff', 'tof_2_v38', 'tof_2_v38_diff', 'tof_2_v39', 'tof_2_v39_diff', 'tof_2_v3_diff', 'tof_2_v4', 'tof_2_v40', 'tof_2_v40_diff', 'tof_2_v41', 'tof_2_v41_diff', 'tof_2_v42', 'tof_2_v42_diff', 'tof_2_v43', 'tof_2_v43_diff', 'tof_2_v44', 'tof_2_v44_diff', 'tof_2_v45', 'tof_2_v45_diff', 'tof_2_v46', 'tof_2_v46_diff', 'tof_2_v47', 'tof_2_v47_diff', 'tof_2_v48', 'tof_2_v48_diff', 'tof_2_v49', 'tof_2_v49_diff', 'tof_2_v4_diff', 'tof_2_v5', 'tof_2_v50', 'tof_2_v50_diff', 'tof_2_v51', 'tof_2_v51_diff', 'tof_2_v52', 'tof_2_v52_diff', 'tof_2_v53', 'tof_2_v53_diff', 'tof_2_v54', 'tof_2_v54_diff', 'tof_2_v55', 'tof_2_v55_diff', 'tof_2_v56', 'tof_2_v56_diff', 'tof_2_v57', 'tof_2_v57_diff', 'tof_2_v58', 'tof_2_v58_diff', 'tof_2_v59', 'tof_2_v59_diff', 'tof_2_v5_diff', 'tof_2_v6', 'tof_2_v60', 'tof_2_v60_diff', 'tof_2_v61', 'tof_2_v61_diff', 'tof_2_v62', 'tof_2_v62_diff', 'tof_2_v63', 'tof_2_v63_diff', 'tof_2_v6_diff', 'tof_2_v7', 'tof_2_v7_diff', 'tof_2_v8', 'tof_2_v8_diff', 'tof_2_v9', 'tof_2_v9_diff', 'tof_3_v0', 'tof_3_v0_diff', 'tof_3_v1', 'tof_3_v10', 'tof_3_v10_diff', 'tof_3_v11', 'tof_3_v11_diff', 'tof_3_v12', 'tof_3_v12_diff', 'tof_3_v13', 'tof_3_v13_diff', 'tof_3_v14', 'tof_3_v14_diff', 'tof_3_v15', 'tof_3_v15_diff', 'tof_3_v16', 'tof_3_v16_diff', 'tof_3_v17', 'tof_3_v17_diff', 'tof_3_v18', 'tof_3_v18_diff', 'tof_3_v19', 'tof_3_v19_diff', 'tof_3_v1_diff', 'tof_3_v2', 'tof_3_v20', 'tof_3_v20_diff', 'tof_3_v21', 'tof_3_v21_diff', 'tof_3_v22', 'tof_3_v22_diff', 'tof_3_v23', 'tof_3_v23_diff', 'tof_3_v24', 'tof_3_v24_diff', 'tof_3_v25', 'tof_3_v25_diff', 'tof_3_v26', 'tof_3_v26_diff', 'tof_3_v27', 'tof_3_v27_diff', 'tof_3_v28', 'tof_3_v28_diff', 'tof_3_v29', 'tof_3_v29_diff', 'tof_3_v2_diff', 'tof_3_v3', 'tof_3_v30', 'tof_3_v30_diff', 'tof_3_v31', 'tof_3_v31_diff', 'tof_3_v32', 'tof_3_v32_diff', 'tof_3_v33', 'tof_3_v33_diff', 'tof_3_v34', 'tof_3_v34_diff', 'tof_3_v35', 'tof_3_v35_diff', 'tof_3_v36', 'tof_3_v36_diff', 'tof_3_v37', 'tof_3_v37_diff', 'tof_3_v38', 'tof_3_v38_diff', 'tof_3_v39', 'tof_3_v39_diff', 'tof_3_v3_diff', 'tof_3_v4', 'tof_3_v40', 'tof_3_v40_diff', 'tof_3_v41', 'tof_3_v41_diff', 'tof_3_v42', 'tof_3_v42_diff', 'tof_3_v43', 'tof_3_v43_diff', 'tof_3_v44', 'tof_3_v44_diff', 'tof_3_v45', 'tof_3_v45_diff', 'tof_3_v46', 'tof_3_v46_diff', 'tof_3_v47', 'tof_3_v47_diff', 'tof_3_v48', 'tof_3_v48_diff', 'tof_3_v49', 'tof_3_v49_diff', 'tof_3_v4_diff', 'tof_3_v5', 'tof_3_v50', 'tof_3_v50_diff', 'tof_3_v51', 'tof_3_v51_diff', 'tof_3_v52', 'tof_3_v52_diff', 'tof_3_v53', 'tof_3_v53_diff', 'tof_3_v54', 'tof_3_v54_diff', 'tof_3_v55', 'tof_3_v55_diff', 'tof_3_v56', 'tof_3_v56_diff', 'tof_3_v57', 'tof_3_v57_diff', 'tof_3_v58', 'tof_3_v58_diff', 'tof_3_v59', 'tof_3_v59_diff', 'tof_3_v5_diff', 'tof_3_v6', 'tof_3_v60', 'tof_3_v60_diff', 'tof_3_v61', 'tof_3_v61_diff', 'tof_3_v62', 'tof_3_v62_diff', 'tof_3_v63', 'tof_3_v63_diff', 'tof_3_v6_diff', 'tof_3_v7', 'tof_3_v7_diff', 'tof_3_v8', 'tof_3_v8_diff', 'tof_3_v9', 'tof_3_v9_diff', 'tof_4_v0', 'tof_4_v0_diff', 'tof_4_v1', 'tof_4_v10', 'tof_4_v10_diff', 'tof_4_v11', 'tof_4_v11_diff', 'tof_4_v12', 'tof_4_v12_diff', 'tof_4_v13', 'tof_4_v13_diff', 'tof_4_v14', 'tof_4_v14_diff', 'tof_4_v15', 'tof_4_v15_diff', 'tof_4_v16', 'tof_4_v16_diff', 'tof_4_v17', 'tof_4_v17_diff', 'tof_4_v18', 'tof_4_v18_diff', 'tof_4_v19', 'tof_4_v19_diff', 'tof_4_v1_diff', 'tof_4_v2', 'tof_4_v20', 'tof_4_v20_diff', 'tof_4_v21', 'tof_4_v21_diff', 'tof_4_v22', 'tof_4_v22_diff', 'tof_4_v23', 'tof_4_v23_diff', 'tof_4_v24', 'tof_4_v24_diff', 'tof_4_v25', 'tof_4_v25_diff', 'tof_4_v26', 'tof_4_v26_diff', 'tof_4_v27', 'tof_4_v27_diff', 'tof_4_v28', 'tof_4_v28_diff', 'tof_4_v29', 'tof_4_v29_diff', 'tof_4_v2_diff', 'tof_4_v3', 'tof_4_v30', 'tof_4_v30_diff', 'tof_4_v31', 'tof_4_v31_diff', 'tof_4_v32', 'tof_4_v32_diff', 'tof_4_v33', 'tof_4_v33_diff', 'tof_4_v34', 'tof_4_v34_diff', 'tof_4_v35', 'tof_4_v35_diff', 'tof_4_v36', 'tof_4_v36_diff', 'tof_4_v37', 'tof_4_v37_diff', 'tof_4_v38', 'tof_4_v38_diff', 'tof_4_v39', 'tof_4_v39_diff', 'tof_4_v3_diff', 'tof_4_v4', 'tof_4_v40', 'tof_4_v40_diff', 'tof_4_v41', 'tof_4_v41_diff', 'tof_4_v42', 'tof_4_v42_diff', 'tof_4_v43', 'tof_4_v43_diff', 'tof_4_v44', 'tof_4_v44_diff', 'tof_4_v45', 'tof_4_v45_diff', 'tof_4_v46', 'tof_4_v46_diff', 'tof_4_v47', 'tof_4_v47_diff', 'tof_4_v48', 'tof_4_v48_diff', 'tof_4_v49', 'tof_4_v49_diff', 'tof_4_v4_diff', 'tof_4_v5', 'tof_4_v50', 'tof_4_v50_diff', 'tof_4_v51', 'tof_4_v51_diff', 'tof_4_v52', 'tof_4_v52_diff', 'tof_4_v53', 'tof_4_v53_diff', 'tof_4_v54', 'tof_4_v54_diff', 'tof_4_v55', 'tof_4_v55_diff', 'tof_4_v56', 'tof_4_v56_diff', 'tof_4_v57', 'tof_4_v57_diff', 'tof_4_v58', 'tof_4_v58_diff', 'tof_4_v59', 'tof_4_v59_diff', 'tof_4_v5_diff', 'tof_4_v6', 'tof_4_v60', 'tof_4_v60_diff', 'tof_4_v61', 'tof_4_v61_diff', 'tof_4_v62', 'tof_4_v62_diff', 'tof_4_v63', 'tof_4_v63_diff', 'tof_4_v6_diff', 'tof_4_v7', 'tof_4_v7_diff', 'tof_4_v8', 'tof_4_v8_diff', 'tof_4_v9', 'tof_4_v9_diff', 'tof_5_v0', 'tof_5_v0_diff', 'tof_5_v1', 'tof_5_v10', 'tof_5_v10_diff', 'tof_5_v11', 'tof_5_v11_diff', 'tof_5_v12', 'tof_5_v12_diff', 'tof_5_v13', 'tof_5_v13_diff', 'tof_5_v14', 'tof_5_v14_diff', 'tof_5_v15', 'tof_5_v15_diff', 'tof_5_v16', 'tof_5_v16_diff', 'tof_5_v17', 'tof_5_v17_diff', 'tof_5_v18', 'tof_5_v18_diff', 'tof_5_v19', 'tof_5_v19_diff', 'tof_5_v1_diff', 'tof_5_v2', 'tof_5_v20', 'tof_5_v20_diff', 'tof_5_v21', 'tof_5_v21_diff', 'tof_5_v22', 'tof_5_v22_diff', 'tof_5_v23', 'tof_5_v23_diff', 'tof_5_v24', 'tof_5_v24_diff', 'tof_5_v25', 'tof_5_v25_diff', 'tof_5_v26', 'tof_5_v26_diff', 'tof_5_v27', 'tof_5_v27_diff', 'tof_5_v28', 'tof_5_v28_diff', 'tof_5_v29', 'tof_5_v29_diff', 'tof_5_v2_diff', 'tof_5_v3', 'tof_5_v30', 'tof_5_v30_diff', 'tof_5_v31', 'tof_5_v31_diff', 'tof_5_v32', 'tof_5_v32_diff', 'tof_5_v33', 'tof_5_v33_diff', 'tof_5_v34', 'tof_5_v34_diff', 'tof_5_v35', 'tof_5_v35_diff', 'tof_5_v36', 'tof_5_v36_diff', 'tof_5_v37', 'tof_5_v37_diff', 'tof_5_v38', 'tof_5_v38_diff', 'tof_5_v39', 'tof_5_v39_diff', 'tof_5_v3_diff', 'tof_5_v4', 'tof_5_v40', 'tof_5_v40_diff', 'tof_5_v41', 'tof_5_v41_diff', 'tof_5_v42', 'tof_5_v42_diff', 'tof_5_v43', 'tof_5_v43_diff', 'tof_5_v44', 'tof_5_v44_diff', 'tof_5_v45', 'tof_5_v45_diff', 'tof_5_v46', 'tof_5_v46_diff', 'tof_5_v47', 'tof_5_v47_diff', 'tof_5_v48', 'tof_5_v48_diff', 'tof_5_v49', 'tof_5_v49_diff', 'tof_5_v4_diff', 'tof_5_v5', 'tof_5_v50', 'tof_5_v50_diff', 'tof_5_v51', 'tof_5_v51_diff', 'tof_5_v52', 'tof_5_v52_diff', 'tof_5_v53', 'tof_5_v53_diff', 'tof_5_v54', 'tof_5_v54_diff', 'tof_5_v55', 'tof_5_v55_diff', 'tof_5_v56', 'tof_5_v56_diff', 'tof_5_v57', 'tof_5_v57_diff', 'tof_5_v58', 'tof_5_v58_diff', 'tof_5_v59', 'tof_5_v59_diff', 'tof_5_v5_diff', 'tof_5_v6', 'tof_5_v60', 'tof_5_v60_diff', 'tof_5_v61', 'tof_5_v61_diff', 'tof_5_v62', 'tof_5_v62_diff', 'tof_5_v63', 'tof_5_v63_diff', 'tof_5_v6_diff', 'tof_5_v7', 'tof_5_v7_diff', 'tof_5_v8', 'tof_5_v8_diff', 'tof_5_v9', 'tof_5_v9_diff']\n",
      "non_imu_feats_idx: [46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695]\n",
      "imu_feats_idx: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45]\n"
     ]
    }
   ],
   "source": [
    "dataset_path = kagglehub.dataset_download(DATASET_HANDLE)\n",
    "meta_data_path = join(\n",
    "    dataset_path,\n",
    "    \"preprocessed_dataset\",\n",
    "    \"full_dataset_meta_data.json\"\n",
    ")\n",
    "with open(meta_data_path, \"r\") as fp:\n",
    "    meta_data = json.load(fp)\n",
    "# Convert target names into a ndarray to index it batchwise.\n",
    "is_thm_tof_feat = lambda feat: feat.startswith((\"thm\", \"tof\"))\n",
    "non_imu_feats_idx = [feat_idx for feat_idx, feat in enumerate(meta_data[\"feature_cols\"]) if is_thm_tof_feat(feat)]\n",
    "imu_feats_idx = [feat_idx for feat_idx, feat in enumerate(meta_data[\"feature_cols\"]) if not is_thm_tof_feat(feat)]\n",
    "print(meta_data[\"feature_cols\"])\n",
    "print(\"non_imu_feats_idx:\", non_imu_feats_idx)\n",
    "print(\"imu_feats_idx:\", imu_feats_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc6fe74",
   "metadata": {},
   "source": [
    "#### Compute class weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "74233c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_weighted_cross_entropy_loss(\n",
    "    dataset: Dataset[tuple[torch.Tensor, torch.Tensor]]\n",
    ") -> nn.CrossEntropyLoss:\n",
    "    \"\"\"\n",
    "    Computes class weights from a dataset with one-hot encoded targets and returns a CrossEntropyLoss with those weights.\n",
    "\n",
    "    Args:\n",
    "        dataset: A PyTorch Dataset that yields (x, y) where y is a one-hot encoded tensor of shape (num_classes,)\n",
    "\n",
    "    Returns:\n",
    "        A torch.nn.CrossEntropyLoss object with class weights based on inverse class frequency.\n",
    "    \"\"\"\n",
    "    class_counts: Counter = Counter()\n",
    "    num_samples = 0\n",
    "\n",
    "    for _, y in dataset:\n",
    "        class_idx = y.argmax().item()\n",
    "        class_counts[class_idx] += 1\n",
    "        num_samples += 1\n",
    "\n",
    "    num_classes = len(class_counts)\n",
    "    weights = torch.tensor(\n",
    "        [num_samples / class_counts[i] for i in range(num_classes)],\n",
    "        dtype=torch.float32,\n",
    "    )\n",
    "\n",
    "    # Optional: normalize weights so they sum to 1\n",
    "    weights = weights / weights.sum()\n",
    "\n",
    "    return nn.CrossEntropyLoss(weight=weights.to(device))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2161df0c",
   "metadata": {
    "papermill": {
     "duration": 0.00278,
     "end_time": "2025-06-14T10:01:12.877551",
     "exception": false,
     "start_time": "2025-06-14T10:01:12.874771",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### BFRBs indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e657c570",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T10:01:12.884365Z",
     "iopub.status.busy": "2025-06-14T10:01:12.883937Z",
     "iopub.status.idle": "2025-06-14T10:01:45.309186Z",
     "shell.execute_reply": "2025-06-14T10:01:45.308564Z"
    },
    "papermill": {
     "duration": 32.430139,
     "end_time": "2025-06-14T10:01:45.310511",
     "exception": false,
     "start_time": "2025-06-14T10:01:12.880372",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets...\n",
      "Train rows: 574945, Test rows: 107\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading datasets...\")\n",
    "competition_dataset_path = kagglehub.competition_download(COMPETITION_HANDLE)\n",
    "train_df = pd.read_csv(join(competition_dataset_path, \"train.csv\"))\n",
    "train_dem_df = pd.read_csv(join(competition_dataset_path, \"train_demographics.csv\"))\n",
    "test_df = pd.read_csv(join(competition_dataset_path, \"test.csv\"))\n",
    "test_dem_df = pd.read_csv(join(competition_dataset_path, \"test_demographics.csv\"))\n",
    "print(f\"Train rows: {len(train_df)}, Test rows: {len(test_df)}\")\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "train_df['gesture'] = label_encoder.fit_transform(train_df['gesture'].astype(str))\n",
    "gesture_classes = label_encoder.classes_\n",
    "\n",
    "bfrb_gestures = [\n",
    "    'Above ear - pull hair',\n",
    "    'Forehead - pull hairline',\n",
    "    'Forehead - scratch',\n",
    "    'Eyebrow - pull hair',\n",
    "    'Eyelash - pull hair',\n",
    "    'Neck - pinch skin',\n",
    "    'Neck - scratch',\n",
    "    'Cheek - pinch skin'\n",
    "]\n",
    "bfrb_indices = label_encoder.transform(bfrb_gestures)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de16cc1",
   "metadata": {},
   "source": [
    "### Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d3d46b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CosineAnnealingWarmupRestarts(_LRScheduler):\n",
    "    def __init__(\n",
    "        self,\n",
    "        optimizer: Optimizer,\n",
    "        warmup_steps: int,\n",
    "        max_lr: float,\n",
    "        min_lr: float,\n",
    "        cycle_length: int,\n",
    "        cycle_mult: float = 1.0,\n",
    "        gamma: float = 1.0,\n",
    "        last_epoch: int = -1,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            optimizer: Wrapped optimizer.\n",
    "            warmup_steps: Number of steps for linear warmup.\n",
    "            max_lr: Initial maximum learning rate.\n",
    "            min_lr: Minimum learning rate after decay.\n",
    "            cycle_length: Initial number of steps per cosine cycle.\n",
    "            cycle_mult: Multiplicative factor for increasing cycle lengths.\n",
    "            gamma: Multiplicative decay factor for max_lr after each cycle.\n",
    "            last_epoch: The index of last epoch. Default: -1.\n",
    "        \"\"\"\n",
    "        self.warmup_steps = warmup_steps\n",
    "        self.max_lr = max_lr\n",
    "        self.min_lr = min_lr\n",
    "        self.cycle_length = cycle_length\n",
    "        self.cycle_mult = cycle_mult\n",
    "        self.gamma = gamma\n",
    "\n",
    "        self.current_cycle = 0\n",
    "        self.cycle_step = 0\n",
    "        self.lr = max_lr\n",
    "\n",
    "        super().__init__(optimizer, last_epoch)\n",
    "\n",
    "    def get_lr(self) -> list[float]:\n",
    "        if self.last_epoch < self.warmup_steps:\n",
    "            # Linear warmup\n",
    "            scale = (self.last_epoch + 1) / self.warmup_steps\n",
    "            return [self.min_lr + scale * (self.max_lr - self.min_lr) for _ in self.base_lrs]\n",
    "\n",
    "        # Adjust for post-warmup step index\n",
    "        t = self.cycle_step\n",
    "        T = self.cycle_length\n",
    "\n",
    "        cosine_decay = 0.5 * (1 + math.cos(math.pi * t / T))\n",
    "        lr = self.min_lr + (self.max_lr - self.min_lr) * cosine_decay\n",
    "\n",
    "        return [lr for _ in self.base_lrs]\n",
    "\n",
    "    def step(self, epoch: Optional[int] = None) -> None:\n",
    "        if self.last_epoch >= self.warmup_steps:\n",
    "            self.cycle_step += 1\n",
    "            if self.cycle_step >= self.cycle_length:\n",
    "                self.current_cycle += 1\n",
    "                self.cycle_step = 0\n",
    "                self.cycle_length = int(self.cycle_length * self.cycle_mult)\n",
    "                self.max_lr *= self.gamma\n",
    "        super().step(epoch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c54244a",
   "metadata": {},
   "source": [
    "## Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "80ae01a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiScaleConvs(nn.Module):\n",
    "    def __init__(self, in_channels:int, kernel_sizes:list[int]):\n",
    "        super().__init__()\n",
    "        def mk_conv_block(k_size) -> nn.Sequential:\n",
    "            return nn.Sequential(\n",
    "                nn.Conv1d(in_channels, in_channels, k_size, padding=k_size // 2, groups=in_channels),\n",
    "                nn.BatchNorm1d(in_channels),\n",
    "                nn.ReLU(),\n",
    "            )\n",
    "        self.convs = nn.ModuleList(map(mk_conv_block, kernel_sizes))\n",
    "\n",
    "    def forward(self, x:Tensor) -> Tensor:\n",
    "        yes = torch.cat([conv(x) for conv in self.convs] + [x], dim=1)\n",
    "        # print(\"stem output shape:\", yes.shape)\n",
    "        return yes\n",
    "    \n",
    "class SqueezeExcitationBlock(nn.Module):\n",
    "    # Copy/paste of https://www.kaggle.com/code/wasupandceacar/lb-0-82-5fold-single-bert-model#Model implementation\n",
    "    def __init__(self, channels:int, reduction:int=8):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(channels, channels // reduction, bias=True)\n",
    "        self.fc2 = nn.Linear(channels // reduction, channels, bias=True)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, C, L)\n",
    "        se = F.adaptive_avg_pool1d(x, 1).squeeze(-1)      # -> (B, C)\n",
    "        se = F.relu(self.fc1(se), inplace=True)          # -> (B, C//r)\n",
    "        se = self.sigmoid(self.fc2(se)).unsqueeze(-1)    # -> (B, C, 1)\n",
    "        return x * se\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_chns:int, out_chns:int, dropout_ratio:float=0.3, se_reduction:int=8, kernel_size:int=3):\n",
    "        super().__init__()\n",
    "        self.blocks = nn.Sequential(\n",
    "            nn.Conv1d(in_chns, out_chns, kernel_size=kernel_size, padding=kernel_size // 2),\n",
    "            nn.BatchNorm1d(out_chns),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(out_chns, out_chns, kernel_size=kernel_size, padding=kernel_size // 2),\n",
    "            nn.BatchNorm1d(out_chns),\n",
    "            SqueezeExcitationBlock(out_chns, se_reduction),\n",
    "        )\n",
    "        self.head = nn.Sequential(nn.ReLU(), nn.Dropout(dropout_ratio))\n",
    "        if in_chns == out_chns:\n",
    "            self.skip_connection = nn.Identity() \n",
    "        else:\n",
    "            # TODO: set bias to False ?\n",
    "            self.skip_connection = nn.Sequential(\n",
    "                nn.Conv1d(in_chns, out_chns, 1),\n",
    "                nn.BatchNorm1d(out_chns)\n",
    "            )\n",
    "            self.head.insert(1, nn.MaxPool1d(2))\n",
    "\n",
    "    def forward(self, x:Tensor) -> Tensor:\n",
    "        activaition_maps = self.skip_connection(x) + self.blocks(x)\n",
    "        return self.head(activaition_maps)\n",
    "\n",
    "class MBConvBlock(nn.Module):\n",
    "    # From this schema: https://media.licdn.com/dms/image/v2/D5612AQFjbDOm5uyxdw/article-inline_image-shrink_1500_2232/article-inline_image-shrink_1500_2232/0/1683677500817?e=1758153600&v=beta&t=n48_UW5TZTyDPhRFlJXSidUQQPQpuC756M0kNeKmYTY\n",
    "    def __init__(self, in_chns:int, out_chns:int, se_reduction:int=8, expansion_ratio:int=4, dropout_ratio:float=0.3):\n",
    "        super().__init__()\n",
    "        expanded_channels = in_chns * expansion_ratio\n",
    "        self.blocks = nn.Sequential(\n",
    "            nn.Conv1d(in_chns, expanded_channels, kernel_size=1),\n",
    "            nn.BatchNorm1d(expanded_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(\n",
    "                expanded_channels,\n",
    "                expanded_channels,\n",
    "                kernel_size=3,\n",
    "                padding=1,\n",
    "                groups=expanded_channels,\n",
    "            ),\n",
    "            nn.BatchNorm1d(expanded_channels),\n",
    "            nn.ReLU(),\n",
    "            SqueezeExcitationBlock(expanded_channels, se_reduction),\n",
    "            nn.Conv1d(expanded_channels, out_chns, kernel_size=1)\n",
    "        )\n",
    "        self.head = nn.Sequential(\n",
    "            nn.BatchNorm1d(out_chns)\n",
    "            # nn.ReLU(),\n",
    "            # nn.Dropout(dropout_ratio),\n",
    "        )\n",
    "        if in_chns == out_chns:\n",
    "            self.skip_connection = nn.Identity() \n",
    "        else:\n",
    "            # TODO: set bias to False ?\n",
    "            self.skip_connection = nn.Sequential(\n",
    "                nn.Conv1d(in_chns, out_chns, 1),\n",
    "                nn.BatchNorm1d(out_chns)\n",
    "            )\n",
    "            self.head.add_module(\"max_pool\", nn.MaxPool1d(2))\n",
    "            \n",
    "    def forward(self, x:Tensor) -> Tensor:\n",
    "        activaition_maps = self.skip_connection(x) + self.blocks(x)\n",
    "        return self.head(activaition_maps)\n",
    "\n",
    "class AdditiveAttentionLayer(nn.Module):\n",
    "    # Copied (and slightly modified) from https://www.kaggle.com/code/myso1987/cmi3-pyroch-baseline-model-add-aug-folds\n",
    "    def __init__(self, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.attention = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        # x shape: (batch, channels, seq_len)\n",
    "        x = x.swapaxes(1, 2)\n",
    "        # x shape: (batch, seq_len, hidden_dim)\n",
    "        scores = torch.tanh(self.attention(x))  # (batch, seq_len, 1)\n",
    "        weights = F.softmax(scores.squeeze(-1), dim=1)  # (batch, seq_len)\n",
    "        context = torch.sum(x * weights.unsqueeze(-1), dim=1)  # (batch, hidden_dim)\n",
    "        return context\n",
    "\n",
    "class CMIHARModule(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            imu_idx:list[int],\n",
    "            tof_thm_idx:list[int],\n",
    "            mlp_width:int,\n",
    "            n_class:int,            \n",
    "            tof_thm_dropout_ratio:float=0,\n",
    "        ):\n",
    "        super().__init__()\n",
    "        self.imu_idx = imu_idx\n",
    "        self.tof_thm_idx = tof_thm_idx\n",
    "        self.imu_branch = nn.Sequential(\n",
    "            ResidualBlock(len(imu_idx), len(imu_idx) * 2),\n",
    "            ResidualBlock(len(imu_idx) * 2, len(imu_idx) * 4),\n",
    "        )\n",
    "        self.tof_and_thm_branch = nn.Sequential(\n",
    "            nn.Conv1d(len(tof_thm_idx), 64, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.MaxPool1d(2),\n",
    "            nn.Dropout(tof_thm_dropout_ratio),\n",
    "            nn.Conv1d(64, 128, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.MaxPool1d(2),\n",
    "            nn.Dropout(tof_thm_dropout_ratio),\n",
    "        )\n",
    "        # print(\"imu expected activation maps size:\", len(imu_idx) * 4)\n",
    "        # print(\"expected tof and thm activation maps size:\", len(tof_thm_idx) * 4)\n",
    "        # print(\"concatenated acitvation maps size:\", (len(imu_idx) + len(tof_thm_idx)) * 4)\n",
    "        self.lstm = nn.GRU(len(imu_idx) * 4 + 128, mlp_width // 2, bidirectional=True)\n",
    "        self.attention = AdditiveAttentionLayer(mlp_width)\n",
    "        self.head = nn.Sequential(\n",
    "            # Head\n",
    "            nn.LazyLinear(mlp_width),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(mlp_width, mlp_width // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(mlp_width // 2, n_class),\n",
    "        )\n",
    "\n",
    "    def forward(self, x:Tensor) -> Tensor:\n",
    "        imu_activation_maps = self.imu_branch(x[:, self.imu_idx])\n",
    "        tof_thm_activation_maps = self.tof_and_thm_branch(x[:, self.tof_thm_idx])\n",
    "        concatenated_activation_maps = torch.cat((imu_activation_maps, tof_thm_activation_maps), 1)\n",
    "        lstm_output, _  = self.lstm(concatenated_activation_maps.swapaxes(1, 2))\n",
    "        lstm_output = lstm_output.swapaxes(1, 2) # redundant\n",
    "        attended = self.attention(lstm_output)\n",
    "        return self.head(attended)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc08e41",
   "metadata": {},
   "source": [
    "### Create model function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "36e3e463",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CMIHARModule(\n",
       "  (imu_branch): Sequential(\n",
       "    (0): ResidualBlock(\n",
       "      (blocks): Sequential(\n",
       "        (0): Conv1d(46, 92, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(92, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv1d(92, 92, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (4): BatchNorm1d(92, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): SqueezeExcitationBlock(\n",
       "          (fc1): Linear(in_features=92, out_features=11, bias=True)\n",
       "          (fc2): Linear(in_features=11, out_features=92, bias=True)\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (head): Sequential(\n",
       "        (0): ReLU()\n",
       "        (1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (2): Dropout(p=0.3, inplace=False)\n",
       "      )\n",
       "      (skip_connection): Sequential(\n",
       "        (0): Conv1d(46, 92, kernel_size=(1,), stride=(1,))\n",
       "        (1): BatchNorm1d(92, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): ResidualBlock(\n",
       "      (blocks): Sequential(\n",
       "        (0): Conv1d(92, 184, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv1d(184, 184, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (4): BatchNorm1d(184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): SqueezeExcitationBlock(\n",
       "          (fc1): Linear(in_features=184, out_features=23, bias=True)\n",
       "          (fc2): Linear(in_features=23, out_features=184, bias=True)\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (head): Sequential(\n",
       "        (0): ReLU()\n",
       "        (1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (2): Dropout(p=0.3, inplace=False)\n",
       "      )\n",
       "      (skip_connection): Sequential(\n",
       "        (0): Conv1d(92, 184, kernel_size=(1,), stride=(1,))\n",
       "        (1): BatchNorm1d(184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (tof_and_thm_branch): Sequential(\n",
       "    (0): Conv1d(650, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Dropout(p=0, inplace=False)\n",
       "    (4): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "    (5): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (7): Dropout(p=0, inplace=False)\n",
       "  )\n",
       "  (lstm): GRU(312, 128, bidirectional=True)\n",
       "  (attention): AdditiveAttentionLayer(\n",
       "    (attention): Linear(in_features=256, out_features=1, bias=True)\n",
       "  )\n",
       "  (head): Sequential(\n",
       "    (0): LazyLinear(in_features=0, out_features=256, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=128, out_features=18, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input channels: 696\n"
     ]
    }
   ],
   "source": [
    "def mk_model() -> nn.Module:\n",
    "    return (\n",
    "        CMIHARModule(\n",
    "            imu_idx=imu_feats_idx,\n",
    "            tof_thm_idx=non_imu_feats_idx,\n",
    "            mlp_width=256,\n",
    "            n_class=18,\n",
    "        )\n",
    "        .to(device)\n",
    "    )\n",
    "\n",
    "display(mk_model())\n",
    "print(\"input channels:\", len(meta_data[\"feature_cols\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8afc6e79",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a69ec966",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(epochs:int,\n",
    "        model: nn.Module,\n",
    "        scheduler: LRScheduler,\n",
    "        optimizer: torch.optim.Optimizer,\n",
    "        train_loader: DL,\n",
    "        criterion: callable=nn.L1Loss(),\n",
    "        evaluation_func: callable=None,\n",
    "        validation_loader: DL=None,\n",
    "        save_checkpoints=True,\n",
    "    ) -> tuple[DF, str]:\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "        (training_metrics, path_to_checkpoints)\n",
    "    \"\"\"\n",
    "    # Setup\n",
    "    metrics: list[dict] = []\n",
    "    step = 0\n",
    "    model_device = next(model.parameters()).device\n",
    "    last_epoch_metric = {}\n",
    "    # Training loop\n",
    "    with Progress() as progress:\n",
    "        task: Task = progress.add_task(\n",
    "            \"training...\",\n",
    "            total=len(train_loader),\n",
    "        )\n",
    "        for epoch in range(epochs):\n",
    "            progress.update(\n",
    "                task,\n",
    "                description=f\"epoch: {epoch}\",\n",
    "                completed=0,\n",
    "            )\n",
    "            total_epoch_loss = 0\n",
    "            total_accuracy = 0\n",
    "            for batch_idx, (x, y) in enumerate(train_loader):\n",
    "                # forward\n",
    "                x = x.to(model_device)\n",
    "                y = y.to(model_device)\n",
    "                model.train()\n",
    "                optimizer.zero_grad()\n",
    "                y_pred: Tensor = model(x)\n",
    "                loss_value = criterion(y_pred, y)\n",
    "                # Verify loss value\n",
    "                if torch.isnan(loss_value).any().item():\n",
    "                    progress.print(\"Warning: Got NaN loss, stopped training.\")\n",
    "                    return DF.from_records(metrics)\n",
    "                if torch.isinf(loss_value).any().item():\n",
    "                    progress.print(\"Warning: Got infinite loss, stopped training.\")\n",
    "                    return DF.from_records(metrics)\n",
    "                # TODO: Use gradient clipping?\n",
    "                loss_value.backward()\n",
    "                optimizer.step()\n",
    "                if step > 0: # If it's not the first training step, idk why it throws an error otherwise\n",
    "                    scheduler.step()\n",
    "                # metrics\n",
    "                total_epoch_loss += loss_value.item()\n",
    "                metrics.append({\n",
    "                    \"step\": step,\n",
    "                    \"epoch\": epoch,\n",
    "                    \"batch_train_loss\": loss_value.item(),\n",
    "                    \"lr\": optimizer.state_dict()[\"param_groups\"][-1][\"lr\"],\n",
    "                })\n",
    "                step += 1\n",
    "                if \"validation_accuracy\" in last_epoch_metric:\n",
    "                    last_validation_acc = \"%.2f\" % last_epoch_metric[\"validation_accuracy\"]\n",
    "                    val_acc_str = \"val. acc: \" + last_validation_acc\n",
    "                else:\n",
    "                    val_acc_str = \"\"\n",
    "                progress.update(\n",
    "                    task,\n",
    "                    advance=1,\n",
    "                    description=f\"epoch: {epoch}, batch_loss: {(total_epoch_loss / (batch_idx+1)):.2f}, {val_acc_str}\"\n",
    "                )\n",
    "            # Post epoch evalution\n",
    "            metrics[-1][\"train_epoch_loss\"] = total_epoch_loss / len(train_loader)\n",
    "            metrics[-1][\"train_epoch_accuracy\"] = total_accuracy / len(train_loader)\n",
    "            if evaluation_func:\n",
    "                progress.update(\n",
    "                    task,\n",
    "                    completed=0,\n",
    "                    description=f\"epoch: {epoch}, evaluating...\"\n",
    "                )\n",
    "                eval_metrics = evaluation_func(model, criterion, validation_loader)\n",
    "                metrics[-1].update(eval_metrics)\n",
    "            last_epoch_metric = metrics[-1]\n",
    "\n",
    "    return DF.from_records(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a490227",
   "metadata": {},
   "source": [
    "### Create model and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "34cd5bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mk_model_and_fit(\n",
    "        train_loader:DL,\n",
    "        mk_scheduler:callable,\n",
    "        epochs:int,\n",
    "        validation_loader:Optional[DL]=None,\n",
    "        save_checkpoints=False,\n",
    "        criterion=nn.CrossEntropyLoss()\n",
    "    ) -> tuple[nn.Module, DF, list[str]]:\n",
    "    model = mk_model()\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), STARTING_LR)\n",
    "    lr_scheduler = mk_scheduler(optimizer)\n",
    "    training_metrics = fit(\n",
    "        epochs=epochs,\n",
    "        model=model,\n",
    "        scheduler=lr_scheduler,\n",
    "        optimizer=optimizer,\n",
    "        train_loader=train_loader,\n",
    "        criterion=criterion,\n",
    "        # evaluation_func=evaluate_model if validation_loader else None,\n",
    "        validation_loader=validation_loader,\n",
    "        save_checkpoints=save_checkpoints,\n",
    "    )\n",
    "\n",
    "    return model, training_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60b2c5d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9256152c",
   "metadata": {},
   "source": [
    "## Search max learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "40b0c8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_process_mock_training_metrics(training_metrics:DF) -> DF:\n",
    "    training_metrics = (\n",
    "        training_metrics\n",
    "        .query(\"batch_train_loss.notna()\")\n",
    "        .set_index(\"lr\", drop=False)\n",
    "        .sort_index()\n",
    "    )\n",
    "    training_metrics[\"ewm_batch_train_loss\"] = (\n",
    "        training_metrics\n",
    "        .ewm(com=30, ignore_na=False)\n",
    "        [\"batch_train_loss\"]\n",
    "        .mean()\n",
    "    )\n",
    "    training_metrics[\"ewm_batch_train_loss_diff\"] = training_metrics[\"ewm_batch_train_loss\"].diff()\n",
    "    return training_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7c231028",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plt_lr_search_training_metrics(training_metrics:DF):\n",
    "    (    \n",
    "        px.line(\n",
    "            (\n",
    "                training_metrics\n",
    "                .reset_index(drop=True)\n",
    "                .melt(\n",
    "                    id_vars=\"lr\",\n",
    "                    value_vars=[\n",
    "                        \"batch_train_loss\",\n",
    "                        \"ewm_batch_train_loss\",\n",
    "                        # \"ewm_batch_train_loss_diff\",\n",
    "                    ],\n",
    "                )\n",
    "            ),\n",
    "            x=\"lr\",\n",
    "            facet_row=\"variable\",\n",
    "            y=\"value\",\n",
    "            log_x=True,\n",
    "            log_y=True,\n",
    "            height=750,\n",
    "        )\n",
    "        .update_yaxes(matches=None)\n",
    "        .show()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e9ae0c04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "211088779a6d4325bb4f57c02c192c4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "variable=batch_train_loss<br>lr=%{x}<br>value=%{y}<extra></extra>",
         "legendgroup": "",
         "line": {
          "color": "#636efa",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "",
         "orientation": "v",
         "showlegend": false,
         "type": "scatter",
         "x": {
          "bdata": "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",
          "dtype": "f8"
         },
         "xaxis": "x2",
         "y": {
          "bdata": "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",
          "dtype": "f8"
         },
         "yaxis": "y2"
        },
        {
         "hovertemplate": "variable=ewm_batch_train_loss<br>lr=%{x}<br>value=%{y}<extra></extra>",
         "legendgroup": "",
         "line": {
          "color": "#636efa",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "",
         "orientation": "v",
         "showlegend": false,
         "type": "scatter",
         "x": {
          "bdata": "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",
          "dtype": "f8"
         },
         "xaxis": "x",
         "y": {
          "bdata": "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",
          "dtype": "f8"
         },
         "yaxis": "y"
        }
       ],
       "layout": {
        "annotations": [
         {
          "font": {},
          "showarrow": false,
          "text": "variable=ewm_batch_train_loss",
          "textangle": 90,
          "x": 0.98,
          "xanchor": "left",
          "xref": "paper",
          "y": 0.2425,
          "yanchor": "middle",
          "yref": "paper"
         },
         {
          "font": {},
          "showarrow": false,
          "text": "variable=batch_train_loss",
          "textangle": 90,
          "x": 0.98,
          "xanchor": "left",
          "xref": "paper",
          "y": 0.7575000000000001,
          "yanchor": "middle",
          "yref": "paper"
         }
        ],
        "height": 750,
        "legend": {
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          0.98
         ],
         "title": {
          "text": "lr"
         },
         "type": "log"
        },
        "xaxis2": {
         "anchor": "y2",
         "domain": [
          0,
          0.98
         ],
         "matches": "x",
         "showticklabels": false,
         "type": "log"
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          0.485
         ],
         "title": {
          "text": "value"
         },
         "type": "log"
        },
        "yaxis2": {
         "anchor": "x2",
         "domain": [
          0.515,
          1
         ],
         "title": {
          "text": "value"
         },
         "type": "log"
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum learning rate: 0.006579695781215554\n"
     ]
    }
   ],
   "source": [
    "train_dataset = CMIDataset(\"full_dataset\")\n",
    "full_dataset_loader = DL(train_dataset, TRAIN_BATCH_SIZE, shuffle=True)\n",
    "_, mock_training_metrics = mk_model_and_fit(\n",
    "    full_dataset_loader,\n",
    "    partial(torch.optim.lr_scheduler.ExponentialLR, gamma=MOCK_TRAINING_GAMMA),\n",
    "    MOCK_TRAINING_EPOCHS,\n",
    "    criterion= nn.CrossEntropyLoss(label_smoothing=0.1),\n",
    ")\n",
    "mock_training_metrics = post_process_mock_training_metrics(mock_training_metrics)\n",
    "plt_lr_search_training_metrics(mock_training_metrics)\n",
    "max_lr = mock_training_metrics[\"ewm_batch_train_loss\"].idxmin()\n",
    "print(\"Maximum learning rate:\", max_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1cc3c5f",
   "metadata": {
    "papermill": {
     "duration": 0.003108,
     "end_time": "2025-06-14T10:01:56.186803",
     "exception": false,
     "start_time": "2025-06-14T10:01:56.183695",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "81f397f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixup_data(x, y, alpha=0.2):\n",
    "    \"\"\"\n",
    "    Return mixed inputs and mixed targets (one-hot) for mixup.\n",
    "    x: Tensor of shape (batch_size, features, seq_len)\n",
    "    y: Tensor of shape (batch_size, num_classes)\n",
    "    \"\"\"\n",
    "    if alpha > 0:\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "    else:\n",
    "        lam = 1.0\n",
    "    batch_size = x.size(0)\n",
    "    index = torch.randperm(batch_size).to(x.device)\n",
    "\n",
    "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "    mixed_y = lam * y + (1 - lam) * y[index, :]\n",
    "    return mixed_x, mixed_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2be28a9c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T10:01:56.194003Z",
     "iopub.status.busy": "2025-06-14T10:01:56.193740Z",
     "iopub.status.idle": "2025-06-14T10:09:14.752385Z",
     "shell.execute_reply": "2025-06-14T10:09:14.751491Z"
    },
    "papermill": {
     "duration": 438.563878,
     "end_time": "2025-06-14T10:09:14.753712",
     "exception": false,
     "start_time": "2025-06-14T10:01:56.189834",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training: 1\n",
      "\n",
      "==================================================\n",
      "Fold 1/5\n",
      "Epoch 01: Train Loss = 2.7538, Val Loss = 2.3582\n",
      "  Binary F1 = 0.8374, Macro F1 = 0.2399, Final Metric = 0.5386\n",
      "  New best metric! Saving model...\n",
      "Epoch 02: Train Loss = 2.2351, Val Loss = 1.9240\n",
      "  Binary F1 = 0.9434, Macro F1 = 0.3426, Final Metric = 0.6430\n",
      "  New best metric! Saving model...\n",
      "Epoch 03: Train Loss = 1.9481, Val Loss = 1.7545\n",
      "  Binary F1 = 0.9425, Macro F1 = 0.4016, Final Metric = 0.6721\n",
      "  New best metric! Saving model...\n",
      "Epoch 04: Train Loss = 1.7532, Val Loss = 1.4688\n",
      "  Binary F1 = 0.9803, Macro F1 = 0.5505, Final Metric = 0.7654\n",
      "  New best metric! Saving model...\n",
      "Epoch 05: Train Loss = 1.8079, Val Loss = 1.5790\n",
      "  Binary F1 = 0.9659, Macro F1 = 0.5473, Final Metric = 0.7566\n",
      "Epoch 06: Train Loss = 1.6441, Val Loss = 1.5160\n",
      "  Binary F1 = 0.9787, Macro F1 = 0.5330, Final Metric = 0.7559\n",
      "Epoch 07: Train Loss = 1.5366, Val Loss = 1.3856\n",
      "  Binary F1 = 0.9823, Macro F1 = 0.6077, Final Metric = 0.7950\n",
      "  New best metric! Saving model...\n",
      "Epoch 08: Train Loss = 1.4581, Val Loss = 1.3171\n",
      "  Binary F1 = 0.9852, Macro F1 = 0.6384, Final Metric = 0.8118\n",
      "  New best metric! Saving model...\n",
      "Epoch 09: Train Loss = 1.3486, Val Loss = 1.3026\n",
      "  Binary F1 = 0.9882, Macro F1 = 0.6481, Final Metric = 0.8182\n",
      "  New best metric! Saving model...\n",
      "Epoch 10: Train Loss = 1.2500, Val Loss = 1.2886\n",
      "  Binary F1 = 0.9907, Macro F1 = 0.6461, Final Metric = 0.8184\n",
      "  New best metric! Saving model...\n",
      "Epoch 11: Train Loss = 1.3926, Val Loss = 1.3756\n",
      "  Binary F1 = 0.9798, Macro F1 = 0.6332, Final Metric = 0.8065\n",
      "Epoch 12: Train Loss = 1.4810, Val Loss = 1.3460\n",
      "  Binary F1 = 0.9868, Macro F1 = 0.6349, Final Metric = 0.8109\n",
      "Epoch 13: Train Loss = 1.1772, Val Loss = 1.3326\n",
      "  Binary F1 = 0.9872, Macro F1 = 0.6334, Final Metric = 0.8103\n",
      "Epoch 14: Train Loss = 1.2552, Val Loss = 1.2886\n",
      "  Binary F1 = 0.9907, Macro F1 = 0.6585, Final Metric = 0.8246\n",
      "  New best metric! Saving model...\n",
      "Epoch 15: Train Loss = 1.2630, Val Loss = 1.2856\n",
      "  Binary F1 = 0.9907, Macro F1 = 0.6560, Final Metric = 0.8233\n",
      "Epoch 16: Train Loss = 1.3833, Val Loss = 1.4070\n",
      "  Binary F1 = 0.9817, Macro F1 = 0.6318, Final Metric = 0.8067\n",
      "Epoch 17: Train Loss = 1.1860, Val Loss = 1.3438\n",
      "  Binary F1 = 0.9812, Macro F1 = 0.6217, Final Metric = 0.8015\n",
      "Epoch 18: Train Loss = 1.2635, Val Loss = 1.3105\n",
      "  Binary F1 = 0.9887, Macro F1 = 0.6597, Final Metric = 0.8242\n",
      "Epoch 19: Train Loss = 1.0950, Val Loss = 1.3321\n",
      "  Binary F1 = 0.9867, Macro F1 = 0.6534, Final Metric = 0.8201\n",
      "Epoch 20: Train Loss = 1.0761, Val Loss = 1.3018\n",
      "  Binary F1 = 0.9882, Macro F1 = 0.6728, Final Metric = 0.8305\n",
      "  New best metric! Saving model...\n",
      "Epoch 21: Train Loss = 1.3850, Val Loss = 1.3785\n",
      "  Binary F1 = 0.9827, Macro F1 = 0.6381, Final Metric = 0.8104\n",
      "Epoch 22: Train Loss = 1.1024, Val Loss = 1.3822\n",
      "  Binary F1 = 0.9847, Macro F1 = 0.6354, Final Metric = 0.8100\n",
      "Epoch 23: Train Loss = 1.1727, Val Loss = 1.3460\n",
      "  Binary F1 = 0.9852, Macro F1 = 0.6521, Final Metric = 0.8187\n",
      "Epoch 24: Train Loss = 1.1353, Val Loss = 1.3015\n",
      "  Binary F1 = 0.9887, Macro F1 = 0.6539, Final Metric = 0.8213\n",
      "Epoch 25: Train Loss = 1.0890, Val Loss = 1.3001\n",
      "  Binary F1 = 0.9867, Macro F1 = 0.6599, Final Metric = 0.8233\n",
      "\n",
      "Fold 1 completed.\n",
      "Final validation metrics - Binary F1: 0.9867, Macro F1: 0.6599, Final: 0.8233\n",
      "Best validation metrics - Binary F1: 0.9882, Macro F1: 0.6728, Final: 0.8305\n",
      "training: 2\n",
      "\n",
      "==================================================\n",
      "Fold 2/5\n",
      "Epoch 01: Train Loss = 2.7435, Val Loss = 2.4583\n",
      "  Binary F1 = 0.7249, Macro F1 = 0.2021, Final Metric = 0.4635\n",
      "  New best metric! Saving model...\n",
      "Epoch 02: Train Loss = 2.2094, Val Loss = 1.9961\n",
      "  Binary F1 = 0.9008, Macro F1 = 0.3906, Final Metric = 0.6457\n",
      "  New best metric! Saving model...\n",
      "Epoch 03: Train Loss = 1.8607, Val Loss = 1.9237\n",
      "  Binary F1 = 0.8959, Macro F1 = 0.4004, Final Metric = 0.6481\n",
      "  New best metric! Saving model...\n",
      "Epoch 04: Train Loss = 1.7832, Val Loss = 1.9214\n",
      "  Binary F1 = 0.8970, Macro F1 = 0.4403, Final Metric = 0.6686\n",
      "  New best metric! Saving model...\n",
      "Epoch 05: Train Loss = 1.6838, Val Loss = 1.7470\n",
      "  Binary F1 = 0.9006, Macro F1 = 0.5150, Final Metric = 0.7078\n",
      "  New best metric! Saving model...\n",
      "Epoch 06: Train Loss = 1.6289, Val Loss = 1.6987\n",
      "  Binary F1 = 0.9196, Macro F1 = 0.5344, Final Metric = 0.7270\n",
      "  New best metric! Saving model...\n",
      "Epoch 07: Train Loss = 1.5224, Val Loss = 1.6522\n",
      "  Binary F1 = 0.9406, Macro F1 = 0.5218, Final Metric = 0.7312\n",
      "  New best metric! Saving model...\n",
      "Epoch 08: Train Loss = 1.4230, Val Loss = 1.5056\n",
      "  Binary F1 = 0.9443, Macro F1 = 0.5662, Final Metric = 0.7552\n",
      "  New best metric! Saving model...\n",
      "Epoch 09: Train Loss = 1.2568, Val Loss = 1.4944\n",
      "  Binary F1 = 0.9435, Macro F1 = 0.5800, Final Metric = 0.7617\n",
      "  New best metric! Saving model...\n",
      "Epoch 10: Train Loss = 1.3252, Val Loss = 1.4976\n",
      "  Binary F1 = 0.9421, Macro F1 = 0.5836, Final Metric = 0.7629\n",
      "  New best metric! Saving model...\n",
      "Epoch 11: Train Loss = 1.6034, Val Loss = 1.5655\n",
      "  Binary F1 = 0.9295, Macro F1 = 0.5460, Final Metric = 0.7378\n",
      "Epoch 12: Train Loss = 1.3757, Val Loss = 1.5978\n",
      "  Binary F1 = 0.9368, Macro F1 = 0.5511, Final Metric = 0.7440\n",
      "Epoch 13: Train Loss = 1.3590, Val Loss = 1.5216\n",
      "  Binary F1 = 0.9338, Macro F1 = 0.5787, Final Metric = 0.7562\n",
      "Epoch 14: Train Loss = 1.3061, Val Loss = 1.4976\n",
      "  Binary F1 = 0.9464, Macro F1 = 0.5945, Final Metric = 0.7704\n",
      "  New best metric! Saving model...\n",
      "Epoch 15: Train Loss = 1.2320, Val Loss = 1.4739\n",
      "  Binary F1 = 0.9469, Macro F1 = 0.5958, Final Metric = 0.7713\n",
      "  New best metric! Saving model...\n",
      "Epoch 16: Train Loss = 1.2159, Val Loss = 1.5876\n",
      "  Binary F1 = 0.9364, Macro F1 = 0.5689, Final Metric = 0.7526\n",
      "Epoch 17: Train Loss = 1.3129, Val Loss = 1.5386\n",
      "  Binary F1 = 0.9447, Macro F1 = 0.5841, Final Metric = 0.7644\n",
      "Epoch 18: Train Loss = 1.4486, Val Loss = 1.5459\n",
      "  Binary F1 = 0.9492, Macro F1 = 0.5792, Final Metric = 0.7642\n",
      "Epoch 19: Train Loss = 1.1698, Val Loss = 1.4843\n",
      "  Binary F1 = 0.9412, Macro F1 = 0.5887, Final Metric = 0.7649\n",
      "Epoch 20: Train Loss = 1.1117, Val Loss = 1.4771\n",
      "  Binary F1 = 0.9458, Macro F1 = 0.5985, Final Metric = 0.7722\n",
      "  New best metric! Saving model...\n",
      "Epoch 21: Train Loss = 1.3653, Val Loss = 1.5938\n",
      "  Binary F1 = 0.9298, Macro F1 = 0.5554, Final Metric = 0.7426\n",
      "Epoch 22: Train Loss = 1.1489, Val Loss = 1.5656\n",
      "  Binary F1 = 0.9335, Macro F1 = 0.5583, Final Metric = 0.7459\n",
      "Epoch 23: Train Loss = 1.2623, Val Loss = 1.5000\n",
      "  Binary F1 = 0.9449, Macro F1 = 0.6002, Final Metric = 0.7726\n",
      "  New best metric! Saving model...\n",
      "Epoch 24: Train Loss = 1.0176, Val Loss = 1.4983\n",
      "  Binary F1 = 0.9406, Macro F1 = 0.6011, Final Metric = 0.7708\n",
      "Epoch 25: Train Loss = 1.0293, Val Loss = 1.4961\n",
      "  Binary F1 = 0.9412, Macro F1 = 0.5976, Final Metric = 0.7694\n",
      "\n",
      "Fold 2 completed.\n",
      "Final validation metrics - Binary F1: 0.9412, Macro F1: 0.5976, Final: 0.7694\n",
      "Best validation metrics - Binary F1: 0.9449, Macro F1: 0.6002, Final: 0.7726\n",
      "training: 3\n",
      "\n",
      "==================================================\n",
      "Fold 3/5\n",
      "Epoch 01: Train Loss = 2.7369, Val Loss = 2.3102\n",
      "  Binary F1 = 0.8586, Macro F1 = 0.2485, Final Metric = 0.5535\n",
      "  New best metric! Saving model...\n",
      "Epoch 02: Train Loss = 2.1919, Val Loss = 1.8993\n",
      "  Binary F1 = 0.9336, Macro F1 = 0.4187, Final Metric = 0.6761\n",
      "  New best metric! Saving model...\n",
      "Epoch 03: Train Loss = 1.9072, Val Loss = 1.7096\n",
      "  Binary F1 = 0.9345, Macro F1 = 0.4451, Final Metric = 0.6898\n",
      "  New best metric! Saving model...\n",
      "Epoch 04: Train Loss = 1.7985, Val Loss = 1.6598\n",
      "  Binary F1 = 0.9315, Macro F1 = 0.4521, Final Metric = 0.6918\n",
      "  New best metric! Saving model...\n",
      "Epoch 05: Train Loss = 1.6653, Val Loss = 1.5160\n",
      "  Binary F1 = 0.9432, Macro F1 = 0.5650, Final Metric = 0.7541\n",
      "  New best metric! Saving model...\n",
      "Epoch 06: Train Loss = 1.6148, Val Loss = 1.5216\n",
      "  Binary F1 = 0.9430, Macro F1 = 0.5620, Final Metric = 0.7525\n",
      "Epoch 07: Train Loss = 1.4580, Val Loss = 1.5470\n",
      "  Binary F1 = 0.9497, Macro F1 = 0.5608, Final Metric = 0.7553\n",
      "  New best metric! Saving model...\n",
      "Epoch 08: Train Loss = 1.5268, Val Loss = 1.4683\n",
      "  Binary F1 = 0.9636, Macro F1 = 0.6030, Final Metric = 0.7833\n",
      "  New best metric! Saving model...\n",
      "Epoch 09: Train Loss = 1.3966, Val Loss = 1.3462\n",
      "  Binary F1 = 0.9603, Macro F1 = 0.6353, Final Metric = 0.7978\n",
      "  New best metric! Saving model...\n",
      "Epoch 10: Train Loss = 1.3347, Val Loss = 1.3216\n",
      "  Binary F1 = 0.9657, Macro F1 = 0.6408, Final Metric = 0.8032\n",
      "  New best metric! Saving model...\n",
      "Epoch 11: Train Loss = 1.5151, Val Loss = 1.4303\n",
      "  Binary F1 = 0.9673, Macro F1 = 0.6053, Final Metric = 0.7863\n",
      "Epoch 12: Train Loss = 1.3623, Val Loss = 1.4859\n",
      "  Binary F1 = 0.9665, Macro F1 = 0.5760, Final Metric = 0.7712\n",
      "Epoch 13: Train Loss = 1.3296, Val Loss = 1.3269\n",
      "  Binary F1 = 0.9566, Macro F1 = 0.6472, Final Metric = 0.8019\n",
      "Epoch 14: Train Loss = 1.1812, Val Loss = 1.3200\n",
      "  Binary F1 = 0.9665, Macro F1 = 0.6473, Final Metric = 0.8069\n",
      "  New best metric! Saving model...\n",
      "Epoch 15: Train Loss = 1.3018, Val Loss = 1.3209\n",
      "  Binary F1 = 0.9642, Macro F1 = 0.6428, Final Metric = 0.8035\n",
      "Epoch 16: Train Loss = 1.2598, Val Loss = 1.4646\n",
      "  Binary F1 = 0.9562, Macro F1 = 0.6016, Final Metric = 0.7789\n",
      "Epoch 17: Train Loss = 1.2628, Val Loss = 1.4447\n",
      "  Binary F1 = 0.9696, Macro F1 = 0.6128, Final Metric = 0.7912\n",
      "Epoch 18: Train Loss = 1.1603, Val Loss = 1.4100\n",
      "  Binary F1 = 0.9654, Macro F1 = 0.6179, Final Metric = 0.7917\n",
      "Epoch 19: Train Loss = 1.1311, Val Loss = 1.3298\n",
      "  Binary F1 = 0.9669, Macro F1 = 0.6561, Final Metric = 0.8115\n",
      "  New best metric! Saving model...\n",
      "Epoch 20: Train Loss = 1.1092, Val Loss = 1.3233\n",
      "  Binary F1 = 0.9689, Macro F1 = 0.6511, Final Metric = 0.8100\n",
      "Epoch 21: Train Loss = 1.0989, Val Loss = 1.3452\n",
      "  Binary F1 = 0.9691, Macro F1 = 0.6460, Final Metric = 0.8076\n",
      "Epoch 22: Train Loss = 1.3204, Val Loss = 1.3855\n",
      "  Binary F1 = 0.9612, Macro F1 = 0.6334, Final Metric = 0.7973\n",
      "Epoch 23: Train Loss = 1.1941, Val Loss = 1.3918\n",
      "  Binary F1 = 0.9628, Macro F1 = 0.6454, Final Metric = 0.8041\n",
      "Epoch 24: Train Loss = 1.0951, Val Loss = 1.3524\n",
      "  Binary F1 = 0.9648, Macro F1 = 0.6577, Final Metric = 0.8113\n",
      "Epoch 25: Train Loss = 0.9510, Val Loss = 1.3397\n",
      "  Binary F1 = 0.9643, Macro F1 = 0.6727, Final Metric = 0.8185\n",
      "  New best metric! Saving model...\n",
      "\n",
      "Fold 3 completed.\n",
      "Final validation metrics - Binary F1: 0.9643, Macro F1: 0.6727, Final: 0.8185\n",
      "Best validation metrics - Binary F1: 0.9643, Macro F1: 0.6727, Final: 0.8185\n",
      "training: 4\n",
      "\n",
      "==================================================\n",
      "Fold 4/5\n",
      "Epoch 01: Train Loss = 2.7619, Val Loss = 2.4259\n",
      "  Binary F1 = 0.8480, Macro F1 = 0.1737, Final Metric = 0.5109\n",
      "  New best metric! Saving model...\n",
      "Epoch 02: Train Loss = 2.1665, Val Loss = 2.0424\n",
      "  Binary F1 = 0.9069, Macro F1 = 0.3398, Final Metric = 0.6233\n",
      "  New best metric! Saving model...\n",
      "Epoch 03: Train Loss = 1.8725, Val Loss = 1.9488\n",
      "  Binary F1 = 0.9178, Macro F1 = 0.3823, Final Metric = 0.6501\n",
      "  New best metric! Saving model...\n",
      "Epoch 04: Train Loss = 1.7022, Val Loss = 1.7936\n",
      "  Binary F1 = 0.9314, Macro F1 = 0.4771, Final Metric = 0.7043\n",
      "  New best metric! Saving model...\n",
      "Epoch 05: Train Loss = 1.7340, Val Loss = 1.8679\n",
      "  Binary F1 = 0.9239, Macro F1 = 0.4695, Final Metric = 0.6967\n",
      "Epoch 06: Train Loss = 1.6567, Val Loss = 1.6958\n",
      "  Binary F1 = 0.9268, Macro F1 = 0.4698, Final Metric = 0.6983\n",
      "Epoch 07: Train Loss = 1.5400, Val Loss = 1.5903\n",
      "  Binary F1 = 0.9418, Macro F1 = 0.5312, Final Metric = 0.7365\n",
      "  New best metric! Saving model...\n",
      "Epoch 08: Train Loss = 1.3459, Val Loss = 1.5616\n",
      "  Binary F1 = 0.9416, Macro F1 = 0.5627, Final Metric = 0.7522\n",
      "  New best metric! Saving model...\n",
      "Epoch 09: Train Loss = 1.2776, Val Loss = 1.5560\n",
      "  Binary F1 = 0.9391, Macro F1 = 0.5514, Final Metric = 0.7452\n",
      "Epoch 10: Train Loss = 1.3740, Val Loss = 1.5530\n",
      "  Binary F1 = 0.9382, Macro F1 = 0.5495, Final Metric = 0.7438\n",
      "Epoch 11: Train Loss = 1.3011, Val Loss = 1.7048\n",
      "  Binary F1 = 0.9361, Macro F1 = 0.4993, Final Metric = 0.7177\n",
      "Epoch 12: Train Loss = 1.2238, Val Loss = 1.5974\n",
      "  Binary F1 = 0.9407, Macro F1 = 0.5432, Final Metric = 0.7420\n",
      "Epoch 13: Train Loss = 1.1974, Val Loss = 1.6027\n",
      "  Binary F1 = 0.9423, Macro F1 = 0.5354, Final Metric = 0.7388\n",
      "Epoch 14: Train Loss = 1.1048, Val Loss = 1.5358\n",
      "  Binary F1 = 0.9466, Macro F1 = 0.5653, Final Metric = 0.7560\n",
      "  New best metric! Saving model...\n",
      "Epoch 15: Train Loss = 1.1875, Val Loss = 1.5284\n",
      "  Binary F1 = 0.9466, Macro F1 = 0.5594, Final Metric = 0.7530\n",
      "Epoch 16: Train Loss = 1.2508, Val Loss = 1.6393\n",
      "  Binary F1 = 0.9443, Macro F1 = 0.5273, Final Metric = 0.7358\n",
      "Epoch 17: Train Loss = 1.1549, Val Loss = 1.6484\n",
      "  Binary F1 = 0.9361, Macro F1 = 0.5252, Final Metric = 0.7306\n",
      "Epoch 18: Train Loss = 1.2911, Val Loss = 1.5915\n",
      "  Binary F1 = 0.9380, Macro F1 = 0.5423, Final Metric = 0.7401\n",
      "Epoch 19: Train Loss = 1.3187, Val Loss = 1.5711\n",
      "  Binary F1 = 0.9393, Macro F1 = 0.5455, Final Metric = 0.7424\n",
      "Epoch 20: Train Loss = 1.0385, Val Loss = 1.5671\n",
      "  Binary F1 = 0.9420, Macro F1 = 0.5538, Final Metric = 0.7479\n",
      "Epoch 21: Train Loss = 1.1926, Val Loss = 1.7355\n",
      "  Binary F1 = 0.9387, Macro F1 = 0.5380, Final Metric = 0.7383\n",
      "Epoch 22: Train Loss = 1.0878, Val Loss = 1.6744\n",
      "  Binary F1 = 0.9363, Macro F1 = 0.5284, Final Metric = 0.7324\n",
      "Epoch 23: Train Loss = 1.1461, Val Loss = 1.5956\n",
      "  Binary F1 = 0.9455, Macro F1 = 0.5480, Final Metric = 0.7468\n",
      "Epoch 24: Train Loss = 1.1486, Val Loss = 1.5652\n",
      "  Binary F1 = 0.9453, Macro F1 = 0.5594, Final Metric = 0.7523\n",
      "Epoch 25: Train Loss = 0.9859, Val Loss = 1.5661\n",
      "  Binary F1 = 0.9427, Macro F1 = 0.5512, Final Metric = 0.7470\n",
      "\n",
      "Fold 4 completed.\n",
      "Final validation metrics - Binary F1: 0.9427, Macro F1: 0.5512, Final: 0.7470\n",
      "Best validation metrics - Binary F1: 0.9466, Macro F1: 0.5653, Final: 0.7560\n",
      "training: 5\n",
      "\n",
      "==================================================\n",
      "Fold 5/5\n",
      "Epoch 01: Train Loss = 2.7442, Val Loss = 2.3608\n",
      "  Binary F1 = 0.8682, Macro F1 = 0.2253, Final Metric = 0.5467\n",
      "  New best metric! Saving model...\n",
      "Epoch 02: Train Loss = 2.1955, Val Loss = 1.9890\n",
      "  Binary F1 = 0.9433, Macro F1 = 0.3554, Final Metric = 0.6494\n",
      "  New best metric! Saving model...\n",
      "Epoch 03: Train Loss = 1.8717, Val Loss = 1.6847\n",
      "  Binary F1 = 0.9587, Macro F1 = 0.4663, Final Metric = 0.7125\n",
      "  New best metric! Saving model...\n",
      "Epoch 04: Train Loss = 1.8735, Val Loss = 1.6651\n",
      "  Binary F1 = 0.9566, Macro F1 = 0.4755, Final Metric = 0.7160\n",
      "  New best metric! Saving model...\n",
      "Epoch 05: Train Loss = 1.6632, Val Loss = 1.6541\n",
      "  Binary F1 = 0.9363, Macro F1 = 0.4723, Final Metric = 0.7043\n",
      "Epoch 06: Train Loss = 1.4965, Val Loss = 1.5359\n",
      "  Binary F1 = 0.9650, Macro F1 = 0.5555, Final Metric = 0.7603\n",
      "  New best metric! Saving model...\n",
      "Epoch 07: Train Loss = 1.4374, Val Loss = 1.5284\n",
      "  Binary F1 = 0.9742, Macro F1 = 0.5880, Final Metric = 0.7811\n",
      "  New best metric! Saving model...\n",
      "Epoch 08: Train Loss = 1.4578, Val Loss = 1.4088\n",
      "  Binary F1 = 0.9631, Macro F1 = 0.6125, Final Metric = 0.7878\n",
      "  New best metric! Saving model...\n",
      "Epoch 09: Train Loss = 1.2783, Val Loss = 1.3784\n",
      "  Binary F1 = 0.9674, Macro F1 = 0.6153, Final Metric = 0.7913\n",
      "  New best metric! Saving model...\n",
      "Epoch 10: Train Loss = 1.2011, Val Loss = 1.3550\n",
      "  Binary F1 = 0.9715, Macro F1 = 0.6176, Final Metric = 0.7946\n",
      "  New best metric! Saving model...\n",
      "Epoch 11: Train Loss = 1.4952, Val Loss = 1.4091\n",
      "  Binary F1 = 0.9681, Macro F1 = 0.6080, Final Metric = 0.7881\n",
      "Epoch 12: Train Loss = 1.4161, Val Loss = 1.4101\n",
      "  Binary F1 = 0.9737, Macro F1 = 0.6111, Final Metric = 0.7924\n",
      "Epoch 13: Train Loss = 1.4627, Val Loss = 1.4111\n",
      "  Binary F1 = 0.9750, Macro F1 = 0.6111, Final Metric = 0.7930\n",
      "Epoch 14: Train Loss = 1.1847, Val Loss = 1.3577\n",
      "  Binary F1 = 0.9774, Macro F1 = 0.6110, Final Metric = 0.7942\n",
      "Epoch 15: Train Loss = 1.1900, Val Loss = 1.3326\n",
      "  Binary F1 = 0.9804, Macro F1 = 0.6232, Final Metric = 0.8018\n",
      "  New best metric! Saving model...\n",
      "Epoch 16: Train Loss = 1.2165, Val Loss = 1.4764\n",
      "  Binary F1 = 0.9706, Macro F1 = 0.5691, Final Metric = 0.7698\n",
      "Epoch 17: Train Loss = 1.4410, Val Loss = 1.4092\n",
      "  Binary F1 = 0.9721, Macro F1 = 0.6167, Final Metric = 0.7944\n",
      "Epoch 18: Train Loss = 1.1762, Val Loss = 1.3900\n",
      "  Binary F1 = 0.9784, Macro F1 = 0.6179, Final Metric = 0.7981\n",
      "Epoch 19: Train Loss = 1.0583, Val Loss = 1.3672\n",
      "  Binary F1 = 0.9804, Macro F1 = 0.6329, Final Metric = 0.8066\n",
      "  New best metric! Saving model...\n",
      "Epoch 20: Train Loss = 1.1768, Val Loss = 1.3691\n",
      "  Binary F1 = 0.9789, Macro F1 = 0.6298, Final Metric = 0.8043\n",
      "Epoch 21: Train Loss = 1.2453, Val Loss = 1.4718\n",
      "  Binary F1 = 0.9717, Macro F1 = 0.6075, Final Metric = 0.7896\n",
      "Epoch 22: Train Loss = 1.2094, Val Loss = 1.4409\n",
      "  Binary F1 = 0.9658, Macro F1 = 0.6118, Final Metric = 0.7888\n",
      "Epoch 23: Train Loss = 1.0393, Val Loss = 1.4518\n",
      "  Binary F1 = 0.9740, Macro F1 = 0.6007, Final Metric = 0.7874\n",
      "Epoch 24: Train Loss = 1.0561, Val Loss = 1.3937\n",
      "  Binary F1 = 0.9749, Macro F1 = 0.6279, Final Metric = 0.8014\n",
      "Epoch 25: Train Loss = 1.0368, Val Loss = 1.3876\n",
      "  Binary F1 = 0.9774, Macro F1 = 0.6167, Final Metric = 0.7971\n",
      "\n",
      "Fold 5 completed.\n",
      "Final validation metrics - Binary F1: 0.9774, Macro F1: 0.6167, Final: 0.7971\n",
      "Best validation metrics - Binary F1: 0.9804, Macro F1: 0.6329, Final: 0.8066\n",
      "\n",
      "==================================================\n",
      "Cross-Validation Results\n",
      "==================================================\n",
      "\n",
      "Best Fold-wise Metrics:\n",
      "Fold 1: Binary F1 = 0.9882, Macro F1 = 0.6728, Final = 0.8305\n",
      "Fold 2: Binary F1 = 0.9449, Macro F1 = 0.6002, Final = 0.7726\n",
      "Fold 3: Binary F1 = 0.9643, Macro F1 = 0.6727, Final = 0.8185\n",
      "Fold 4: Binary F1 = 0.9466, Macro F1 = 0.5653, Final = 0.7560\n",
      "Fold 5: Binary F1 = 0.9804, Macro F1 = 0.6329, Final = 0.8066\n",
      "\n",
      "Global Statistics (Best Metrics):\n",
      "Mean Best Final Metric: 0.7968 Â± 0.0281\n",
      "Mean Best Binary F1: 0.9649 Â± 0.0174\n",
      "Mean Best Macro F1: 0.6288 Â± 0.0418\n"
     ]
    }
   ],
   "source": [
    "seed_everything(seed=SEED)\n",
    "\n",
    "n_splits = 5\n",
    "batch_size = 128\n",
    "gkf = GroupKFold(n_splits=n_splits)\n",
    "\n",
    "fold_metrics = []\n",
    "best_fold_metrics = []\n",
    "best_models = []\n",
    "\n",
    "fold_patterns = join(dataset_path, \"preprocessed_dataset\", \"fold*\")\n",
    "fold_pths = glob(fold_patterns)\n",
    "all_training_metrics = {}\n",
    "\n",
    "for fold, fold_pth in enumerate(fold_pths):\n",
    "    print(\"training:\", fold + 1)\n",
    "    train_dataset = CMIDataset(fold_pth, \"train\")\n",
    "    # criterion = compute_weighted_cross_entropy_loss(train_dataset)\n",
    "    criterion = torch.nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "    train_loader = DL(train_dataset, TRAIN_BATCH_SIZE, shuffle=True)\n",
    "    validation_dataset = CMIDataset(fold_pth, \"validation\")\n",
    "    validation_loader = DL(validation_dataset, VALIDATION_BATCH_SIZE, shuffle=False)\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Fold {fold + 1}/{n_splits}\")\n",
    "    \n",
    "    seed_everything(seed=SEED + fold)\n",
    "    model = mk_model()\n",
    "    \n",
    "    # Optimizer et scheduler\n",
    "    min_lr = max_lr / 100\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), min_lr)\n",
    "    steps_per_epoch = len(train_loader)\n",
    "    n_training_steps = TRAINING_EPOCHS * len(train_loader)\n",
    "    scheduler = CosineAnnealingWarmupRestarts(\n",
    "        optimizer,\n",
    "        warmup_steps=WARMUP_EPOCHS * steps_per_epoch,\n",
    "        max_lr = max_lr,\n",
    "        min_lr = min_lr,\n",
    "        cycle_length=steps_per_epoch * 5,\n",
    "        gamma=0.9,\n",
    "    ) \n",
    "\n",
    "\n",
    "    # Early stopping\n",
    "    best_metric = -np.inf\n",
    "    best_binary_f1 = -np.inf\n",
    "    best_macro_f1 = -np.inf\n",
    "    epochs_no_improve = 0\n",
    "    \n",
    "    for epoch in range(1, TRAINING_EPOCHS + 1):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        total = 0\n",
    "        for batch_x, batch_y in train_loader:\n",
    "            batch_x = batch_x.to(device).clone()\n",
    "            add_noise = torch.randn_like(batch_x, device=device) * 0.04\n",
    "            scale_noise = torch.rand_like(batch_x, device=device) * (1.1 - 0.9) + 0.9\n",
    "            batch_x = (add_noise + batch_x) * scale_noise\n",
    "            batch_y = batch_y.to(device)\n",
    "            batch_x = batch_x.float()\n",
    "            \n",
    "            batch_x, batch_y = mixup_data(batch_x, batch_y)\n",
    "    \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_x)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "    \n",
    "            train_loss += loss.item() * batch_x.size(0)\n",
    "            total += batch_x.size(0)\n",
    "        train_loss /= total\n",
    "    \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        total = 0\n",
    "        all_true = []\n",
    "        all_pred = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch_x, batch_y in validation_loader:\n",
    "                batch_x = batch_x.to(device).clone()\n",
    "                batch_y = batch_y.to(device)\n",
    "                batch_x[VALIDATION_BATCH_SIZE // 2, non_imu_feats_idx] = 0.0\n",
    "                \n",
    "                outputs = model(batch_x)\n",
    "                loss = criterion(outputs, batch_y)\n",
    "                val_loss += loss.item() * batch_x.size(0)\n",
    "                total += batch_x.size(0)\n",
    "                \n",
    "                # Get predicted class indices\n",
    "                preds = torch.argmax(outputs, dim=1).cpu().numpy()\n",
    "                # Get true class indices from one-hot\n",
    "                trues = torch.argmax(batch_y, dim=1).cpu().numpy()\n",
    "                \n",
    "                all_true.append(trues)\n",
    "                all_pred.append(preds)\n",
    "\n",
    "        val_loss /= total\n",
    "        all_true = np.concatenate(all_true)\n",
    "        all_pred = np.concatenate(all_pred)\n",
    "\n",
    "        # Compute competition metrics\n",
    "        # Binary classification: BFRB (1) vs non-BFRB (0)\n",
    "        binary_true = np.isin(all_true, bfrb_indices).astype(int)\n",
    "        binary_pred = np.isin(all_pred, bfrb_indices).astype(int)\n",
    "        binary_f1 = f1_score(binary_true, binary_pred)\n",
    "        \n",
    "        # Collapse non-BFRB gestures into a single class\n",
    "        collapsed_true = np.where(\n",
    "            np.isin(all_true, bfrb_indices),\n",
    "            all_true,\n",
    "            len(bfrb_gestures)  # Single non-BFRB class\n",
    "        )\n",
    "        collapsed_pred = np.where(\n",
    "            np.isin(all_pred, bfrb_indices),\n",
    "            all_pred,\n",
    "            len(bfrb_gestures)  # Single non-BFRB class\n",
    "        )\n",
    "\n",
    "        # Macro F1 on collapsed classes\n",
    "        macro_f1 = f1_score(collapsed_true, collapsed_pred, average='macro')\n",
    "        final_metric = (binary_f1 + macro_f1) / 2\n",
    "\n",
    "        print(f\"Epoch {epoch:02d}: Train Loss = {train_loss:.4f}, Val Loss = {val_loss:.4f}\")\n",
    "        print(f\"  Binary F1 = {binary_f1:.4f}, Macro F1 = {macro_f1:.4f}, Final Metric = {final_metric:.4f}\")\n",
    "\n",
    "        if final_metric > best_metric:\n",
    "            best_metric = final_metric\n",
    "            best_binary_f1 = binary_f1\n",
    "            best_macro_f1 = macro_f1\n",
    "            epochs_no_improve = 0\n",
    "            best_model_state = model.state_dict()\n",
    "            print(f\"  New best metric! Saving model...\")\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            if epochs_no_improve >= PATIENCE:\n",
    "                print(f\"Early stopping triggered at epoch {epoch}\")\n",
    "                model.load_state_dict(best_model_state)\n",
    "                break\n",
    "\n",
    "    torch.save(best_model_state, f\"best_model_fold{fold}.pth\")\n",
    "    # Free memory used by datasets and data loaders\n",
    "    del train_dataset\n",
    "    del validation_dataset\n",
    "    del train_loader\n",
    "    del validation_loader\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    best_models.append(best_model_state)\n",
    "    fold_metrics.append({\n",
    "        'binary_f1': binary_f1,\n",
    "        'macro_f1': macro_f1,\n",
    "        'final_metric': final_metric\n",
    "    })\n",
    "    \n",
    "    best_fold_metrics.append({\n",
    "        'binary_f1': best_binary_f1,\n",
    "        'macro_f1': best_macro_f1,\n",
    "        'final_metric': best_metric\n",
    "    })\n",
    "    \n",
    "    print(f\"\\nFold {fold + 1} completed.\")\n",
    "    print(f\"Final validation metrics - Binary F1: {binary_f1:.4f}, Macro F1: {macro_f1:.4f}, Final: {final_metric:.4f}\")\n",
    "    print(f\"Best validation metrics - Binary F1: {best_binary_f1:.4f}, Macro F1: {best_macro_f1:.4f}, Final: {best_metric:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Cross-Validation Results\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Statistiques pour les meilleures mÃ©triques\n",
    "best_binary_f1 = [m['binary_f1'] for m in best_fold_metrics]\n",
    "best_macro_f1 = [m['macro_f1'] for m in best_fold_metrics]\n",
    "best_metrics = [m['final_metric'] for m in best_fold_metrics]\n",
    "\n",
    "print(\"\\nBest Fold-wise Metrics:\")\n",
    "for i, (bf1, mf1, fm) in enumerate(zip(best_binary_f1, best_macro_f1, best_metrics)):\n",
    "    print(f\"Fold {i+1}: Binary F1 = {bf1:.4f}, Macro F1 = {mf1:.4f}, Final = {fm:.4f}\")\n",
    "\n",
    "print(\"\\nGlobal Statistics (Best Metrics):\")\n",
    "print(f\"Mean Best Final Metric: {np.mean(best_metrics):.4f} Â± {np.std(best_metrics):.4f}\")\n",
    "print(f\"Mean Best Binary F1: {np.mean(best_binary_f1):.4f} Â± {np.std(best_binary_f1):.4f}\")\n",
    "print(f\"Mean Best Macro F1: {np.mean(best_macro_f1):.4f} Â± {np.std(best_macro_f1):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ea7558",
   "metadata": {
    "papermill": {
     "duration": 0.012909,
     "end_time": "2025-06-14T10:09:14.961270",
     "exception": false,
     "start_time": "2025-06-14T10:09:14.948361",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aea5e4f",
   "metadata": {
    "papermill": {
     "duration": 0.012906,
     "end_time": "2025-06-14T10:09:14.780212",
     "exception": false,
     "start_time": "2025-06-14T10:09:14.767306",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Reloading best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a0574d4d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T10:09:14.807902Z",
     "iopub.status.busy": "2025-06-14T10:09:14.807165Z",
     "iopub.status.idle": "2025-06-14T10:09:14.933288Z",
     "shell.execute_reply": "2025-06-14T10:09:14.932459Z"
    },
    "papermill": {
     "duration": 0.141435,
     "end_time": "2025-06-14T10:09:14.934745",
     "exception": false,
     "start_time": "2025-06-14T10:09:14.793310",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_ensemble = []\n",
    "for fold in range(5):\n",
    "    model = mk_model().to(device)\n",
    "    checkpoint = torch.load(f\"best_model_fold{fold}.pth\", map_location=device, weights_only=True)\n",
    "    model.load_state_dict(checkpoint)\n",
    "    model.eval()\n",
    "    model_ensemble.append(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a826dec8",
   "metadata": {},
   "source": [
    "### Define preprocessing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "481e69b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fillna_val_per_feature_col(df:DF) -> dict:\n",
    "    return {col: 1.0 if col == 'rot_w' else 0 for col in get_feature_cols(df)}\n",
    "\n",
    "def imputed_features(df:DF) -> DF:\n",
    "    # Missing ToF values are already imputed by -1 which is inconvinient since we want all missing values to be NaN.    \n",
    "    # So we replace them by NaN and then perform imputing.  \n",
    "    tof_vals_to_nan = {col: -1.0 for col in df.columns if col.startswith(\"tof\")}\n",
    "\n",
    "    df[get_feature_cols(df)] = (\n",
    "        df\n",
    "        .loc[:, get_feature_cols(df)]\n",
    "        # df.replace with np.nan sets dtype to floar64 so we set it back to float32\n",
    "        .replace(tof_vals_to_nan, value=np.nan)\n",
    "        .astype(\"float32\")\n",
    "        .groupby(df[\"sequence_id\"], observed=True, as_index=False)\n",
    "        .ffill()\n",
    "        .groupby(df[\"sequence_id\"], observed=True, as_index=False)\n",
    "        .bfill()\n",
    "        # In case there are only nan in the column in the sequence\n",
    "        .fillna(get_fillna_val_per_feature_col(df))\n",
    "    )\n",
    "    return df\n",
    "\n",
    "def norm_quat_rotations(df:DF) -> DF:\n",
    "    df[QUATERNION_COLS] /= np.linalg.norm(df[QUATERNION_COLS], axis=1, keepdims=True)\n",
    "    return df\n",
    "\n",
    "def add_linear_acc_cols(df:DF) -> DF:\n",
    "    # Vectorized version of https://www.kaggle.com/code/wasupandceacar/lb-0-82-5fold-single-bert-model#Dataset `remove_gravity_from_acc`\n",
    "    rotations:Rotation = Rotation.from_quat(df[QUATERNION_COLS])\n",
    "    gravity_sensor_frame = rotations.apply(GRAVITY_WORLD, inverse=True).astype(\"float32\")\n",
    "    df[LINEAR_ACC_COLS] = df[RAW_ACCELRATION_COLS] - gravity_sensor_frame\n",
    "    return df\n",
    "\n",
    "def add_acc_magnitude(df:DF, acc_cols:list[str], acc_mag_col_name:str) -> DF:\n",
    "    return df.assign(**{acc_mag_col_name: np.linalg.norm(df.loc[:, acc_cols], axis=1)})\n",
    "\n",
    "def add_quat_angle_mag(df:DF) -> DF:\n",
    "    return df.assign(quat_rot_mag=np.arccos(df[\"rot_w\"]) * 2)\n",
    "\n",
    "def add_angular_velocity_features(df:DF) -> DF:\n",
    "    rotations = Rotation.from_quat(df[QUATERNION_COLS])\n",
    "    delta_rotations = rotations[1:] * rotations[:-1].inv()\n",
    "    delta_rot_velocity = delta_rotations.as_rotvec()\n",
    "    # Add extra line to avoid shape mismatch\n",
    "    delta_rot_velocity = np.vstack((np.zeros((1, 3)), delta_rot_velocity))\n",
    "    delta_rot_magnitude = norm(delta_rot_velocity, axis=1, keepdims=True)\n",
    "    delta_rot_axes = delta_rot_velocity / (delta_rot_magnitude + EPSILON)\n",
    "    df[DELTA_ROTATION_ANGULAR_VELOCITY_COLS] = delta_rot_velocity\n",
    "    df[DELTA_ROTATION_AXES_COLS] = delta_rot_axes\n",
    "    df[\"delta_rot_mag\"] = delta_rot_magnitude.squeeze()\n",
    "\n",
    "    return df\n",
    "\n",
    "def rot_euler_angles(df:DF) -> ndarray:\n",
    "    df[EULER_ANGLES_COLS] = (\n",
    "        Rotation\n",
    "        .from_quat(df[QUATERNION_COLS])\n",
    "        .as_euler(\"xyz\")\n",
    "        .squeeze()\n",
    "    )\n",
    "    return df\n",
    "\n",
    "def agg_tof_cols_per_sensor(df:DF) -> DF:\n",
    "    for tof_idx in tqdm(range(1, 6)):\n",
    "        tof_name = f\"tof_{tof_idx}\"\n",
    "        tof_cols = [f\"{tof_name}_v{v_idx}\" for v_idx in range(64)]\n",
    "        if any(map(lambda col: col not in df.columns, tof_cols)):\n",
    "            print(f\"Some (or) all ToF {tof_idx} columns are not in the df. Maybe you already ran this cell?\")\n",
    "            continue\n",
    "        df = pd.concat(\n",
    "            (\n",
    "                df.drop(columns=tof_cols),\n",
    "                # For some reasons, it's faster to call all the aggregation functions seperatly than agg(list of functions)\n",
    "                df[tof_cols].mean(axis=\"columns\").to_frame(tof_name + \"_mean\"),\n",
    "                df[tof_cols].std(axis=\"columns\").to_frame(tof_name + \"_std\"),\n",
    "                df[tof_cols].median(axis=\"columns\").to_frame(tof_name + \"_median\"),\n",
    "                df[tof_cols].min(axis=\"columns\").to_frame(tof_name + \"_min\"),\n",
    "                df[tof_cols].max(axis=\"columns\").to_frame(tof_name + \"_max\"),\n",
    "            ),\n",
    "            axis=\"columns\",\n",
    "        )\n",
    "    return df\n",
    "\n",
    "def add_diff_features(df:DF) -> DF:\n",
    "    return pd.concat(\n",
    "        (\n",
    "            df,\n",
    "            df\n",
    "            .groupby(\"sequence_id\", as_index=False, observed=True)\n",
    "            [get_feature_cols(df)]\n",
    "            .diff()\n",
    "            .fillna(get_fillna_val_per_feature_col(df))\n",
    "            .add_suffix(\"_diff\")\n",
    "        ),\n",
    "        axis=\"columns\",\n",
    "    )\n",
    "\n",
    "def length_normed_sequence_feat_arr(sequence: DF) -> ndarray:\n",
    "    features = (\n",
    "        sequence\n",
    "        .loc[:, meta_data[\"feature_cols\"]]\n",
    "        .values\n",
    "    )\n",
    "    normed_sequence_len = meta_data[\"pad_seq_len\"]\n",
    "    len_diff = abs(normed_sequence_len - len(features))\n",
    "    if len(features) < normed_sequence_len:\n",
    "        padded_features = np.pad(\n",
    "            features,\n",
    "            ((len_diff // 2 + len_diff % 2, len_diff // 2), (0, 0)),\n",
    "        )\n",
    "        return padded_features\n",
    "    elif len(features) > normed_sequence_len:\n",
    "        return features[len_diff // 2:-len_diff // 2]\n",
    "    else:\n",
    "        return features\n",
    "\n",
    "def preprocess_sequence(sequence_df:pl.DataFrame) -> ndarray:\n",
    "    return (\n",
    "        sequence_df                     \n",
    "        .to_pandas()                            # Convert to pandas dataframe.\n",
    "        .pipe(imputed_features)                 # Impute missing data.\n",
    "        .pipe(norm_quat_rotations)              # Norm quaternions\n",
    "        .pipe(add_linear_acc_cols)              # Add gravity free acceleration.\n",
    "        .pipe(add_acc_magnitude, RAW_ACCELRATION_COLS, \"acc_mag\")\n",
    "        .pipe(add_acc_magnitude, LINEAR_ACC_COLS, \"linear_acc_mag\")\n",
    "        .pipe(add_quat_angle_mag)\n",
    "        .pipe(add_angular_velocity_features)\n",
    "        .pipe(rot_euler_angles)                 # Add rotation acc expressed as euler angles.\n",
    "        # .pipe(agg_tof_cols_per_sensor)          # Aggregate ToF columns.\n",
    "        .pipe(add_diff_features)                # \n",
    "        .loc[:, sorted(meta_data[\"feature_cols\"])]      # Retain only the usefull columns a.k.a features.\n",
    "        .sub(meta_data[\"mean\"])                 # Subtract features by their mean, std norm pt.1.\n",
    "        .div(meta_data[\"std\"])                  # Divide by Standard deviation, std norm pt.2.\n",
    "        .pipe(length_normed_sequence_feat_arr)  # get feature ndarray of sequence.\n",
    "        .T                                      # Transpose to swap channel and X dimensions.\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ebb0960",
   "metadata": {},
   "source": [
    "### Define prediction function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "57d8dfff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T10:09:14.989742Z",
     "iopub.status.busy": "2025-06-14T10:09:14.989258Z",
     "iopub.status.idle": "2025-06-14T10:09:14.995936Z",
     "shell.execute_reply": "2025-06-14T10:09:14.995244Z"
    },
    "papermill": {
     "duration": 0.021303,
     "end_time": "2025-06-14T10:09:14.997034",
     "exception": false,
     "start_time": "2025-06-14T10:09:14.975731",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict(sequence: pl.DataFrame, _: pl.DataFrame) -> str:\n",
    "    \"\"\"\n",
    "    Kaggle evaluation API will call this for each sequence.\n",
    "    sequence: polars DataFrame for a single sequence\n",
    "    demographics: unused in this model\n",
    "    Returns: predicted gesture string\n",
    "    \"\"\"\n",
    "    x_tensor = (\n",
    "        torch.unsqueeze(Tensor(preprocess_sequence(sequence)), dim=0)\n",
    "        .float()\n",
    "        .to(device)\n",
    "    )\n",
    "    print(x_tensor.shape)\n",
    "\n",
    "    all_outputs = []\n",
    "    with torch.no_grad():\n",
    "        for model_idx, model in enumerate(model_ensemble): # Only take the first one bc it's the only one that takes in the correct input shape\n",
    "            outputs = model(x_tensor)\n",
    "            all_outputs.append(outputs)\n",
    "\n",
    "    avg_outputs = torch.mean(torch.stack(all_outputs), dim=0)\n",
    "    pred_idx = torch.argmax(avg_outputs, dim=1).item()\n",
    "\n",
    "    return str(gesture_classes[pred_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cdcf446",
   "metadata": {},
   "source": [
    "### Run inference server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c386b7d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T10:09:15.023324Z",
     "iopub.status.busy": "2025-06-14T10:09:15.023122Z",
     "iopub.status.idle": "2025-06-14T10:09:16.373534Z",
     "shell.execute_reply": "2025-06-14T10:09:16.372710Z"
    },
    "papermill": {
     "duration": 1.365137,
     "end_time": "2025-06-14T10:09:16.374918",
     "exception": false,
     "start_time": "2025-06-14T10:09:15.009781",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 696, 127])\n",
      "torch.Size([1, 696, 127])\n",
      "torch.Size([1, 696, 127])\n",
      "torch.Size([1, 696, 127])\n",
      "torch.Size([1, 696, 127])\n",
      "torch.Size([1, 696, 127])\n",
      "torch.Size([1, 696, 127])\n",
      "torch.Size([1, 696, 127])\n",
      "torch.Size([1, 696, 127])\n",
      "torch.Size([1, 696, 127])\n",
      "torch.Size([1, 696, 127])\n",
      "torch.Size([1, 696, 127])\n",
      "torch.Size([1, 696, 127])\n",
      "torch.Size([1, 696, 127])\n",
      "torch.Size([1, 696, 127])\n",
      "torch.Size([1, 696, 127])\n",
      "torch.Size([1, 696, 127])\n",
      "torch.Size([1, 696, 127])\n"
     ]
    }
   ],
   "source": [
    "inference_server = kaggle_evaluation.cmi_inference_server.CMIInferenceServer(predict)\n",
    "\n",
    "if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
    "    inference_server.serve()\n",
    "else:\n",
    "    inference_server.run_local_gateway(\n",
    "        data_paths=(\n",
    "            join(competition_dataset_path, 'test.csv'),\n",
    "            join(competition_dataset_path, 'test_demographics.csv'),\n",
    "        )\n",
    "    )\n",
    "    inference_server = kaggle_evaluation.cmi_inference_server.CMIInferenceServer(predict)\n",
    "    inference_server.run_local_gateway(\n",
    "        data_paths=(\n",
    "            join(competition_dataset_path, 'train.csv'),\n",
    "            join(competition_dataset_path, 'train_demographics.csv'),\n",
    "        )\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 12518947,
     "sourceId": 102335,
     "sourceType": "competition"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 510.403331,
   "end_time": "2025-06-14T10:09:19.701325",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-06-14T10:00:49.297994",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
